seed:  666
number of classes: 10
how to merge clusters:  [[0, 9], [1, 5], 2, [3, 8], 4, 6, 7]
whether to further subcluster data according to chemical reaction: False
number of epochs to train: 3000
learning rate decay to half at epoch 2000.
batch size: 96
number of hardest positive pairs for each mini-batch:  128
number of hardest negative pairs for each mini-batch:  128
number of workers to load data:  36
similar margin of contrastive loss: 0.0
dissimilar margin of contrastive loss: 2.0
device:  cuda
number of classes after merging:  7
number of pockets in training set:  10527
number of pockets in validation set:  2254
number of pockets in test set:  2263
model architecture:
SelectiveSiameseNet(
  (embedding_net): EmbeddingNet(
    (set2set): Set2Set(32, 64)
    (conv1): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=11, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=11, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=32, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=32, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=32, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=32, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv4): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=32, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=32, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.003
    weight_decay: 0.0005
)
loss function:
SelectiveContrastiveLoss(similar_margin=0.0, dissimilar_margin=2.0, num_pos_pair=128, num_neg_pair=128)
epoch: 1, train loss: 1.5932605933705601, validation loss: 1.518914855044821.
epoch: 2, train loss: 1.4633330019242172, validation loss: 1.4922131559123164.
epoch: 3, train loss: 1.441222664413102, validation loss: 1.5105068165323008.
epoch: 4, train loss: 1.4339610885042664, validation loss: 1.4677168960156648.
epoch: 5, train loss: 1.4126101819747086, validation loss: 1.4457329200661702.
epoch: 6, train loss: 1.4105464559082592, validation loss: 1.4436278965162195.
epoch: 7, train loss: 1.3974832383864517, validation loss: 1.4227195148882659.
epoch: 8, train loss: 1.4006381056724337, validation loss: 1.4302359663921853.
epoch: 9, train loss: 1.3982235783830694, validation loss: 1.440024469209754.
epoch: 10, train loss: 1.4436888191678108, validation loss: 1.4585118812063467.
epoch: 11, train loss: 1.4040118324647255, validation loss: 1.425384547399438.
epoch: 12, train loss: 1.415762471496512, validation loss: 1.4326571070629617.
epoch: 13, train loss: 1.393282328176936, validation loss: 1.6088312656983086.
epoch: 14, train loss: 1.4095623897849967, validation loss: 1.4405129681462827.
epoch: 15, train loss: 1.3968286404915906, validation loss: 1.4344714102537737.
epoch: 16, train loss: 1.3949455493087068, validation loss: 1.4489878727042156.
epoch: 17, train loss: 1.3791229320228646, validation loss: 1.410249798194222.
epoch: 18, train loss: 1.3924811564454245, validation loss: 1.4204091870266458.
epoch: 19, train loss: 1.3841869054584328, validation loss: 1.3875531683797422.
epoch: 20, train loss: 1.367539703299146, validation loss: 1.3818719749865325.
epoch: 21, train loss: 1.365550371485019, validation loss: 1.4180036783218384.
epoch: 22, train loss: 1.4297680898543892, validation loss: 1.7202838607456372.
epoch: 23, train loss: 1.4869305617218718, validation loss: 1.448838322058968.
epoch: 24, train loss: 1.4120614627085695, validation loss: 1.4260950762292612.
epoch: 25, train loss: 1.3871842272784731, validation loss: 1.3869316163270369.
epoch: 26, train loss: 1.3762799895137823, validation loss: 1.3990959654683652.
epoch: 27, train loss: 1.3662296708570707, validation loss: 1.3724844766699749.
epoch: 28, train loss: 1.359895448072241, validation loss: 1.3706316118654998.
epoch: 29, train loss: 1.3562877998439544, validation loss: 1.361446219941844.
epoch: 30, train loss: 1.353964280644688, validation loss: 1.3667738074841707.
epoch: 31, train loss: 1.35936464957141, validation loss: 1.3698965362880542.
epoch: 32, train loss: 1.368087221723084, validation loss: 1.4580406417017397.
epoch: 33, train loss: 1.3739747169914596, validation loss: 1.3626496843669726.
epoch: 34, train loss: 1.359029511792944, validation loss: 1.3640055034471594.
epoch: 35, train loss: 1.3667347649915502, validation loss: 1.4488400946492734.
epoch: 36, train loss: 1.3738373539863376, validation loss: 1.3819713696189548.
epoch: 37, train loss: 1.3572555124212842, validation loss: 1.3605713377828184.
epoch: 38, train loss: 1.3537191185382529, validation loss: 1.3657721436542014.
epoch: 39, train loss: 1.3516063274593528, validation loss: 1.3554090313289477.
epoch: 40, train loss: 1.3475178731690853, validation loss: 1.3675422668457031.
epoch: 41, train loss: 1.3499347693329558, validation loss: 1.385278784710428.
epoch: 42, train loss: 1.3511943248433804, validation loss: 1.3752926536228345.
epoch: 43, train loss: 1.358384841079012, validation loss: 1.3640157087989475.
epoch: 44, train loss: 1.353615334274572, validation loss: 1.421715964441714.
epoch: 45, train loss: 1.3601399649173842, validation loss: 1.3776561591936194.
epoch: 46, train loss: 1.3424250029642648, validation loss: 1.3554793648097827.
epoch: 47, train loss: 1.3399224161008083, validation loss: 1.3566762675409731.
epoch: 48, train loss: 1.3413346305899663, validation loss: 1.3392656730568928.
epoch: 49, train loss: 1.3364301974620294, validation loss: 1.3527511565581611.
epoch: 50, train loss: 1.3565689992467198, validation loss: 1.3567962439163872.
epoch: 51, train loss: 1.3373280851119156, validation loss: 1.3715562613114067.
epoch: 52, train loss: 1.3399954017149198, validation loss: 1.4029161826423977.
epoch: 53, train loss: 1.3531663122527096, validation loss: 1.3708834440811821.
epoch: 54, train loss: 1.3563934466160765, validation loss: 1.4416815923607869.
epoch: 55, train loss: 1.3735852055593367, validation loss: 1.3801922590836235.
epoch: 56, train loss: 1.3709765410204546, validation loss: 1.3790141240410183.
epoch: 57, train loss: 1.369394026765036, validation loss: 1.3858509685682214.
epoch: 58, train loss: 1.3917750612311406, validation loss: 1.470240038374196.
epoch: 59, train loss: 1.4150249258093877, validation loss: 1.4054421134617017.
epoch: 60, train loss: 1.3957514172300287, validation loss: 1.4391677846079287.
epoch: 61, train loss: 1.39182162941049, validation loss: 1.399793935858685.
epoch: 62, train loss: 1.4034099589794053, validation loss: 1.5015685610149219.
epoch: 63, train loss: 1.3908840844390589, validation loss: 1.4048718162204907.
epoch: 64, train loss: 1.3723855237348364, validation loss: 1.3761208886685579.
epoch: 65, train loss: 1.358331920903757, validation loss: 1.3634110585502957.
epoch: 66, train loss: 1.3565806380105674, validation loss: 1.3763425505679587.
epoch: 67, train loss: 1.357373385254396, validation loss: 1.372708445009978.
epoch: 68, train loss: 1.3579695552860924, validation loss: 1.4217395937961081.
epoch: 69, train loss: 1.4163052248298575, validation loss: 1.4418953657150269.
epoch: 70, train loss: 1.412332117010694, validation loss: 1.4541736582051152.
epoch: 71, train loss: 1.433827445047711, validation loss: 1.4320587178935176.
epoch: 72, train loss: 1.3940918478397055, validation loss: 1.4609076613965242.
epoch: 73, train loss: 1.4020288340542295, validation loss: 1.3857668845549873.
epoch: 74, train loss: 1.373973476777383, validation loss: 1.476971491523411.
epoch: 75, train loss: 1.3796152773253414, validation loss: 1.3612476535465405.
epoch: 76, train loss: 1.37094573034059, validation loss: 1.3937333407609358.
epoch: 77, train loss: 1.369272596245512, validation loss: 1.3836943947750588.
epoch: 78, train loss: 1.3637772131403652, validation loss: 1.3675683373990266.
epoch: 79, train loss: 1.3509077293063523, validation loss: 1.3531463820001353.
epoch: 80, train loss: 1.3452920213751836, validation loss: 1.355648159980774.
epoch: 81, train loss: 1.3562149837476398, validation loss: 1.3651670735815298.
epoch: 82, train loss: 1.3497229858275948, validation loss: 1.3450708078301472.
epoch: 83, train loss: 1.345355273386754, validation loss: 1.3607778238213581.
epoch: 84, train loss: 1.3449622042682192, validation loss: 1.3457290711610213.
epoch: 85, train loss: 1.3474852852865096, validation loss: 1.3579634272533914.
epoch: 86, train loss: 1.3418615662723505, validation loss: 1.3432589717533276.
epoch: 87, train loss: 1.3416446633295183, validation loss: 1.4562043314394744.
epoch: 88, train loss: 1.3896698251776738, validation loss: 1.381977889848792.
epoch: 89, train loss: 1.359161037917531, validation loss: 1.3790494825529016.
epoch: 90, train loss: 1.3489544894717156, validation loss: 1.3563122334687605.
epoch: 91, train loss: 1.3410528526393646, validation loss: 1.3459985826326453.
epoch: 92, train loss: 1.33493112752197, validation loss: 1.341298362483149.
epoch: 93, train loss: 1.340111039100437, validation loss: 1.3482075566830842.
epoch: 94, train loss: 1.3433242740981075, validation loss: 1.3495734152586565.
epoch: 95, train loss: 1.347806078578354, validation loss: 1.348648568858271.
epoch: 96, train loss: 1.3388283427702177, validation loss: 1.3433320159497468.
epoch: 97, train loss: 1.3400699939202825, validation loss: 1.340121424716452.
epoch: 98, train loss: 1.337455639051735, validation loss: 1.3436551353205806.
epoch: 99, train loss: 1.3336503986918598, validation loss: 1.3508947051089744.
epoch: 100, train loss: 1.3402566056732739, validation loss: 1.339507652365643.
epoch: 101, train loss: 1.33364408278684, validation loss: 1.3524632609408835.
epoch: 102, train loss: 1.3391037818488725, validation loss: 1.3597762481026028.
epoch: 103, train loss: 1.3407892699635358, validation loss: 1.3605854303940483.
epoch: 104, train loss: 1.3626309250472883, validation loss: 1.3684024292489756.
epoch: 105, train loss: 1.3361857090521296, validation loss: 1.350040316581726.
epoch: 106, train loss: 1.3346970868766854, validation loss: 1.339051225911016.
epoch: 107, train loss: 1.3331083431156403, validation loss: 1.342472843501879.
epoch: 108, train loss: 1.3405491146472617, validation loss: 1.35598493658978.
epoch: 109, train loss: 1.347235733215962, validation loss: 1.3519840395968894.
epoch: 110, train loss: 1.3886453613228755, validation loss: 1.5294205986935159.
epoch: 111, train loss: 1.4124189090291295, validation loss: 1.405294428700986.
epoch: 112, train loss: 1.411362611919368, validation loss: 1.4311292171478271.
epoch: 113, train loss: 1.4158399137881919, validation loss: 1.4142145125762275.
epoch: 114, train loss: 1.392007520439428, validation loss: 1.4898747153904126.
epoch: 115, train loss: 1.3950603030143527, validation loss: 1.3934589468914529.
epoch: 116, train loss: 1.3938492044396358, validation loss: 1.4114082740700764.
epoch: 117, train loss: 1.3782607393527249, validation loss: 1.3786697750506194.
epoch: 118, train loss: 1.3771282193857595, validation loss: 1.4263042574343474.
epoch: 119, train loss: 1.3663805143548808, validation loss: 1.3737413883209229.
epoch: 120, train loss: 1.3542833448550022, validation loss: 1.363146476123644.
epoch: 121, train loss: 1.3482558672581244, validation loss: 1.3658039051553477.
epoch: 122, train loss: 1.3672790428914061, validation loss: 1.3606455999871958.
epoch: 123, train loss: 1.362162011479019, validation loss: 1.3613655981810198.
epoch: 124, train loss: 1.3671677309438723, validation loss: 1.36949318388234.
epoch: 125, train loss: 1.3543062822534404, validation loss: 1.3838509269382642.
epoch: 126, train loss: 1.3625426084623424, validation loss: 1.3776296895483267.
epoch: 127, train loss: 1.3602894675841026, validation loss: 1.3629777483318164.
epoch: 128, train loss: 1.3423621577954075, validation loss: 1.3415666663128396.
epoch: 129, train loss: 1.3374771940598793, validation loss: 1.338391143342723.
epoch: 130, train loss: 1.3330208522464158, validation loss: 1.3410570569660352.
epoch: 131, train loss: 1.3294361009510285, validation loss: 1.3348538616429204.
epoch: 132, train loss: 1.3391851055512733, validation loss: 1.3669398608415022.
epoch: 133, train loss: 1.3475111832312487, validation loss: 1.34476972144583.
epoch: 134, train loss: 1.3408809462818532, validation loss: 1.3687452647996985.
epoch: 135, train loss: 1.3456479004763682, validation loss: 1.342261604640795.
epoch: 136, train loss: 1.3331850198430752, validation loss: 1.3483381323192432.
epoch: 137, train loss: 1.3273606989361824, validation loss: 1.3472357884697292.
epoch: 138, train loss: 1.3260374441059357, validation loss: 1.3303031247595083.
epoch: 139, train loss: 1.3244683611283607, validation loss: 1.3520124321398528.
epoch: 140, train loss: 1.3373645336256115, validation loss: 1.3592135491578474.
epoch: 141, train loss: 1.3319639339359528, validation loss: 1.3476650611214016.
epoch: 142, train loss: 1.3273396284208385, validation loss: 1.3871761664100315.
epoch: 143, train loss: 1.3382517405606191, validation loss: 1.3375539831493213.
epoch: 144, train loss: 1.3285996192092195, validation loss: 1.352544437284055.
epoch: 145, train loss: 1.3444730415256745, validation loss: 1.3506087116573169.
epoch: 146, train loss: 1.3294808634924233, validation loss: 1.3448672968408335.
epoch: 147, train loss: 1.3384430014759028, validation loss: 1.3656490522882212.
epoch: 148, train loss: 1.343728554358176, validation loss: 1.3687196192534075.
epoch: 149, train loss: 1.3338232937209102, validation loss: 1.3484256060227104.
epoch: 150, train loss: 1.3324694513180935, validation loss: 1.348115806994231.
epoch: 151, train loss: 1.3283353497128967, validation loss: 1.3515257472577302.
epoch: 152, train loss: 1.3528390696289343, validation loss: 1.4162710853244946.
epoch: 153, train loss: 1.3545169360047087, validation loss: 1.4244781006937441.
epoch: 154, train loss: 1.4148188249780498, validation loss: 1.4307904295299365.
epoch: 155, train loss: 1.390202696170282, validation loss: 1.4172377586364746.
epoch: 156, train loss: 1.3758916450203011, validation loss: 1.436020006304202.
epoch: 157, train loss: 1.378401517868042, validation loss: 1.4055120063864666.
epoch: 158, train loss: 1.3665071572732488, validation loss: 1.3721342605093252.
epoch: 159, train loss: 1.3549158266924937, validation loss: 1.383746473685555.
epoch: 160, train loss: 1.3532190016650278, validation loss: 1.366242818210436.
epoch: 161, train loss: 1.356786350591467, validation loss: 1.370868444442749.
epoch: 162, train loss: 1.3504667610203454, validation loss: 1.3480078707570615.
epoch: 163, train loss: 1.3333234983846682, validation loss: 1.3791294512541399.
epoch: 164, train loss: 1.3402678233767868, validation loss: 1.3652463529420935.
epoch: 165, train loss: 1.4102061593204462, validation loss: 1.7182572354441104.
epoch: 166, train loss: 1.4740071110769148, validation loss: 1.4312667017397673.
epoch: 167, train loss: 1.4020892283238402, validation loss: 1.4332613426706065.
epoch: 168, train loss: 1.3996866886768866, validation loss: 1.377985135368679.
epoch: 169, train loss: 1.370439152105139, validation loss: 1.3765996072603308.
epoch: 170, train loss: 1.361964416066441, validation loss: 1.3535803089971128.
epoch: 171, train loss: 1.3507771699800404, validation loss: 1.3500506204107534.
epoch: 172, train loss: 1.358844274774604, validation loss: 1.3700241057769111.
epoch: 173, train loss: 1.3549965510674573, validation loss: 1.3530439760373987.
epoch: 174, train loss: 1.340419434626168, validation loss: 1.3516726182854695.
epoch: 175, train loss: 1.344302197115137, validation loss: 1.356323216272437.
epoch: 176, train loss: 1.3374287316558557, validation loss: 1.3411940232567165.
epoch: 177, train loss: 1.329477347365213, validation loss: 1.3301302090935085.
epoch: 178, train loss: 1.3266186451693194, validation loss: 1.3527476580246636.
epoch: 179, train loss: 1.3319868702407276, validation loss: 1.3380398853965427.
epoch: 180, train loss: 1.333061573702261, validation loss: 1.3466664967329607.
epoch: 181, train loss: 1.329912607822943, validation loss: 1.3347223219664202.
epoch: 182, train loss: 1.3327034810267457, validation loss: 1.3420971528343533.
epoch: 183, train loss: 1.329309803630234, validation loss: 1.3321972204291301.
epoch: 184, train loss: 1.3261789575629277, validation loss: 1.3352205908816794.
epoch: 185, train loss: 1.32896475945044, validation loss: 1.3392373945402063.
epoch: 186, train loss: 1.3237309674604223, validation loss: 1.3280897710634314.
epoch: 187, train loss: 1.4178430826292125, validation loss: 1.4958674544873445.
epoch: 188, train loss: 1.4331727749710783, validation loss: 1.4232247653214827.
epoch: 189, train loss: 1.4199127790031083, validation loss: 1.4471797217493472.
epoch: 190, train loss: 1.4071659177815148, validation loss: 1.3956303544666455.
epoch: 191, train loss: 1.3800783321398113, validation loss: 1.4269047820049783.
epoch: 192, train loss: 1.3629180499173086, validation loss: 1.358451599660127.
epoch: 193, train loss: 1.3538705416775625, validation loss: 1.363481288370879.
epoch: 194, train loss: 1.3484445504092295, validation loss: 1.3604733270147573.
epoch: 195, train loss: 1.341904873148017, validation loss: 1.3458233190619426.
epoch: 196, train loss: 1.3331789806348469, validation loss: 1.3343536179998647.
epoch: 197, train loss: 1.3286639801952818, validation loss: 1.3314136992330137.
epoch: 198, train loss: 1.3454659969434826, validation loss: 1.3649415814358254.
epoch: 199, train loss: 1.3537742796294185, validation loss: 1.3417798643526824.
epoch: 200, train loss: 1.3350511931498117, validation loss: 1.3414413047873455.
epoch: 201, train loss: 1.3335929365333068, validation loss: 1.3480893684470134.
epoch: 202, train loss: 1.331284291153654, validation loss: 1.3456432612045952.
epoch: 203, train loss: 1.331068918245648, validation loss: 1.3255594139513762.
epoch: 204, train loss: 1.3236323627856894, validation loss: 1.3337393221647844.
epoch: 205, train loss: 1.3233614788142913, validation loss: 1.3270417918329653.
epoch: 206, train loss: 1.322536122908286, validation loss: 1.3388158756753672.
epoch: 207, train loss: 1.3297823437856973, validation loss: 1.3483233503673389.
epoch: 208, train loss: 1.3226099058028755, validation loss: 1.3262273073196411.
epoch: 209, train loss: 1.3220981764137198, validation loss: 1.3214728054792986.
epoch: 210, train loss: 1.315863207939568, validation loss: 1.328499716261159.
epoch: 211, train loss: 1.3154250755222565, validation loss: 1.3249634556148364.
epoch: 212, train loss: 1.3130331804992956, validation loss: 1.3193244415780772.
epoch: 213, train loss: 1.3102663689797078, validation loss: 1.3097900722337805.
epoch: 214, train loss: 1.318050382334158, validation loss: 1.3375952969426694.
epoch: 215, train loss: 1.314751898476837, validation loss: 1.3197277006895647.
epoch: 216, train loss: 1.311873984993051, validation loss: 1.3168181595594988.
epoch: 217, train loss: 1.3084081487918118, validation loss: 1.3188971281051636.
epoch: 218, train loss: 1.3082632318549199, validation loss: 1.3146805452263874.
epoch: 219, train loss: 1.305503064339314, validation loss: 1.324132141859635.
epoch: 220, train loss: 1.304539521899792, validation loss: 1.3308985336967136.
epoch: 221, train loss: 1.304968733306325, validation loss: 1.3093778102294258.
epoch: 222, train loss: 1.308709984525628, validation loss: 1.316955390183822.
epoch: 223, train loss: 1.3087081832623264, validation loss: 1.3207067147545193.
epoch: 224, train loss: 1.3095423092535876, validation loss: 1.316209466561027.
epoch: 225, train loss: 1.3038755950577763, validation loss: 1.32339608669281.
epoch: 226, train loss: 1.3143870032161749, validation loss: 1.376027506330739.
epoch: 227, train loss: 1.314974567212096, validation loss: 1.3523707027020662.
epoch: 228, train loss: 1.3399066028245, validation loss: 1.3477436096771904.
epoch: 229, train loss: 1.3378596546453074, validation loss: 1.3927137126093325.
epoch: 230, train loss: 1.3347014221576377, validation loss: 1.3696113617523857.
epoch: 231, train loss: 1.319826153440213, validation loss: 1.3249415470206218.
epoch: 232, train loss: 1.3266071945155433, validation loss: 1.354123566461646.
epoch: 233, train loss: 1.3332736557776774, validation loss: 1.3473940828572148.
epoch: 234, train loss: 1.3157599420722472, validation loss: 1.3169651446135149.
epoch: 235, train loss: 1.3103916185711502, validation loss: 1.320089868877245.
epoch: 236, train loss: 1.3065528705579426, validation loss: 1.3268787964530613.
epoch: 237, train loss: 1.3042029175189658, validation loss: 1.32866865137349.
epoch: 238, train loss: 1.3134692163642394, validation loss: 1.3252955882445625.
epoch: 239, train loss: 1.320887470464094, validation loss: 1.3256883724876072.
epoch: 240, train loss: 1.3109873117656883, validation loss: 1.3388811971830286.
epoch: 241, train loss: 1.3074050343364751, validation loss: 1.3205979077712349.
epoch: 242, train loss: 1.3065779580982453, validation loss: 1.329335119413293.
epoch: 243, train loss: 1.3314569597944208, validation loss: 1.419513842333918.
epoch: 244, train loss: 1.3387619267909898, validation loss: 1.357610407082931.
epoch: 245, train loss: 1.3337350657226843, validation loss: 1.339778589165729.
epoch: 246, train loss: 1.3220668046846302, validation loss: 1.3303156780159993.
epoch: 247, train loss: 1.316548915084349, validation loss: 1.338943009791167.
epoch: 248, train loss: 1.3251446737061947, validation loss: 1.3364649959232495.
epoch: 249, train loss: 1.3192181051324268, validation loss: 1.3558916268141374.
epoch: 250, train loss: 1.3098222903155405, validation loss: 1.329643109570379.
epoch: 251, train loss: 1.3176388040595097, validation loss: 1.3314916413763296.
epoch: 252, train loss: 1.3095913163018882, validation loss: 1.3424751343934431.
epoch: 253, train loss: 1.3074449016413558, validation loss: 1.3190461552661399.
epoch: 254, train loss: 1.3098123401676842, validation loss: 1.3169313254563704.
epoch: 255, train loss: 1.391530663595287, validation loss: 1.3969991569933684.
epoch: 256, train loss: 1.3811055268716375, validation loss: 1.3915746626646623.
epoch: 257, train loss: 1.363300285208116, validation loss: 1.3515978325968203.
epoch: 258, train loss: 1.3395394294633778, validation loss: 1.3648840188980103.
epoch: 259, train loss: 1.3251380023606327, validation loss: 1.328152755032415.
epoch: 260, train loss: 1.3154163787124353, validation loss: 1.311025909755541.
epoch: 261, train loss: 1.3102102892114482, validation loss: 1.3252095035884692.
epoch: 262, train loss: 1.3078723949029905, validation loss: 1.3126059926074485.
epoch: 263, train loss: 1.3018401795571004, validation loss: 1.3113764420799587.
epoch: 264, train loss: 1.2980774794149836, validation loss: 1.3121309073075005.
epoch: 265, train loss: 1.3058578880555038, validation loss: 1.3059808845105378.
epoch: 266, train loss: 1.2976780123666887, validation loss: 1.309155215387759.
epoch: 267, train loss: 1.2938624850106895, validation loss: 1.2968685937964397.
epoch: 268, train loss: 1.294991663836558, validation loss: 1.303252707356992.
epoch: 269, train loss: 1.2931177659865913, validation loss: 1.3154818337896597.
epoch: 270, train loss: 1.2957296141790688, validation loss: 1.2983764461849048.
epoch: 271, train loss: 1.294574725518533, validation loss: 1.3038556834925776.
epoch: 272, train loss: 1.2907775454564925, validation loss: 1.2947061891141145.
epoch: 273, train loss: 1.2915628175123022, validation loss: 1.3100142271622368.
epoch: 274, train loss: 1.2948162063546138, validation loss: 1.298862151477648.
epoch: 275, train loss: 1.2903671603684033, validation loss: 1.2958347849223926.
epoch: 276, train loss: 1.2852415141709355, validation loss: 1.3004480082055796.
epoch: 277, train loss: 1.2865474694365755, validation loss: 1.289794895959937.
epoch: 278, train loss: 1.2945806859830105, validation loss: 1.3438193176103674.
epoch: 279, train loss: 1.2991338530811696, validation loss: 1.3001946625502214.
epoch: 280, train loss: 1.2905172076793985, validation loss: 1.3019686833671902.
epoch: 281, train loss: 1.2902238883009745, validation loss: 1.291277807691823.
epoch: 282, train loss: 1.284140643723514, validation loss: 1.2920687561449797.
epoch: 283, train loss: 1.2894060885140655, validation loss: 1.3054328949555107.
epoch: 284, train loss: 1.3039284178970056, validation loss: 1.3033082485198975.
epoch: 285, train loss: 1.2877432326658056, validation loss: 1.29213329501774.
epoch: 286, train loss: 1.2828571424571746, validation loss: 1.3040750493174014.
epoch: 287, train loss: 1.2993630509857739, validation loss: 1.3345629754273787.
epoch: 288, train loss: 1.2997402357398917, validation loss: 1.3271649868591973.
epoch: 289, train loss: 1.3411781230104078, validation loss: 1.3464535319286843.
epoch: 290, train loss: 1.339817942829307, validation loss: 1.3554543775060903.
epoch: 291, train loss: 1.326977327329303, validation loss: 1.3386386632919312.
epoch: 292, train loss: 1.3337793601762264, validation loss: 1.3936032886090486.
epoch: 293, train loss: 1.3358610649721339, validation loss: 1.3563641257908032.
epoch: 294, train loss: 1.3239779220808536, validation loss: 1.3331433275471563.
epoch: 295, train loss: 1.3194859924666378, validation loss: 1.3325527284456335.
epoch: 296, train loss: 1.3210789271450918, validation loss: 1.3190150986547056.
epoch: 297, train loss: 1.3124486546997631, validation loss: 1.3254505136738652.
epoch: 298, train loss: 1.3231541268322446, validation loss: 1.3661457559336787.
epoch: 299, train loss: 1.3484669967528877, validation loss: 1.3586255622946697.
epoch: 300, train loss: 1.3284033941566398, validation loss: 1.3390614053477412.
epoch: 301, train loss: 1.319610537738975, validation loss: 1.3530789613723755.
epoch: 302, train loss: 1.3202292492630285, validation loss: 1.3163391818170962.
epoch: 303, train loss: 1.3077813343170586, validation loss: 1.3219168704489004.
epoch: 304, train loss: 1.305022665120046, validation loss: 1.3078899072564167.
epoch: 305, train loss: 1.2978866756509204, validation loss: 1.3127697550732156.
epoch: 306, train loss: 1.3020533684196822, validation loss: 1.3285359921662703.
epoch: 307, train loss: 1.316748366443389, validation loss: 1.3224583864212036.
epoch: 308, train loss: 1.3036380820318099, validation loss: 1.3175721324008445.
epoch: 309, train loss: 1.3221029327550065, validation loss: 1.3577942122583804.
epoch: 310, train loss: 1.3189937073156375, validation loss: 1.338826578596364.
epoch: 311, train loss: 1.3155381799837864, validation loss: 1.3425865536150725.
epoch: 312, train loss: 1.312542253677998, validation loss: 1.3334659597148066.
epoch: 313, train loss: 1.3093669370773735, validation loss: 1.309833101604296.
epoch: 314, train loss: 1.3065151326153257, validation loss: 1.3112297265425972.
epoch: 315, train loss: 1.300912803466167, validation loss: 1.3084957184998884.
epoch: 316, train loss: 1.295208950655176, validation loss: 1.298925669296928.
epoch: 317, train loss: 1.293950340069762, validation loss: 1.3053798105405725.
epoch: 318, train loss: 1.2994773650388105, validation loss: 1.3072805871134219.
epoch: 319, train loss: 1.3015123113579707, validation loss: 1.3261749744415283.
epoch: 320, train loss: 1.2977352525116106, validation loss: 1.2968037180278613.
epoch: 321, train loss: 1.3020518580707936, validation loss: 1.3087957009025242.
epoch: 322, train loss: 1.2977747414090217, validation loss: 1.3007681525271872.
epoch: 323, train loss: 1.2912591433306353, validation loss: 1.3000983207122139.
epoch: 324, train loss: 1.293537245977909, validation loss: 1.3067541588907656.
epoch: 325, train loss: 1.2887050766463672, validation loss: 1.3015346475269483.
epoch: 326, train loss: 1.2885395900918803, validation loss: 1.3058382583701091.
epoch: 327, train loss: 1.28806365083117, validation loss: 1.2999849630438762.
epoch: 328, train loss: 1.2895489242098748, validation loss: 1.3318213794542395.
epoch: 329, train loss: 1.292131269743683, validation loss: 1.287362020948659.
epoch: 330, train loss: 1.284351438557336, validation loss: 1.3016415160635244.
epoch: 331, train loss: 1.2878484080690857, validation loss: 1.2880715598230776.
epoch: 332, train loss: 1.2833976844035158, validation loss: 1.2974191126616106.
epoch: 333, train loss: 1.2867684615861386, validation loss: 1.2935630238574485.
epoch: 334, train loss: 1.292474438291077, validation loss: 1.3039066117742788.
epoch: 335, train loss: 1.2885232190473364, validation loss: 1.3012450415155161.
epoch: 336, train loss: 1.2846245459460337, validation loss: 1.2865445976671965.
epoch: 337, train loss: 1.2859733498424566, validation loss: 1.2944032886753911.
epoch: 338, train loss: 1.2846742879360094, validation loss: 1.291870505913444.
epoch: 339, train loss: 1.280884608216242, validation loss: 1.2860870361328125.
epoch: 340, train loss: 1.2794026431687382, validation loss: 1.2910035485806672.
epoch: 341, train loss: 1.283636984475162, validation loss: 1.2870293233705603.
epoch: 342, train loss: 1.286016297996591, validation loss: 1.2949858800224636.
epoch: 343, train loss: 1.2806810228102798, validation loss: 1.292379353357398.
epoch: 344, train loss: 1.2801396015587203, validation loss: 1.292971828709478.
epoch: 345, train loss: 1.279061118397144, validation loss: 1.2889074916424959.
epoch: 346, train loss: 1.2827433500814875, validation loss: 1.298463868058246.
epoch: 347, train loss: 1.292270825543535, validation loss: 1.3083626498346743.
epoch: 348, train loss: 1.2917403945135415, validation loss: 1.301182746887207.
epoch: 349, train loss: 1.2799549573058382, validation loss: 1.2924462712329368.
epoch: 350, train loss: 1.2835299050042388, validation loss: 1.2966558570447175.
epoch: 351, train loss: 1.2830195131651851, validation loss: 1.2865125148192695.
epoch: 352, train loss: 1.278662661893652, validation loss: 1.3067448916642561.
epoch: 353, train loss: 1.2781595800994734, validation loss: 1.2907419619352922.
epoch: 354, train loss: 1.2739945529797756, validation loss: 1.2999196363532024.
epoch: 355, train loss: 1.276534043320822, validation loss: 1.2914089275443035.
epoch: 356, train loss: 1.2742931875613852, validation loss: 1.2852029748584912.
epoch: 357, train loss: 1.2763859022647963, validation loss: 1.2811723170073137.
epoch: 358, train loss: 1.2734846664131234, validation loss: 1.2932516751082048.
epoch: 359, train loss: 1.2763633356181854, validation loss: 1.2900562027226323.
epoch: 360, train loss: 1.2775455122693964, validation loss: 1.2959267108336738.
epoch: 361, train loss: 1.2824929077690894, validation loss: 1.3246292290480242.
epoch: 362, train loss: 1.2743540510125118, validation loss: 1.2837283974108489.
epoch: 363, train loss: 1.274474051020561, validation loss: 1.302442218946374.
epoch: 364, train loss: 1.274532797139719, validation loss: 1.2904474890750388.
epoch: 365, train loss: 1.274219718548136, validation loss: 1.283397042233011.
epoch: 366, train loss: 1.2715133155157807, validation loss: 1.2861777647681858.
epoch: 367, train loss: 1.2725542685307494, validation loss: 1.284176080123238.
epoch: 368, train loss: 1.2758834777622048, validation loss: 1.2935420482055.
epoch: 369, train loss: 1.2733023221339654, validation loss: 1.3005729654560918.
epoch: 370, train loss: 1.2727623346748702, validation loss: 1.2971360942591792.
epoch: 371, train loss: 1.2760564438793638, validation loss: 1.2825547145760579.
epoch: 372, train loss: 1.2744764045837822, validation loss: 1.2927438331686931.
epoch: 373, train loss: 1.2727511355636316, validation loss: 1.2795755033907683.
epoch: 374, train loss: 1.2739627689396569, validation loss: 1.293253629103951.
epoch: 375, train loss: 1.2758173625403588, validation loss: 1.28349028462949.
epoch: 376, train loss: 1.2733543936265719, validation loss: 1.2896255151085232.
epoch: 377, train loss: 1.2735658096610953, validation loss: 1.2843966017598691.
epoch: 378, train loss: 1.2729302677539511, validation loss: 1.2916780399239582.
epoch: 379, train loss: 1.2733816838045733, validation loss: 1.2876445055007935.
epoch: 380, train loss: 1.2785772117999716, validation loss: 1.3273193473401277.
epoch: 381, train loss: 1.2784132673106063, validation loss: 1.28551375347635.
epoch: 382, train loss: 1.2740373195858177, validation loss: 1.2904750678850256.
epoch: 383, train loss: 1.274512714202251, validation loss: 1.300455259240192.
epoch: 384, train loss: 1.2777805929883905, validation loss: 1.279416799545288.
epoch: 385, train loss: 1.2746904136937693, validation loss: 1.2990727372791455.
epoch: 386, train loss: 1.2698174594739162, validation loss: 1.2901884783869204.
epoch: 387, train loss: 1.2725427599128234, validation loss: 1.2887853435848071.
epoch: 388, train loss: 1.2687678380843697, validation loss: 1.3054872751235962.
epoch: 389, train loss: 1.2713211271740974, validation loss: 1.2808528983074685.
epoch: 390, train loss: 1.26900453742491, validation loss: 1.2861700265303901.
epoch: 391, train loss: 1.2711079864326966, validation loss: 1.2855493037596992.
epoch: 392, train loss: 1.2761487687399629, validation loss: 1.2853746880655703.
epoch: 393, train loss: 1.2746828247647766, validation loss: 1.2747041142505149.
epoch: 394, train loss: 1.2750381625026739, validation loss: 1.288547184156335.
epoch: 395, train loss: 1.2708988966198143, validation loss: 1.2946923038233882.
epoch: 396, train loss: 1.2717054426123242, validation loss: 1.2986206593720808.
epoch: 397, train loss: 1.2706620944749325, validation loss: 1.2858734338179878.
epoch: 398, train loss: 1.2688033230807803, validation loss: 1.290957818860593.
epoch: 399, train loss: 1.2715489109721752, validation loss: 1.2801592298175977.
epoch: 400, train loss: 1.2685670469879011, validation loss: 1.2809071385342141.
epoch: 401, train loss: 1.271098858719572, validation loss: 1.277188057484834.
epoch: 402, train loss: 1.271723314162788, validation loss: 1.2885801014692888.
epoch: 403, train loss: 1.2692957963418523, validation loss: 1.2914839827496072.
epoch: 404, train loss: 1.2662172415934572, validation loss: 1.2755166136700173.
epoch: 405, train loss: 1.2663863514541487, validation loss: 1.2738307507141777.
epoch: 406, train loss: 1.2663391227022223, validation loss: 1.2760116069213203.
epoch: 407, train loss: 1.2683582994916023, validation loss: 1.2753714530364326.
epoch: 408, train loss: 1.2723192140596722, validation loss: 1.293928623199463.
epoch: 409, train loss: 1.2682056470748482, validation loss: 1.2842088574948518.
epoch: 410, train loss: 1.2647421972467265, validation loss: 1.28801153017127.
epoch: 411, train loss: 1.269127945287512, validation loss: 1.2939132970312368.
epoch: 412, train loss: 1.268537961014914, validation loss: 1.2862459213837334.
epoch: 413, train loss: 1.2672817969540937, validation loss: 1.2786950546762217.
epoch: 414, train loss: 1.268616668674924, validation loss: 1.2837984976561174.
epoch: 415, train loss: 1.2687717337127125, validation loss: 1.2819053712098494.
epoch: 416, train loss: 1.269080396092266, validation loss: 1.2703350730564282.
epoch: 417, train loss: 1.267668668283235, validation loss: 1.2866459618444028.
epoch: 418, train loss: 1.269230911491114, validation loss: 1.2935194088065105.
epoch: 419, train loss: 1.2674313586786252, validation loss: 1.3214616827342822.
epoch: 420, train loss: 1.2702383743513614, validation loss: 1.281513872353927.
epoch: 421, train loss: 1.271281916067141, validation loss: 1.273926890414694.
epoch: 422, train loss: 1.2670721318743645, validation loss: 1.2898041994675347.
epoch: 423, train loss: 1.2653037604935673, validation loss: 1.2828558320584504.
epoch: 424, train loss: 1.2620464902405346, validation loss: 1.2718958232713782.
epoch: 425, train loss: 1.2668642779009058, validation loss: 1.3019072387529456.
epoch: 426, train loss: 1.266845777494098, validation loss: 1.273235585378564.
epoch: 427, train loss: 1.2651822370126706, validation loss: 1.280349207961041.
epoch: 428, train loss: 1.270300596132191, validation loss: 1.2955289560815562.
epoch: 429, train loss: 1.267535179033192, validation loss: 1.3362057571825774.
epoch: 430, train loss: 1.2657642320755425, validation loss: 1.279351918593697.
epoch: 431, train loss: 1.2630473430003595, validation loss: 1.2730305039364358.
epoch: 432, train loss: 1.2667276531184486, validation loss: 1.28993849132372.
epoch: 433, train loss: 1.2667172665989728, validation loss: 1.2863730710485708.
epoch: 434, train loss: 1.2683338572125915, validation loss: 1.300158319265946.
epoch: 435, train loss: 1.26427824672209, validation loss: 1.2854420620462168.
epoch: 436, train loss: 1.2650707719522878, validation loss: 1.2863277196884155.
epoch: 437, train loss: 1.2675398938152769, validation loss: 1.2845124369082244.
epoch: 438, train loss: 1.266144655166416, validation loss: 1.283836903779403.
epoch: 439, train loss: 1.269099040862617, validation loss: 1.2800238184306933.
epoch: 440, train loss: 1.2665489212088628, validation loss: 1.304889010346454.
epoch: 441, train loss: 1.2666301092970262, validation loss: 1.2759205673051917.
epoch: 442, train loss: 1.2653713587227218, validation loss: 1.280296019885851.
epoch: 443, train loss: 1.26385518170278, validation loss: 1.2891312008318694.
epoch: 444, train loss: 1.265518360181686, validation loss: 1.2830680453259011.
epoch: 445, train loss: 1.261642935079172, validation loss: 1.311086944911791.
epoch: 446, train loss: 1.2684053926292909, validation loss: 1.298136565996253.
epoch: 447, train loss: 1.2669402098436968, validation loss: 1.2943128036416096.
epoch: 448, train loss: 1.2657044983785086, validation loss: 1.28873538452646.
epoch: 449, train loss: 1.2688932309456922, validation loss: 1.2897254954213682.
epoch: 450, train loss: 1.2665136954106322, validation loss: 1.282322821409806.
epoch: 451, train loss: 1.2648204324442311, validation loss: 1.2852187312167624.
epoch: 452, train loss: 1.2636068567223506, validation loss: 1.295667104099108.
epoch: 453, train loss: 1.262239367590038, validation loss: 1.277043316675269.
epoch: 454, train loss: 1.2908248682634547, validation loss: 1.2955282460088315.
epoch: 455, train loss: 1.2800520931908843, validation loss: 1.287850172623344.
epoch: 456, train loss: 1.2757270565820396, validation loss: 1.3213791328927744.
epoch: 457, train loss: 1.2756230492110645, validation loss: 1.2882594336634097.
epoch: 458, train loss: 1.2773422254334896, validation loss: 1.2814935082974641.
epoch: 459, train loss: 1.2689439801994813, validation loss: 1.2857339485831882.
epoch: 460, train loss: 1.2683595681409223, validation loss: 1.2788753820502239.
epoch: 461, train loss: 1.2646974522039431, validation loss: 1.2827077222907024.
epoch: 462, train loss: 1.263643287737435, validation loss: 1.2804105022679204.
epoch: 463, train loss: 1.264084953780568, validation loss: 1.2871464853701384.
epoch: 464, train loss: 1.2647912097633431, validation loss: 1.287407750668733.
epoch: 465, train loss: 1.264742221307317, validation loss: 1.281487242035244.
epoch: 466, train loss: 1.2634756729143475, validation loss: 1.2988185830738233.
epoch: 467, train loss: 1.2736646855643037, validation loss: 1.281435904295548.
epoch: 468, train loss: 1.2668261626444826, validation loss: 1.283563442852186.
epoch: 469, train loss: 1.2640416195633215, validation loss: 1.2955666365830794.
epoch: 470, train loss: 1.2633785709328609, validation loss: 1.274396072263303.
epoch: 471, train loss: 1.293622439060736, validation loss: 1.2896047778751538.
epoch: 472, train loss: 1.2723434047961453, validation loss: 1.285696822664012.
epoch: 473, train loss: 1.2682541783796537, validation loss: 1.2877219086108.
epoch: 474, train loss: 1.2689121360078863, validation loss: 1.297278881072998.
epoch: 475, train loss: 1.2674461460988455, validation loss: 1.2958622859871907.
epoch: 476, train loss: 1.2714446958051908, validation loss: 1.28548961100371.
epoch: 477, train loss: 1.2700239966768738, validation loss: 1.2844799601513406.
epoch: 478, train loss: 1.2680134609204914, validation loss: 1.2901843164278113.
epoch: 479, train loss: 1.2647833146086527, validation loss: 1.278691986332769.
epoch: 480, train loss: 1.2664086370293153, validation loss: 1.2808735733446868.
epoch: 481, train loss: 1.263726207094455, validation loss: 1.2812719759733782.
epoch: 482, train loss: 1.2677398132621696, validation loss: 1.2862542867660522.
epoch: 483, train loss: 1.267870264315824, validation loss: 1.2821837093519128.
epoch: 484, train loss: 1.2652368665835179, validation loss: 1.2892311137655508.
epoch: 485, train loss: 1.2651286978240406, validation loss: 1.2915192790653394.
epoch: 486, train loss: 1.2709375466775457, validation loss: 1.2838402105414348.
epoch: 487, train loss: 1.2668524313410487, validation loss: 1.2917783312175586.
epoch: 488, train loss: 1.266677673803557, validation loss: 1.283249502596648.
epoch: 489, train loss: 1.2712003692574458, validation loss: 1.2937973582226296.
epoch: 490, train loss: 1.2668888295462373, validation loss: 1.2824254295100337.
epoch: 491, train loss: 1.268583587550242, validation loss: 1.283021092414856.
epoch: 492, train loss: 1.2637467854613558, validation loss: 1.2745500543843145.
epoch: 493, train loss: 1.2641642881095956, validation loss: 1.2856839014136272.
epoch: 494, train loss: 1.2616703171248829, validation loss: 1.2766433746918389.
epoch: 495, train loss: 1.260851417112788, validation loss: 1.2894175363623577.
epoch: 496, train loss: 1.2632626415392674, validation loss: 1.2904013084328694.
epoch: 497, train loss: 1.2634926848455306, validation loss: 1.2702510719713958.
epoch: 498, train loss: 1.26215738331506, validation loss: 1.2725841584412947.
epoch: 499, train loss: 1.2605632171718353, validation loss: 1.274960818498031.
epoch: 500, train loss: 1.2581943929742236, validation loss: 1.2820885907048765.
epoch: 501, train loss: 1.2657340896238976, validation loss: 1.2784490481666897.
epoch: 502, train loss: 1.2635240970401589, validation loss: 1.2870959976445073.
epoch: 503, train loss: 1.2600623073927852, validation loss: 1.266511471375175.
epoch: 504, train loss: 1.260359208518212, validation loss: 1.2842776930850486.
epoch: 505, train loss: 1.2564379698639616, validation loss: 1.2850565340207971.
epoch: 506, train loss: 1.2617512635134776, validation loss: 1.2757427536922952.
epoch: 507, train loss: 1.2646099755523401, validation loss: 1.3056625957074373.
epoch: 508, train loss: 1.259200327986971, validation loss: 1.280353095220483.
epoch: 509, train loss: 1.2590740776936942, validation loss: 1.2830744981765747.
epoch: 510, train loss: 1.2629697399401882, validation loss: 1.3519062840420266.
epoch: 511, train loss: 1.2694160544544184, validation loss: 1.2951479424601016.
epoch: 512, train loss: 1.2631566437012558, validation loss: 1.3026285119678662.
epoch: 513, train loss: 1.2627431908878712, validation loss: 1.287179024323173.
epoch: 514, train loss: 1.2604664279780258, validation loss: 1.273201558900916.
epoch: 515, train loss: 1.2578466091680964, validation loss: 1.2778888681660527.
epoch: 516, train loss: 1.2591595485669758, validation loss: 1.2834002246027407.
epoch: 517, train loss: 1.265219284853804, validation loss: 1.3367605053860208.
epoch: 518, train loss: 1.2759726539664311, validation loss: 1.274340753969939.
epoch: 519, train loss: 1.262587351536532, validation loss: 1.3268089864564978.
epoch: 520, train loss: 1.2613722162509182, validation loss: 1.2893472909927368.
epoch: 521, train loss: 1.2638777735036448, validation loss: 1.2836875241735708.
epoch: 522, train loss: 1.2589628346469424, validation loss: 1.275603138882181.
epoch: 523, train loss: 1.2615379324746787, validation loss: 1.2787982847379602.
epoch: 524, train loss: 1.2581098221857614, validation loss: 1.2722042902656223.
epoch: 525, train loss: 1.259665022202588, validation loss: 1.2910700518151987.
epoch: 526, train loss: 1.2581848310768058, validation loss: 1.283604393834653.
epoch: 527, train loss: 1.2584124092662006, validation loss: 1.2731011224829631.
epoch: 528, train loss: 1.2584160741316068, validation loss: 1.3034851447395657.
epoch: 529, train loss: 1.2580043777413326, validation loss: 1.2794005922649219.
epoch: 530, train loss: 1.2570065445856218, validation loss: 1.29441397604735.
epoch: 531, train loss: 1.2590014201785447, validation loss: 1.2788855200228484.
epoch: 532, train loss: 1.259014394305168, validation loss: 1.2798516128374182.
epoch: 533, train loss: 1.2580022385360998, validation loss: 1.2832934441773787.
epoch: 534, train loss: 1.2606639129306199, validation loss: 1.281551454378211.
epoch: 535, train loss: 1.2605062548173678, validation loss: 1.271354333214138.
epoch: 536, train loss: 1.2557452578063404, validation loss: 1.2747256289357725.
epoch: 537, train loss: 1.2574650355435293, validation loss: 1.2696121723755547.
epoch: 538, train loss: 1.257564341256378, validation loss: 1.2831221041472063.
epoch: 539, train loss: 1.2586531453176375, validation loss: 1.274445678876794.
epoch: 540, train loss: 1.2588561467074473, validation loss: 1.2978913058405337.
epoch: 541, train loss: 1.2566325423914357, validation loss: 1.3409678314043127.
epoch: 542, train loss: 1.2581240419947772, validation loss: 1.2760762753693953.
epoch: 543, train loss: 1.256870942378263, validation loss: 1.2667689012444538.
epoch: 544, train loss: 1.2579117368120667, validation loss: 1.2934780328170112.
epoch: 545, train loss: 1.2574250785582657, validation loss: 1.283007061999777.
epoch: 546, train loss: 1.257312488118443, validation loss: 1.2781598930773528.
epoch: 547, train loss: 1.2585453451226611, validation loss: 1.2775336089341536.
epoch: 548, train loss: 1.260707436351601, validation loss: 1.3142017333403877.
epoch: 549, train loss: 1.262163974823208, validation loss: 1.296902666921201.
epoch: 550, train loss: 1.2617938616953859, validation loss: 1.2839089994845183.
epoch: 551, train loss: 1.2604461613051388, validation loss: 1.2872460614080015.
epoch: 552, train loss: 1.2594398806948182, validation loss: 1.2768677991369497.
epoch: 553, train loss: 1.2605256979618598, validation loss: 1.2702941065249236.
epoch: 554, train loss: 1.2559464798061126, validation loss: 1.27166980245839.
epoch: 555, train loss: 1.257703644420029, validation loss: 1.3027292956476626.
epoch: 556, train loss: 1.259419295765938, validation loss: 1.276067262110503.
epoch: 557, train loss: 1.2584273541739228, validation loss: 1.2718174768530803.
epoch: 558, train loss: 1.2599796855121577, validation loss: 1.2850852375445159.
epoch: 559, train loss: 1.259173251073295, validation loss: 1.2728099252866663.
epoch: 560, train loss: 1.2596599672912459, validation loss: 1.2714268746583357.
epoch: 561, train loss: 1.2599996229924193, validation loss: 1.2726842786954797.
epoch: 562, train loss: 1.25851312033627, validation loss: 1.2914886319118997.
epoch: 563, train loss: 1.2644855997978, validation loss: 1.3571683790372766.
epoch: 564, train loss: 1.2725556202984731, validation loss: 1.2814270465270332.
epoch: 565, train loss: 1.262540002481653, validation loss: 1.2922565315080725.
epoch: 566, train loss: 1.2630532651866249, validation loss: 1.2702282822650413.
epoch: 567, train loss: 1.2600874649275333, validation loss: 1.283926803132762.
epoch: 568, train loss: 1.2592329191505363, validation loss: 1.2713262412859045.
epoch: 569, train loss: 1.2600624091034636, validation loss: 1.2938456898150237.
epoch: 570, train loss: 1.263525292414044, validation loss: 1.269735320754673.
epoch: 571, train loss: 1.2578529206984634, validation loss: 1.3044341284295786.
epoch: 572, train loss: 1.2574414386661774, validation loss: 1.2786296346913213.
epoch: 573, train loss: 1.2604359891436516, validation loss: 1.2832097385240637.
epoch: 574, train loss: 1.2580316088615207, validation loss: 1.2938209979430488.
epoch: 575, train loss: 1.2574403110994112, validation loss: 1.2740899894548499.
epoch: 576, train loss: 1.2676730002831975, validation loss: 1.3204724995986274.
epoch: 577, train loss: 1.2770201700543045, validation loss: 1.2862656479296477.
epoch: 578, train loss: 1.2652578671044166, validation loss: 1.2822275731874548.
epoch: 579, train loss: 1.2613310387375158, validation loss: 1.291759060776752.
epoch: 580, train loss: 1.2616193392954835, validation loss: 1.2708019329153972.
epoch: 581, train loss: 1.2616347654150166, validation loss: 1.2796416282653809.
epoch: 582, train loss: 1.2609002491749755, validation loss: 1.286450930263685.
epoch: 583, train loss: 1.256136343019818, validation loss: 1.279664951822032.
epoch: 584, train loss: 1.2599771219656009, validation loss: 1.2778685870377913.
epoch: 585, train loss: 1.2578098292744488, validation loss: 1.2753801967786706.
epoch: 586, train loss: 1.2544666867737377, validation loss: 1.2795523094094319.
epoch: 587, train loss: 1.2570818301734574, validation loss: 1.2757016213043877.
epoch: 588, train loss: 1.254443355656545, validation loss: 1.269885804342187.
epoch: 589, train loss: 1.2558584508545902, validation loss: 1.2856436656868977.
epoch: 590, train loss: 1.2591548337848908, validation loss: 1.2724782954091611.
epoch: 591, train loss: 1.2574786975843097, validation loss: 1.2800280840500542.
epoch: 592, train loss: 1.2564445394988453, validation loss: 1.2744181467139202.
epoch: 593, train loss: 1.2543358420013289, validation loss: 1.2852879037027773.
epoch: 594, train loss: 1.2595893035241224, validation loss: 1.2914467531701792.
epoch: 595, train loss: 1.2580202139845682, validation loss: 1.2701672833898794.
epoch: 596, train loss: 1.2546578897248715, validation loss: 1.280028866684955.
epoch: 597, train loss: 1.2542904429479476, validation loss: 1.2694534426150115.
epoch: 598, train loss: 1.256414009890425, validation loss: 1.2861958897632102.
epoch: 599, train loss: 1.2550625910452746, validation loss: 1.2728736659754878.
epoch: 600, train loss: 1.2558047169939093, validation loss: 1.2836640088454536.
epoch: 601, train loss: 1.2582519218462322, validation loss: 1.2700097249901814.
epoch: 602, train loss: 1.2582617079446075, validation loss: 1.286696107491203.
epoch: 603, train loss: 1.25660699004427, validation loss: 1.288917759190435.
epoch: 604, train loss: 1.2541086837786053, validation loss: 1.2634969379590906.
epoch: 605, train loss: 1.2553340677821307, validation loss: 1.3062674584596052.
epoch: 606, train loss: 1.257766863621703, validation loss: 1.2881599457367607.
epoch: 607, train loss: 1.2599646038965349, validation loss: 1.3044166305790776.
epoch: 608, train loss: 1.2612552008497606, validation loss: 1.2750256942666096.
epoch: 609, train loss: 1.257428230495628, validation loss: 1.3117068124854045.
epoch: 610, train loss: 1.2761042872700123, validation loss: 1.280844227127407.
epoch: 611, train loss: 1.2757289147158282, validation loss: 1.3385361070218293.
epoch: 612, train loss: 1.2672646822185691, validation loss: 1.2911010876945828.
epoch: 613, train loss: 1.2628060305884126, validation loss: 1.28353678661844.
epoch: 614, train loss: 1.2562403405478242, validation loss: 1.2755578134370886.
epoch: 615, train loss: 1.2540381731243309, validation loss: 1.26796119109444.
epoch: 616, train loss: 1.2542968288474126, validation loss: 1.265363978302997.
epoch: 617, train loss: 1.2536764866715178, validation loss: 1.2676495002663655.
epoch: 618, train loss: 1.2547128156784477, validation loss: 1.293991031854049.
epoch: 619, train loss: 1.2565492938417908, validation loss: 1.2736729124317998.
epoch: 620, train loss: 1.2553553121899246, validation loss: 1.2718227376108584.
epoch: 621, train loss: 1.253267802229715, validation loss: 1.2672590380129607.
epoch: 622, train loss: 1.2546144723892212, validation loss: 1.2700987432314002.
epoch: 623, train loss: 1.2569128603016564, validation loss: 1.2829028419826343.
epoch: 624, train loss: 1.2562737935179964, validation loss: 1.2654720959456072.
epoch: 625, train loss: 1.2522978377998422, validation loss: 1.305382920348126.
epoch: 626, train loss: 1.2552337219955725, validation loss: 1.2713825443516606.
epoch: 627, train loss: 1.2584910381824599, validation loss: 1.2750947890074358.
epoch: 628, train loss: 1.2565620011145915, validation loss: 1.2869243414505669.
epoch: 629, train loss: 1.256509325919895, validation loss: 1.2777213583821836.
epoch: 630, train loss: 1.2578309599412691, validation loss: 1.2733369910198709.
epoch: 631, train loss: 1.255417554750355, validation loss: 1.2757297961608223.
epoch: 632, train loss: 1.2546092665523565, validation loss: 1.263702366663062.
epoch: 633, train loss: 1.253686019040029, validation loss: 1.2725728076437246.
epoch: 634, train loss: 1.2534103426364585, validation loss: 1.2667641017747961.
epoch: 635, train loss: 1.254713008163172, validation loss: 1.2768927553425664.
epoch: 636, train loss: 1.257404833758643, validation loss: 1.2696115659630818.
epoch: 637, train loss: 1.257878604285214, validation loss: 1.2876030724981558.
epoch: 638, train loss: 1.2542655916388976, validation loss: 1.2785280269125234.
epoch: 639, train loss: 1.2527832820874836, validation loss: 1.2714268435602603.
epoch: 640, train loss: 1.2536234604109318, validation loss: 1.2678757905960083.
epoch: 641, train loss: 1.25307093082218, validation loss: 1.269270482270614.
epoch: 642, train loss: 1.2535764744522375, validation loss: 1.2782991709916487.
epoch: 643, train loss: 1.2563899175836406, validation loss: 1.287782757178597.
epoch: 644, train loss: 1.2548997697480229, validation loss: 1.2834292702052905.
epoch: 645, train loss: 1.2531710655317394, validation loss: 1.2690524121989375.
epoch: 646, train loss: 1.2524488890936616, validation loss: 1.2814917253411335.
epoch: 647, train loss: 1.2641608813487062, validation loss: 1.2846483199492744.
epoch: 648, train loss: 1.2558765750412548, validation loss: 1.272897430088209.
epoch: 649, train loss: 1.2546541548650199, validation loss: 1.2757612414982007.
epoch: 650, train loss: 1.2537868143221653, validation loss: 1.288078302922456.
epoch: 651, train loss: 1.2539585708478176, validation loss: 1.2856303401615308.
epoch: 652, train loss: 1.2554404582452336, validation loss: 1.2792781384094902.
epoch: 653, train loss: 1.2566848304293572, validation loss: 1.287009570909583.
epoch: 654, train loss: 1.256359894341285, validation loss: 1.2686692890913591.
epoch: 655, train loss: 1.255758650805972, validation loss: 1.2999267163483992.
epoch: 656, train loss: 1.2581757525785253, validation loss: 1.2784952702729597.
epoch: 657, train loss: 1.250751590510027, validation loss: 1.2766414517941682.
epoch: 658, train loss: 1.253417155064574, validation loss: 1.2677508022474206.
epoch: 659, train loss: 1.2522637855022325, validation loss: 1.3025407013685808.
epoch: 660, train loss: 1.2558837275986279, validation loss: 1.280684787294139.
epoch: 661, train loss: 1.2523249059642128, validation loss: 1.2825762810914412.
epoch: 662, train loss: 1.263555487361523, validation loss: 1.281175566756207.
epoch: 663, train loss: 1.2579960571516544, validation loss: 1.269961989444235.
epoch: 664, train loss: 1.2565627098083496, validation loss: 1.2697662737058557.
epoch: 665, train loss: 1.2557450303243936, validation loss: 1.2806633451710576.
epoch: 666, train loss: 1.2535772531404408, validation loss: 1.2720544234566067.
epoch: 667, train loss: 1.250094687173126, validation loss: 1.2816231198932813.
epoch: 668, train loss: 1.2530773790604477, validation loss: 1.2842377942541372.
epoch: 669, train loss: 1.2542529029583713, validation loss: 1.273156772489133.
epoch: 670, train loss: 1.2560754500397848, validation loss: 1.2829085432964822.
epoch: 671, train loss: 1.2527685329454754, validation loss: 1.2627278514530347.
epoch: 672, train loss: 1.250923319694099, validation loss: 1.2710396103236987.
epoch: 673, train loss: 1.2531464548285949, validation loss: 1.2706660498743472.
epoch: 674, train loss: 1.2509782620526235, validation loss: 1.2953259167463884.
epoch: 675, train loss: 1.2525800838382966, validation loss: 1.3067942235780798.
epoch: 676, train loss: 1.255491763079932, validation loss: 1.271180764488552.
epoch: 677, train loss: 1.2524992621273077, validation loss: 1.266229282254758.
epoch: 678, train loss: 1.2540555251847714, validation loss: 1.3091955495917278.
epoch: 679, train loss: 1.252238006766783, validation loss: 1.2829377288403718.
epoch: 680, train loss: 1.2514806176544329, validation loss: 1.2922358772029048.
epoch: 681, train loss: 1.252970503010881, validation loss: 1.2864502046419226.
epoch: 682, train loss: 1.2525846192596155, validation loss: 1.2817396806633992.
epoch: 683, train loss: 1.254776056753386, validation loss: 1.2926779518956724.
epoch: 684, train loss: 1.2509042429267814, validation loss: 1.2704961973687876.
epoch: 685, train loss: 1.254265304005474, validation loss: 1.2795625199442324.
epoch: 686, train loss: 1.2547420613262632, validation loss: 1.2900487806486047.
epoch: 687, train loss: 1.2513048725390652, validation loss: 1.272867555203645.
epoch: 688, train loss: 1.2553649790790102, validation loss: 1.2781890164250913.
epoch: 689, train loss: 1.2530064943733565, validation loss: 1.2807547890621682.
epoch: 690, train loss: 1.255047908616722, validation loss: 1.295686732167783.
epoch: 691, train loss: 1.2546284865895543, validation loss: 1.27871398822121.
epoch: 692, train loss: 1.2558914860454173, validation loss: 1.2958331678224646.
epoch: 693, train loss: 1.2525590220722584, validation loss: 1.2747517046721086.
epoch: 694, train loss: 1.2499061921320924, validation loss: 1.2819162607192993.
epoch: 695, train loss: 1.2538950246408445, validation loss: 1.2867809689563254.
epoch: 696, train loss: 1.2546220919407836, validation loss: 1.2659133050752722.
epoch: 697, train loss: 1.2521448529094732, validation loss: 1.2695559055908867.
epoch: 698, train loss: 1.2567625876960404, validation loss: 1.2740314680597056.
epoch: 699, train loss: 1.252334227255725, validation loss: 1.280415643816409.
epoch: 700, train loss: 1.2539535509336979, validation loss: 1.271611706070278.
epoch: 701, train loss: 1.2496795960522573, validation loss: 1.2730513500130696.
epoch: 702, train loss: 1.2513788183894725, validation loss: 1.270303233810093.
epoch: 703, train loss: 1.2527241663101616, validation loss: 1.3201266682666282.
epoch: 704, train loss: 1.2518206812919828, validation loss: 1.2731139919032222.
epoch: 705, train loss: 1.252519351626755, validation loss: 1.2774886825810308.
epoch: 706, train loss: 1.2524720835029532, validation loss: 1.2925356730170872.
epoch: 707, train loss: 1.2512854928270392, validation loss: 1.28066493117291.
epoch: 708, train loss: 1.316873481514257, validation loss: 1.3496129720107368.
epoch: 709, train loss: 1.3085720593776178, validation loss: 1.3365088390267414.
epoch: 710, train loss: 1.2879235339820931, validation loss: 1.3127311105313508.
epoch: 711, train loss: 1.2796615919935594, validation loss: 1.3018597053444905.
epoch: 712, train loss: 1.274258071129475, validation loss: 1.2982885267423547.
epoch: 713, train loss: 1.2731930695542502, validation loss: 1.2833251953125.
epoch: 714, train loss: 1.2677997449122438, validation loss: 1.281707789586938.
epoch: 715, train loss: 1.267186191103874, validation loss: 1.2918664009674736.
epoch: 716, train loss: 1.2681412992127445, validation loss: 1.2801578563192617.
epoch: 717, train loss: 1.2644272780199663, validation loss: 1.2812337097914324.
epoch: 718, train loss: 1.2651757920553925, validation loss: 1.2854470999344536.
epoch: 719, train loss: 1.2633774378977785, validation loss: 1.2907093037729678.
epoch: 720, train loss: 1.2659876062235702, validation loss: 1.2865423378737078.
epoch: 721, train loss: 1.2670050695401813, validation loss: 1.279613733291626.
epoch: 722, train loss: 1.264451334235865, validation loss: 1.2702655429425447.
epoch: 723, train loss: 1.2620159453208293, validation loss: 1.2763970261034758.
epoch: 724, train loss: 1.2645226738868502, validation loss: 1.276534106420434.
epoch: 725, train loss: 1.2600661723985584, validation loss: 1.2703809012537417.
epoch: 726, train loss: 1.2603263144099384, validation loss: 1.2884658989698992.
epoch: 727, train loss: 1.2606371367743257, validation loss: 1.2748201359873232.
epoch: 728, train loss: 1.2583105968772819, validation loss: 1.276019863460375.
epoch: 729, train loss: 1.2596562871145547, validation loss: 1.2697812111481377.
epoch: 730, train loss: 1.2598293024465579, validation loss: 1.2871488851049673.
epoch: 731, train loss: 1.2578871807920824, validation loss: 1.2769675617632659.
epoch: 732, train loss: 1.2574086364256132, validation loss: 1.2729341154513152.
epoch: 733, train loss: 1.2570616116217517, validation loss: 1.272740716519563.
epoch: 734, train loss: 1.257069134930952, validation loss: 1.2656455869260042.
epoch: 735, train loss: 1.2559319100248705, validation loss: 1.2832031560980754.
epoch: 736, train loss: 1.2566264441253943, validation loss: 1.2676615248555723.
epoch: 737, train loss: 1.2568047921591943, validation loss: 1.2822535193484763.
epoch: 738, train loss: 1.2580742081370921, validation loss: 1.282226614330126.
epoch: 739, train loss: 1.2550555314492742, validation loss: 1.289370640464451.
epoch: 740, train loss: 1.2557674241722177, validation loss: 1.2901879600856616.
epoch: 741, train loss: 1.2575235498060875, validation loss: 1.2765965513561084.
epoch: 742, train loss: 1.2569144034604414, validation loss: 1.2804827068163.
epoch: 743, train loss: 1.2575051740768852, validation loss: 1.2724124659662661.
epoch: 744, train loss: 1.2565732035068198, validation loss: 1.2793170576510222.
epoch: 745, train loss: 1.259137643586605, validation loss: 1.275999753371529.
epoch: 746, train loss: 1.2565325334531452, validation loss: 1.2698771694432134.
epoch: 747, train loss: 1.2573425529200002, validation loss: 1.291323615157086.
epoch: 748, train loss: 1.2570150609410138, validation loss: 1.2719514680945354.
epoch: 749, train loss: 1.2569817523343847, validation loss: 1.2708520526471345.
epoch: 750, train loss: 1.2572543467950383, validation loss: 1.2796429292015408.
epoch: 751, train loss: 1.256488001674687, validation loss: 1.2756095761838167.
epoch: 752, train loss: 1.2675175098104214, validation loss: 1.3103779761687568.
epoch: 753, train loss: 1.2624077381344017, validation loss: 1.2788482748943826.
epoch: 754, train loss: 1.2552165733564884, validation loss: 1.2669972336810569.
epoch: 755, train loss: 1.2575881371804334, validation loss: 1.2708054988280586.
epoch: 756, train loss: 1.2546830057004177, validation loss: 1.2661034490751184.
epoch: 757, train loss: 1.2569558500149929, validation loss: 1.2663373480672422.
epoch: 758, train loss: 1.2536142386427713, validation loss: 1.2781878191491831.
epoch: 759, train loss: 1.2556309885934953, validation loss: 1.2899484738059666.
epoch: 760, train loss: 1.2560160291304283, validation loss: 1.2718312481175298.
epoch: 761, train loss: 1.257231846861883, validation loss: 1.2891626876333486.
epoch: 762, train loss: 1.2542638144361864, validation loss: 1.2818483736204065.
epoch: 763, train loss: 1.2557780512975991, validation loss: 1.2868976230206697.
epoch: 764, train loss: 1.2544280367160061, validation loss: 1.2708495958991672.
epoch: 765, train loss: 1.2574496137986488, validation loss: 1.2704929839009824.
epoch: 766, train loss: 1.2548987056137224, validation loss: 1.2756007806114529.
epoch: 767, train loss: 1.2549053682099789, validation loss: 1.2704630934673806.
epoch: 768, train loss: 1.2581216917125457, validation loss: 1.2807046745134436.
epoch: 769, train loss: 1.254857190158389, validation loss: 1.2799792393394138.
epoch: 770, train loss: 1.2560790591283675, validation loss: 1.2704328920530237.
epoch: 771, train loss: 1.2525543269761112, validation loss: 1.269392096478006.
epoch: 772, train loss: 1.2555442403215882, validation loss: 1.270658446394879.
epoch: 773, train loss: 1.2532354943249204, validation loss: 1.2636797687281733.
epoch: 774, train loss: 1.2567587062853192, validation loss: 1.2853647418644116.
epoch: 775, train loss: 1.2601782269434099, validation loss: 1.276183413422626.
epoch: 776, train loss: 1.25543097618523, validation loss: 1.2764360645542974.
epoch: 777, train loss: 1.2569950556536333, validation loss: 1.2833365823911584.
epoch: 778, train loss: 1.2561598797456934, validation loss: 1.270795210548069.
epoch: 779, train loss: 1.2545382178157842, validation loss: 1.2794812710388848.
epoch: 780, train loss: 1.2550886836620645, validation loss: 1.2763938644657964.
epoch: 781, train loss: 1.2542476916531904, validation loss: 1.2756043568901394.
epoch: 782, train loss: 1.2560630982075263, validation loss: 1.2717565557231074.
epoch: 783, train loss: 1.252941724357255, validation loss: 1.2795732384142668.
epoch: 784, train loss: 1.2540013462031654, validation loss: 1.274225706639497.
epoch: 785, train loss: 1.254347869015615, validation loss: 1.2829333802928096.
epoch: 786, train loss: 1.2549049930834988, validation loss: 1.2650029192800107.
epoch: 787, train loss: 1.252465326851661, validation loss: 1.2625722625981206.
epoch: 788, train loss: 1.2531863746293095, validation loss: 1.2835570003675378.
epoch: 789, train loss: 1.2542927057371227, validation loss: 1.3333643260209456.
epoch: 790, train loss: 1.2546543178208378, validation loss: 1.2888586210167927.
epoch: 791, train loss: 1.2587487785094376, validation loss: 1.2628844924595044.
epoch: 792, train loss: 1.2537856266039227, validation loss: 1.2859626334646475.
epoch: 793, train loss: 1.2525920167975468, validation loss: 1.263893168905507.
epoch: 794, train loss: 1.2494850814889331, validation loss: 1.2691514803015667.
epoch: 795, train loss: 1.2527334832270212, validation loss: 1.2944640802300496.
epoch: 796, train loss: 1.2564039952164396, validation loss: 1.2760101867758709.
epoch: 797, train loss: 1.2956949680223377, validation loss: 1.3214549033538154.
epoch: 798, train loss: 1.288756050101114, validation loss: 1.3030179583508035.
epoch: 799, train loss: 1.2708574642828845, validation loss: 1.2862449314283289.
epoch: 800, train loss: 1.2624316762346741, validation loss: 1.289474984873896.
epoch: 801, train loss: 1.264144778251648, validation loss: 1.287919220717057.
epoch: 802, train loss: 1.2561370681185242, validation loss: 1.2710223716238271.
epoch: 803, train loss: 1.254398803098486, validation loss: 1.2689418067102847.
epoch: 804, train loss: 1.2533900420600121, validation loss: 1.2641008211218792.
epoch: 805, train loss: 1.2579307370229598, validation loss: 1.2693000617234602.
epoch: 806, train loss: 1.2554923427214317, validation loss: 1.2656615661538166.
epoch: 807, train loss: 1.2534450467573393, validation loss: 1.262848719306614.
epoch: 808, train loss: 1.2584599595551098, validation loss: 1.3141125025956526.
epoch: 809, train loss: 1.2577842911449046, validation loss: 1.277005294094915.
epoch: 810, train loss: 1.251977293863209, validation loss: 1.2571533348249353.
epoch: 811, train loss: 1.2537223231901817, validation loss: 1.2745145922121794.
epoch: 812, train loss: 1.2538896689721204, validation loss: 1.2827195032783176.
epoch: 813, train loss: 1.2558482229162793, validation loss: 1.2737231358237888.
epoch: 814, train loss: 1.2533468642366041, validation loss: 1.2665010224217954.
epoch: 815, train loss: 1.2526051331003871, validation loss: 1.2657856941223145.
epoch: 816, train loss: 1.254957089730359, validation loss: 1.2791978950085847.
epoch: 817, train loss: 1.2540087218678326, validation loss: 1.308339175970658.
epoch: 818, train loss: 1.2563556684266537, validation loss: 1.2702097944591357.
epoch: 819, train loss: 1.2527984227609197, validation loss: 1.2880483088286028.
epoch: 820, train loss: 1.254641827093352, validation loss: 1.2642458884612373.
epoch: 821, train loss: 1.2527462134667493, validation loss: 1.2747567632923955.
epoch: 822, train loss: 1.2554218998742759, validation loss: 1.2939128823902295.
epoch: 823, train loss: 1.2536607576072762, validation loss: 1.2706390463787576.
epoch: 824, train loss: 1.2535010674677858, validation loss: 1.2858588332715242.
epoch: 825, train loss: 1.2536019918021806, validation loss: 1.2609725205794624.
epoch: 826, train loss: 1.2509921887599, validation loss: 1.264504365299059.
epoch: 827, train loss: 1.2500789898251174, validation loss: 1.2690128347148066.
epoch: 828, train loss: 1.2590950060328212, validation loss: 1.2812159216922263.
epoch: 829, train loss: 1.2565193712164502, validation loss: 1.3333775945331738.
epoch: 830, train loss: 1.2578187415359217, validation loss: 1.3213512845661328.
epoch: 831, train loss: 1.2538808671706314, validation loss: 1.2849614931189495.
epoch: 832, train loss: 1.2513872297531967, validation loss: 1.5451681976733.
epoch: 833, train loss: 1.2553208333636643, validation loss: 1.3059347919795825.
epoch: 834, train loss: 1.2549410424101244, validation loss: 1.2882070126740828.
epoch: 835, train loss: 1.2531238094382329, validation loss: 1.2813133778779402.
epoch: 836, train loss: 1.2534911501298256, validation loss: 1.2774937722993933.
epoch: 837, train loss: 1.2565147723626653, validation loss: 1.270644530006077.
epoch: 838, train loss: 1.250304329285928, validation loss: 1.2706291831058005.
epoch: 839, train loss: 1.2510183109055966, validation loss: 1.2778325443682463.
epoch: 840, train loss: 1.254101328893539, validation loss: 1.2834833653076836.
epoch: 841, train loss: 1.25117886832001, validation loss: 1.2811896282693613.
epoch: 842, train loss: 1.2522953005012023, validation loss: 1.273418753043465.
epoch: 843, train loss: 1.251510374042966, validation loss: 1.2677126915558525.
epoch: 844, train loss: 1.2475609210653043, validation loss: 1.2812690683033154.
epoch: 845, train loss: 1.2542832750792896, validation loss: 1.3298934076143347.
epoch: 846, train loss: 1.2545350166635776, validation loss: 1.261178503865781.
epoch: 847, train loss: 1.2495705961087429, validation loss: 1.2647590689037158.
epoch: 848, train loss: 1.2515885337777095, validation loss: 1.2773436152416726.
epoch: 849, train loss: 1.2584418845832894, validation loss: 1.2810766645099805.
epoch: 850, train loss: 1.2519468473731925, validation loss: 1.269955671351889.
epoch: 851, train loss: 1.2502699729499467, validation loss: 1.3090511871420818.
epoch: 852, train loss: 1.2565710019627843, validation loss: 1.3352062287537947.
epoch: 853, train loss: 1.2656895283165328, validation loss: 1.286515412123307.
epoch: 854, train loss: 1.257926926700347, validation loss: 1.2664573710897695.
epoch: 855, train loss: 1.2519160727842138, validation loss: 1.2794348001480103.
epoch: 856, train loss: 1.253499947556662, validation loss: 1.266956749169723.
epoch: 857, train loss: 1.2518362189651628, validation loss: 1.2747428469035937.
epoch: 858, train loss: 1.2516747144384122, validation loss: 1.3053601565568342.
epoch: 859, train loss: 1.250992796836643, validation loss: 1.2906942574874214.
epoch: 860, train loss: 1.2514133169016708, validation loss: 1.2798980059831038.
epoch: 861, train loss: 1.252079006728776, validation loss: 1.27662295880525.
epoch: 862, train loss: 1.252520651992308, validation loss: 1.2627627642258354.
epoch: 863, train loss: 1.2468196569232766, validation loss: 1.262901124746903.
epoch: 864, train loss: 1.2522915131455168, validation loss: 1.3067835465721462.
epoch: 865, train loss: 1.2532938500063135, validation loss: 1.2771784170814182.
epoch: 866, train loss: 1.2525367747753038, validation loss: 1.2845831591150034.
epoch: 867, train loss: 1.2510640118100227, validation loss: 1.308365365733271.
epoch: 868, train loss: 1.2540346405921725, validation loss: 1.2721183144527932.
epoch: 869, train loss: 1.2529276270385181, validation loss: 1.2686569276063338.
epoch: 870, train loss: 1.2507223481432013, validation loss: 1.2663506269454956.
epoch: 871, train loss: 1.2512516876973143, validation loss: 1.2798831514690234.
epoch: 872, train loss: 1.250685902910495, validation loss: 1.2840715180272642.
epoch: 873, train loss: 1.250207729295853, validation loss: 1.2655067029206648.
epoch: 874, train loss: 1.254195941697567, validation loss: 1.2684999963511592.
epoch: 875, train loss: 1.2531124473711766, validation loss: 1.2708743655163308.
epoch: 876, train loss: 1.252169984196304, validation loss: 1.2641377708186274.
epoch: 877, train loss: 1.2531049765578104, validation loss: 1.2746657910554304.
epoch: 878, train loss: 1.2512723951164735, validation loss: 1.2715978570606397.
epoch: 879, train loss: 1.2511255150541254, validation loss: 1.3069066327551138.
epoch: 880, train loss: 1.2530660104314122, validation loss: 1.3052549051201863.
epoch: 881, train loss: 1.2531949533235043, validation loss: 1.271163302919139.
epoch: 882, train loss: 1.2549621621403126, validation loss: 1.2849029924558557.
epoch: 883, train loss: 1.2515617051255812, validation loss: 1.278348191924717.
epoch: 884, train loss: 1.250396955997572, validation loss: 1.2607950023982837.
epoch: 885, train loss: 1.2509180876093173, validation loss: 1.2890014596607373.
epoch: 886, train loss: 1.2533790124665707, validation loss: 1.2757200313651043.
epoch: 887, train loss: 1.2527408807649525, validation loss: 1.2703706129737522.
epoch: 888, train loss: 1.2498323283064257, validation loss: 1.2701536209686943.
epoch: 889, train loss: 1.2526777239020812, validation loss: 1.2826204196266506.
epoch: 890, train loss: 1.2531514998969682, validation loss: 1.3059323093165522.
epoch: 891, train loss: 1.2523098866873925, validation loss: 1.2735662149346394.
epoch: 892, train loss: 1.2464573886416375, validation loss: 1.2699120148368503.
epoch: 893, train loss: 1.2482441488755953, validation loss: 1.2748682447101758.
epoch: 894, train loss: 1.2493562829603844, validation loss: 1.2833994575168775.
epoch: 895, train loss: 1.2508990053736835, validation loss: 1.2718330207078352.
epoch: 896, train loss: 1.2483647339934603, validation loss: 1.2682294119959292.
epoch: 897, train loss: 1.2496927703192475, validation loss: 1.2701239585876465.
epoch: 898, train loss: 1.2491927387517527, validation loss: 1.2980248720749565.
epoch: 899, train loss: 1.2504379683678304, validation loss: 1.2615150316901829.
epoch: 900, train loss: 1.2513751546177296, validation loss: 1.2702775053356006.
epoch: 901, train loss: 1.2498899479524805, validation loss: 1.300230368323948.
epoch: 902, train loss: 1.2505690646827767, validation loss: 1.273203378138335.
epoch: 903, train loss: 1.2525305551126462, validation loss: 1.2754193026086558.
epoch: 904, train loss: 1.2514629287457248, validation loss: 1.2946822021318518.
epoch: 905, train loss: 1.2532959443713547, validation loss: 1.2719127095263938.
epoch: 906, train loss: 1.2525832270263533, validation loss: 1.311460448348004.
epoch: 907, train loss: 1.2478477254920048, validation loss: 1.2686558599057405.
epoch: 908, train loss: 1.2522897250061735, validation loss: 1.2742634597031965.
epoch: 909, train loss: 1.2526133607286927, validation loss: 1.266237761663354.
epoch: 910, train loss: 1.2513893623964503, validation loss: 1.2752968072891235.
epoch: 911, train loss: 1.2492491214647206, validation loss: 1.30912272826485.
epoch: 912, train loss: 1.2508436682027415, validation loss: 1.2815622816915098.
epoch: 913, train loss: 1.2503856147101167, validation loss: 1.2652892392614614.
epoch: 914, train loss: 1.2584603073400096, validation loss: 1.3118230985558552.
epoch: 915, train loss: 1.2610753271557869, validation loss: 1.280558150747548.
epoch: 916, train loss: 1.2591551979747386, validation loss: 1.2761745660201362.
epoch: 917, train loss: 1.2519471131333517, validation loss: 1.2665739318598872.
epoch: 918, train loss: 1.2529587275391325, validation loss: 1.2986957508584727.
epoch: 919, train loss: 1.2512673784833435, validation loss: 1.2744870911473813.
epoch: 920, train loss: 1.2507660487376222, validation loss: 1.2972804826238882.
epoch: 921, train loss: 1.252003292424963, validation loss: 1.2732647450073906.
epoch: 922, train loss: 1.2504331967152587, validation loss: 1.2910405397415161.
epoch: 923, train loss: 1.2466427995524276, validation loss: 1.266977978789288.
epoch: 924, train loss: 1.2489485871901207, validation loss: 1.286838666252468.
epoch: 925, train loss: 1.2494709447983208, validation loss: 1.2745198011398315.
epoch: 926, train loss: 1.2499134409318275, validation loss: 1.277450654817664.
epoch: 927, train loss: 1.2490975528682045, validation loss: 1.2705826085546743.
epoch: 928, train loss: 1.2495216874901307, validation loss: 1.297652218652808.
epoch: 929, train loss: 1.2507181987849945, validation loss: 1.263783750326737.
epoch: 930, train loss: 1.2531372932119107, validation loss: 1.2783781341884448.
epoch: 931, train loss: 1.2482146418422735, validation loss: 1.3108550361965015.
epoch: 932, train loss: 1.2501457656195405, validation loss: 1.280533598816913.
epoch: 933, train loss: 1.2459258256702248, validation loss: 1.2873244130093118.
epoch: 934, train loss: 1.2508402964390746, validation loss: 1.2600850540658701.
epoch: 935, train loss: 1.2486900714559293, validation loss: 1.2849171265311863.
epoch: 936, train loss: 1.252994639064194, validation loss: 1.2746758979299795.
epoch: 937, train loss: 1.2484422626845333, validation loss: 1.2669077541517175.
epoch: 938, train loss: 1.246559146347396, validation loss: 1.2926571058190388.
epoch: 939, train loss: 1.2527189484430015, validation loss: 1.2793596620145051.
epoch: 940, train loss: 1.2533032544162295, validation loss: 1.2676418138586956.
epoch: 941, train loss: 1.251686882535252, validation loss: 1.277540279471356.
epoch: 942, train loss: 1.2488920918298423, validation loss: 1.2655035671980486.
epoch: 943, train loss: 1.2472609161236965, validation loss: 1.2822435161341792.
epoch: 944, train loss: 1.2476362110277928, validation loss: 1.2844054128812707.
epoch: 945, train loss: 1.2489721479765865, validation loss: 1.3081081950146218.
epoch: 946, train loss: 1.252077584966607, validation loss: 1.2952969074249268.
epoch: 947, train loss: 1.2492540068582658, validation loss: 1.2692711456962253.
epoch: 948, train loss: 1.2523123277436703, validation loss: 1.2742115829301917.
epoch: 949, train loss: 1.252756350631014, validation loss: 1.26374584177266.
epoch: 950, train loss: 1.2480352952939655, validation loss: 1.2790155099785847.
epoch: 951, train loss: 1.250856304387434, validation loss: 1.2981007928433625.
epoch: 952, train loss: 1.2504262803891384, validation loss: 1.2775025626887446.
epoch: 953, train loss: 1.2520481687073315, validation loss: 1.2661579847335815.
epoch: 954, train loss: 1.2481078379744783, validation loss: 1.2797521871069204.
epoch: 955, train loss: 1.2457921767453535, validation loss: 1.2801785935526309.
epoch: 956, train loss: 1.247219389731731, validation loss: 1.2808252313862676.
epoch: 957, train loss: 1.2455898228041622, validation loss: 1.2662774272586987.
epoch: 958, train loss: 1.2495034265955653, validation loss: 1.2788212403007175.
epoch: 959, train loss: 1.2497275159993302, validation loss: 1.2812581425127776.
epoch: 960, train loss: 1.250896755708467, validation loss: 1.2770207757535188.
epoch: 961, train loss: 1.2503132076438415, validation loss: 1.2896419970885566.
epoch: 962, train loss: 1.249625891720483, validation loss: 1.2643377418103425.
epoch: 963, train loss: 1.2501002495441962, validation loss: 1.3028300482293833.
epoch: 964, train loss: 1.2497492755224946, validation loss: 1.2812223693598872.
epoch: 965, train loss: 1.250372501688266, validation loss: 1.2873549150383992.
epoch: 966, train loss: 1.2494086224004763, validation loss: 1.2790707090626592.
epoch: 967, train loss: 1.2490286980200251, validation loss: 1.2947453571402507.
epoch: 968, train loss: 1.2467642366339307, validation loss: 1.287706960802493.
epoch: 969, train loss: 1.2505091964651684, validation loss: 1.270417384479357.
epoch: 970, train loss: 1.2503195421411357, validation loss: 1.289385489795519.
epoch: 971, train loss: 1.2524624680160383, validation loss: 1.277335472728895.
epoch: 972, train loss: 1.2519056261132617, validation loss: 1.267909542373989.
epoch: 973, train loss: 1.2462139260878258, validation loss: 1.2777169580044954.
epoch: 974, train loss: 1.2491125677703718, validation loss: 1.2657886484394902.
epoch: 975, train loss: 1.251584471912559, validation loss: 1.2637227825496509.
epoch: 976, train loss: 1.248561724610285, validation loss: 1.2713145950566167.
epoch: 977, train loss: 1.2519858922433416, validation loss: 1.2801985066869985.
epoch: 978, train loss: 1.2511040606629957, validation loss: 1.2964157436204993.
epoch: 979, train loss: 1.2498369107552625, validation loss: 1.2727275620336118.
epoch: 980, train loss: 1.2509841361177076, validation loss: 1.260917736136395.
epoch: 981, train loss: 1.250320992338548, validation loss: 1.2986796576043833.
epoch: 982, train loss: 1.2546146025351428, validation loss: 1.3105385407157566.
epoch: 983, train loss: 1.2546502023661903, validation loss: 1.2774856246036033.
epoch: 984, train loss: 1.246926144722405, validation loss: 1.3142503448154614.
epoch: 985, train loss: 1.2512446860654638, validation loss: 1.2869990804921025.
epoch: 986, train loss: 1.2483383209333507, validation loss: 1.2801058447879294.
epoch: 987, train loss: 1.248469389906717, validation loss: 1.266595291054767.
epoch: 988, train loss: 1.2468346127676309, validation loss: 1.2652732133865356.
epoch: 989, train loss: 1.2488199439617471, validation loss: 1.2907246143921562.
epoch: 990, train loss: 1.2492180187767798, validation loss: 1.3216074756954028.
epoch: 991, train loss: 1.2465386685975102, validation loss: 1.2753491090691609.
epoch: 992, train loss: 1.2463617784167649, validation loss: 1.2654000779856807.
epoch: 993, train loss: 1.249544425841865, validation loss: 1.2888445439546004.
epoch: 994, train loss: 1.25197852532798, validation loss: 1.2700495253438535.
epoch: 995, train loss: 1.246125874169376, validation loss: 1.27695399781932.
epoch: 996, train loss: 1.2480053245474438, validation loss: 1.2809134669925855.
epoch: 997, train loss: 1.250984851373445, validation loss: 1.2761875857477603.
epoch: 998, train loss: 1.2508815669138498, validation loss: 1.2695995983870134.
epoch: 999, train loss: 1.2487914693464928, validation loss: 1.273695883543595.
epoch: 1000, train loss: 1.249579080747902, validation loss: 1.2593968329222307.
epoch: 1001, train loss: 1.2484443625178905, validation loss: 1.3658883830775386.
epoch: 1002, train loss: 1.2476484742733316, validation loss: 1.284862139950628.
epoch: 1003, train loss: 1.246456202017058, validation loss: 1.2866017144659292.
epoch: 1004, train loss: 1.24936741973282, validation loss: 1.2721333140912263.
epoch: 1005, train loss: 1.250964387841181, validation loss: 1.4178238381510195.
epoch: 1006, train loss: 1.312039012208991, validation loss: 1.3543492970259294.
epoch: 1007, train loss: 1.28438825126088, validation loss: 1.2910679008649744.
epoch: 1008, train loss: 1.2684103381743126, validation loss: 1.2918402889500493.
epoch: 1009, train loss: 1.2600847996702982, validation loss: 1.2705260359722634.
epoch: 1010, train loss: 1.2557762992491417, validation loss: 1.270341106083082.
epoch: 1011, train loss: 1.2541096451085643, validation loss: 1.2674413556637971.
epoch: 1012, train loss: 1.253248998878199, validation loss: 1.2793144143146018.
epoch: 1013, train loss: 1.2517381840889608, validation loss: 1.2772049333738245.
epoch: 1014, train loss: 1.2544924655091871, validation loss: 1.2753944293312405.
epoch: 1015, train loss: 1.2467869170215151, validation loss: 1.2691379578217217.
epoch: 1016, train loss: 1.250387230050673, validation loss: 1.2819831267647122.
epoch: 1017, train loss: 1.2486164088642926, validation loss: 1.2650748491287231.
epoch: 1018, train loss: 1.251328341457822, validation loss: 1.2755198841509612.
epoch: 1019, train loss: 1.2479431290145313, validation loss: 1.2678362234779026.
epoch: 1020, train loss: 1.2486221287228645, validation loss: 1.2629304605981577.
epoch: 1021, train loss: 1.2459815204690357, validation loss: 1.2683695140092268.
epoch: 1022, train loss: 1.2486849181148985, validation loss: 1.2628789259039837.
epoch: 1023, train loss: 1.2515667491002913, validation loss: 1.2710668004077414.
epoch: 1024, train loss: 1.2465788869682801, validation loss: 1.267375515854877.
epoch: 1025, train loss: 1.2496330420905297, validation loss: 1.2670596941657688.
epoch: 1026, train loss: 1.2478952134421113, validation loss: 1.262334994647814.
epoch: 1027, train loss: 1.24763067162365, validation loss: 1.267252372658771.
epoch: 1028, train loss: 1.2483970331489493, validation loss: 1.272411838821743.
epoch: 1029, train loss: 1.2457622256847696, validation loss: 1.2623966569485872.
epoch: 1030, train loss: 1.250319976325429, validation loss: 1.2663983313933662.
epoch: 1031, train loss: 1.248445993169732, validation loss: 1.2664473626924597.
epoch: 1032, train loss: 1.2477276893930698, validation loss: 1.2809036348177039.
epoch: 1033, train loss: 1.2504818866012293, validation loss: 1.2699729618818865.
epoch: 1034, train loss: 1.2465847238488155, validation loss: 1.2577349932297417.
epoch: 1035, train loss: 1.2471409915784084, validation loss: 1.2761115250380144.
epoch: 1036, train loss: 1.2495954856960052, validation loss: 1.2986465796180393.
epoch: 1037, train loss: 1.2501018791023744, validation loss: 1.275942553644595.
epoch: 1038, train loss: 1.24969623613795, validation loss: 1.286111365193906.
epoch: 1039, train loss: 1.250411741230466, validation loss: 1.2677059536394866.
epoch: 1040, train loss: 1.2502937010668833, validation loss: 1.3056413609048594.
epoch: 1041, train loss: 1.249110829939536, validation loss: 1.2735104249871296.
epoch: 1042, train loss: 1.2530967664281163, validation loss: 1.2667421517164812.
epoch: 1043, train loss: 1.251473507749925, validation loss: 1.2650753415149192.
epoch: 1044, train loss: 1.2562910121515256, validation loss: 1.2682610698368237.
epoch: 1045, train loss: 1.2559628945971848, validation loss: 1.275322587593742.
epoch: 1046, train loss: 1.2563453190917269, validation loss: 1.2865372844364331.
epoch: 1047, train loss: 1.2512013037270362, validation loss: 1.2718619263690452.
epoch: 1048, train loss: 1.2485467523609826, validation loss: 1.275202460910963.
epoch: 1049, train loss: 1.2505513440578355, validation loss: 1.2853580246800962.
epoch: 1050, train loss: 1.24879460597257, validation loss: 1.265389603117238.
epoch: 1051, train loss: 1.2478431036712927, validation loss: 1.274964944176052.
epoch: 1052, train loss: 1.2470696978612776, validation loss: 1.2668950091237607.
epoch: 1053, train loss: 1.246208387777346, validation loss: 1.283400146857552.
epoch: 1054, train loss: 1.2481753541788925, validation loss: 1.264211426610532.
epoch: 1055, train loss: 1.2473910478276944, validation loss: 1.2722427948661472.
epoch: 1056, train loss: 1.2459796590542576, validation loss: 1.2804849614267764.
epoch: 1057, train loss: 1.246036589692492, validation loss: 1.2688585053319517.
epoch: 1058, train loss: 1.2452581836542953, validation loss: 1.287485957145691.
epoch: 1059, train loss: 1.2548867332825966, validation loss: 1.271903836208841.
epoch: 1060, train loss: 1.2469912920523127, validation loss: 1.26995631404545.
epoch: 1061, train loss: 1.2487473301931258, validation loss: 1.257117888201838.
epoch: 1062, train loss: 1.2463769333078227, validation loss: 1.2654845507248589.
epoch: 1063, train loss: 1.2459510138275427, validation loss: 1.2835302663886028.
epoch: 1064, train loss: 1.2497822560301615, validation loss: 1.3110668918360835.
epoch: 1065, train loss: 1.251577953679846, validation loss: 1.266508750293566.
epoch: 1066, train loss: 1.2500878178745234, validation loss: 1.2921160770499187.
epoch: 1067, train loss: 1.2486471276764477, validation loss: 1.282336571942205.
epoch: 1068, train loss: 1.2497696898399142, validation loss: 1.2644079975459888.
epoch: 1069, train loss: 1.248193172139859, validation loss: 1.2704393656357476.
epoch: 1070, train loss: 1.2493621931163543, validation loss: 1.2682643662328306.
epoch: 1071, train loss: 1.248303157473923, validation loss: 1.2681161839029063.
epoch: 1072, train loss: 1.2459731386342179, validation loss: 1.2834695111150327.
epoch: 1073, train loss: 1.2473542362178138, validation loss: 1.2669257910355278.
epoch: 1074, train loss: 1.2509845407730942, validation loss: 1.2895663302877676.
epoch: 1075, train loss: 1.2492069038776084, validation loss: 1.2915807547776594.
epoch: 1076, train loss: 1.249143150968289, validation loss: 1.266320482544277.
epoch: 1077, train loss: 1.2505931383972868, validation loss: 1.3856723049412603.
epoch: 1078, train loss: 1.252106580165548, validation loss: 1.3155624607334966.
epoch: 1079, train loss: 1.2512397470824215, validation loss: 1.2901605315830396.
epoch: 1080, train loss: 1.249799736049197, validation loss: 1.270711883254673.
epoch: 1081, train loss: 1.2469247874863651, validation loss: 1.2828280148298845.
epoch: 1082, train loss: 1.251030688985772, validation loss: 1.2661773484686147.
epoch: 1083, train loss: 1.247459160078556, validation loss: 1.2825685169385828.
epoch: 1084, train loss: 1.254181934059213, validation loss: 1.3178589136704155.
epoch: 1085, train loss: 1.2486519168276307, validation loss: 1.2759756264479265.
epoch: 1086, train loss: 1.2475118823007707, validation loss: 1.2996649690296338.
epoch: 1087, train loss: 1.2452257127936828, validation loss: 1.2720980177754941.
epoch: 1088, train loss: 1.2486220018579326, validation loss: 1.2975610857424529.
epoch: 1089, train loss: 1.2564768495909664, validation loss: 1.2753739512485007.
epoch: 1090, train loss: 1.2479105651925464, validation loss: 1.2813307565191518.
epoch: 1091, train loss: 1.2466833219615692, validation loss: 1.2630915175313535.
epoch: 1092, train loss: 1.2464646166617717, validation loss: 1.2616880717484846.
epoch: 1093, train loss: 1.248330704662778, validation loss: 1.293530832166257.
epoch: 1094, train loss: 1.2482943644217395, validation loss: 1.2734999190206113.
epoch: 1095, train loss: 1.2493183754999704, validation loss: 1.281098873718925.
epoch: 1096, train loss: 1.2506400292072821, validation loss: 1.2798236919486004.
epoch: 1097, train loss: 1.2484691394578427, validation loss: 1.2816074827442998.
epoch: 1098, train loss: 1.247635999950794, validation loss: 1.269646836363751.
epoch: 1099, train loss: 1.2579662952948054, validation loss: 1.3916098916012307.
epoch: 1100, train loss: 1.2597813956234434, validation loss: 1.300085363180741.
epoch: 1101, train loss: 1.2530642791625557, validation loss: 1.3038625198861826.
epoch: 1102, train loss: 1.2486106343225603, validation loss: 1.2654971298964128.
epoch: 1103, train loss: 1.2461294624783577, validation loss: 1.2630298759626306.
epoch: 1104, train loss: 1.2470596722506602, validation loss: 1.2739636949870898.
epoch: 1105, train loss: 1.248429298400879, validation loss: 1.292675443317579.
epoch: 1106, train loss: 1.2498075655840952, validation loss: 1.2743307248405789.
epoch: 1107, train loss: 1.2485652713600648, validation loss: 1.277182496112326.
epoch: 1108, train loss: 1.2479482943858575, validation loss: 1.290443171625552.
epoch: 1109, train loss: 1.2506266449569563, validation loss: 1.2794309232545935.
epoch: 1110, train loss: 1.2524176803203897, validation loss: 1.2909863046977832.
epoch: 1111, train loss: 1.248631915914903, validation loss: 1.2809832199760105.
epoch: 1112, train loss: 1.2463672587630945, validation loss: 1.2654324821803882.
epoch: 1113, train loss: 1.2472671182877426, validation loss: 1.2830547819966855.
epoch: 1114, train loss: 1.2483660190477284, validation loss: 1.3063208486722864.
epoch: 1115, train loss: 1.2515692601510144, validation loss: 1.3299507887467095.
epoch: 1116, train loss: 1.2473828508219589, validation loss: 1.2691041904947031.
epoch: 1117, train loss: 1.2467023757619595, validation loss: 1.2588069698084956.
epoch: 1118, train loss: 1.2456653205626602, validation loss: 1.2717159416364587.
epoch: 1119, train loss: 1.2482326172907419, validation loss: 1.2998108967490818.
epoch: 1120, train loss: 1.248354661355325, validation loss: 1.2752143922059431.
epoch: 1121, train loss: 1.254739300920329, validation loss: 1.3736029707867166.
epoch: 1122, train loss: 1.2623676006947089, validation loss: 1.2680568850558738.
epoch: 1123, train loss: 1.2536936746824772, validation loss: 1.2934891037319018.
epoch: 1124, train loss: 1.2517351316749503, validation loss: 1.2734793787417205.
epoch: 1125, train loss: 1.2496692390616881, validation loss: 1.2894923531490823.
epoch: 1126, train loss: 1.248966626071055, validation loss: 1.312274518220321.
epoch: 1127, train loss: 1.2490886099841616, validation loss: 1.2737661703773167.
epoch: 1128, train loss: 1.247582376550097, validation loss: 1.2700706668522046.
epoch: 1129, train loss: 1.2550910984704253, validation loss: 1.2781661126924597.
epoch: 1130, train loss: 1.2476653527776036, validation loss: 1.2619512962258381.
epoch: 1131, train loss: 1.2473571048964054, validation loss: 1.2769677017046057.
epoch: 1132, train loss: 1.2492577482800964, validation loss: 1.2728156317835269.
epoch: 1133, train loss: 1.2514303419568122, validation loss: 1.2939188117566316.
epoch: 1134, train loss: 1.255670402028145, validation loss: 1.274121792420097.
epoch: 1135, train loss: 1.246969291923243, validation loss: 1.271524683288906.
epoch: 1136, train loss: 1.2506207752665248, validation loss: 1.266281159027763.
epoch: 1137, train loss: 1.2474846161833597, validation loss: 1.2826636563176694.
epoch: 1138, train loss: 1.2470991174015431, validation loss: 1.2788973269255266.
epoch: 1139, train loss: 1.247518718789477, validation loss: 1.307930977448173.
epoch: 1140, train loss: 1.2482930367146063, validation loss: 1.335004599198051.
epoch: 1141, train loss: 1.250581996156535, validation loss: 1.2717783969381582.
epoch: 1142, train loss: 1.2470355099494304, validation loss: 1.3039745092391968.
epoch: 1143, train loss: 1.2499330393764951, validation loss: 1.2591654010440991.
epoch: 1144, train loss: 1.2466831327578343, validation loss: 1.2708755472432012.
epoch: 1145, train loss: 1.2508064016289668, validation loss: 1.2795107571975044.
epoch: 1146, train loss: 1.2466314670142777, validation loss: 1.279594265896341.
epoch: 1147, train loss: 1.2476992869595869, validation loss: 1.2656250984772393.
epoch: 1148, train loss: 1.2468874268575545, validation loss: 1.2735321729079536.
epoch: 1149, train loss: 1.2484146728428132, validation loss: 1.2677907218103823.
epoch: 1150, train loss: 1.245626915485487, validation loss: 1.283727537030759.
epoch: 1151, train loss: 1.2500215189172588, validation loss: 1.279113505197608.
epoch: 1152, train loss: 1.2493973489201398, validation loss: 1.2670929587405662.
epoch: 1153, train loss: 1.2496331667681353, validation loss: 1.276304359021394.
epoch: 1154, train loss: 1.2519150338041674, validation loss: 1.447733718415965.
epoch: 1155, train loss: 1.2500583622433723, validation loss: 1.2886081001032954.
epoch: 1156, train loss: 1.2526403414000065, validation loss: 1.353540099185446.
epoch: 1157, train loss: 1.2483425774705519, validation loss: 1.304448770440143.
epoch: 1158, train loss: 1.2455864936933605, validation loss: 1.2598408978918325.
epoch: 1159, train loss: 1.2455225198640736, validation loss: 1.2647839525471563.
epoch: 1160, train loss: 1.2514168527148186, validation loss: 1.2702002214348835.
epoch: 1161, train loss: 1.248213751600423, validation loss: 1.2826676576033882.
epoch: 1162, train loss: 1.2480531230979008, validation loss: 1.279157104699508.
epoch: 1163, train loss: 1.247518540522374, validation loss: 1.268054443856944.
epoch: 1164, train loss: 1.2541764559002098, validation loss: 1.2999598306158315.
epoch: 1165, train loss: 1.2484893077010408, validation loss: 1.270807940026988.
epoch: 1166, train loss: 1.2493826905521779, validation loss: 1.2893476952677188.
epoch: 1167, train loss: 1.246510699254657, validation loss: 1.281136004821114.
epoch: 1168, train loss: 1.260175912752064, validation loss: 1.2815314686816672.
epoch: 1169, train loss: 1.24826123298855, validation loss: 1.2851088306178218.
epoch: 1170, train loss: 1.2490184339908286, validation loss: 1.2701433534207551.
epoch: 1171, train loss: 1.2467520925976814, validation loss: 1.266574688579725.
epoch: 1172, train loss: 1.2543533231140276, validation loss: 1.3000915879788606.
epoch: 1173, train loss: 1.248207989088986, validation loss: 1.2728581273037454.
epoch: 1174, train loss: 1.2493118638292364, validation loss: 1.312652173249618.
epoch: 1175, train loss: 1.2492774779643487, validation loss: 1.2761043828466665.
epoch: 1176, train loss: 1.248550306766405, validation loss: 1.2656275033950806.
epoch: 1177, train loss: 1.2469048215708602, validation loss: 1.2806268515794172.
epoch: 1178, train loss: 1.2491854265195514, validation loss: 1.2743695456048716.
epoch: 1179, train loss: 1.2483988387869038, validation loss: 1.2672657603802888.
epoch: 1180, train loss: 1.2470851753829817, validation loss: 1.2826325167780337.
epoch: 1181, train loss: 1.2495516079281448, validation loss: 1.2663993213487708.
epoch: 1182, train loss: 1.2464189168510087, validation loss: 1.2812046019927315.
epoch: 1183, train loss: 1.2467512778185923, validation loss: 1.2743426509525464.
epoch: 1184, train loss: 1.2471499169638398, validation loss: 1.3289363125096196.
epoch: 1185, train loss: 1.2464219834826409, validation loss: 1.3039132201153298.
epoch: 1186, train loss: 1.2499217407419048, validation loss: 1.2657835846361907.
epoch: 1187, train loss: 1.2470004799169139, validation loss: 1.2716805675755376.
epoch: 1188, train loss: 1.2476410450191673, validation loss: 1.2611606328383735.
epoch: 1189, train loss: 1.247870224331497, validation loss: 1.2662570476531982.
epoch: 1190, train loss: 1.2499385831552907, validation loss: 1.2733355605083962.
epoch: 1191, train loss: 1.2471067577327064, validation loss: 1.3113467175027598.
epoch: 1192, train loss: 1.2499245011478388, validation loss: 1.2846455833186274.
epoch: 1193, train loss: 1.245476425240893, validation loss: 1.2802107178646585.
epoch: 1194, train loss: 1.2454880432251396, validation loss: 1.2756933595823206.
epoch: 1195, train loss: 1.2431970473823197, validation loss: 1.2794768240140832.
epoch: 1196, train loss: 1.249746021874454, validation loss: 1.3012522148049397.
epoch: 1197, train loss: 1.2577258829676776, validation loss: 1.277554532755976.
epoch: 1198, train loss: 1.2502136514821183, validation loss: 1.2729055155878481.
epoch: 1199, train loss: 1.2505345814818636, validation loss: 1.3189513994299846.
epoch: 1200, train loss: 1.2480648242005514, validation loss: 1.2841011389442112.
epoch: 1201, train loss: 1.246971379726305, validation loss: 1.2866545915603638.
epoch: 1202, train loss: 1.2452121677748653, validation loss: 1.2620990328166797.
epoch: 1203, train loss: 1.2451969910105434, validation loss: 1.2764202045357746.
epoch: 1204, train loss: 1.2431073484070805, validation loss: 1.272926646730174.
epoch: 1205, train loss: 1.2465970691190946, validation loss: 1.292430421580439.
epoch: 1206, train loss: 1.248592549507771, validation loss: 1.3258398356645003.
epoch: 1207, train loss: 1.2463327110360523, validation loss: 1.2859012717786042.
epoch: 1208, train loss: 1.2470576139765048, validation loss: 1.2634973215020222.
epoch: 1209, train loss: 1.2451260428909863, validation loss: 1.2694607921268628.
epoch: 1210, train loss: 1.2471241010438412, validation loss: 1.2639981974726138.
epoch: 1211, train loss: 1.2688012833988995, validation loss: 1.3019321275793987.
epoch: 1212, train loss: 1.2599567721743103, validation loss: 1.326359230539073.
epoch: 1213, train loss: 1.2553656505882194, validation loss: 1.2688604489616726.
epoch: 1214, train loss: 1.2540005828262468, validation loss: 1.2886940759161245.
epoch: 1215, train loss: 1.2514050783367332, validation loss: 1.2685876307280168.
epoch: 1216, train loss: 1.2497420278164224, validation loss: 1.2710054957348367.
epoch: 1217, train loss: 1.2442641695705028, validation loss: 1.2715120730192766.
epoch: 1218, train loss: 1.2503066314469784, validation loss: 1.2612616342046987.
epoch: 1219, train loss: 1.2499890425883302, validation loss: 1.2606377860774165.
epoch: 1220, train loss: 1.2500969280890368, validation loss: 1.276950478553772.
epoch: 1221, train loss: 1.247172025365567, validation loss: 1.270561264908832.
epoch: 1222, train loss: 1.2450266879632932, validation loss: 1.2860925871392954.
epoch: 1223, train loss: 1.2486495370164923, validation loss: 1.281827968099843.
epoch: 1224, train loss: 1.247681689918588, validation loss: 1.2815192937850952.
epoch: 1225, train loss: 1.24631491166736, validation loss: 1.286070528237716.
epoch: 1226, train loss: 1.2468200528293574, validation loss: 1.285915934521219.
epoch: 1227, train loss: 1.246821603643785, validation loss: 1.2623424374538919.
epoch: 1228, train loss: 1.2458115663003484, validation loss: 1.2575861889383066.
epoch: 1229, train loss: 1.2464216160118033, validation loss: 1.2928500071815823.
epoch: 1230, train loss: 1.2459159848886892, validation loss: 1.2589531722276106.
epoch: 1231, train loss: 1.2475319728938812, validation loss: 1.284064329188803.
epoch: 1232, train loss: 1.2474584940376632, validation loss: 1.2816727990689485.
epoch: 1233, train loss: 1.247461712688481, validation loss: 1.286437734313633.
epoch: 1234, train loss: 1.2456284805175362, validation loss: 1.2731082491252734.
epoch: 1235, train loss: 1.24716591506923, validation loss: 1.2670422636944314.
epoch: 1236, train loss: 1.2463685405363731, validation loss: 1.2618996060412864.
epoch: 1237, train loss: 1.247852821962549, validation loss: 1.2733855558478313.
epoch: 1238, train loss: 1.2479781043638878, validation loss: 1.271383549856103.
epoch: 1239, train loss: 1.2455236222765862, validation loss: 1.2743820625802744.
epoch: 1240, train loss: 1.2514408553412202, validation loss: 1.293917785520139.
epoch: 1241, train loss: 1.2517283706490052, validation loss: 1.2730672100315923.
epoch: 1242, train loss: 1.2493075876060975, validation loss: 1.2706427677817966.
epoch: 1243, train loss: 1.2467995335202697, validation loss: 1.2743604286857273.
epoch: 1244, train loss: 1.2472562166528964, validation loss: 1.275068355643231.
epoch: 1245, train loss: 1.2464372947675373, validation loss: 1.2766881040904834.
epoch: 1246, train loss: 1.2524094800336645, validation loss: 1.2798730808755625.
epoch: 1247, train loss: 1.2521805566385251, validation loss: 1.2884405955024387.
epoch: 1248, train loss: 1.2469346676397761, validation loss: 1.27663835235264.
epoch: 1249, train loss: 1.246848173097733, validation loss: 1.2888408640156621.
epoch: 1250, train loss: 1.2468364304358805, validation loss: 1.2826040361238562.
epoch: 1251, train loss: 1.2466360068102496, validation loss: 1.260710586672244.
epoch: 1252, train loss: 1.245284866849217, validation loss: 1.2641019665676614.
epoch: 1253, train loss: 1.2468668703639179, validation loss: 1.2707257529963618.
epoch: 1254, train loss: 1.2454112286961407, validation loss: 1.2638249086297078.
epoch: 1255, train loss: 1.247913603388935, validation loss: 1.2711580214293108.
epoch: 1256, train loss: 1.2480643495507198, validation loss: 1.2762315532435542.
epoch: 1257, train loss: 1.245648614857175, validation loss: 1.269386975661568.
epoch: 1258, train loss: 1.2474101541239186, validation loss: 1.27329393055128.
epoch: 1259, train loss: 1.2545253410251862, validation loss: 1.2937751541966978.
epoch: 1260, train loss: 1.2466485544082222, validation loss: 1.264381978822791.
epoch: 1261, train loss: 1.2451222806895546, validation loss: 1.274851399919261.
epoch: 1262, train loss: 1.2448094700454573, validation loss: 1.264274581618931.
epoch: 1263, train loss: 1.244518936227221, validation loss: 1.2782420801079792.
epoch: 1264, train loss: 1.2457711434145586, validation loss: 1.2736188587935076.
epoch: 1265, train loss: 1.24906518371827, validation loss: 1.3138242234354434.
epoch: 1266, train loss: 1.2516908558136826, validation loss: 1.2784523912098096.
epoch: 1267, train loss: 1.244142733582663, validation loss: 1.2630721278812573.
epoch: 1268, train loss: 1.2472042304660202, validation loss: 1.2662563738615618.
epoch: 1269, train loss: 1.2486135139377839, validation loss: 1.2841585459916487.
epoch: 1270, train loss: 1.2448682599111434, validation loss: 1.273066759109497.
epoch: 1271, train loss: 1.2480756842761958, validation loss: 1.2767179271449214.
epoch: 1272, train loss: 1.246134095235702, validation loss: 1.2736100787701814.
epoch: 1273, train loss: 1.246321752530719, validation loss: 1.293967806774637.
epoch: 1274, train loss: 1.2490283097695867, validation loss: 1.2642630805139956.
epoch: 1275, train loss: 1.2475895848842935, validation loss: 1.2840399534805962.
epoch: 1276, train loss: 1.246423242288992, validation loss: 1.2723085102827654.
epoch: 1277, train loss: 1.2433189787995924, validation loss: 1.263589646505273.
epoch: 1278, train loss: 1.2431628693134413, validation loss: 1.265491060588671.
epoch: 1279, train loss: 1.24771897945929, validation loss: 1.2671906999919726.
epoch: 1280, train loss: 1.245307757220137, validation loss: 1.2847808858622676.
epoch: 1281, train loss: 1.2440512169391738, validation loss: 1.2708289260449617.
epoch: 1282, train loss: 1.2475509906033857, validation loss: 1.373380738755931.
epoch: 1283, train loss: 1.2494470876291257, validation loss: 1.283341267834539.
epoch: 1284, train loss: 1.2457122726177952, validation loss: 1.268197220304738.
epoch: 1285, train loss: 1.2463910153152746, validation loss: 1.3422025545783665.
epoch: 1286, train loss: 1.2464461348472384, validation loss: 1.2677771112193232.
epoch: 1287, train loss: 1.2466004605686993, validation loss: 1.297657240992007.
epoch: 1288, train loss: 1.2466244456964894, validation loss: 1.2739935335905657.
epoch: 1289, train loss: 1.2485237405934464, validation loss: 1.3169105312098628.
epoch: 1290, train loss: 1.2485646687516379, validation loss: 1.2903003329816072.
epoch: 1291, train loss: 1.2459049421712893, validation loss: 1.2598491492478743.
epoch: 1292, train loss: 1.2500584103645536, validation loss: 1.4992622759031213.
epoch: 1293, train loss: 1.2475873647479836, validation loss: 1.2825451208197551.
epoch: 1294, train loss: 1.2469842455802707, validation loss: 1.2622880832008694.
epoch: 1295, train loss: 1.24517340725715, validation loss: 1.2776928310808928.
epoch: 1296, train loss: 1.246118071976058, validation loss: 1.287914955097696.
epoch: 1297, train loss: 1.2456808363625762, validation loss: 1.2735878073650857.
epoch: 1298, train loss: 1.2450807816391691, validation loss: 1.279816798541857.
epoch: 1299, train loss: 1.2532906827576664, validation loss: 1.2685425488845161.
epoch: 1300, train loss: 1.249387217224191, validation loss: 1.3325073200723399.
epoch: 1301, train loss: 1.245378803769383, validation loss: 1.2704401586366736.
epoch: 1302, train loss: 1.2449689272346847, validation loss: 1.263353917909705.
epoch: 1303, train loss: 1.2462348369283414, validation loss: 1.2842977720758189.
epoch: 1304, train loss: 1.2478545761983328, validation loss: 1.2912642022837764.
epoch: 1305, train loss: 1.2460349306054073, validation loss: 1.275863476421522.
epoch: 1306, train loss: 1.2448484536704667, validation loss: 1.264887783838355.
epoch: 1307, train loss: 1.2494984723012381, validation loss: 1.2981449210125466.
epoch: 1308, train loss: 1.2494570596502461, validation loss: 1.2645757353824119.
epoch: 1309, train loss: 1.2492989979752707, validation loss: 1.3218724572140237.
epoch: 1310, train loss: 1.2510678811904488, validation loss: 1.2852446773777837.
epoch: 1311, train loss: 1.2441402629974785, validation loss: 1.288869199545487.
epoch: 1312, train loss: 1.2505472832863485, validation loss: 1.2733980572741965.
epoch: 1313, train loss: 1.2451485679783951, validation loss: 1.2926460815512615.
epoch: 1314, train loss: 1.2451576945978566, validation loss: 1.269532701243525.
epoch: 1315, train loss: 1.2468217009798102, validation loss: 1.2790147532587466.
epoch: 1316, train loss: 1.253086732068193, validation loss: 1.2646901503853176.
epoch: 1317, train loss: 1.2447375474719826, validation loss: 1.2741896225058513.
epoch: 1318, train loss: 1.2490625392406358, validation loss: 1.2881184298059214.
epoch: 1319, train loss: 1.2438774907260859, validation loss: 1.2853035615838093.
epoch: 1320, train loss: 1.2444899694635234, validation loss: 1.2793162957481716.
epoch: 1321, train loss: 1.2521266423234152, validation loss: 1.3499301257340803.
epoch: 1322, train loss: 1.2505066044833681, validation loss: 1.2710270933482959.
epoch: 1323, train loss: 1.2473574187777459, validation loss: 1.2749916263248608.
epoch: 1324, train loss: 1.2465303906606973, validation loss: 1.270402711370717.
epoch: 1325, train loss: 1.2489024597570437, validation loss: 1.2691063829090283.
epoch: 1326, train loss: 1.249903313610532, validation loss: 1.293592095375061.
epoch: 1327, train loss: 1.2456191723499823, validation loss: 1.2665041892424873.
epoch: 1328, train loss: 1.2483380125203263, validation loss: 1.2657798476841138.
epoch: 1329, train loss: 1.2430009437263558, validation loss: 1.2875902341759724.
epoch: 1330, train loss: 1.2471688198387076, validation loss: 1.2687666675318843.
epoch: 1331, train loss: 1.2479945694634673, validation loss: 1.2750541956528374.
epoch: 1332, train loss: 1.2535393555229957, validation loss: 1.2712072185848071.
epoch: 1333, train loss: 1.2474239517789367, validation loss: 1.2608058815417083.
epoch: 1334, train loss: 1.2454920766550466, validation loss: 1.2842070434404456.
epoch: 1335, train loss: 1.2492864328786868, validation loss: 1.2884785973507424.
epoch: 1336, train loss: 1.2470967944608915, validation loss: 1.2780281460803489.
epoch: 1337, train loss: 1.2445810223938127, validation loss: 1.2593271939650825.
epoch: 1338, train loss: 1.2442423663008104, validation loss: 1.2630872881930808.
epoch: 1339, train loss: 1.2447999059607129, validation loss: 1.2615184628445169.
epoch: 1340, train loss: 1.2481281505812198, validation loss: 1.3231834691503774.
epoch: 1341, train loss: 1.2492401162418751, validation loss: 1.2649307354636814.
epoch: 1342, train loss: 1.24572534954876, validation loss: 1.2665478353915007.
epoch: 1343, train loss: 1.2456674291453231, validation loss: 1.2667095868483833.
epoch: 1344, train loss: 1.2478004026850429, validation loss: 1.2903162396472434.
epoch: 1345, train loss: 1.2465998699905676, validation loss: 1.2713078830553137.
epoch: 1346, train loss: 1.249024969722153, validation loss: 1.2715969293013862.
epoch: 1347, train loss: 1.249414836594818, validation loss: 1.279566588609115.
epoch: 1348, train loss: 1.24655308417224, validation loss: 1.2672173717747564.
epoch: 1349, train loss: 1.2455525442000923, validation loss: 1.2635152961896814.
epoch: 1350, train loss: 1.2437981935816074, validation loss: 1.2658756142077239.
epoch: 1351, train loss: 1.2471670295120378, validation loss: 1.2688085825546929.
epoch: 1352, train loss: 1.2487468697609159, validation loss: 1.2774698423302693.
epoch: 1353, train loss: 1.2487654587544432, validation loss: 1.282758785330731.
epoch: 1354, train loss: 1.2492956437102152, validation loss: 1.2934695896895037.
epoch: 1355, train loss: 1.2501738990118745, validation loss: 1.274060327073802.
epoch: 1356, train loss: 1.247074948538334, validation loss: 1.2786487807398257.
epoch: 1357, train loss: 1.2439307433749558, validation loss: 1.2658312113388726.
epoch: 1358, train loss: 1.243796437158497, validation loss: 1.268148069796355.
epoch: 1359, train loss: 1.24675487159589, validation loss: 1.271790799887284.
epoch: 1360, train loss: 1.245557226172281, validation loss: 1.2780492098435112.
epoch: 1361, train loss: 1.2466125182055552, validation loss: 1.2663005901419597.
epoch: 1362, train loss: 1.2433638583629503, validation loss: 1.2683776565220044.
epoch: 1363, train loss: 1.245108719265789, validation loss: 1.2626420777776968.
epoch: 1364, train loss: 1.2443800497492519, validation loss: 1.2662101984024048.
epoch: 1365, train loss: 1.2430272681997456, validation loss: 1.272009103194527.
epoch: 1366, train loss: 1.246038787955538, validation loss: 1.2641404452531233.
epoch: 1367, train loss: 1.244121092175125, validation loss: 1.2608055912930032.
epoch: 1368, train loss: 1.2453954438550756, validation loss: 1.2882042345793352.
epoch: 1369, train loss: 1.2615479821458868, validation loss: 1.2652860465257063.
epoch: 1370, train loss: 1.2477563094655308, validation loss: 1.2866796410602073.
epoch: 1371, train loss: 1.2473345732470171, validation loss: 1.2734943472820779.
epoch: 1372, train loss: 1.2464392196147813, validation loss: 1.2787437749945598.
epoch: 1373, train loss: 1.2465001683716381, validation loss: 1.2757479367048845.
epoch: 1374, train loss: 1.2443405608518407, validation loss: 1.2918066771134087.
epoch: 1375, train loss: 1.2472643513198292, validation loss: 1.270303638085075.
epoch: 1376, train loss: 1.2451974044152356, validation loss: 1.2665319701899653.
epoch: 1377, train loss: 1.2505754155850193, validation loss: 1.2948590154233186.
epoch: 1378, train loss: 1.2452572638835382, validation loss: 1.2605213652486387.
epoch: 1379, train loss: 1.2462098084458517, validation loss: 1.2770211541134378.
epoch: 1380, train loss: 1.247258249772798, validation loss: 1.2648546229238096.
epoch: 1381, train loss: 1.2481931524539212, validation loss: 1.3514907774717912.
epoch: 1382, train loss: 1.248688558919714, validation loss: 1.2640772228655608.
epoch: 1383, train loss: 1.2427393394872683, validation loss: 1.2600610048874565.
epoch: 1384, train loss: 1.2433552949800404, validation loss: 1.2578382388405178.
epoch: 1385, train loss: 1.2426533403746578, validation loss: 1.2667182683944702.
epoch: 1386, train loss: 1.2448238145320787, validation loss: 1.2878975038943083.
epoch: 1387, train loss: 1.249892810069093, validation loss: 1.2656701440396516.
epoch: 1388, train loss: 1.2440120134878596, validation loss: 1.264153724131377.
epoch: 1389, train loss: 1.2445444809187443, validation loss: 1.2787501345510068.
epoch: 1390, train loss: 1.2454992051518292, validation loss: 1.2861796202866926.
epoch: 1391, train loss: 1.243577284550448, validation loss: 1.2827091476191645.
epoch: 1392, train loss: 1.244638167390036, validation loss: 1.2794839765714563.
epoch: 1393, train loss: 1.2582463288525922, validation loss: 1.2896944854570471.
epoch: 1394, train loss: 1.2519682284888871, validation loss: 1.268570925878442.
epoch: 1395, train loss: 1.2472981094220363, validation loss: 1.2824204900990361.
epoch: 1396, train loss: 1.2524221315296418, validation loss: 1.2749733562054841.
epoch: 1397, train loss: 1.2531897245197121, validation loss: 1.3134743441706118.
epoch: 1398, train loss: 1.25446280317569, validation loss: 1.275241680767225.
epoch: 1399, train loss: 1.2508293160604775, validation loss: 1.2651592959528384.
epoch: 1400, train loss: 1.246969942652851, validation loss: 1.2675455497658772.
epoch: 1401, train loss: 1.2477440123164325, validation loss: 1.2795457891795947.
epoch: 1402, train loss: 1.2498930517686617, validation loss: 1.2924512728400852.
epoch: 1403, train loss: 1.2496694304527494, validation loss: 1.260669443918311.
epoch: 1404, train loss: 1.2485769210605446, validation loss: 1.2679897339447685.
epoch: 1405, train loss: 1.2511576031326155, validation loss: 1.265464616858441.
epoch: 1406, train loss: 1.253978697531814, validation loss: 1.2634706704512886.
epoch: 1407, train loss: 1.2459035947782184, validation loss: 1.2741044293279233.
epoch: 1408, train loss: 1.251117462411933, validation loss: 1.3233159054880557.
epoch: 1409, train loss: 1.2470684073386935, validation loss: 1.2719735062640647.
epoch: 1410, train loss: 1.2492598513944433, validation loss: 1.273112820542377.
epoch: 1411, train loss: 1.2455336008596858, validation loss: 1.2678749716800193.
epoch: 1412, train loss: 1.2439171786702008, validation loss: 1.2672536165817925.
epoch: 1413, train loss: 1.2438122230932254, validation loss: 1.2618739967760833.
epoch: 1414, train loss: 1.2462535079466093, validation loss: 1.2612279809039573.
epoch: 1415, train loss: 1.244514485017969, validation loss: 1.2661809454793516.
epoch: 1416, train loss: 1.2441686566816557, validation loss: 1.2678481081257695.
epoch: 1417, train loss: 1.24440044984905, validation loss: 1.3103614941887234.
epoch: 1418, train loss: 1.2494812952269108, validation loss: 1.277618460033251.
epoch: 1419, train loss: 1.243876608139878, validation loss: 1.281558228575665.
epoch: 1420, train loss: 1.2413678530159347, validation loss: 1.2786466764367146.
epoch: 1421, train loss: 1.2426450657188346, validation loss: 1.2614827156066895.
epoch: 1422, train loss: 1.2454484176198277, validation loss: 1.2721362010292385.
epoch: 1423, train loss: 1.2433139851333899, validation loss: 1.2764753258746604.
epoch: 1424, train loss: 1.2459675861061166, validation loss: 1.2648876905441284.
epoch: 1425, train loss: 1.2450406245135386, validation loss: 1.2705989143122798.
epoch: 1426, train loss: 1.2459584343324013, validation loss: 1.2762487919434258.
epoch: 1427, train loss: 1.2468876893367242, validation loss: 1.2895152827967769.
epoch: 1428, train loss: 1.2484569451130858, validation loss: 1.2676404559093972.
epoch: 1429, train loss: 1.244844637879538, validation loss: 1.2732593080271846.
epoch: 1430, train loss: 1.2477711034477303, validation loss: 1.2669203696043596.
epoch: 1431, train loss: 1.2478807825560962, validation loss: 1.2632631063461304.
epoch: 1432, train loss: 1.244209626399049, validation loss: 1.3892143083655315.
epoch: 1433, train loss: 1.2491284313551876, validation loss: 1.2890699894531914.
epoch: 1434, train loss: 1.2445420026779175, validation loss: 1.2807338911554087.
epoch: 1435, train loss: 1.2453827245519795, validation loss: 1.2772512124932331.
epoch: 1436, train loss: 1.2765182869150005, validation loss: 1.3125342182491138.
epoch: 1437, train loss: 1.2663458159210486, validation loss: 1.2777719964151797.
epoch: 1438, train loss: 1.2534249244479958, validation loss: 1.2758757549783457.
epoch: 1439, train loss: 1.25089952595737, validation loss: 1.2826148686201677.
epoch: 1440, train loss: 1.2491331581675678, validation loss: 1.2690559573795483.
epoch: 1441, train loss: 1.2476133436238, validation loss: 1.2626777161722598.
epoch: 1442, train loss: 1.2474575983274967, validation loss: 1.272660141405852.
epoch: 1443, train loss: 1.2448859160099555, validation loss: 1.2679878058640852.
epoch: 1444, train loss: 1.2431313018186376, validation loss: 1.2607619969741157.
epoch: 1445, train loss: 1.2437740105007766, validation loss: 1.2759952700656394.
epoch: 1446, train loss: 1.2460861731013027, validation loss: 1.2703968545664912.
epoch: 1447, train loss: 1.241839368408973, validation loss: 1.2636879527050515.
epoch: 1448, train loss: 1.245575982496279, validation loss: 1.2539740023405657.
epoch: 1449, train loss: 1.2467172473942467, validation loss: 1.272353514381077.
epoch: 1450, train loss: 1.2445601717047734, validation loss: 1.2619037317193074.
epoch: 1451, train loss: 1.2447371078193734, validation loss: 1.2731400261754575.
epoch: 1452, train loss: 1.2449106043631877, validation loss: 1.2723067117773967.
epoch: 1453, train loss: 1.2468341873326432, validation loss: 1.274494425110195.
epoch: 1454, train loss: 1.2463141625080634, validation loss: 1.2585259727809741.
epoch: 1455, train loss: 1.2482360579551908, validation loss: 1.2857166787852412.
epoch: 1456, train loss: 1.2467741627211963, validation loss: 1.2655205933944038.
epoch: 1457, train loss: 1.2447947635563141, validation loss: 1.2712688135064167.
epoch: 1458, train loss: 1.2474355806998156, validation loss: 1.2670871848645417.
epoch: 1459, train loss: 1.2466790173031868, validation loss: 1.2763992807139521.
epoch: 1460, train loss: 1.2421417815969624, validation loss: 1.2604311549145242.
epoch: 1461, train loss: 1.2455269371697661, validation loss: 1.2715450836264568.
epoch: 1462, train loss: 1.2460926060282855, validation loss: 1.447071998015694.
epoch: 1463, train loss: 1.2474822691821177, validation loss: 1.3144915052082227.
epoch: 1464, train loss: 1.2442424253586235, validation loss: 1.2926934594693391.
epoch: 1465, train loss: 1.2477702285171648, validation loss: 1.2623498698939448.
epoch: 1466, train loss: 1.2458382615255654, validation loss: 1.2649298128874407.
epoch: 1467, train loss: 1.246538725467997, validation loss: 1.2785115449324898.
epoch: 1468, train loss: 1.2443724389469952, validation loss: 1.2683112051175989.
epoch: 1469, train loss: 1.2437553219838973, validation loss: 1.2867374161015386.
epoch: 1470, train loss: 1.2474569486915519, validation loss: 1.2737201244934746.
epoch: 1471, train loss: 1.2445947664593338, validation loss: 1.266339483468429.
epoch: 1472, train loss: 1.2447793122825273, validation loss: 1.261106066081835.
epoch: 1473, train loss: 1.2468916669898076, validation loss: 1.2729275796724402.
epoch: 1474, train loss: 1.2483829981690153, validation loss: 1.2805222272872925.
epoch: 1475, train loss: 1.2443494829562827, validation loss: 1.3213581002276877.
epoch: 1476, train loss: 1.2508811469471783, validation loss: 1.2547959037449048.
epoch: 1477, train loss: 1.245113476700739, validation loss: 1.2823736408482427.
epoch: 1478, train loss: 1.2455994568833517, validation loss: 1.2865464272706404.
epoch: 1479, train loss: 1.2433208970848573, validation loss: 1.269422753997471.
epoch: 1480, train loss: 1.241433303290551, validation loss: 1.281266046606976.
epoch: 1481, train loss: 1.2437611840186862, validation loss: 1.265290996302729.
epoch: 1482, train loss: 1.2459475764440835, validation loss: 1.257536820743395.
epoch: 1483, train loss: 1.2454977855769866, validation loss: 1.2785243625226228.
epoch: 1484, train loss: 1.2443392615799511, validation loss: 1.2618795736976292.
epoch: 1485, train loss: 1.2458057020782332, validation loss: 1.2903990901034812.
epoch: 1486, train loss: 1.2463398460948139, validation loss: 1.2670087710670803.
epoch: 1487, train loss: 1.2518506793800843, validation loss: 1.2775672777839329.
epoch: 1488, train loss: 1.248183826787756, validation loss: 1.2581527699594912.
epoch: 1489, train loss: 1.2452274779660986, validation loss: 1.2955534820971282.
epoch: 1490, train loss: 1.2433610837393945, validation loss: 1.270042466080707.
epoch: 1491, train loss: 1.242772085951009, validation loss: 1.2767686999362449.
epoch: 1492, train loss: 1.2465955467399108, validation loss: 1.2661622399869172.
epoch: 1493, train loss: 1.2472082507719688, validation loss: 1.2767517359360405.
epoch: 1494, train loss: 1.245139701650777, validation loss: 1.2725692572801008.
epoch: 1495, train loss: 1.246376083531511, validation loss: 1.2593789411627727.
epoch: 1496, train loss: 1.2505293745513355, validation loss: 1.2706398186476335.
epoch: 1497, train loss: 1.2458973685535817, validation loss: 1.2593511135681816.
epoch: 1498, train loss: 1.24336723450127, validation loss: 1.2659194262131401.
epoch: 1499, train loss: 1.2468099353510305, validation loss: 1.2742480609727942.
epoch: 1500, train loss: 1.2436593442881874, validation loss: 1.2661071912102078.
epoch: 1501, train loss: 1.2409533207569647, validation loss: 1.276348326517188.
epoch: 1502, train loss: 1.2418642831504891, validation loss: 1.2664700953856758.
epoch: 1503, train loss: 1.2475600887876037, validation loss: 1.2694941137147986.
epoch: 1504, train loss: 1.2464237617790153, validation loss: 1.2638038655985957.
epoch: 1505, train loss: 1.2445646010407614, validation loss: 1.2710470168486885.
epoch: 1506, train loss: 1.2488452250804376, validation loss: 1.2750643906386003.
epoch: 1507, train loss: 1.2435476036246764, validation loss: 1.2639689445495605.
epoch: 1508, train loss: 1.2454420098470986, validation loss: 1.2849246056183525.
epoch: 1509, train loss: 1.2427269296908596, validation loss: 1.2679570861484692.
epoch: 1510, train loss: 1.2481223027640527, validation loss: 1.2821297956549602.
epoch: 1511, train loss: 1.247482794140457, validation loss: 1.2627232385718303.
epoch: 1512, train loss: 1.2422671941442227, validation loss: 1.2822042496308037.
epoch: 1513, train loss: 1.2460443240786911, validation loss: 1.2745601871739263.
epoch: 1514, train loss: 1.2455807628981563, validation loss: 1.274538999018462.
epoch: 1515, train loss: 1.24810966986035, validation loss: 1.2715682724247808.
epoch: 1516, train loss: 1.2458935735422536, validation loss: 1.2680609848188318.
epoch: 1517, train loss: 1.2431020791377496, validation loss: 1.288430965465048.
epoch: 1518, train loss: 1.2460294327604662, validation loss: 1.259760073993517.
epoch: 1519, train loss: 1.2457263743111846, validation loss: 1.2571988779565562.
epoch: 1520, train loss: 1.2466714994623027, validation loss: 1.2668725407641868.
epoch: 1521, train loss: 1.2444636613950817, validation loss: 1.263265785963639.
epoch: 1522, train loss: 1.2514719930263833, validation loss: 1.3247109392414922.
epoch: 1523, train loss: 1.2504420302329806, validation loss: 1.27088098940642.
epoch: 1524, train loss: 1.2442121319814559, validation loss: 1.2598761838415395.
epoch: 1525, train loss: 1.2418960081327945, validation loss: 1.2593327449715657.
epoch: 1526, train loss: 1.2464593375494721, validation loss: 1.2713782528172368.
epoch: 1527, train loss: 1.2477623727343499, validation loss: 1.263646177623583.
epoch: 1528, train loss: 1.2461170439326434, validation loss: 1.3188686785490618.
epoch: 1529, train loss: 1.250110193130073, validation loss: 1.2753773824028347.
epoch: 1530, train loss: 1.2624536216805835, validation loss: 1.2844564240911733.
epoch: 1531, train loss: 1.251673105659835, validation loss: 1.2792602932971457.
epoch: 1532, train loss: 1.247679400881496, validation loss: 1.276503614757372.
epoch: 1533, train loss: 1.2498374936777517, validation loss: 1.2724585377651711.
epoch: 1534, train loss: 1.2438141195052261, validation loss: 1.2943992459255715.
epoch: 1535, train loss: 1.2460783446600678, validation loss: 1.2666848172312197.
epoch: 1536, train loss: 1.245810634499296, validation loss: 1.2740127107371455.
epoch: 1537, train loss: 1.2459370313434426, validation loss: 1.2699601753898289.
epoch: 1538, train loss: 1.2431025844101513, validation loss: 1.2687107894731604.
epoch: 1539, train loss: 1.2429630625138588, validation loss: 1.2669423922248508.
epoch: 1540, train loss: 1.2466036956244653, validation loss: 1.2778295485869697.
epoch: 1541, train loss: 1.2437928466621888, validation loss: 1.279655451359956.
epoch: 1542, train loss: 1.242809438924177, validation loss: 1.2696863516517307.
epoch: 1543, train loss: 1.2477341835651923, validation loss: 1.269627850988637.
epoch: 1544, train loss: 1.2442491229521024, validation loss: 1.2547928820485654.
epoch: 1545, train loss: 1.2434052994491858, validation loss: 1.2713357261989429.
epoch: 1546, train loss: 1.2453671934407786, validation loss: 1.2836169937382573.
epoch: 1547, train loss: 1.2421584052777073, validation loss: 1.2703625741212263.
epoch: 1548, train loss: 1.2427225976908973, validation loss: 1.2846388557682866.
epoch: 1549, train loss: 1.2460820817072458, validation loss: 1.2787990621898486.
epoch: 1550, train loss: 1.2438828168659035, validation loss: 1.2700886311738386.
epoch: 1551, train loss: 1.2466824995268375, validation loss: 1.2694677684618079.
epoch: 1552, train loss: 1.2436784691766862, validation loss: 1.2820250573365584.
epoch: 1553, train loss: 1.2439059554983716, validation loss: 1.2679725989051487.
epoch: 1554, train loss: 1.2444970749933786, validation loss: 1.3053955150687175.
epoch: 1555, train loss: 1.2463649850372875, validation loss: 1.2667143811350283.
epoch: 1556, train loss: 1.2455179822554283, validation loss: 1.265300558960956.
epoch: 1557, train loss: 1.2440009609274907, validation loss: 1.2570164618284807.
epoch: 1558, train loss: 1.244379728212269, validation loss: 1.278425501740497.
epoch: 1559, train loss: 1.2430147654419645, validation loss: 1.2679592422817065.
epoch: 1560, train loss: 1.2448720735147458, validation loss: 1.2950916912244714.
epoch: 1561, train loss: 1.2477643522647544, validation loss: 1.2908742842466936.
epoch: 1562, train loss: 1.2466476860396358, validation loss: 1.302335956822271.
epoch: 1563, train loss: 1.248973371785715, validation loss: 1.4212945077730261.
epoch: 1564, train loss: 1.2469532708509252, validation loss: 1.302070861277373.
epoch: 1565, train loss: 1.247655575428534, validation loss: 1.2893543658049211.
epoch: 1566, train loss: 1.2471468907977463, validation loss: 1.2844875325327334.
epoch: 1567, train loss: 1.2426854218911687, validation loss: 1.2590361885402515.
epoch: 1568, train loss: 1.2469418650373407, validation loss: 1.2860364602959675.
epoch: 1569, train loss: 1.244572305898054, validation loss: 1.2635740819184675.
epoch: 1570, train loss: 1.246347470021029, validation loss: 1.2739768909371418.
epoch: 1571, train loss: 1.2466801470572795, validation loss: 1.2599425471347312.
epoch: 1572, train loss: 1.2427182492859867, validation loss: 1.2625726305920144.
epoch: 1573, train loss: 1.2465278478937412, validation loss: 1.287517267724742.
epoch: 1574, train loss: 1.2437623531446544, validation loss: 1.2962015037951262.
epoch: 1575, train loss: 1.2453890940464964, validation loss: 1.265677317329075.
epoch: 1576, train loss: 1.2451910513256668, validation loss: 1.262113648912181.
epoch: 1577, train loss: 1.244696063732882, validation loss: 1.2845897830050925.
epoch: 1578, train loss: 1.245626195855097, validation loss: 1.2640903203383735.
epoch: 1579, train loss: 1.2477477274903463, validation loss: 1.272750051125236.
epoch: 1580, train loss: 1.2447423453724713, validation loss: 1.2739090297533118.
epoch: 1581, train loss: 1.245890139439784, validation loss: 1.3013112441353176.
epoch: 1582, train loss: 1.2467028460371385, validation loss: 1.2718018552531367.
epoch: 1583, train loss: 1.2450213508868435, validation loss: 1.2965894574704377.
epoch: 1584, train loss: 1.2456060779204063, validation loss: 1.263119505799335.
epoch: 1585, train loss: 1.244568178413111, validation loss: 1.273061270299165.
epoch: 1586, train loss: 1.2434189811759038, validation loss: 1.2801391456438147.
epoch: 1587, train loss: 1.242730636115468, validation loss: 1.2621967585190483.
epoch: 1588, train loss: 1.244543131338347, validation loss: 1.5196982881297236.
epoch: 1589, train loss: 1.2458609944089838, validation loss: 1.2595380907473357.
epoch: 1590, train loss: 1.2453704656810936, validation loss: 1.262010341105254.
epoch: 1591, train loss: 1.243539550982484, validation loss: 1.2707979212636533.
epoch: 1592, train loss: 1.2463730814260081, validation loss: 1.2701553469118865.
epoch: 1593, train loss: 1.2451235799614442, validation loss: 1.3044119555017222.
epoch: 1594, train loss: 1.245934035799919, validation loss: 1.2574549135954485.
epoch: 1595, train loss: 1.2464039981912036, validation loss: 1.2808548160221265.
epoch: 1596, train loss: 1.2488622348242944, validation loss: 1.2625561434289683.
epoch: 1597, train loss: 1.2465488341970181, validation loss: 1.2806580636812293.
epoch: 1598, train loss: 1.2465137494813412, validation loss: 1.2576894760131836.
epoch: 1599, train loss: 1.242234415964249, validation loss: 1.2563220366187717.
epoch: 1600, train loss: 1.2432164555295893, validation loss: 1.2638450083525286.
epoch: 1601, train loss: 1.2465439641147578, validation loss: 1.2691407048183938.
epoch: 1602, train loss: 1.2433203939997821, validation loss: 1.2754265899243562.
epoch: 1603, train loss: 1.2419728489097106, validation loss: 1.2696938255558843.
epoch: 1604, train loss: 1.245209597666329, validation loss: 1.2742096133854077.
epoch: 1605, train loss: 1.2480785278005337, validation loss: 1.2590823639994082.
epoch: 1606, train loss: 1.2494680651830972, validation loss: 1.278337043264638.
epoch: 1607, train loss: 1.2454669136519825, validation loss: 1.2788216497587122.
epoch: 1608, train loss: 1.2450370449538624, validation loss: 1.2802438632301663.
epoch: 1609, train loss: 1.2472328691307557, validation loss: 1.2669144195059072.
epoch: 1610, train loss: 1.242600039604607, validation loss: 1.271207130473593.
epoch: 1611, train loss: 1.2463044168752269, validation loss: 1.2659934966460518.
epoch: 1612, train loss: 1.2457751538775383, validation loss: 1.304711129354394.
epoch: 1613, train loss: 1.2468915127832956, validation loss: 1.2660110877907795.
epoch: 1614, train loss: 1.2436204033160427, validation loss: 1.2653407739556355.
epoch: 1615, train loss: 1.24628677280671, validation loss: 1.267686532891315.
epoch: 1616, train loss: 1.2405409287968907, validation loss: 1.275694515394128.
epoch: 1617, train loss: 1.2444742480549245, validation loss: 1.3058847292609836.
epoch: 1618, train loss: 1.2455683837243177, validation loss: 1.28334815605827.
epoch: 1619, train loss: 1.2457231469110612, validation loss: 1.2710978933002637.
epoch: 1620, train loss: 1.2481526300447796, validation loss: 1.2724932691325312.
epoch: 1621, train loss: 1.2458338223466086, validation loss: 1.2847758998041567.
epoch: 1622, train loss: 1.2447949604156914, validation loss: 1.2780316186987835.
epoch: 1623, train loss: 1.2435317750370831, validation loss: 1.277573445568914.
epoch: 1624, train loss: 1.2493474035088075, validation loss: 1.2664090809614763.
epoch: 1625, train loss: 1.245229467339472, validation loss: 1.2545398473739624.
epoch: 1626, train loss: 1.243605316232104, validation loss: 1.2716061395147573.
epoch: 1627, train loss: 1.245244802684959, validation loss: 1.3035292158956113.
epoch: 1628, train loss: 1.2432108122274417, validation loss: 1.2602300540260647.
epoch: 1629, train loss: 1.2474984302433259, validation loss: 1.2690242891726287.
epoch: 1630, train loss: 1.2438827173425517, validation loss: 1.2786834758260976.
epoch: 1631, train loss: 1.3095933220802096, validation loss: 1.3345219622487607.
epoch: 1632, train loss: 1.2835925401897605, validation loss: 1.3113977649937505.
epoch: 1633, train loss: 1.2763444939884572, validation loss: 1.2863685099974922.
epoch: 1634, train loss: 1.2650412452330284, validation loss: 1.2787523943444956.
epoch: 1635, train loss: 1.260011303315469, validation loss: 1.2710463897041653.
epoch: 1636, train loss: 1.2565165615956717, validation loss: 1.272524797398111.
epoch: 1637, train loss: 1.2511680049633762, validation loss: 1.2585159902987273.
epoch: 1638, train loss: 1.2488907564670668, validation loss: 1.2599453822426174.
epoch: 1639, train loss: 1.2506728741007114, validation loss: 1.2765509304792986.
epoch: 1640, train loss: 1.250125230999168, validation loss: 1.2591402997141299.
epoch: 1641, train loss: 1.248563823349979, validation loss: 1.2798066605692324.
epoch: 1642, train loss: 1.2474555291167093, validation loss: 1.2579425210538118.
epoch: 1643, train loss: 1.249549102345738, validation loss: 1.2613426654235176.
epoch: 1644, train loss: 1.2494135187306534, validation loss: 1.2606119850407476.
epoch: 1645, train loss: 1.2466757024100068, validation loss: 1.265432798344156.
epoch: 1646, train loss: 1.245017727580639, validation loss: 1.2648533012555994.
epoch: 1647, train loss: 1.2479524667109918, validation loss: 1.2817245825477268.
epoch: 1648, train loss: 1.247187339931453, validation loss: 1.2875934735588406.
epoch: 1649, train loss: 1.2449119725358595, validation loss: 1.2680300888807878.
epoch: 1650, train loss: 1.2495416293450452, validation loss: 1.2813088997550632.
epoch: 1651, train loss: 1.2465766099614835, validation loss: 1.2762726545333862.
epoch: 1652, train loss: 1.2482903889559824, validation loss: 1.2779103310211846.
epoch: 1653, train loss: 1.2482935638602721, validation loss: 1.2656512830568396.
epoch: 1654, train loss: 1.2480054262581222, validation loss: 1.2660289536351743.
epoch: 1655, train loss: 1.2480011084757814, validation loss: 1.2670795554700105.
epoch: 1656, train loss: 1.2434303826148356, validation loss: 1.2805176817852517.
epoch: 1657, train loss: 1.24959907509865, validation loss: 1.2947609009950056.
epoch: 1658, train loss: 1.2471743264329542, validation loss: 1.2612922502600628.
epoch: 1659, train loss: 1.2462893768188057, validation loss: 1.2587783699450286.
epoch: 1660, train loss: 1.2468035078923636, validation loss: 1.2751569333283796.
epoch: 1661, train loss: 1.2447056825007867, validation loss: 1.2692666053771973.
epoch: 1662, train loss: 1.2444143907739482, validation loss: 1.2594846901686296.
epoch: 1663, train loss: 1.2444462951170194, validation loss: 1.276657197786414.
epoch: 1664, train loss: 1.2480248497166764, validation loss: 1.2813059298888496.
epoch: 1665, train loss: 1.2466722081560608, validation loss: 1.2669857999552852.
epoch: 1666, train loss: 1.2491918036697107, validation loss: 1.2840038382488748.
epoch: 1667, train loss: 1.2523361816318757, validation loss: 1.2814364174137944.
epoch: 1668, train loss: 1.2475725882643953, validation loss: 1.3470657286436662.
epoch: 1669, train loss: 1.25118273223212, validation loss: 1.2648533634517505.
epoch: 1670, train loss: 1.2445806680469338, validation loss: 1.270962093187415.
epoch: 1671, train loss: 1.2438993902381408, validation loss: 1.272927367168924.
epoch: 1672, train loss: 1.2470550099644093, validation loss: 1.3078373359597248.
epoch: 1673, train loss: 1.247390780973872, validation loss: 1.2718209546545278.
epoch: 1674, train loss: 1.2464806016432035, validation loss: 1.2619960981866587.
epoch: 1675, train loss: 1.247020859237111, validation loss: 1.2625590044519175.
epoch: 1676, train loss: 1.2454935027918685, validation loss: 1.2773147406785383.
epoch: 1677, train loss: 1.2439166963647266, validation loss: 1.2522461051526277.
epoch: 1678, train loss: 1.2413931581952156, validation loss: 1.257892308027848.
epoch: 1679, train loss: 1.2488657115796291, validation loss: 1.2679121235142583.
epoch: 1680, train loss: 1.2412010934374749, validation loss: 1.2614797250084255.
epoch: 1681, train loss: 1.2435192493123746, validation loss: 1.268872038177822.
epoch: 1682, train loss: 1.2461185641245012, validation loss: 1.283369779586792.
epoch: 1683, train loss: 1.245675072757476, validation loss: 1.2595155342765476.
epoch: 1684, train loss: 1.244349205165828, validation loss: 1.3311335625855818.
epoch: 1685, train loss: 1.244420785422719, validation loss: 1.2590953007988308.
epoch: 1686, train loss: 1.2486224097943088, validation loss: 1.3071435016134512.
epoch: 1687, train loss: 1.2455703873153126, validation loss: 1.2760627477065376.
epoch: 1688, train loss: 1.2503159046173096, validation loss: 1.2757143145022185.
epoch: 1689, train loss: 1.245220952077743, validation loss: 1.2724512919135715.
epoch: 1690, train loss: 1.2457337018546708, validation loss: 1.2741493245829707.
epoch: 1691, train loss: 1.2445751581716975, validation loss: 1.2750845992046853.
epoch: 1692, train loss: 1.242978615498324, validation loss: 1.2683760083240012.
epoch: 1693, train loss: 1.2454859335488135, validation loss: 1.2781825169273044.
epoch: 1694, train loss: 1.24261180632705, validation loss: 1.26076965228371.
epoch: 1695, train loss: 1.242157710801571, validation loss: 1.301074541133383.
epoch: 1696, train loss: 1.2454526041625837, validation loss: 1.2758386135101318.
epoch: 1697, train loss: 1.242725091243009, validation loss: 1.2616758398387744.
epoch: 1698, train loss: 1.244816500112551, validation loss: 1.267014353171639.
epoch: 1699, train loss: 1.2483254113328566, validation loss: 1.2713391521702642.
epoch: 1700, train loss: 1.244742228350508, validation loss: 1.2657366420911706.
epoch: 1701, train loss: 1.2456411681043993, validation loss: 1.4420824776525083.
epoch: 1702, train loss: 1.246398460974387, validation loss: 1.3219994099243828.
epoch: 1703, train loss: 1.2431488299588545, validation loss: 1.2794770209685615.
epoch: 1704, train loss: 1.2459045747004518, validation loss: 1.2588630085406096.
epoch: 1705, train loss: 1.2458670893940358, validation loss: 1.2637653143509575.
epoch: 1706, train loss: 1.2478673644022111, validation loss: 1.269737746404565.
epoch: 1707, train loss: 1.2446714956826026, validation loss: 1.2801596703736677.
epoch: 1708, train loss: 1.2460026642598143, validation loss: 1.2720017847807512.
epoch: 1709, train loss: 1.2459366977761646, validation loss: 1.27490002176036.
epoch: 1710, train loss: 1.2459038386651136, validation loss: 1.2876028599946394.
epoch: 1711, train loss: 1.2485363013153776, validation loss: 1.2714920976887578.
epoch: 1712, train loss: 1.2469951176862104, validation loss: 1.3070765837379124.
epoch: 1713, train loss: 1.24520529410161, validation loss: 1.2858605747637541.
epoch: 1714, train loss: 1.246088601033622, validation loss: 1.2729970216751099.
epoch: 1715, train loss: 1.2444415409630591, validation loss: 1.2750968725784966.
epoch: 1716, train loss: 1.2455895056418322, validation loss: 1.2750307580699092.
epoch: 1717, train loss: 1.2446920762368299, validation loss: 1.2588261106739873.
epoch: 1718, train loss: 1.2416307051247413, validation loss: 1.2753197887669439.
epoch: 1719, train loss: 1.245742135091659, validation loss: 1.2704267398170803.
epoch: 1720, train loss: 1.24467241217237, validation loss: 1.274897549463355.
epoch: 1721, train loss: 1.2451085945881835, validation loss: 1.2670116424560547.
epoch: 1722, train loss: 1.2442124524247755, validation loss: 1.2686399376910666.
epoch: 1723, train loss: 1.2418832560198023, validation loss: 1.2813053753065027.
epoch: 1724, train loss: 1.2425646945970867, validation loss: 1.2712505485700525.
epoch: 1725, train loss: 1.2419716655661206, validation loss: 1.2798495603644329.
epoch: 1726, train loss: 1.2442466589288974, validation loss: 1.2636280215304831.
epoch: 1727, train loss: 1.2441651099318758, validation loss: 1.2809828416160915.
epoch: 1728, train loss: 1.2444225560634508, validation loss: 1.2652893843858137.
epoch: 1729, train loss: 1.240931029713482, validation loss: 1.2779121139775151.
epoch: 1730, train loss: 1.246101738116063, validation loss: 1.2562952663587488.
epoch: 1731, train loss: 1.2434366678972857, validation loss: 1.272701973500459.
epoch: 1732, train loss: 1.242674956627942, validation loss: 1.2997416413348655.
epoch: 1733, train loss: 1.2447931591523897, validation loss: 1.3064171179481174.
epoch: 1734, train loss: 1.251566842061664, validation loss: 1.2697510408318562.
epoch: 1735, train loss: 1.2449623532251481, validation loss: 1.2727778787198274.
epoch: 1736, train loss: 1.2439959585119824, validation loss: 1.2626681431480076.
epoch: 1737, train loss: 1.2420289746118247, validation loss: 1.267280884411024.
epoch: 1738, train loss: 1.2428488403285316, validation loss: 1.3106046448583188.
epoch: 1739, train loss: 1.2434641461853588, validation loss: 1.2595661101133928.
epoch: 1740, train loss: 1.2431242476909532, validation loss: 1.2658841609954834.
epoch: 1741, train loss: 1.2481966663938049, validation loss: 1.2818665504455566.
epoch: 1742, train loss: 1.2431465212358248, validation loss: 1.269232786220053.
epoch: 1743, train loss: 1.2438387641119302, validation loss: 1.2766986618871274.
epoch: 1744, train loss: 1.2487500359158996, validation loss: 1.2877422001050867.
epoch: 1745, train loss: 1.2495350236192755, validation loss: 1.2611318930335667.
epoch: 1746, train loss: 1.244643856626038, validation loss: 1.2800914463789568.
epoch: 1747, train loss: 1.2455594102177052, validation loss: 1.27165833245153.
epoch: 1748, train loss: 1.243874133180041, validation loss: 1.2658649372017903.
epoch: 1749, train loss: 1.2469244528254237, validation loss: 1.2654342081235803.
epoch: 1750, train loss: 1.2463002915776105, validation loss: 1.2688562973685886.
epoch: 1751, train loss: 1.2438892038590317, validation loss: 1.2679513278214827.
epoch: 1752, train loss: 1.242477217945484, validation loss: 1.257007650707079.
epoch: 1753, train loss: 1.2437163383588878, validation loss: 1.2655090663744055.
epoch: 1754, train loss: 1.2435569347591575, validation loss: 1.3011649691540261.
epoch: 1755, train loss: 1.2452537565056336, validation loss: 1.265852943710659.
epoch: 1756, train loss: 1.2439468388163715, validation loss: 1.3060609309569648.
epoch: 1757, train loss: 1.2450568140099902, validation loss: 1.2678816214851711.
epoch: 1758, train loss: 1.2449914523220937, validation loss: 1.268855913825657.
epoch: 1759, train loss: 1.3063130739632003, validation loss: 1.4329929559127144.
epoch: 1760, train loss: 1.294810054499075, validation loss: 1.3195496642071267.
epoch: 1761, train loss: 1.2779252715067033, validation loss: 1.2914569429729297.
epoch: 1762, train loss: 1.2663283282463704, validation loss: 1.301446567411008.
epoch: 1763, train loss: 1.2555162501991342, validation loss: 1.278841319291488.
epoch: 1764, train loss: 1.2544366799363302, validation loss: 1.2740810228430706.
epoch: 1765, train loss: 1.2629906464060512, validation loss: 1.2658432618431423.
epoch: 1766, train loss: 1.253996164426891, validation loss: 1.2704624196757441.
epoch: 1767, train loss: 1.2504320100906792, validation loss: 1.265879257865574.
epoch: 1768, train loss: 1.2512214194744005, validation loss: 1.2705326598623525.
epoch: 1769, train loss: 1.248278370691002, validation loss: 1.2834622341653574.
epoch: 1770, train loss: 1.247409262788405, validation loss: 1.258060476054316.
epoch: 1771, train loss: 1.2455450963536534, validation loss: 1.2709440925846929.
epoch: 1772, train loss: 1.2462225485285487, validation loss: 1.2555846856987996.
epoch: 1773, train loss: 1.2458269355493947, validation loss: 1.2653127960536792.
epoch: 1774, train loss: 1.246570797141539, validation loss: 1.2643885560657666.
epoch: 1775, train loss: 1.2451255638665015, validation loss: 1.269667651342309.
epoch: 1776, train loss: 1.2455022466292076, validation loss: 1.2624326374219812.
epoch: 1777, train loss: 1.2463443158963405, validation loss: 1.2936743705169014.
epoch: 1778, train loss: 1.2472151911586797, validation loss: 1.2738490622976553.
epoch: 1779, train loss: 1.2450861482445252, validation loss: 1.2729492239330127.
epoch: 1780, train loss: 1.2461827676230615, validation loss: 1.2699384844821433.
epoch: 1781, train loss: 1.2467245902490178, validation loss: 1.268386317336041.
epoch: 1782, train loss: 1.2459580428009733, validation loss: 1.3196325250293897.
epoch: 1783, train loss: 1.2480053190791278, validation loss: 1.3581195810566777.
epoch: 1784, train loss: 1.2582068891700255, validation loss: 1.2689988872279292.
epoch: 1785, train loss: 1.2481208700652515, validation loss: 1.264910744584125.
epoch: 1786, train loss: 1.2431031060875009, validation loss: 1.2672199788300886.
epoch: 1787, train loss: 1.2457976866205898, validation loss: 1.2681373979734338.
epoch: 1788, train loss: 1.2440603030930966, validation loss: 1.2754539251327515.
epoch: 1789, train loss: 1.2453329377218123, validation loss: 1.2704888167588606.
epoch: 1790, train loss: 1.2451297022880765, validation loss: 1.2688782266948535.
epoch: 1791, train loss: 1.2466848738696596, validation loss: 1.2983461462933084.
epoch: 1792, train loss: 1.246488163230616, validation loss: 1.263464585594509.
epoch: 1793, train loss: 1.2440622312213303, validation loss: 1.2690269014109736.
epoch: 1794, train loss: 1.2480604593906928, validation loss: 1.281331435493801.
epoch: 1795, train loss: 1.246254083213456, validation loss: 1.283387303352356.
epoch: 1796, train loss: 1.2462163408961864, validation loss: 1.2677822527678118.
epoch: 1797, train loss: 1.2429770635902335, validation loss: 1.2648483203805012.
epoch: 1798, train loss: 1.2442195393623563, validation loss: 1.2694306425426318.
epoch: 1799, train loss: 1.2454339320506524, validation loss: 1.2560413661210432.
epoch: 1800, train loss: 1.2427432777684764, validation loss: 1.279018759727478.
epoch: 1801, train loss: 1.2443260129438627, validation loss: 1.270756508993066.
epoch: 1802, train loss: 1.2436780546783308, validation loss: 1.2677684659543245.
epoch: 1803, train loss: 1.2442605243910343, validation loss: 1.2650147883788398.
epoch: 1804, train loss: 1.2451156421538887, validation loss: 1.28192022572393.
epoch: 1805, train loss: 1.2503204181653644, validation loss: 1.4288914514624553.
epoch: 1806, train loss: 1.2557426887914676, validation loss: 1.2779255068820456.
epoch: 1807, train loss: 1.2480724678127044, validation loss: 1.3105104954346367.
epoch: 1808, train loss: 1.2473815602993747, validation loss: 1.2662611215010933.
epoch: 1809, train loss: 1.2448182248194284, validation loss: 1.2709865207257478.
epoch: 1810, train loss: 1.243037699559413, validation loss: 1.2673356222069783.
epoch: 1811, train loss: 1.2529159040626037, validation loss: 1.3503408483836963.
epoch: 1812, train loss: 1.2564589539799123, validation loss: 1.2834497949351436.
epoch: 1813, train loss: 1.2477081182899825, validation loss: 1.258933134700941.
epoch: 1814, train loss: 1.2477454034560318, validation loss: 1.2625722107679949.
epoch: 1815, train loss: 1.2482938372760737, validation loss: 1.2859660283378933.
epoch: 1816, train loss: 1.2489947299344824, validation loss: 1.2648029845693838.
epoch: 1817, train loss: 1.2447309329969074, validation loss: 1.2672707982685254.
epoch: 1818, train loss: 1.2439667511423793, validation loss: 1.2880674082299937.
epoch: 1819, train loss: 1.2432020990126724, validation loss: 1.2557592702948528.
epoch: 1820, train loss: 1.2413036582666799, validation loss: 1.2622827706129656.
epoch: 1821, train loss: 1.2439335125301956, validation loss: 1.2642880626346753.
epoch: 1822, train loss: 1.2467897714824852, validation loss: 1.285822287849758.
epoch: 1823, train loss: 1.243746174584835, validation loss: 1.2581045834914497.
epoch: 1824, train loss: 1.2415808242395383, validation loss: 1.2814349506212317.
epoch: 1825, train loss: 1.2460866050982693, validation loss: 1.2646649557611216.
epoch: 1826, train loss: 1.2450410740091167, validation loss: 1.2591139907422273.
epoch: 1827, train loss: 1.2447363422551285, validation loss: 1.290804992551389.
epoch: 1828, train loss: 1.2441471607313244, validation loss: 1.276032779527747.
epoch: 1829, train loss: 1.2436430487064047, validation loss: 1.2950859899106233.
epoch: 1830, train loss: 1.2479506960702598, validation loss: 1.2851706484089727.
epoch: 1831, train loss: 1.24776888659241, validation loss: 1.2758966217870298.
epoch: 1832, train loss: 1.2490904079664737, validation loss: 1.2778316943541816.
epoch: 1833, train loss: 1.2435016336791012, validation loss: 1.2676357445509538.
epoch: 1834, train loss: 1.2425167112175477, validation loss: 1.2775996042334514.
epoch: 1835, train loss: 1.2424521982122998, validation loss: 1.2884521847185881.
epoch: 1836, train loss: 1.2397328221469843, validation loss: 1.2744061687718267.
epoch: 1837, train loss: 1.248479385988428, validation loss: 1.5918792227040166.
epoch: 1838, train loss: 1.2430851678235815, validation loss: 1.266184371450673.
epoch: 1839, train loss: 1.2415856451069542, validation loss: 1.263648535894311.
epoch: 1840, train loss: 1.245282711239036, validation loss: 1.2594775894413823.
epoch: 1841, train loss: 1.2452518633746226, validation loss: 1.2735454310541567.
epoch: 1842, train loss: 1.2423592379333777, validation loss: 1.2810049989949102.
epoch: 1843, train loss: 1.2472911110711753, validation loss: 1.2616520601770151.
epoch: 1844, train loss: 1.2451542058122267, validation loss: 1.2645864953165469.
epoch: 1845, train loss: 1.243907125718003, validation loss: 1.2599005440007085.
epoch: 1846, train loss: 1.2486622410083035, validation loss: 1.2794104140737783.
epoch: 1847, train loss: 1.2428961729784624, validation loss: 1.2579652692960657.
epoch: 1848, train loss: 1.2483787372571613, validation loss: 1.2749780209168144.
epoch: 1849, train loss: 1.2455921446511504, validation loss: 1.2615884646125461.
epoch: 1850, train loss: 1.2461211320457108, validation loss: 1.2674641661022021.
epoch: 1851, train loss: 1.2450597537766903, validation loss: 1.2701915917189226.
epoch: 1852, train loss: 1.24461169417845, validation loss: 1.2640618552332339.
epoch: 1853, train loss: 1.2434118286185307, validation loss: 1.2709101749503093.
epoch: 1854, train loss: 1.2476055873643368, validation loss: 1.2642224975254224.
epoch: 1855, train loss: 1.245603586555621, validation loss: 1.264281671980153.
epoch: 1856, train loss: 1.2526748355375517, validation loss: 1.2875269755073215.
epoch: 1857, train loss: 1.2457443716329173, validation loss: 1.2653688762498938.
epoch: 1858, train loss: 1.244088624595502, validation loss: 1.2624662959057351.
epoch: 1859, train loss: 1.2424033913043662, validation loss: 1.268062332402105.
epoch: 1860, train loss: 1.2449985020751253, validation loss: 1.291327160337697.
epoch: 1861, train loss: 1.243451365637123, validation loss: 1.2669241998506628.
epoch: 1862, train loss: 1.2444130915020584, validation loss: 1.2713273815486743.
epoch: 1863, train loss: 1.2431900894969976, validation loss: 1.2841903126758079.
epoch: 1864, train loss: 1.2457417107503348, validation loss: 1.2671237562013709.
epoch: 1865, train loss: 1.2442630955932337, validation loss: 1.2769822296888933.
epoch: 1866, train loss: 1.2512873247129108, validation loss: 1.2733246036197827.
epoch: 1867, train loss: 1.2460152523233257, validation loss: 1.2679681259652842.
epoch: 1868, train loss: 1.2441581498592271, validation loss: 1.255184443100639.
epoch: 1869, train loss: 1.2440355327151238, validation loss: 1.3420725024264792.
epoch: 1870, train loss: 1.2450353749301455, validation loss: 1.2623468222825422.
epoch: 1871, train loss: 1.241740642337624, validation loss: 1.2691759855850884.
epoch: 1872, train loss: 1.2464038975741885, validation loss: 1.3034464690996252.
epoch: 1873, train loss: 1.2451450627878171, validation loss: 1.2728345705115276.
epoch: 1874, train loss: 1.242765268054577, validation loss: 1.2586213453956272.
epoch: 1875, train loss: 1.240443916495787, validation loss: 1.3419806387113489.
epoch: 1876, train loss: 1.2458793482649217, validation loss: 1.2701609393824702.
epoch: 1877, train loss: 1.24496126940491, validation loss: 1.2591027125068333.
epoch: 1878, train loss: 1.2453440285603934, validation loss: 1.2638491806776628.
epoch: 1879, train loss: 1.2455348421674255, validation loss: 1.2691303336102029.
epoch: 1880, train loss: 1.243184218712903, validation loss: 1.2734634720760842.
epoch: 1881, train loss: 1.2419915275836209, validation loss: 1.269240783608478.
epoch: 1882, train loss: 1.2430796699786404, validation loss: 1.2609044831732046.
epoch: 1883, train loss: 1.2429099739144702, validation loss: 1.2754731385604194.
epoch: 1884, train loss: 1.2419542719464782, validation loss: 1.2801717830740886.
epoch: 1885, train loss: 1.2415803867742556, validation loss: 1.2679226035657136.
epoch: 1886, train loss: 1.2498178657041776, validation loss: 1.2812708253445833.
epoch: 1887, train loss: 1.2447642164492825, validation loss: 1.26956045627594.
epoch: 1888, train loss: 1.2448568617532012, validation loss: 1.268869135690772.
epoch: 1889, train loss: 1.2458332908262901, validation loss: 1.276104035584823.
epoch: 1890, train loss: 1.2442997759635295, validation loss: 1.2775356251260508.
epoch: 1891, train loss: 1.243178187160317, validation loss: 1.2612561142962913.
epoch: 1892, train loss: 1.2441862318493904, validation loss: 1.2659499645233154.
epoch: 1893, train loss: 1.2432649704294467, validation loss: 1.2620858990627786.
epoch: 1894, train loss: 1.245015516193635, validation loss: 1.276150159213854.
epoch: 1895, train loss: 1.2435099017729454, validation loss: 1.3550850101139233.
epoch: 1896, train loss: 1.2419460902520276, validation loss: 1.2702855545541514.
epoch: 1897, train loss: 1.242585327647148, validation loss: 1.2636471779450127.
epoch: 1898, train loss: 1.2427029467503958, validation loss: 1.2685818568519924.
epoch: 1899, train loss: 1.2456363745785635, validation loss: 1.269473645998084.
epoch: 1900, train loss: 1.2831392277271376, validation loss: 1.3805987886760547.
epoch: 1901, train loss: 1.3052764343559196, validation loss: 1.3264936312385227.
epoch: 1902, train loss: 1.2967323535079256, validation loss: 1.3149625062942505.
epoch: 1903, train loss: 1.2821563197932113, validation loss: 1.3005559340767239.
epoch: 1904, train loss: 1.2753106902498719, validation loss: 1.2921829327293064.
epoch: 1905, train loss: 1.2701643202282966, validation loss: 1.2894650594047878.
epoch: 1906, train loss: 1.2690836584896124, validation loss: 1.2941792788712874.
epoch: 1907, train loss: 1.2646263323792624, validation loss: 1.3586201304974763.
epoch: 1908, train loss: 1.2585104999192265, validation loss: 1.2711502520934395.
epoch: 1909, train loss: 1.254173856262767, validation loss: 1.2678979635238647.
epoch: 1910, train loss: 1.2523524640897, validation loss: 1.271683288657147.
epoch: 1911, train loss: 1.2523982098343176, validation loss: 1.2685093879699707.
epoch: 1912, train loss: 1.2513503229946172, validation loss: 1.2883154827615488.
epoch: 1913, train loss: 1.2501952352873775, validation loss: 1.3131992713264797.
epoch: 1914, train loss: 1.250543004875883, validation loss: 1.2725791257360708.
epoch: 1915, train loss: 1.2467827906302356, validation loss: 1.2841137958609539.
epoch: 1916, train loss: 1.2507576975253745, validation loss: 1.2735510183417278.
epoch: 1917, train loss: 1.2514418801036449, validation loss: 1.292721090109452.
epoch: 1918, train loss: 1.2461503733188735, validation loss: 1.2655073974443518.
epoch: 1919, train loss: 1.2471567064250282, validation loss: 1.2702496103618457.
epoch: 1920, train loss: 1.2484334390097802, validation loss: 1.275624244109444.
epoch: 1921, train loss: 1.2483964677250714, validation loss: 1.3032885634380837.
epoch: 1922, train loss: 1.2478800869862967, validation loss: 1.273016297298929.
epoch: 1923, train loss: 1.2455725768290529, validation loss: 1.259702900181646.
epoch: 1924, train loss: 1.2459696421929456, validation loss: 1.275269477263741.
epoch: 1925, train loss: 1.246494274620616, validation loss: 1.2849880975225698.
epoch: 1926, train loss: 1.2438215345417687, validation loss: 1.3014090527658877.
epoch: 1927, train loss: 1.25243333392187, validation loss: 1.264173326284989.
epoch: 1928, train loss: 1.2512594275518294, validation loss: 1.2702376635178276.
epoch: 1929, train loss: 1.249237858921016, validation loss: 1.2630369404087896.
epoch: 1930, train loss: 1.2479606320004943, validation loss: 1.2757929719012717.
epoch: 1931, train loss: 1.248764885674923, validation loss: 1.2812499170717986.
epoch: 1932, train loss: 1.24530539490761, validation loss: 1.2638109093127043.
epoch: 1933, train loss: 1.2469336647506153, validation loss: 1.2747109143630317.
epoch: 1934, train loss: 1.2477874427760414, validation loss: 1.284362642661385.
epoch: 1935, train loss: 1.2443323846257062, validation loss: 1.2773592990377676.
epoch: 1936, train loss: 1.2448594515476752, validation loss: 1.260715541632279.
epoch: 1937, train loss: 1.245998951273227, validation loss: 1.2554358036621758.
epoch: 1938, train loss: 1.2471771469903647, validation loss: 1.2889272233714228.
epoch: 1939, train loss: 1.2452192262772026, validation loss: 1.2715066775031711.
epoch: 1940, train loss: 1.2440565496409706, validation loss: 1.2618678652721902.
epoch: 1941, train loss: 1.2440538811027457, validation loss: 1.2756005059117856.
epoch: 1942, train loss: 1.2454043922074345, validation loss: 1.2703557532766592.
epoch: 1943, train loss: 1.2465778228339799, validation loss: 1.267548540364141.
epoch: 1944, train loss: 1.2449535984511768, validation loss: 1.2654518770134968.
epoch: 1945, train loss: 1.2430738352854318, validation loss: 1.2613226434458857.
epoch: 1946, train loss: 1.2460572938306615, validation loss: 1.2622130176295405.
epoch: 1947, train loss: 1.2446704577962193, validation loss: 1.290434464164402.
epoch: 1948, train loss: 1.247648407559876, validation loss: 1.2601434044215991.
epoch: 1949, train loss: 1.2472826526799332, validation loss: 1.2859028422314187.
epoch: 1950, train loss: 1.2485855522505733, validation loss: 1.2660840801570727.
epoch: 1951, train loss: 1.24643112978804, validation loss: 1.2633645068044248.
epoch: 1952, train loss: 1.2462342736917897, validation loss: 1.262356338293656.
epoch: 1953, train loss: 1.2464493239691499, validation loss: 1.2659943000130032.
epoch: 1954, train loss: 1.2436408187271257, validation loss: 1.2599254846572876.
epoch: 1955, train loss: 1.2467345994546872, validation loss: 1.2910180713819421.
epoch: 1956, train loss: 1.248099081013181, validation loss: 1.2745938819387685.
epoch: 1957, train loss: 1.2446088550287648, validation loss: 1.3455217299254045.
epoch: 1958, train loss: 1.2446858948523845, validation loss: 1.2645356084989465.
epoch: 1959, train loss: 1.2470152279652587, validation loss: 1.2664638550385185.
epoch: 1960, train loss: 1.2444272872504838, validation loss: 1.2705268393392148.
epoch: 1961, train loss: 1.2433763294044984, validation loss: 1.294666482054669.
epoch: 1962, train loss: 1.2463051485359122, validation loss: 1.26211518826692.
epoch: 1963, train loss: 1.244797880496454, validation loss: 1.273004464481188.
epoch: 1964, train loss: 1.2431323965755077, validation loss: 1.2686449341152026.
epoch: 1965, train loss: 1.2426332410322416, validation loss: 1.277300829472749.
epoch: 1966, train loss: 1.2466674660323958, validation loss: 1.271907231082087.
epoch: 1967, train loss: 1.2438502049227373, validation loss: 1.263967032017915.
epoch: 1968, train loss: 1.2453197339259157, validation loss: 1.271254529123721.
epoch: 1969, train loss: 1.2454453105226568, validation loss: 1.2692252397537231.
epoch: 1970, train loss: 1.2453510006633373, validation loss: 1.268587148707846.
epoch: 1971, train loss: 1.2483299008203208, validation loss: 1.2879855062650598.
epoch: 1972, train loss: 1.2468053671198154, validation loss: 1.2659839391708374.
epoch: 1973, train loss: 1.2453446913202968, validation loss: 1.2817570230235225.
epoch: 1974, train loss: 1.2455072304524413, validation loss: 1.3126933678336765.
epoch: 1975, train loss: 1.243621471824996, validation loss: 1.2558517870695696.
epoch: 1976, train loss: 1.2473093686847512, validation loss: 1.2740790273832239.
epoch: 1977, train loss: 1.2458434782990622, validation loss: 1.2832506895065308.
epoch: 1978, train loss: 1.243809181615847, validation loss: 1.2845534397208171.
epoch: 1979, train loss: 1.2476607254885752, validation loss: 1.26956161727076.
epoch: 1980, train loss: 1.2431609193119435, validation loss: 1.3038477742153665.
epoch: 1981, train loss: 1.2435936949668673, validation loss: 1.2746043153431104.
epoch: 1982, train loss: 1.245550586542952, validation loss: 1.3042072990666265.
epoch: 1983, train loss: 1.2434184015344043, validation loss: 1.2659819903581038.
epoch: 1984, train loss: 1.2441598614421459, validation loss: 1.2636799864147021.
epoch: 1985, train loss: 1.2431737807912564, validation loss: 1.2967146064924158.
epoch: 1986, train loss: 1.2484952441049277, validation loss: 1.2723949007366016.
epoch: 1987, train loss: 1.2451963085647022, validation loss: 1.2620525671088176.
epoch: 1988, train loss: 1.246131609339233, validation loss: 1.2701892282651819.
epoch: 1989, train loss: 1.2474006064441225, validation loss: 1.2657024134760317.
epoch: 1990, train loss: 1.246225577975632, validation loss: 1.2702806721562925.
epoch: 1991, train loss: 1.2432986574435452, validation loss: 1.2540958964306375.
epoch: 1992, train loss: 1.2438165146276492, validation loss: 1.3753255294716877.
epoch: 1993, train loss: 1.2447235584259033, validation loss: 1.26254809939343.
epoch: 1994, train loss: 1.2453309439737863, validation loss: 1.264038376186205.
epoch: 1995, train loss: 1.24589940057982, validation loss: 1.2866281685621843.
epoch: 1996, train loss: 1.249871295526487, validation loss: 1.3219196070795474.
epoch: 1997, train loss: 1.2454505579187236, validation loss: 1.2726324952167014.
epoch: 1998, train loss: 1.2435786855330162, validation loss: 1.2812170878700588.
epoch: 1999, train loss: 1.2450221219194044, validation loss: 1.290659873381905.
epoch: 2000, train loss: 1.2397062231641296, validation loss: 1.2480304293010547.
epoch: 2001, train loss: 1.2308680486241612, validation loss: 1.2526737192402715.
epoch: 2002, train loss: 1.230408238708426, validation loss: 1.2438417776771213.
epoch: 2003, train loss: 1.2278266860804428, validation loss: 1.2550609422766643.
epoch: 2004, train loss: 1.2298801328064104, validation loss: 1.243848468946374.
epoch: 2005, train loss: 1.2282088305972039, validation loss: 1.2525353483531787.
epoch: 2006, train loss: 1.2277977674379261, validation loss: 1.2477132341136103.
epoch: 2007, train loss: 1.2284107416047962, validation loss: 1.2445827670719312.
epoch: 2008, train loss: 1.2271841141062045, validation loss: 1.249461521273074.
epoch: 2009, train loss: 1.2276478677714637, validation loss: 1.24452689419622.
epoch: 2010, train loss: 1.2271259541905255, validation loss: 1.2455324245535808.
epoch: 2011, train loss: 1.2268747495948722, validation loss: 1.249735054762467.
epoch: 2012, train loss: 1.2279006188068915, validation loss: 1.2566496341124824.
epoch: 2013, train loss: 1.2258278273661203, validation loss: 1.2561384439468384.
epoch: 2014, train loss: 1.2251905126309177, validation loss: 1.2438634944998699.
epoch: 2015, train loss: 1.2226422850145113, validation loss: 1.2435209906619529.
epoch: 2016, train loss: 1.2263273591295294, validation loss: 1.242256304492121.
epoch: 2017, train loss: 1.2277271441363413, validation loss: 1.247110885122548.
epoch: 2018, train loss: 1.2236712263264786, validation loss: 1.2504165794538415.
epoch: 2019, train loss: 1.2243611495429223, validation loss: 1.2436014569323997.
epoch: 2020, train loss: 1.226517016734552, validation loss: 1.2732531039611152.
epoch: 2021, train loss: 1.2250025742644564, validation loss: 1.251780250798101.
epoch: 2022, train loss: 1.2234022617340088, validation loss: 1.247019042139468.
epoch: 2023, train loss: 1.2250565421690636, validation loss: 1.2480612682259602.
epoch: 2024, train loss: 1.2261613673026408, validation loss: 1.2492763633313386.
epoch: 2025, train loss: 1.2266926863871583, validation loss: 1.258989577708037.
epoch: 2026, train loss: 1.223762288006074, validation loss: 1.2619803418283877.
epoch: 2027, train loss: 1.2247593982504048, validation loss: 1.2649433405502983.
epoch: 2028, train loss: 1.2281287164863097, validation loss: 1.2641038687332817.
epoch: 2029, train loss: 1.2268192024405944, validation loss: 1.2495685712150906.
epoch: 2030, train loss: 1.2267813015421596, validation loss: 1.2523930642915808.
epoch: 2031, train loss: 1.2251256912126454, validation loss: 1.2515020007672517.
epoch: 2032, train loss: 1.2247455995017236, validation loss: 1.249730047972306.
epoch: 2033, train loss: 1.2238406194459408, validation loss: 1.2553577941396963.
epoch: 2034, train loss: 1.2254981316557718, validation loss: 1.2409673929214478.
epoch: 2035, train loss: 1.2240425249852172, validation loss: 1.2386433715405671.
epoch: 2036, train loss: 1.225164596093904, validation loss: 1.2482089685357136.
epoch: 2037, train loss: 1.2248537299829885, validation loss: 1.2470132682634436.
epoch: 2038, train loss: 1.2214727543909616, validation loss: 1.2456780412922734.
epoch: 2039, train loss: 1.2251351699916595, validation loss: 1.245434512262759.
epoch: 2040, train loss: 1.2230457319032162, validation loss: 1.242189858270728.
epoch: 2041, train loss: 1.2233372554866546, validation loss: 1.2426544635192207.
epoch: 2042, train loss: 1.2233989359041966, validation loss: 1.2485488238541975.
epoch: 2043, train loss: 1.2243129452434154, validation loss: 1.2535023741100146.
epoch: 2044, train loss: 1.224074104510316, validation loss: 1.2494037358657173.
epoch: 2045, train loss: 1.2230161690930708, validation loss: 1.2483881711959839.
epoch: 2046, train loss: 1.2226395224212507, validation loss: 1.2505311136660369.
epoch: 2047, train loss: 1.2256712115139043, validation loss: 1.2933112279228542.
epoch: 2048, train loss: 1.223564862111293, validation loss: 1.2486225470252659.
epoch: 2049, train loss: 1.2228958934818932, validation loss: 1.2688914589259936.
epoch: 2050, train loss: 1.2244433383329199, validation loss: 1.246899241986482.
epoch: 2051, train loss: 1.2239452086457419, validation loss: 1.2532535065775332.
epoch: 2052, train loss: 1.222159399898774, validation loss: 1.2731250887331755.
epoch: 2053, train loss: 1.2278325065560298, validation loss: 1.2821597482847131.
epoch: 2054, train loss: 1.2237994911473826, validation loss: 1.2458394714023755.
epoch: 2055, train loss: 1.2233378493457758, validation loss: 1.261630882387576.
epoch: 2056, train loss: 1.2259752192628492, validation loss: 1.2557015159855718.
epoch: 2057, train loss: 1.2289135073303084, validation loss: 1.2502898133319358.
epoch: 2058, train loss: 1.2274751641334745, validation loss: 1.2432019192239512.
epoch: 2059, train loss: 1.2261835030459483, validation loss: 1.2459231770556907.
epoch: 2060, train loss: 1.2248401204380421, validation loss: 1.2437425178030264.
epoch: 2061, train loss: 1.2219787857948092, validation loss: 1.2456640782563582.
epoch: 2062, train loss: 1.2280757416278945, validation loss: 1.241928903952889.
epoch: 2063, train loss: 1.221814820525843, validation loss: 1.2421036958694458.
epoch: 2064, train loss: 1.2243726472242162, validation loss: 1.2656838945720508.
epoch: 2065, train loss: 1.2235405893500793, validation loss: 1.2433818786040596.
epoch: 2066, train loss: 1.224778715623628, validation loss: 1.2534134439800098.
epoch: 2067, train loss: 1.2224184449659574, validation loss: 1.2497105287468953.
epoch: 2068, train loss: 1.2228792577708534, validation loss: 1.2427973902743796.
epoch: 2069, train loss: 1.2211461953066904, validation loss: 1.2437063507411792.
epoch: 2070, train loss: 1.2238695490250893, validation loss: 1.2522851176883862.
epoch: 2071, train loss: 1.2256135514023108, validation loss: 1.2410413130469944.
epoch: 2072, train loss: 1.2238718336875285, validation loss: 1.2460294028987056.
epoch: 2073, train loss: 1.22323667565617, validation loss: 1.2595426569814268.
epoch: 2074, train loss: 1.2239297223747323, validation loss: 1.2559173003486965.
epoch: 2075, train loss: 1.2253299798440496, validation loss: 1.2570736252743264.
epoch: 2076, train loss: 1.223932432472159, validation loss: 1.2482979971429575.
epoch: 2077, train loss: 1.2259748047644938, validation loss: 1.244129522987034.
epoch: 2078, train loss: 1.2214924107997789, validation loss: 1.2524196116820625.
epoch: 2079, train loss: 1.221762983077163, validation loss: 1.2490763664245605.
epoch: 2080, train loss: 1.2222086563022858, validation loss: 1.5586782175561655.
epoch: 2081, train loss: 1.2234897755701608, validation loss: 1.2482106167337168.
epoch: 2082, train loss: 1.2248723277258218, validation loss: 1.2472073306208071.
epoch: 2083, train loss: 1.2236916887650795, validation loss: 1.2452917980111164.
epoch: 2084, train loss: 1.2201577589052532, validation loss: 1.2545515247013257.
epoch: 2085, train loss: 1.2264378092704562, validation loss: 1.2531915436620298.
epoch: 2086, train loss: 1.223689894063757, validation loss: 1.248428401739701.
epoch: 2087, train loss: 1.2226713294282965, validation loss: 1.2531004884968633.
epoch: 2088, train loss: 1.2242397430839889, validation loss: 1.2532325775726982.
epoch: 2089, train loss: 1.2238101948291884, validation loss: 1.244412619134654.
epoch: 2090, train loss: 1.2205782647526593, validation loss: 1.2566724238188371.
epoch: 2091, train loss: 1.2222562350264383, validation loss: 1.2875602608141692.
epoch: 2092, train loss: 1.2248766137919296, validation loss: 1.2392256830049597.
epoch: 2093, train loss: 1.2247388417567682, validation loss: 1.2542002149250195.
epoch: 2094, train loss: 1.2221146384510426, validation loss: 1.2433024541191433.
epoch: 2095, train loss: 1.2209283693121114, validation loss: 1.2648356893788213.
epoch: 2096, train loss: 1.2257452645433058, validation loss: 1.244000310483186.
epoch: 2097, train loss: 1.221346399106017, validation loss: 1.2530250031015147.
epoch: 2098, train loss: 1.2216493952164955, validation loss: 1.2793097599692966.
epoch: 2099, train loss: 1.2206556589231579, validation loss: 1.2588300912276558.
epoch: 2100, train loss: 1.2198194713767516, validation loss: 1.2477120886678281.
epoch: 2101, train loss: 1.221262426551329, validation loss: 1.2577226006466409.
epoch: 2102, train loss: 1.2266836953819344, validation loss: 1.264809276746667.
epoch: 2103, train loss: 1.223804315295788, validation loss: 1.2501656283502993.
epoch: 2104, train loss: 1.2225059937993321, validation loss: 1.2412335717159768.
epoch: 2105, train loss: 1.2212365679784651, validation loss: 1.2659668715103813.
epoch: 2106, train loss: 1.219107266959794, validation loss: 1.2454112042551455.
epoch: 2107, train loss: 1.2224830487452516, validation loss: 1.2601084812827732.
epoch: 2108, train loss: 1.2252287470966303, validation loss: 1.244454819223155.
epoch: 2109, train loss: 1.2244109538717007, validation loss: 1.244541240775067.
epoch: 2110, train loss: 1.2194959997037136, validation loss: 1.2436511050099912.
epoch: 2111, train loss: 1.2214765964298073, validation loss: 1.261070235915806.
epoch: 2112, train loss: 1.2261152322139215, validation loss: 1.288075706233149.
epoch: 2113, train loss: 1.2234219586083648, validation loss: 1.275124772735264.
epoch: 2114, train loss: 1.2226651906967163, validation loss: 1.2407811880111694.
epoch: 2115, train loss: 1.2195605859843963, validation loss: 1.2466555211855017.
epoch: 2116, train loss: 1.2205819810202363, validation loss: 1.263952586961829.
epoch: 2117, train loss: 1.2233548328417156, validation loss: 1.2533283181812451.
epoch: 2118, train loss: 1.2227043296219011, validation loss: 1.2526391433632893.
epoch: 2119, train loss: 1.2207855051810588, validation loss: 1.2510961086853691.
epoch: 2120, train loss: 1.2214218563989763, validation loss: 1.241679751354715.
epoch: 2121, train loss: 1.2202089007841337, validation loss: 1.2434723688208538.
epoch: 2122, train loss: 1.2181599293280085, validation loss: 1.248560941737631.
epoch: 2123, train loss: 1.22391062701514, validation loss: 1.2491404129111248.
epoch: 2124, train loss: 1.2187021631713306, validation loss: 1.2708459107772163.
epoch: 2125, train loss: 1.2178921108945795, validation loss: 1.2529758007630059.
epoch: 2126, train loss: 1.223954782573455, validation loss: 1.2468336094980654.
epoch: 2127, train loss: 1.2221685746394166, validation loss: 1.2978517024413398.
epoch: 2128, train loss: 1.2242132326878539, validation loss: 1.2911193318988965.
epoch: 2129, train loss: 1.227451923790328, validation loss: 1.2510437498921934.
epoch: 2130, train loss: 1.222582707711316, validation loss: 1.2469251363173774.
epoch: 2131, train loss: 1.2212049961090088, validation loss: 1.245346820872763.
epoch: 2132, train loss: 1.2206612781647148, validation loss: 1.2444651334182075.
epoch: 2133, train loss: 1.2223629820237465, validation loss: 1.2462387603262197.
epoch: 2134, train loss: 1.217007489379393, validation loss: 1.2557822517726733.
epoch: 2135, train loss: 1.2296118933126468, validation loss: 1.2465975543727046.
epoch: 2136, train loss: 1.22323413835753, validation loss: 1.2578975065894749.
epoch: 2137, train loss: 1.2202087946988027, validation loss: 1.2453822519468225.
epoch: 2138, train loss: 1.2249727019476235, validation loss: 1.2529471542524255.
epoch: 2139, train loss: 1.221494440638691, validation loss: 1.2455036691997363.
epoch: 2140, train loss: 1.2215693390697515, validation loss: 1.279969536739847.
epoch: 2141, train loss: 1.2266038995270336, validation loss: 1.250417154768239.
epoch: 2142, train loss: 1.2243588255086075, validation loss: 1.247299049211585.
epoch: 2143, train loss: 1.2225001372328592, validation loss: 1.2610776476238086.
epoch: 2144, train loss: 1.2215673923492432, validation loss: 1.2540817623553069.
epoch: 2145, train loss: 1.2220302262437452, validation loss: 1.2534675909125286.
epoch: 2146, train loss: 1.2203609516861242, validation loss: 1.330961471018584.
epoch: 2147, train loss: 1.2301849454914757, validation loss: 1.2672965578410937.
epoch: 2148, train loss: 1.2266616099471346, validation loss: 1.2588885970737622.
epoch: 2149, train loss: 1.2214781713048253, validation loss: 1.2660977995913962.
epoch: 2150, train loss: 1.2243098600195088, validation loss: 1.2443988271381543.
epoch: 2151, train loss: 1.2242439985275269, validation loss: 1.2548332525336223.
epoch: 2152, train loss: 1.2222399875658367, validation loss: 1.2682727782622627.
epoch: 2153, train loss: 1.2240981760374996, validation loss: 1.2437460474345996.
epoch: 2154, train loss: 1.2190284466524737, validation loss: 1.2552144009134043.
epoch: 2155, train loss: 1.2223818324027804, validation loss: 1.2489515232003254.
epoch: 2156, train loss: 1.2218225614740215, validation loss: 1.2519295422927192.
epoch: 2157, train loss: 1.2239210955593565, validation loss: 1.2457862729611604.
epoch: 2158, train loss: 1.2220862458605286, validation loss: 1.2674441389415576.
epoch: 2159, train loss: 1.222069015196704, validation loss: 1.25348917297695.
epoch: 2160, train loss: 1.2185301069819598, validation loss: 1.2725274459175442.
epoch: 2161, train loss: 1.2267755849645772, validation loss: 1.2564449621283489.
epoch: 2162, train loss: 1.2188346287526122, validation loss: 1.246090749035711.
epoch: 2163, train loss: 1.2213258240201057, validation loss: 1.2586992046107417.
epoch: 2164, train loss: 1.2223032166104797, validation loss: 1.2506392935047979.
epoch: 2165, train loss: 1.2215516140701574, validation loss: 1.2808503275332244.
epoch: 2166, train loss: 1.224140229575131, validation loss: 1.247898262480031.
epoch: 2167, train loss: 1.2208598742791272, validation loss: 1.255422592163086.
epoch: 2168, train loss: 1.2236508765351881, validation loss: 1.2560681104660034.
epoch: 2169, train loss: 1.2189346683134727, validation loss: 1.2432902273924455.
epoch: 2170, train loss: 1.220633017907449, validation loss: 1.2648485017859417.
epoch: 2171, train loss: 1.2229790971913468, validation loss: 1.2499150037765503.
epoch: 2172, train loss: 1.2225919502590774, validation loss: 1.2448166453320046.
epoch: 2173, train loss: 1.2208071400266174, validation loss: 1.2549723179444023.
epoch: 2174, train loss: 1.223240424733643, validation loss: 1.2433367034663325.
epoch: 2175, train loss: 1.221471922113261, validation loss: 1.2611737665922746.
epoch: 2176, train loss: 1.2194939895507393, validation loss: 1.2726101564324421.
epoch: 2177, train loss: 1.2246927580702196, validation loss: 1.2460420287173728.
epoch: 2178, train loss: 1.2223272881376634, validation loss: 1.2500285169352656.
epoch: 2179, train loss: 1.2214570701669116, validation loss: 1.262721341589223.
epoch: 2180, train loss: 1.2201738455973634, validation loss: 1.2425452729930049.
epoch: 2181, train loss: 1.2214284960283053, validation loss: 1.248480314793794.
epoch: 2182, train loss: 1.2222843181102647, validation loss: 1.2546379099721494.
epoch: 2183, train loss: 1.223301184286765, validation loss: 1.2449625264043394.
epoch: 2184, train loss: 1.2221516195787203, validation loss: 1.2439832842868308.
epoch: 2185, train loss: 1.2183461101776962, validation loss: 1.2614662699077441.
epoch: 2186, train loss: 1.2255246475202228, validation loss: 1.2524744738703188.
epoch: 2187, train loss: 1.2193772913119114, validation loss: 1.2466285384219626.
epoch: 2188, train loss: 1.217937412611935, validation loss: 1.2580013741617617.
epoch: 2189, train loss: 1.221626423914498, validation loss: 1.2604138332864512.
epoch: 2190, train loss: 1.2206834368749495, validation loss: 1.248875592065894.
epoch: 2191, train loss: 1.2221174655704323, validation loss: 1.2491058370341426.
epoch: 2192, train loss: 1.2221992890769189, validation loss: 1.2651763739793196.
epoch: 2193, train loss: 1.2224066924611363, validation loss: 1.280743526375812.
epoch: 2194, train loss: 1.2219391240986115, validation loss: 1.2607397877651711.
epoch: 2195, train loss: 1.2212215891671836, validation loss: 1.2564392867295637.
epoch: 2196, train loss: 1.2187426090240479, validation loss: 1.2519079965093862.
epoch: 2197, train loss: 1.2217283697303283, validation loss: 1.272794485092163.
epoch: 2198, train loss: 1.2234466546172396, validation loss: 1.2617182887118796.
epoch: 2199, train loss: 1.2221276421065723, validation loss: 1.251810187878816.
epoch: 2200, train loss: 1.2205871999810596, validation loss: 1.2553113750789477.
epoch: 2201, train loss: 1.2196409439821856, validation loss: 1.254385725311611.
epoch: 2202, train loss: 1.2229088949500968, validation loss: 1.2422079936317776.
epoch: 2203, train loss: 1.2234224168532486, validation loss: 1.2479406232419221.
epoch: 2204, train loss: 1.221739660709276, validation loss: 1.242414396742116.
epoch: 2205, train loss: 1.2194966690255962, validation loss: 1.2507232634917549.
epoch: 2206, train loss: 1.2199771940161328, validation loss: 1.241602467453998.
epoch: 2207, train loss: 1.2212504717188144, validation loss: 1.25049540789231.
epoch: 2208, train loss: 1.2196224162337976, validation loss: 1.244674651519112.
epoch: 2209, train loss: 1.220340324104379, validation loss: 1.2451784973559172.
epoch: 2210, train loss: 1.2166555332481315, validation loss: 1.2402488770692244.
epoch: 2211, train loss: 1.220905166153514, validation loss: 1.2492862058722454.
epoch: 2212, train loss: 1.220572644417439, validation loss: 1.262935933859452.
epoch: 2213, train loss: 1.2236796650317832, validation loss: 1.2377756626709648.
epoch: 2214, train loss: 1.2223996470827576, validation loss: 1.2577591305193694.
epoch: 2215, train loss: 1.2193633799159198, validation loss: 1.3173541970874951.
epoch: 2216, train loss: 1.224090840838371, validation loss: 1.2585142695385476.
epoch: 2217, train loss: 1.2214185491614384, validation loss: 1.2636496606080427.
epoch: 2218, train loss: 1.2178167235960655, validation loss: 1.2638758161793584.
epoch: 2219, train loss: 1.2191438412447588, validation loss: 1.248393592627152.
epoch: 2220, train loss: 1.220670588519595, validation loss: 1.2424312311670054.
epoch: 2221, train loss: 1.221254333443598, validation loss: 1.2621487430904224.
epoch: 2222, train loss: 1.2206827391178237, validation loss: 1.2576339141182278.
epoch: 2223, train loss: 1.2234987556387524, validation loss: 1.2879471156908118.
epoch: 2224, train loss: 1.2225774176623843, validation loss: 1.2460651190384575.
epoch: 2225, train loss: 1.2225979413461248, validation loss: 1.2602914934572966.
epoch: 2226, train loss: 1.2190225310281877, validation loss: 1.2546104089073513.
epoch: 2227, train loss: 1.2192701484085222, validation loss: 1.2492743264073911.
epoch: 2228, train loss: 1.2202172049688638, validation loss: 1.2446782899939495.
epoch: 2229, train loss: 1.2201934724772743, validation loss: 1.2594577488691912.
epoch: 2230, train loss: 1.219248204056276, validation loss: 1.2442767464596292.
epoch: 2231, train loss: 1.221154148425531, validation loss: 1.27154541015625.
epoch: 2232, train loss: 1.2208243717841052, validation loss: 1.2514467394870261.
epoch: 2233, train loss: 1.2236784499719602, validation loss: 1.257331749667292.
epoch: 2234, train loss: 1.2289209190858614, validation loss: 1.2495252619618955.
epoch: 2235, train loss: 1.2240082627042719, validation loss: 1.250323430351589.
epoch: 2236, train loss: 1.2200003249929585, validation loss: 1.254149343656457.
epoch: 2237, train loss: 1.220891458178879, validation loss: 1.24923226626023.
epoch: 2238, train loss: 1.2204542717802416, validation loss: 1.2586390039195186.
epoch: 2239, train loss: 1.2217424025229358, validation loss: 1.247497506763624.
epoch: 2240, train loss: 1.219487216494499, validation loss: 1.2447911138119905.
epoch: 2241, train loss: 1.2184075303033952, validation loss: 1.2542542633802995.
epoch: 2242, train loss: 1.2225611056756536, validation loss: 1.2446172807527625.
epoch: 2243, train loss: 1.225264469417957, validation loss: 1.2595965240312659.
epoch: 2244, train loss: 1.2238569511186093, validation loss: 1.2477350545966106.
epoch: 2245, train loss: 1.2207541257963268, validation loss: 1.2544679278912751.
epoch: 2246, train loss: 1.2186555468708002, validation loss: 1.24771089139192.
epoch: 2247, train loss: 1.2165105955316386, validation loss: 1.2618086027062458.
epoch: 2248, train loss: 1.219696039453559, validation loss: 1.285195811935093.
epoch: 2249, train loss: 1.219857063862162, validation loss: 1.2575650422469429.
epoch: 2250, train loss: 1.2168621732554306, validation loss: 1.2467208737912385.
epoch: 2251, train loss: 1.2197901524535013, validation loss: 1.2482106841128806.
epoch: 2252, train loss: 1.2203116307564832, validation loss: 1.2427663854930713.
epoch: 2253, train loss: 1.2192084942388972, validation loss: 1.249974867571955.
epoch: 2254, train loss: 1.222753453692165, validation loss: 1.2855314327322918.
epoch: 2255, train loss: 1.220820771444828, validation loss: 1.2500408110411272.
epoch: 2256, train loss: 1.2186242834143681, validation loss: 1.2424306610356206.
epoch: 2257, train loss: 1.219013694229476, validation loss: 1.267867570338042.
epoch: 2258, train loss: 1.2224815580823005, validation loss: 1.2498303081678308.
epoch: 2259, train loss: 1.2281238660899871, validation loss: 1.2642924163652502.
epoch: 2260, train loss: 1.2250111934241898, validation loss: 1.2592367296633513.
epoch: 2261, train loss: 1.2206782102584839, validation loss: 1.270943688309711.
epoch: 2262, train loss: 1.2192424798230512, validation loss: 1.2735295503035835.
epoch: 2263, train loss: 1.2199196946730309, validation loss: 1.261097851006881.
epoch: 2264, train loss: 1.2217944641725733, validation loss: 1.2548472570336384.
epoch: 2265, train loss: 1.2190482682044352, validation loss: 1.2520620149114858.
epoch: 2266, train loss: 1.2202182133263404, validation loss: 1.2473241194434788.
epoch: 2267, train loss: 1.2187060314580935, validation loss: 1.261219050573266.
epoch: 2268, train loss: 1.223550294517377, validation loss: 1.2502122080844382.
epoch: 2269, train loss: 1.2226719965628527, validation loss: 1.2647382072780444.
epoch: 2270, train loss: 1.2232310531336232, validation loss: 1.2435126356456592.
epoch: 2271, train loss: 1.2189978240826809, validation loss: 1.2554347981577334.
epoch: 2272, train loss: 1.2284680156532777, validation loss: 1.2678961391034334.
epoch: 2273, train loss: 1.2336065102061, validation loss: 1.2432556515154631.
epoch: 2274, train loss: 1.2201836634119716, validation loss: 1.2460250025210173.
epoch: 2275, train loss: 1.222253658355923, validation loss: 1.2576944568882817.
epoch: 2276, train loss: 1.2200273428488215, validation loss: 1.2466744754625403.
epoch: 2277, train loss: 1.21833474811064, validation loss: 1.2481206551842068.
epoch: 2278, train loss: 1.2187841977548162, validation loss: 1.245657848275226.
epoch: 2279, train loss: 1.2182106206176477, validation loss: 1.251642698826997.
epoch: 2280, train loss: 1.2200768486075444, validation loss: 1.256144870882449.
epoch: 2281, train loss: 1.220877265711443, validation loss: 1.2541532516479492.
epoch: 2282, train loss: 1.2220315441079097, validation loss: 1.2880464273950327.
epoch: 2283, train loss: 1.2219205110444935, validation loss: 1.255772740944572.
epoch: 2284, train loss: 1.220513327406087, validation loss: 1.2617567103842031.
epoch: 2285, train loss: 1.2176373256455868, validation loss: 1.2432714286057844.
epoch: 2286, train loss: 1.2207407798242131, validation loss: 1.2565030170523601.
epoch: 2287, train loss: 1.2185191036364353, validation loss: 1.2641521381295246.
epoch: 2288, train loss: 1.2168717220288898, validation loss: 1.2918993027313896.
epoch: 2289, train loss: 1.2229478916990648, validation loss: 1.2659943933072297.
epoch: 2290, train loss: 1.2209678669588282, validation loss: 1.242791631947393.
epoch: 2291, train loss: 1.221173586101707, validation loss: 1.2564738315084707.
epoch: 2292, train loss: 1.2206699465392927, validation loss: 1.2557340964027073.
epoch: 2293, train loss: 1.2245968558372708, validation loss: 1.2493327026781829.
epoch: 2294, train loss: 1.2184462973830896, validation loss: 1.286375589992689.
epoch: 2295, train loss: 1.222367419015377, validation loss: 1.2491098020387732.
epoch: 2296, train loss: 1.217188258783533, validation loss: 1.2582509828650432.
epoch: 2297, train loss: 1.2232255815365993, validation loss: 1.2474386847537497.
epoch: 2298, train loss: 1.2187968383141614, validation loss: 1.2441113461618838.
epoch: 2299, train loss: 1.220180921598312, validation loss: 1.254317838212718.
epoch: 2300, train loss: 1.2183270126307777, validation loss: 1.244387782138327.
epoch: 2301, train loss: 1.223651473675299, validation loss: 1.2610972912415215.
epoch: 2302, train loss: 1.2174751594525959, validation loss: 1.2565743975017383.
epoch: 2303, train loss: 1.2205491667493769, validation loss: 1.2489992742953093.
epoch: 2304, train loss: 1.219741744732638, validation loss: 1.251544423725294.
epoch: 2305, train loss: 1.2184944809029956, validation loss: 1.247304434361665.
epoch: 2306, train loss: 1.2196130927549589, validation loss: 1.2452351010364036.
epoch: 2307, train loss: 1.2216376952075083, validation loss: 1.244381749111673.
epoch: 2308, train loss: 1.2175917669173775, validation loss: 1.2583545290905496.
epoch: 2309, train loss: 1.2247025813531438, validation loss: 1.257395889448083.
epoch: 2310, train loss: 1.2182315795793446, validation loss: 1.2523831129074097.
epoch: 2311, train loss: 1.2144469875808155, validation loss: 1.2510731686716494.
epoch: 2312, train loss: 1.2211716481305044, validation loss: 1.2541453112726626.
epoch: 2313, train loss: 1.2224292131738925, validation loss: 1.2531408641649329.
epoch: 2314, train loss: 1.2226258461628485, validation loss: 1.2492973493493122.
epoch: 2315, train loss: 1.2221243283070555, validation loss: 1.259440074796262.
epoch: 2316, train loss: 1.2205130397726636, validation loss: 1.2562238340792449.
epoch: 2317, train loss: 1.2190246221122392, validation loss: 1.3065547165663347.
epoch: 2318, train loss: 1.2158377454915177, validation loss: 1.2552585187165632.
epoch: 2319, train loss: 1.2188955676665, validation loss: 1.2609722251477449.
epoch: 2320, train loss: 1.2191190993020293, validation loss: 1.2636834020199983.
epoch: 2321, train loss: 1.2181946717271017, validation loss: 1.2564591843148936.
epoch: 2322, train loss: 1.2200042359325864, validation loss: 1.3228726024213044.
epoch: 2323, train loss: 1.2214024416897276, validation loss: 1.2715538584667703.
epoch: 2324, train loss: 1.2204046194706488, validation loss: 1.2673153047976287.
epoch: 2325, train loss: 1.218916205091214, validation loss: 1.2575793007145757.
epoch: 2326, train loss: 1.2306876051316566, validation loss: 1.2465639840001645.
epoch: 2327, train loss: 1.219240734336573, validation loss: 1.2574892147727634.
epoch: 2328, train loss: 1.2202304284506982, validation loss: 1.2594604025716367.
epoch: 2329, train loss: 1.221392526539094, validation loss: 1.2581858479458352.
epoch: 2330, train loss: 1.2171596682399786, validation loss: 1.2588918001755425.
epoch: 2331, train loss: 1.2188116180787392, validation loss: 1.2509985229243403.
epoch: 2332, train loss: 1.223119136390336, validation loss: 1.2510917653208193.
epoch: 2333, train loss: 1.2221422960998816, validation loss: 1.2497135919073354.
epoch: 2334, train loss: 1.2197989444120214, validation loss: 1.2462261034094768.
epoch: 2335, train loss: 1.2201980603944271, validation loss: 1.2607298674790755.
epoch: 2336, train loss: 1.2173155699301204, validation loss: 1.2529640716055166.
epoch: 2337, train loss: 1.220368170956953, validation loss: 1.2537296854931375.
epoch: 2338, train loss: 1.2179181772634524, validation loss: 1.2669423300286997.
epoch: 2339, train loss: 1.220583259512525, validation loss: 1.2458803394566411.
epoch: 2340, train loss: 1.2238779494521814, validation loss: 1.252237952273825.
epoch: 2341, train loss: 1.2210077966025117, validation loss: 1.272696396578913.
epoch: 2342, train loss: 1.2220062225236805, validation loss: 1.2485609261885933.
epoch: 2343, train loss: 1.2205373070655612, validation loss: 1.2702056791471399.
epoch: 2344, train loss: 1.2242915630340576, validation loss: 1.2446557231571362.
epoch: 2345, train loss: 1.2181629675243972, validation loss: 1.2506056816681572.
epoch: 2346, train loss: 1.2189061761996067, validation loss: 1.2443508531736291.
epoch: 2347, train loss: 1.2181742453793867, validation loss: 1.250504177549611.
epoch: 2348, train loss: 1.2184147758221409, validation loss: 1.2484043577442998.
epoch: 2349, train loss: 1.2190060199947532, validation loss: 1.274991750717163.
epoch: 2350, train loss: 1.2208654016529747, validation loss: 1.2546402837919153.
epoch: 2351, train loss: 1.221788435900977, validation loss: 1.2455382969068445.
epoch: 2352, train loss: 1.223803157106452, validation loss: 1.245345457740452.
epoch: 2353, train loss: 1.2196481271621284, validation loss: 1.2534230221872744.
epoch: 2354, train loss: 1.2202154080802148, validation loss: 1.2708339121030725.
epoch: 2355, train loss: 1.2166367758304701, validation loss: 1.2585972806681758.
epoch: 2356, train loss: 1.2183478381655632, validation loss: 1.2798193382180256.
epoch: 2357, train loss: 1.2175898158222163, validation loss: 1.2599046074825784.
epoch: 2358, train loss: 1.2256848844913169, validation loss: 1.250036737193232.
epoch: 2359, train loss: 1.225438425300318, validation loss: 1.2553180922632632.
epoch: 2360, train loss: 1.219149545792046, validation loss: 1.2478771831678308.
epoch: 2361, train loss: 1.2212497531820874, validation loss: 1.2712664915167766.
epoch: 2362, train loss: 1.218701255430869, validation loss: 1.255637941153153.
epoch: 2363, train loss: 1.2178139336612246, validation loss: 1.2545775434245234.
epoch: 2364, train loss: 1.2189158113724594, validation loss: 1.2552419278932654.
epoch: 2365, train loss: 1.2230057760116158, validation loss: 1.245797354242076.
epoch: 2366, train loss: 1.219879456616323, validation loss: 1.247278674789097.
epoch: 2367, train loss: 1.2152204688535917, validation loss: 1.2548690567845884.
epoch: 2368, train loss: 1.217413517313266, validation loss: 1.307680757149406.
epoch: 2369, train loss: 1.2190343250922107, validation loss: 1.3005749660989512.
epoch: 2370, train loss: 1.2189967851026342, validation loss: 1.266041169995847.
epoch: 2371, train loss: 1.2211879666792143, validation loss: 1.2857272003007971.
epoch: 2372, train loss: 1.2206610605257366, validation loss: 1.2486960110457048.
epoch: 2373, train loss: 1.216849916571871, validation loss: 1.246701162794362.
epoch: 2374, train loss: 1.215269071246506, validation loss: 1.2712987713191821.
epoch: 2375, train loss: 1.218040424749392, validation loss: 1.2641017488811328.
epoch: 2376, train loss: 1.2225560048304567, validation loss: 1.257645202719647.
epoch: 2377, train loss: 1.2223845009410053, validation loss: 1.2526863709740017.
epoch: 2378, train loss: 1.2168761218359712, validation loss: 1.2556616067886353.
epoch: 2379, train loss: 1.2231781952971712, validation loss: 1.2449006516000498.
epoch: 2380, train loss: 1.217214272656572, validation loss: 1.26374191823213.
epoch: 2381, train loss: 1.220322461303221, validation loss: 1.2825836098712424.
epoch: 2382, train loss: 1.2200911099757623, validation loss: 1.2422097506730452.
epoch: 2383, train loss: 1.2165441075596242, validation loss: 1.2593251466751099.
epoch: 2384, train loss: 1.2287810242504156, validation loss: 1.2496386662773464.
epoch: 2385, train loss: 1.2179363298853603, validation loss: 1.2684939892395684.
epoch: 2386, train loss: 1.2171711648276093, validation loss: 1.2657038025234058.
epoch: 2387, train loss: 1.2206857368486737, validation loss: 1.256549208060555.
epoch: 2388, train loss: 1.224510595339154, validation loss: 1.2639078316481218.
epoch: 2389, train loss: 1.2189545292373096, validation loss: 1.2486557338548743.
epoch: 2390, train loss: 1.2198173923229954, validation loss: 1.2658804758735325.
epoch: 2391, train loss: 1.218681183430033, validation loss: 1.2478758770486582.
epoch: 2392, train loss: 1.2185168003817217, validation loss: 1.242735593215279.
epoch: 2393, train loss: 1.2197058867970738, validation loss: 1.2511443832646245.
epoch: 2394, train loss: 1.2193576206854724, validation loss: 1.2514623714529949.
epoch: 2395, train loss: 1.2179055585773713, validation loss: 1.249747810156449.
epoch: 2396, train loss: 1.2190467961337588, validation loss: 1.2462702523107114.
epoch: 2397, train loss: 1.2173780016942854, validation loss: 1.2487248078636501.
epoch: 2398, train loss: 1.2207047950237169, validation loss: 1.270652781362119.
epoch: 2399, train loss: 1.2189883595212885, validation loss: 1.2601863301318625.
epoch: 2400, train loss: 1.2203735561545836, validation loss: 1.251250375872073.
epoch: 2401, train loss: 1.2229586194414612, validation loss: 1.3358744123707647.
epoch: 2402, train loss: 1.2184128291016325, validation loss: 1.2977012292198513.
epoch: 2403, train loss: 1.2142861950288124, validation loss: 1.2900935463283374.
epoch: 2404, train loss: 1.2211054563522339, validation loss: 1.2527207343474678.
epoch: 2405, train loss: 1.2176347456940817, validation loss: 1.2561392784118652.
epoch: 2406, train loss: 1.2156976111438296, validation loss: 1.2602773127348528.
epoch: 2407, train loss: 1.2168501243678802, validation loss: 1.26677535927814.
epoch: 2408, train loss: 1.220987594455754, validation loss: 1.2555360275766123.
epoch: 2409, train loss: 1.221596317553739, validation loss: 1.2532873982968538.
epoch: 2410, train loss: 1.2241000374522777, validation loss: 1.252356954242872.
epoch: 2411, train loss: 1.2182381459332388, validation loss: 1.2519477709479954.
epoch: 2412, train loss: 1.2206706530457243, validation loss: 1.2515437084695566.
epoch: 2413, train loss: 1.2175340346240122, validation loss: 1.2473511073900305.
epoch: 2414, train loss: 1.2193650324410255, validation loss: 1.2598809522131216.
epoch: 2415, train loss: 1.2164301926936578, validation loss: 1.247483771780263.
epoch: 2416, train loss: 1.2175283333577147, validation loss: 1.2543381711711055.
epoch: 2417, train loss: 1.2173148557680462, validation loss: 1.3072023236233254.
epoch: 2418, train loss: 1.2162520130839916, validation loss: 1.2756396739379219.
epoch: 2419, train loss: 1.223128296913357, validation loss: 1.2863636431486711.
epoch: 2420, train loss: 1.219767583619564, validation loss: 1.285127447999042.
epoch: 2421, train loss: 1.2183532528921004, validation loss: 1.2604156317918196.
epoch: 2422, train loss: 1.2291547005329657, validation loss: 1.255656107612278.
epoch: 2423, train loss: 1.2216149590431002, validation loss: 1.2485006684842317.
epoch: 2424, train loss: 1.2154748844444205, validation loss: 1.242478204810101.
epoch: 2425, train loss: 1.219537271272152, validation loss: 1.2522398026093193.
epoch: 2426, train loss: 1.217089505370604, validation loss: 1.279712692550991.
epoch: 2427, train loss: 1.2278488622892887, validation loss: 1.251214141431062.
epoch: 2428, train loss: 1.2259716320475307, validation loss: 1.2423871962920479.
epoch: 2429, train loss: 1.2160393579290547, validation loss: 1.246053845986076.
epoch: 2430, train loss: 1.2170433604389155, validation loss: 1.3019524709038113.
epoch: 2431, train loss: 1.2214165105732209, validation loss: 1.2801918931629346.
epoch: 2432, train loss: 1.22579657812731, validation loss: 1.2661692474199377.
epoch: 2433, train loss: 1.220376349370414, validation loss: 1.2514862236769304.
epoch: 2434, train loss: 1.217405672467083, validation loss: 1.2655781766642695.
epoch: 2435, train loss: 1.2156878676983194, validation loss: 1.2714556818423064.
epoch: 2436, train loss: 1.2178174760363518, validation loss: 1.244771941848423.
epoch: 2437, train loss: 1.2194254759254806, validation loss: 1.25476002174875.
epoch: 2438, train loss: 1.225137451373109, validation loss: 1.2515948907188748.
epoch: 2439, train loss: 1.2207118830549608, validation loss: 1.2769548271013342.
epoch: 2440, train loss: 1.2167537606090582, validation loss: 1.261472048966781.
epoch: 2441, train loss: 1.2195350828520748, validation loss: 1.257046761720077.
epoch: 2442, train loss: 1.2188164936293155, validation loss: 1.2683335905489714.
epoch: 2443, train loss: 1.2278195947682091, validation loss: 1.2521083199459573.
epoch: 2444, train loss: 1.2187752833060168, validation loss: 1.2652977808662083.
epoch: 2445, train loss: 1.2208428393810167, validation loss: 1.2486875212710837.
epoch: 2446, train loss: 1.2228213220561317, validation loss: 1.2620689039644988.
epoch: 2447, train loss: 1.2176246905545576, validation loss: 1.2599252721537715.
epoch: 2448, train loss: 1.2208334765303026, validation loss: 1.254746473353842.
epoch: 2449, train loss: 1.2190675866713219, validation loss: 1.2453872224558955.
epoch: 2450, train loss: 1.2191759796317565, validation loss: 1.249812644460927.
epoch: 2451, train loss: 1.2184325719098432, validation loss: 1.2455114022545193.
epoch: 2452, train loss: 1.2145491269750333, validation loss: 1.270870312400486.
epoch: 2453, train loss: 1.2208791030656307, validation loss: 1.250892955323924.
epoch: 2454, train loss: 1.222141928629044, validation loss: 1.2584753347479778.
epoch: 2455, train loss: 1.2230632523877905, validation loss: 1.2571970483531123.
epoch: 2456, train loss: 1.2215076225613235, validation loss: 1.248154386230137.
epoch: 2457, train loss: 1.2224775060601192, validation loss: 1.2491166436153909.
epoch: 2458, train loss: 1.2179258963383666, validation loss: 1.2482726418453713.
epoch: 2459, train loss: 1.217093735659888, validation loss: 1.2451629016710364.
epoch: 2460, train loss: 1.2306537945336158, validation loss: 1.250005198561627.
epoch: 2461, train loss: 1.22523281552376, validation loss: 1.3071592683377473.
epoch: 2462, train loss: 1.2193976225109275, validation loss: 1.247002917787303.
epoch: 2463, train loss: 1.2175254351502165, validation loss: 1.2552195009977922.
epoch: 2464, train loss: 1.21792572353958, validation loss: 1.2585290411244268.
epoch: 2465, train loss: 1.2180017878156189, validation loss: 1.2799070969871853.
epoch: 2466, train loss: 1.2151915523984016, validation loss: 1.259673631709555.
epoch: 2467, train loss: 1.2169922382459728, validation loss: 1.2632562492204749.
epoch: 2468, train loss: 1.215535244810472, validation loss: 1.440654122311136.
epoch: 2469, train loss: 1.2233483102343499, validation loss: 1.2824531741764233.
epoch: 2470, train loss: 1.224636656428696, validation loss: 1.2554726445156594.
epoch: 2471, train loss: 1.2235443176479515, validation loss: 1.254698079565297.
epoch: 2472, train loss: 1.2187864200784526, validation loss: 1.2656561965527742.
epoch: 2473, train loss: 1.2220516423566625, validation loss: 1.2470892615940259.
epoch: 2474, train loss: 1.2291225752699266, validation loss: 1.248793513878532.
epoch: 2475, train loss: 1.2195157436055875, validation loss: 1.2495061832925547.
epoch: 2476, train loss: 1.2194831950948872, validation loss: 1.2617864816085151.
epoch: 2477, train loss: 1.2227226681665544, validation loss: 1.2467109794202058.
epoch: 2478, train loss: 1.2202909080260391, validation loss: 1.2539136202439018.
epoch: 2479, train loss: 1.2192671463030194, validation loss: 1.2803332442822664.
epoch: 2480, train loss: 1.220810330242192, validation loss: 1.282454843106477.
epoch: 2481, train loss: 1.2158715407782739, validation loss: 1.2484923445660134.
epoch: 2482, train loss: 1.216279856655576, validation loss: 1.2524640663810398.
epoch: 2483, train loss: 1.2202431871256698, validation loss: 1.2531136170677517.
epoch: 2484, train loss: 1.2158193621066733, validation loss: 1.245813602986543.
epoch: 2485, train loss: 1.2279235518306768, validation loss: 1.2514386177062988.
epoch: 2486, train loss: 1.2202028714188742, validation loss: 1.2720991528552512.
epoch: 2487, train loss: 1.2207184253482644, validation loss: 1.2627645316331282.
epoch: 2488, train loss: 1.217391156275338, validation loss: 1.3017911081728728.
epoch: 2489, train loss: 1.223436871799854, validation loss: 1.2481300882671191.
epoch: 2490, train loss: 1.2237131114399762, validation loss: 1.252209378325421.
epoch: 2491, train loss: 1.2208261544551324, validation loss: 1.2593096753825312.
epoch: 2492, train loss: 1.2233797957044128, validation loss: 1.2500098995540454.
epoch: 2493, train loss: 1.2188558742540692, validation loss: 1.251495537550553.
epoch: 2494, train loss: 1.2194071395681538, validation loss: 1.2843493223190308.
epoch: 2495, train loss: 1.2196803169512966, validation loss: 1.2476451137791509.
epoch: 2496, train loss: 1.2171581152382247, validation loss: 1.2412803535876067.
epoch: 2497, train loss: 1.215967905630759, validation loss: 1.2682280229485554.
epoch: 2498, train loss: 1.218886364490614, validation loss: 1.252212405204773.
epoch: 2499, train loss: 1.2184203830334024, validation loss: 1.2762852077898772.
epoch: 2500, train loss: 1.224894579397429, validation loss: 1.2542612656303074.
epoch: 2501, train loss: 1.2189119933942043, validation loss: 1.2479814083679863.
epoch: 2502, train loss: 1.2167943387950233, validation loss: 1.248328421426856.
epoch: 2503, train loss: 1.2245405518680537, validation loss: 1.2446729514909827.
epoch: 2504, train loss: 1.218238781351562, validation loss: 1.2728495546009229.
epoch: 2505, train loss: 1.2188718100206568, validation loss: 1.273545275563779.
epoch: 2506, train loss: 1.2232582689425266, validation loss: 1.2489484444908474.
epoch: 2507, train loss: 1.2213911069642513, validation loss: 1.2494916449422422.
epoch: 2508, train loss: 1.2244371788217387, validation loss: 1.2484958171844482.
epoch: 2509, train loss: 1.2185066074406334, validation loss: 1.256067436674367.
epoch: 2510, train loss: 1.2216878287289121, validation loss: 1.2507437778555828.
epoch: 2511, train loss: 1.216954203920627, validation loss: 1.2817025754762732.
epoch: 2512, train loss: 1.2271359918314382, validation loss: 1.2623886543771494.
epoch: 2513, train loss: 1.2203988832071286, validation loss: 1.2624631031699802.
epoch: 2514, train loss: 1.2216048623443743, validation loss: 1.2671838946964429.
epoch: 2515, train loss: 1.2190388058303694, validation loss: 1.2489478069802988.
epoch: 2516, train loss: 1.2211362517208135, validation loss: 1.2683197259902954.
epoch: 2517, train loss: 1.2151392818590916, validation loss: 1.2463913326678069.
epoch: 2518, train loss: 1.2160193942008761, validation loss: 1.2585105844165967.
epoch: 2519, train loss: 1.2182632586277953, validation loss: 1.2526882731396218.
epoch: 2520, train loss: 1.2233893236982714, validation loss: 1.247258777203767.
epoch: 2521, train loss: 1.2166256226530863, validation loss: 1.277033603709677.
epoch: 2522, train loss: 1.2194142833762212, validation loss: 1.251086774079696.
epoch: 2523, train loss: 1.21714247038605, validation loss: 1.2429050725439321.
epoch: 2524, train loss: 1.2188745244927364, validation loss: 1.2789757925531138.
epoch: 2525, train loss: 1.222672256854696, validation loss: 1.2482014998145725.
epoch: 2526, train loss: 1.218121389730261, validation loss: 1.244099471880042.
epoch: 2527, train loss: 1.2163591581747073, validation loss: 1.243070125579834.
epoch: 2528, train loss: 1.223104376311696, validation loss: 1.2519530887189119.
epoch: 2529, train loss: 1.2194380093058315, validation loss: 1.2640940780225007.
epoch: 2530, train loss: 1.2197646482275166, validation loss: 1.2463521490926328.
epoch: 2531, train loss: 1.215678699519656, validation loss: 1.2478213724882707.
epoch: 2532, train loss: 1.218830996697102, validation loss: 1.2463963187259177.
epoch: 2533, train loss: 1.218601398511764, validation loss: 1.256722761237103.
epoch: 2534, train loss: 1.2198484195481747, validation loss: 1.2770024641700413.
epoch: 2535, train loss: 1.222673588936482, validation loss: 1.2451417083325593.
epoch: 2536, train loss: 1.2180335707620744, validation loss: 1.260588350503341.
epoch: 2537, train loss: 1.2159145906430866, validation loss: 1.2435735412265942.
epoch: 2538, train loss: 1.2207386078090843, validation loss: 1.268326329148334.
epoch: 2539, train loss: 1.2199350606410875, validation loss: 1.252535078836524.
epoch: 2540, train loss: 1.2188887508637314, validation loss: 1.304987415023472.
epoch: 2541, train loss: 1.2203260747664566, validation loss: 1.240781255390333.
epoch: 2542, train loss: 1.2198014237465116, validation loss: 1.2606055425560994.
epoch: 2543, train loss: 1.2196423493394064, validation loss: 1.2842203378677368.
epoch: 2544, train loss: 1.2169746663592278, validation loss: 1.3312601421190344.
epoch: 2545, train loss: 1.2168220434713801, validation loss: 1.2497038011965544.
epoch: 2546, train loss: 1.2211224092256039, validation loss: 1.245915324791618.
epoch: 2547, train loss: 1.2192305534257801, validation loss: 1.2574141854825227.
epoch: 2548, train loss: 1.2136551491711118, validation loss: 1.3015466306520544.
epoch: 2549, train loss: 1.2188288039023722, validation loss: 1.7773609627848086.
epoch: 2550, train loss: 1.217282312725662, validation loss: 1.2462729422942451.
epoch: 2551, train loss: 1.219813267025379, validation loss: 1.2507280525953874.
epoch: 2552, train loss: 1.2219065613702897, validation loss: 1.298623209414275.
epoch: 2553, train loss: 1.218262808038554, validation loss: 1.2625253252361133.
epoch: 2554, train loss: 1.2220792223554138, validation loss: 1.2549942887347678.
epoch: 2555, train loss: 1.2172314836344589, validation loss: 1.2978681533232979.
epoch: 2556, train loss: 1.2212467193603516, validation loss: 1.2528475937636003.
epoch: 2557, train loss: 1.2165766166984489, validation loss: 1.2540479846622632.
epoch: 2558, train loss: 1.2242676621183344, validation loss: 1.2494021809619407.
epoch: 2559, train loss: 1.2173634920645198, validation loss: 1.2554377887559973.
epoch: 2560, train loss: 1.2188708563463404, validation loss: 1.2580976693526558.
epoch: 2561, train loss: 1.2215407911790621, validation loss: 1.2537504901056704.
epoch: 2562, train loss: 1.2144169184046054, validation loss: 1.2491458758063938.
epoch: 2563, train loss: 1.2207376399171461, validation loss: 1.2979681751002436.
epoch: 2564, train loss: 1.2187721641785507, validation loss: 1.2411516749340554.
epoch: 2565, train loss: 1.2170800692444548, validation loss: 1.2536284716232964.
epoch: 2566, train loss: 1.2179904618394484, validation loss: 1.2433399998623391.
epoch: 2567, train loss: 1.21699918082001, validation loss: 1.2759658979332966.
epoch: 2568, train loss: 1.2203281778808033, validation loss: 1.2625709668449734.
epoch: 2569, train loss: 1.2211133941597896, validation loss: 1.246726912000905.
epoch: 2570, train loss: 1.2169861049827086, validation loss: 1.2480954553769983.
epoch: 2571, train loss: 1.2175891650926083, validation loss: 1.2585241379945173.
epoch: 2572, train loss: 1.2144729806742538, validation loss: 1.2772889914719954.
epoch: 2573, train loss: 1.2210238012698813, validation loss: 1.245751194331957.
epoch: 2574, train loss: 1.2188428891908138, validation loss: 1.250462822292162.
epoch: 2575, train loss: 1.2214699841420584, validation loss: 1.2444276187730872.
epoch: 2576, train loss: 1.2252699421086442, validation loss: 1.2595073762147322.
epoch: 2577, train loss: 1.2180368845615912, validation loss: 1.2593685803206072.
epoch: 2578, train loss: 1.2148124701386198, validation loss: 1.2690844794978267.
epoch: 2579, train loss: 1.2207260613047748, validation loss: 1.2638602360435154.
epoch: 2580, train loss: 1.2239204568600437, validation loss: 1.2603816571442976.
epoch: 2581, train loss: 1.2198394460415622, validation loss: 1.2535780357277913.
epoch: 2582, train loss: 1.2176753654392487, validation loss: 1.258100608120794.
epoch: 2583, train loss: 1.2164383896993936, validation loss: 1.2686502985332324.
epoch: 2584, train loss: 1.2204365095960985, validation loss: 1.2452524382135142.
epoch: 2585, train loss: 1.2162965361131441, validation loss: 1.2929211077482805.
epoch: 2586, train loss: 1.2149833615766752, validation loss: 1.2446093196454255.
epoch: 2587, train loss: 1.2196157131720027, validation loss: 1.2453622144201528.
epoch: 2588, train loss: 1.2185064313608571, validation loss: 1.2807890124942944.
epoch: 2589, train loss: 1.2185301321362136, validation loss: 1.2513222798057224.
epoch: 2590, train loss: 1.2181423640032427, validation loss: 1.2588080167770386.
epoch: 2591, train loss: 1.221625302909711, validation loss: 1.2508193098980447.
epoch: 2592, train loss: 1.2198483823636257, validation loss: 1.249171645744987.
epoch: 2593, train loss: 1.2184002596303958, validation loss: 1.2712319467378699.
epoch: 2594, train loss: 1.2201119716014337, validation loss: 1.2551076826841936.
epoch: 2595, train loss: 1.2161261215122467, validation loss: 1.3344890345697817.
epoch: 2596, train loss: 1.221640299219604, validation loss: 1.2491704899331797.
epoch: 2597, train loss: 1.21541884186071, validation loss: 1.276945508044699.
epoch: 2598, train loss: 1.221819746384927, validation loss: 1.2517769492190818.
epoch: 2599, train loss: 1.220846102872026, validation loss: 1.274048406144847.
epoch: 2600, train loss: 1.215961566758812, validation loss: 1.243276772291764.
epoch: 2601, train loss: 1.2177879143198695, validation loss: 1.2584887794826343.
epoch: 2602, train loss: 1.2194709427859804, validation loss: 1.2711283383162126.
epoch: 2603, train loss: 1.2162332501980142, validation loss: 1.2643076285071995.
epoch: 2604, train loss: 1.2170116999827394, validation loss: 1.2751486249591992.
epoch: 2605, train loss: 1.2224697333957077, validation loss: 1.2641302243522976.
epoch: 2606, train loss: 1.216763672478702, validation loss: 1.293562132379283.
epoch: 2607, train loss: 1.2183415747563773, validation loss: 1.246330992035244.
epoch: 2608, train loss: 1.2185314729673054, validation loss: 1.280902043632839.
epoch: 2609, train loss: 1.2174206020635203, validation loss: 1.2671898551609204.
epoch: 2610, train loss: 1.218081531174686, validation loss: 1.2509480351987092.
epoch: 2611, train loss: 1.2162440555904983, validation loss: 1.3293910441191301.
epoch: 2612, train loss: 1.2165169223732906, validation loss: 1.313341850819795.
epoch: 2613, train loss: 1.2217749335350248, validation loss: 1.2499268728753794.
epoch: 2614, train loss: 1.2158170741632444, validation loss: 1.2520883860795393.
epoch: 2615, train loss: 1.216609465966531, validation loss: 1.2461603776268337.
epoch: 2616, train loss: 1.2247630488981895, validation loss: 1.2518343459004941.
epoch: 2617, train loss: 1.2214773751180106, validation loss: 1.2518079643664153.
epoch: 2618, train loss: 1.221868084111345, validation loss: 1.2588362641956494.
epoch: 2619, train loss: 1.2176536387259806, validation loss: 1.250513372213944.
epoch: 2620, train loss: 1.2185617368155663, validation loss: 1.2564328286958777.
epoch: 2621, train loss: 1.2220951034388412, validation loss: 1.251871689506199.
epoch: 2622, train loss: 1.222402498262738, validation loss: 1.2438478936319766.
epoch: 2623, train loss: 1.2181680913365216, validation loss: 1.2512637013974397.
epoch: 2624, train loss: 1.2161653533988042, validation loss: 1.2584571890209033.
epoch: 2625, train loss: 1.2235555889409617, validation loss: 1.2578078560207202.
epoch: 2626, train loss: 1.2262159815622031, validation loss: 1.2441677425218665.
epoch: 2627, train loss: 1.2165811466514518, validation loss: 1.2417955813200579.
epoch: 2628, train loss: 1.2239185199825042, validation loss: 1.2413478882416435.
epoch: 2629, train loss: 1.2172945125387349, validation loss: 1.2618800557178.
epoch: 2630, train loss: 1.2204416235652538, validation loss: 1.2511920255163442.
epoch: 2631, train loss: 1.2180656599342277, validation loss: 1.2455804037011189.
epoch: 2632, train loss: 1.2180428187781518, validation loss: 1.2574493574059529.
epoch: 2633, train loss: 1.223097404208752, validation loss: 1.2914586430010588.
epoch: 2634, train loss: 1.2174587052896482, validation loss: 1.2587983297265095.
epoch: 2635, train loss: 1.2227510399774675, validation loss: 1.268758924111076.
epoch: 2636, train loss: 1.2170441085045491, validation loss: 1.2546727657318115.
epoch: 2637, train loss: 1.2159902677623504, validation loss: 1.2438745135846345.
epoch: 2638, train loss: 1.2157702949068963, validation loss: 1.2426412364710933.
epoch: 2639, train loss: 1.2158117688030279, validation loss: 1.2481209506159243.
epoch: 2640, train loss: 1.2163062719030118, validation loss: 1.2465440708657969.
epoch: 2641, train loss: 1.2161360082276371, validation loss: 1.2560846650082131.
epoch: 2642, train loss: 1.2183479442508942, validation loss: 1.265553873518239.
epoch: 2643, train loss: 1.2179651719714524, validation loss: 1.2599996535674385.
epoch: 2644, train loss: 1.2190717688394248, validation loss: 1.258529606072799.
epoch: 2645, train loss: 1.2150833956692197, validation loss: 1.2897020526554273.
epoch: 2646, train loss: 1.2191336111191216, validation loss: 1.247281727583512.
epoch: 2647, train loss: 1.2184411320117636, validation loss: 1.2743998351304426.
epoch: 2648, train loss: 1.2189896872284216, validation loss: 1.2513560523157534.
epoch: 2649, train loss: 1.215242756616085, validation loss: 1.2584473723950593.
epoch: 2650, train loss: 1.2170185605320363, validation loss: 1.257381040117015.
epoch: 2651, train loss: 1.2216386521628144, validation loss: 1.2680960323499597.
epoch: 2652, train loss: 1.218553958682839, validation loss: 1.2939097933147266.
epoch: 2653, train loss: 1.2186873505968567, validation loss: 1.2566087971562925.
epoch: 2654, train loss: 1.2222125409939968, validation loss: 1.2497842104538628.
epoch: 2655, train loss: 1.2195812441887113, validation loss: 1.2541474052097485.
epoch: 2656, train loss: 1.2168566480689091, validation loss: 1.2505000363225522.
epoch: 2657, train loss: 1.2161313951562305, validation loss: 1.2632323607154514.
epoch: 2658, train loss: 1.2123132353528925, validation loss: 1.253794499065565.
epoch: 2659, train loss: 1.2141574938362891, validation loss: 1.3540722805520762.
epoch: 2660, train loss: 1.2148484877490122, validation loss: 1.2906006211819856.
epoch: 2661, train loss: 1.218448979045273, validation loss: 1.289697476055311.
epoch: 2662, train loss: 1.216106578844403, validation loss: 1.2446186801661616.
epoch: 2663, train loss: 1.2135962652503898, validation loss: 1.2542981272158416.
epoch: 2664, train loss: 1.2179388639030106, validation loss: 1.2568093590114429.
epoch: 2665, train loss: 1.2181735027820693, validation loss: 1.267217402872832.
epoch: 2666, train loss: 1.2202173318337957, validation loss: 1.2729652238928753.
epoch: 2667, train loss: 1.2189086478784543, validation loss: 1.2627342006434565.
epoch: 2668, train loss: 1.2168946113061467, validation loss: 1.2594768016234688.
epoch: 2669, train loss: 1.2147579444657772, validation loss: 1.2589111120804497.
epoch: 2670, train loss: 1.2244075361741793, validation loss: 1.2557122707366943.
epoch: 2671, train loss: 1.2214785442439788, validation loss: 1.2844789390978606.
epoch: 2672, train loss: 1.2172104218684205, validation loss: 1.2786317027133445.
epoch: 2673, train loss: 1.2182114769559387, validation loss: 1.2568518545316614.
epoch: 2674, train loss: 1.2170065291430971, validation loss: 1.2581753316132918.
epoch: 2675, train loss: 1.2218768990367925, validation loss: 1.2798476737478506.
epoch: 2676, train loss: 1.2215186762153556, validation loss: 1.2563667867494666.
epoch: 2677, train loss: 1.2139503791791584, validation loss: 1.2604839957278708.
epoch: 2678, train loss: 1.2186553850086457, validation loss: 1.2501420871071194.
epoch: 2679, train loss: 1.2168622749661087, validation loss: 1.2524146619050398.
epoch: 2680, train loss: 1.2167391044284226, validation loss: 1.2651466494021208.
epoch: 2681, train loss: 1.2180515013703512, validation loss: 1.2929001942924832.
epoch: 2682, train loss: 1.2272726428618126, validation loss: 1.2780256634173186.
epoch: 2683, train loss: 1.2186448803735435, validation loss: 1.2579831973366116.
epoch: 2684, train loss: 1.2193506649874766, validation loss: 1.2624113093251768.
epoch: 2685, train loss: 1.2141364615991574, validation loss: 1.2518979881120764.
epoch: 2686, train loss: 1.2189245869260315, validation loss: 1.2465473413467407.
epoch: 2687, train loss: 1.2235267720091234, validation loss: 1.267031104668327.
epoch: 2688, train loss: 1.2172643580567946, validation loss: 1.2477680703868037.
epoch: 2689, train loss: 1.2181219835893824, validation loss: 1.2529261578684268.
epoch: 2690, train loss: 1.2147981650238737, validation loss: 1.2502431714016458.
epoch: 2691, train loss: 1.21864462336269, validation loss: 1.2566608708837759.
epoch: 2692, train loss: 1.2113395349695049, validation loss: 1.2665806179461272.
epoch: 2693, train loss: 1.2155643450010807, validation loss: 1.2592063986736795.
epoch: 2694, train loss: 1.2174744409158689, validation loss: 1.2569720071295034.
epoch: 2695, train loss: 1.2183890309902505, validation loss: 1.2470723701559978.
epoch: 2696, train loss: 1.2203657845838354, validation loss: 1.273747646290323.
epoch: 2697, train loss: 1.216845878767311, validation loss: 1.2589784860610962.
epoch: 2698, train loss: 1.214795460394763, validation loss: 1.2561705889909163.
epoch: 2699, train loss: 1.21770554070079, validation loss: 1.259952425956726.
epoch: 2700, train loss: 1.2170307461274874, validation loss: 1.2653373531673267.
epoch: 2701, train loss: 1.2219181563876091, validation loss: 1.2941724787587705.
epoch: 2702, train loss: 1.2196684091463001, validation loss: 1.256294556286024.
epoch: 2703, train loss: 1.2200273198818943, validation loss: 1.2542509099711543.
epoch: 2704, train loss: 1.2182169146494035, validation loss: 1.2460760292799578.
epoch: 2705, train loss: 1.215817728173842, validation loss: 1.2465471029281616.
epoch: 2706, train loss: 1.2198236415145594, validation loss: 1.2642548706220544.
epoch: 2707, train loss: 1.2239278839268815, validation loss: 1.2971099252286165.
epoch: 2708, train loss: 1.2175551937260758, validation loss: 1.243251515471417.
epoch: 2709, train loss: 1.22286665877071, validation loss: 1.2916584533193838.
epoch: 2710, train loss: 1.2182036933548954, validation loss: 1.2525680842606917.
epoch: 2711, train loss: 1.2173676720452964, validation loss: 1.2512817745623381.
epoch: 2712, train loss: 1.2191569597349254, validation loss: 1.2745652820753015.
epoch: 2713, train loss: 1.2213939308026516, validation loss: 1.255694182022758.
epoch: 2714, train loss: 1.215973634238637, validation loss: 1.294235198394112.
epoch: 2715, train loss: 1.214739742629025, validation loss: 1.2593441631482996.
epoch: 2716, train loss: 1.2198907771241774, validation loss: 1.2721267005671626.
epoch: 2717, train loss: 1.2173468410421948, validation loss: 1.2536857750104822.
epoch: 2718, train loss: 1.217365226614366, validation loss: 1.2799841632013735.
epoch: 2719, train loss: 1.2223835516413417, validation loss: 1.2659994674765545.
epoch: 2720, train loss: 1.2191115213096688, validation loss: 1.2437067912972493.
epoch: 2721, train loss: 1.215551300880012, validation loss: 1.2570983845254649.
epoch: 2722, train loss: 1.2119271853648195, validation loss: 1.2594074477320132.
epoch: 2723, train loss: 1.2176817414957448, validation loss: 1.2489779721135679.
epoch: 2724, train loss: 1.22329943989395, validation loss: 1.2811420067496921.
epoch: 2725, train loss: 1.2336492166606658, validation loss: 1.2530371883641118.
epoch: 2726, train loss: 1.2204320332325926, validation loss: 1.2491326332092285.
epoch: 2727, train loss: 1.2134413489507974, validation loss: 1.2528074513310972.
epoch: 2728, train loss: 1.2192596470544097, validation loss: 1.2532480436822642.
epoch: 2729, train loss: 1.2260075359169496, validation loss: 1.2490752676258916.
epoch: 2730, train loss: 1.2153873082694657, validation loss: 1.248108516568723.
epoch: 2731, train loss: 1.2154547140138958, validation loss: 1.2630315915397976.
epoch: 2732, train loss: 1.217875685166875, validation loss: 1.2636086629784626.
epoch: 2733, train loss: 1.2174111845296458, validation loss: 1.2788980369982512.
epoch: 2734, train loss: 1.2178892367476717, validation loss: 1.2486940311348957.
epoch: 2735, train loss: 1.2204638293030066, validation loss: 1.2639559507369995.
epoch: 2736, train loss: 1.2179888224383013, validation loss: 1.2578371711399243.
epoch: 2737, train loss: 1.2142583186473321, validation loss: 1.2504946719045225.
epoch: 2738, train loss: 1.2161705712659643, validation loss: 1.300272858661154.
epoch: 2739, train loss: 1.2204804179865285, validation loss: 1.3267566069312717.
epoch: 2740, train loss: 1.2187701266839963, validation loss: 1.2531232885692432.
epoch: 2741, train loss: 1.2175192198622118, validation loss: 1.2433933537939321.
epoch: 2742, train loss: 1.2152380002747982, validation loss: 1.2439086022584334.
epoch: 2743, train loss: 1.2179000552641142, validation loss: 1.2583249289056528.
epoch: 2744, train loss: 1.2203925224619174, validation loss: 1.2933597357376763.
epoch: 2745, train loss: 1.2258858472929088, validation loss: 1.2538101465805718.
epoch: 2746, train loss: 1.219992661694868, validation loss: 1.2505470255146856.
epoch: 2747, train loss: 1.2153569153689463, validation loss: 1.2455077482306438.
epoch: 2748, train loss: 1.2219898033579555, validation loss: 1.2394404929617178.
epoch: 2749, train loss: 1.2178259748931324, validation loss: 1.2587917887646218.
epoch: 2750, train loss: 1.2161048432008936, validation loss: 1.252949217091436.
epoch: 2751, train loss: 1.2128850516922978, validation loss: 1.2534214050873467.
epoch: 2752, train loss: 1.224243692301829, validation loss: 1.2694758591444597.
epoch: 2753, train loss: 1.225082511201911, validation loss: 1.2596757930258047.
epoch: 2754, train loss: 1.2201810364329486, validation loss: 1.2500553286593894.
epoch: 2755, train loss: 1.215907800088235, validation loss: 1.2942158502081167.
epoch: 2756, train loss: 1.2304216929531973, validation loss: 1.254706797392472.
epoch: 2757, train loss: 1.2186661302496533, validation loss: 1.253943629886793.
epoch: 2758, train loss: 1.2145988295931336, validation loss: 1.2811707050903984.
epoch: 2759, train loss: 1.2198710627512102, validation loss: 1.2990264737087747.
epoch: 2760, train loss: 1.2158079978522904, validation loss: 1.25065773466359.
epoch: 2761, train loss: 1.213816698538054, validation loss: 1.2686846670897112.
epoch: 2762, train loss: 1.2193179907055076, validation loss: 1.2439422503761624.
epoch: 2763, train loss: 1.2141536714833812, validation loss: 1.2690081648204639.
epoch: 2764, train loss: 1.2205248163380753, validation loss: 1.2768051002336585.
epoch: 2765, train loss: 1.2137373663963529, validation loss: 1.247111491535021.
epoch: 2766, train loss: 1.2116049582805108, validation loss: 1.304422191951586.
epoch: 2767, train loss: 1.2157573131246304, validation loss: 1.2483445924261343.
epoch: 2768, train loss: 1.2164159039838598, validation loss: 1.2427505565726238.
epoch: 2769, train loss: 1.2190818742874565, validation loss: 1.265809696653615.
epoch: 2770, train loss: 1.2147329651981318, validation loss: 1.255442676336869.
epoch: 2771, train loss: 1.2189723745398564, validation loss: 1.2512192311494246.
epoch: 2772, train loss: 1.2163351511736529, validation loss: 1.265693654184756.
epoch: 2773, train loss: 1.2205672504705027, validation loss: 1.2580757089283154.
epoch: 2774, train loss: 1.2144712898709358, validation loss: 1.271615225335826.
epoch: 2775, train loss: 1.2163514008215808, validation loss: 1.270991475685783.
epoch: 2776, train loss: 1.2230395188025378, validation loss: 1.2705277308173801.
epoch: 2777, train loss: 1.2139036163277583, validation loss: 1.2758933461230735.
epoch: 2778, train loss: 1.2185327831758272, validation loss: 1.2571527335954749.
epoch: 2779, train loss: 1.2168108038946028, validation loss: 1.2465510057366413.
epoch: 2780, train loss: 1.2160620044130799, validation loss: 1.2834093829859858.
epoch: 2781, train loss: 1.2204309865969036, validation loss: 1.26892860557722.
epoch: 2782, train loss: 1.219735940661999, validation loss: 1.248708548753158.
epoch: 2783, train loss: 1.216944494378676, validation loss: 1.2496682923773061.
epoch: 2784, train loss: 1.2178172944882595, validation loss: 1.2659402152766353.
epoch: 2785, train loss: 1.2180107613222315, validation loss: 1.2504938478055208.
epoch: 2786, train loss: 1.2189968277554992, validation loss: 1.2652043104171753.
epoch: 2787, train loss: 1.219511046322114, validation loss: 1.2509449772212817.
epoch: 2788, train loss: 1.2178476053640384, validation loss: 1.254330002743265.
epoch: 2789, train loss: 1.218468237360683, validation loss: 1.2481324465378472.
epoch: 2790, train loss: 1.224096131980966, validation loss: 1.2439474489377893.
epoch: 2791, train loss: 1.2302921857308904, validation loss: 1.2692391613255376.
epoch: 2792, train loss: 1.2258927876796197, validation loss: 1.253735759983892.
epoch: 2793, train loss: 1.2187008387451872, validation loss: 1.2655666496442712.
epoch: 2794, train loss: 1.2141140425970796, validation loss: 1.2559245721153591.
epoch: 2795, train loss: 1.2178542646793051, validation loss: 1.2686272341272105.
epoch: 2796, train loss: 1.2223141324629478, validation loss: 1.2480091323023257.
epoch: 2797, train loss: 1.2130517762735349, validation loss: 1.3543865214223447.
epoch: 2798, train loss: 1.2175676505500024, validation loss: 1.287151927533357.
epoch: 2799, train loss: 1.2185427584779371, validation loss: 1.257625787154488.
epoch: 2800, train loss: 1.2150038907287317, validation loss: 1.2856873429339866.
epoch: 2801, train loss: 1.2149626125983142, validation loss: 1.2668687312499336.
epoch: 2802, train loss: 1.2181389167768146, validation loss: 1.3048760579979939.
epoch: 2803, train loss: 1.2167836394878702, validation loss: 1.3120779991149902.
epoch: 2804, train loss: 1.215349507988046, validation loss: 1.2649318187133125.
epoch: 2805, train loss: 1.2162286349392812, validation loss: 1.253917123960412.
epoch: 2806, train loss: 1.2159613502134972, validation loss: 1.2637646042782327.
epoch: 2807, train loss: 1.220342734538087, validation loss: 1.2986371206200642.
epoch: 2808, train loss: 1.222134846066116, validation loss: 1.2660226148107778.
epoch: 2809, train loss: 1.2173451907044157, validation loss: 1.2534155690151711.
epoch: 2810, train loss: 1.216528819241655, validation loss: 1.2574482378752336.
epoch: 2811, train loss: 1.224933999394058, validation loss: 1.282548805941706.
epoch: 2812, train loss: 1.2217111259425453, validation loss: 1.2548432712969573.
epoch: 2813, train loss: 1.2171408550454936, validation loss: 1.2506251594294673.
epoch: 2814, train loss: 1.2169562796933935, validation loss: 1.2554821346117102.
epoch: 2815, train loss: 1.219937225000574, validation loss: 1.2480994773947673.
epoch: 2816, train loss: 1.2129532558108689, validation loss: 1.2851142986961033.
epoch: 2817, train loss: 1.218999928290691, validation loss: 1.2543300701224285.
epoch: 2818, train loss: 1.2216136269613143, validation loss: 1.2789916059245234.
epoch: 2819, train loss: 1.217038377709345, validation loss: 1.3224713854167773.
epoch: 2820, train loss: 1.2162988295248889, validation loss: 1.2820047191951587.
epoch: 2821, train loss: 1.2162509194207847, validation loss: 1.307814333749854.
epoch: 2822, train loss: 1.2179664646813628, validation loss: 1.272837141285772.
epoch: 2823, train loss: 1.2199592491902342, validation loss: 1.2551101912622866.
epoch: 2824, train loss: 1.2193249234365762, validation loss: 1.260247826576233.
epoch: 2825, train loss: 1.2136034101521203, validation loss: 1.2541494421336963.
epoch: 2826, train loss: 1.217494825704382, validation loss: 1.254541039466858.
epoch: 2827, train loss: 1.2179078049615983, validation loss: 1.256849423698757.
epoch: 2828, train loss: 1.2219449073896496, validation loss: 1.2499300863431848.
epoch: 2829, train loss: 1.2245243459666542, validation loss: 1.24380013735398.
epoch: 2830, train loss: 1.2177522357450712, validation loss: 1.2542066418606301.
epoch: 2831, train loss: 1.2163284207702776, validation loss: 1.265843593555948.
epoch: 2832, train loss: 1.2143458401391265, validation loss: 1.265765817269035.
epoch: 2833, train loss: 1.2191897783804377, validation loss: 1.2458049784535947.
epoch: 2834, train loss: 1.2166434657683067, validation loss: 1.2458830242571624.
epoch: 2835, train loss: 1.2133360379332796, validation loss: 1.2450011553971663.
epoch: 2836, train loss: 1.2132241758731528, validation loss: 1.253880324571029.
epoch: 2837, train loss: 1.2148939677334707, validation loss: 1.2620337994202324.
epoch: 2838, train loss: 1.217862411376533, validation loss: 1.252551794052124.
epoch: 2839, train loss: 1.2193329432688722, validation loss: 1.2661508166271707.
epoch: 2840, train loss: 1.2160331142058067, validation loss: 1.2661384188610574.
epoch: 2841, train loss: 1.2160942237311547, validation loss: 1.290725588798523.
epoch: 2842, train loss: 1.2149375349009803, validation loss: 1.267385493154111.
epoch: 2843, train loss: 1.2166267666248007, validation loss: 1.2646839929663616.
epoch: 2844, train loss: 1.2131682251571516, validation loss: 1.2618614694346553.
epoch: 2845, train loss: 1.215658980772036, validation loss: 1.2621061750080274.
epoch: 2846, train loss: 1.2152806804814469, validation loss: 1.2561259373374607.
epoch: 2847, train loss: 1.2166742206713475, validation loss: 1.2545237230217976.
epoch: 2848, train loss: 1.2178513260062682, validation loss: 1.2587402333383975.
epoch: 2849, train loss: 1.229066575339081, validation loss: 1.2803499128507532.
epoch: 2850, train loss: 1.2161383825704593, validation loss: 1.2551347276438838.
epoch: 2851, train loss: 1.215659309964661, validation loss: 1.2532970749813577.
epoch: 2852, train loss: 1.2159869998966881, validation loss: 1.2731834857360176.
epoch: 2853, train loss: 1.2148823409999183, validation loss: 1.268722414970398.
epoch: 2854, train loss: 1.2166144815059976, validation loss: 1.246490390404411.
epoch: 2855, train loss: 1.221080786591276, validation loss: 1.2608974031780078.
epoch: 2856, train loss: 1.2150834197298102, validation loss: 1.2762200054915056.
epoch: 2857, train loss: 1.2159653891117201, validation loss: 1.2979370873907339.
epoch: 2858, train loss: 1.2206489285197826, validation loss: 1.2620547543401304.
epoch: 2859, train loss: 1.216892127597004, validation loss: 1.2501439011615256.
epoch: 2860, train loss: 1.2213563503475364, validation loss: 1.2640447564747022.
epoch: 2861, train loss: 1.2182413897383104, validation loss: 1.2532076369161191.
epoch: 2862, train loss: 1.2174871952161876, validation loss: 1.2607120120007058.
epoch: 2863, train loss: 1.2191920750731722, validation loss: 1.313979465028514.
epoch: 2864, train loss: 1.227105667831701, validation loss: 1.2537579588268115.
epoch: 2865, train loss: 1.221720037110355, validation loss: 1.2629039857698523.
epoch: 2866, train loss: 1.2168558343834834, validation loss: 1.2466400084288225.
epoch: 2867, train loss: 1.2151716346040777, validation loss: 1.3227236633715422.
epoch: 2868, train loss: 1.2206566191594534, validation loss: 1.2493224869603696.
epoch: 2869, train loss: 1.2109968837248075, validation loss: 1.25209074953328.
epoch: 2870, train loss: 1.222544858215052, validation loss: 1.2502740258755891.
epoch: 2871, train loss: 1.2157994355630437, validation loss: 1.2521636848864348.
epoch: 2872, train loss: 1.215089730166514, validation loss: 1.2564588111379873.
epoch: 2873, train loss: 1.2184164458458577, validation loss: 1.3165555363116057.
epoch: 2874, train loss: 1.2258105496747778, validation loss: 1.2480878311654795.
epoch: 2875, train loss: 1.2155306875158887, validation loss: 1.2490241734877876.
epoch: 2876, train loss: 1.2193410943407532, validation loss: 1.270678805268329.
epoch: 2877, train loss: 1.2142082923049227, validation loss: 1.2715615552404653.
epoch: 2878, train loss: 1.2123445950516867, validation loss: 1.3157703150873599.
epoch: 2879, train loss: 1.2163491456880482, validation loss: 1.2560196544813074.
epoch: 2880, train loss: 1.2116872739354405, validation loss: 1.2476255168085513.
epoch: 2881, train loss: 1.2173056219695906, validation loss: 1.2990453087765237.
epoch: 2882, train loss: 1.2216161161387733, validation loss: 1.2653569605039514.
epoch: 2883, train loss: 1.2161568064208423, validation loss: 1.2598916551341182.
epoch: 2884, train loss: 1.2146415688575956, validation loss: 1.2854725070621655.
epoch: 2885, train loss: 1.2257373081434757, validation loss: 1.2771295620047527.
epoch: 2886, train loss: 1.2256941478186791, validation loss: 1.2507365112719329.
epoch: 2887, train loss: 1.2159393992992715, validation loss: 1.2763554998066113.
epoch: 2888, train loss: 1.2157769782827534, validation loss: 1.288658504900725.
epoch: 2889, train loss: 1.2146931099235465, validation loss: 1.2678939155910327.
epoch: 2890, train loss: 1.2168209509018364, validation loss: 1.260689766510673.
epoch: 2891, train loss: 1.2190463805417402, validation loss: 1.2818358462789785.
epoch: 2892, train loss: 1.2164606326216951, validation loss: 1.25699215868245.
epoch: 2893, train loss: 1.2141515180605267, validation loss: 1.2476812030958093.
epoch: 2894, train loss: 1.2169590379120012, validation loss: 1.2899489765581877.
epoch: 2895, train loss: 1.2159507919888977, validation loss: 1.2533876584923787.
epoch: 2896, train loss: 1.2198740473581016, validation loss: 1.2529851820157922.
epoch: 2897, train loss: 1.220909854687682, validation loss: 1.2539609152337778.
epoch: 2898, train loss: 1.2174532982187534, validation loss: 1.2725468200186025.
epoch: 2899, train loss: 1.2135780524770055, validation loss: 1.2595912321754124.
epoch: 2900, train loss: 1.2141820520435997, validation loss: 1.2599579665971838.
epoch: 2901, train loss: 1.2192141408220343, validation loss: 1.2469106912612915.
epoch: 2902, train loss: 1.215670410646211, validation loss: 1.246889565301978.
epoch: 2903, train loss: 1.2201115888193113, validation loss: 1.2601241961769436.
epoch: 2904, train loss: 1.2282336228484407, validation loss: 1.2552478365276172.
epoch: 2905, train loss: 1.2217797281545237, validation loss: 1.2684172184570977.
epoch: 2906, train loss: 1.2194197943451208, validation loss: 1.6689362111298933.
epoch: 2907, train loss: 1.217598430607297, validation loss: 1.253468606782996.
epoch: 2908, train loss: 1.2172093697644155, validation loss: 1.2529407843299534.
epoch: 2909, train loss: 1.2141377980555963, validation loss: 1.2546518574590269.
epoch: 2910, train loss: 1.2153893731056002, validation loss: 1.288122042365696.
epoch: 2911, train loss: 1.2241529685641648, validation loss: 1.2622280950131624.
epoch: 2912, train loss: 1.2188865307274215, validation loss: 1.249029340951339.
epoch: 2913, train loss: 1.2204447711279633, validation loss: 1.280197781065236.
epoch: 2914, train loss: 1.219350010976879, validation loss: 1.2726313186728435.
epoch: 2915, train loss: 1.2217799906336932, validation loss: 1.2588934794716213.
epoch: 2916, train loss: 1.2161965173318845, validation loss: 1.2482127780499666.
epoch: 2917, train loss: 1.2155446951542426, validation loss: 1.2958786021108213.
epoch: 2918, train loss: 1.2167170725831198, validation loss: 1.2589687419974285.
epoch: 2919, train loss: 1.2176122731025065, validation loss: 1.2682814079782236.
epoch: 2920, train loss: 1.2158680169954212, validation loss: 1.2631456281827844.
epoch: 2921, train loss: 1.217374145437818, validation loss: 1.2599412824796594.
epoch: 2922, train loss: 1.2225066587465618, validation loss: 1.2711326972298.
epoch: 2923, train loss: 1.2183682032681387, validation loss: 1.254633789477141.
epoch: 2924, train loss: 1.2164931691021001, validation loss: 1.2439453550007031.
epoch: 2925, train loss: 1.2124970495154004, validation loss: 1.2801640396532805.
epoch: 2926, train loss: 1.2132334184209141, validation loss: 1.2522192364153655.
epoch: 2927, train loss: 1.2131003644488274, validation loss: 1.2491751598275227.
epoch: 2928, train loss: 1.215593938433796, validation loss: 1.2536575016768083.
epoch: 2929, train loss: 1.2191875210595786, validation loss: 1.3201685988384744.
epoch: 2930, train loss: 1.229947652291814, validation loss: 1.2658214102620664.
epoch: 2931, train loss: 1.222742347542299, validation loss: 1.308097497276638.
epoch: 2932, train loss: 1.2284034796811025, validation loss: 1.2536768394967783.
epoch: 2933, train loss: 1.21988991859856, validation loss: 1.244381158248238.
epoch: 2934, train loss: 1.219979387904526, validation loss: 1.2701230722924937.
epoch: 2935, train loss: 1.2182258323791924, validation loss: 1.2683944442997808.
epoch: 2936, train loss: 1.2209397357538205, validation loss: 1.2791000345478887.
epoch: 2937, train loss: 1.2146923126430687, validation loss: 1.253832977751027.
epoch: 2938, train loss: 1.21618418737289, validation loss: 1.2607049423715342.
epoch: 2939, train loss: 1.2171797653950682, validation loss: 1.242512065431346.
epoch: 2940, train loss: 1.2218861131493104, validation loss: 1.2520204005034075.
epoch: 2941, train loss: 1.2184903457624103, validation loss: 1.2655389930890955.
epoch: 2942, train loss: 1.2127732705632481, validation loss: 1.2952289633128955.
epoch: 2943, train loss: 1.2342385053634644, validation loss: 1.2571191373078718.
epoch: 2944, train loss: 1.216878051057868, validation loss: 1.259242954461471.
epoch: 2945, train loss: 1.2170412988837707, validation loss: 1.2491891435954883.
epoch: 2946, train loss: 1.2179108070671012, validation loss: 1.2560625179954197.
epoch: 2947, train loss: 1.2183192137184493, validation loss: 1.2588129043579102.
epoch: 2948, train loss: 1.2173190029389267, validation loss: 1.2541190852289614.
epoch: 2949, train loss: 1.2169493950835062, validation loss: 1.2593419448189114.
epoch: 2950, train loss: 1.2151488962523433, validation loss: 1.2519331237544185.
epoch: 2951, train loss: 1.2119734932523254, validation loss: 1.2803551165953926.
epoch: 2952, train loss: 1.214848501966634, validation loss: 1.263888841089995.
epoch: 2953, train loss: 1.2199193228275405, validation loss: 1.248907384665116.
epoch: 2954, train loss: 1.2170998897027532, validation loss: 1.2590674835702647.
epoch: 2955, train loss: 1.219524109035457, validation loss: 1.2394738819288171.
epoch: 2956, train loss: 1.2149692270733894, validation loss: 1.3018368327099343.
epoch: 2957, train loss: 1.2181446235114282, validation loss: 1.251447573952053.
epoch: 2958, train loss: 1.2139425933907886, validation loss: 1.3181073665618896.
epoch: 2959, train loss: 1.2145847508666712, validation loss: 1.2549517258353855.
epoch: 2960, train loss: 1.2215024725012822, validation loss: 1.2540035817934119.
epoch: 2961, train loss: 1.2165186197385875, validation loss: 1.366315281909445.
epoch: 2962, train loss: 1.2182249410436787, validation loss: 1.262751086898472.
epoch: 2963, train loss: 1.2128218598322038, validation loss: 1.2549870117850925.
epoch: 2964, train loss: 1.2193318780409086, validation loss: 1.26663004833719.
epoch: 2965, train loss: 1.2244669275546292, validation loss: 1.2628618375114773.
epoch: 2966, train loss: 1.2158477721957985, validation loss: 1.301369739615399.
epoch: 2967, train loss: 1.2227162986720375, validation loss: 1.2453403939371523.
epoch: 2968, train loss: 1.2186676843450703, validation loss: 1.3033284104388694.
epoch: 2969, train loss: 1.2138442413522563, validation loss: 1.2976404065671174.
epoch: 2970, train loss: 1.2179139994700021, validation loss: 1.2496171464090762.
epoch: 2971, train loss: 1.2198142699145396, validation loss: 1.2745101244553276.
epoch: 2972, train loss: 1.2184725638923295, validation loss: 1.2568525749704111.
epoch: 2973, train loss: 1.2158672634614718, validation loss: 1.2466513955074807.
epoch: 2974, train loss: 1.217993720955805, validation loss: 1.2509270180826602.
epoch: 2975, train loss: 1.2151476221347073, validation loss: 1.2657456501670505.
epoch: 2976, train loss: 1.2170846232580483, validation loss: 1.247867262881735.
epoch: 2977, train loss: 1.2191319093791717, validation loss: 1.2649429829224297.
epoch: 2978, train loss: 1.2120914317052298, validation loss: 1.2924157070076985.
epoch: 2979, train loss: 1.213838029345241, validation loss: 1.2543705028036367.
epoch: 2980, train loss: 1.2148213320915853, validation loss: 1.2798948909925378.
epoch: 2981, train loss: 1.2181563071154673, validation loss: 1.2531010638112607.
epoch: 2982, train loss: 1.2281654066995744, validation loss: 1.2548917220986409.
epoch: 2983, train loss: 1.214842190436267, validation loss: 1.249976406926694.
epoch: 2984, train loss: 1.2169048611177218, validation loss: 1.2641952970753545.
epoch: 2985, train loss: 1.219747057748497, validation loss: 1.2896320975345115.
epoch: 2986, train loss: 1.2189577139845682, validation loss: 1.244727761849113.
epoch: 2987, train loss: 1.2144479423487953, validation loss: 1.2524819114933843.
epoch: 2988, train loss: 1.2115790800217094, validation loss: 1.2607324019722317.
epoch: 2989, train loss: 1.2124902141203575, validation loss: 1.25112827964451.
epoch: 2990, train loss: 1.2122755236581926, validation loss: 1.3163160189338352.
epoch: 2991, train loss: 1.2220258537782442, validation loss: 1.2569578937862231.
epoch: 2992, train loss: 1.215432433907045, validation loss: 1.2551243771677432.
epoch: 2993, train loss: 1.2194144758609458, validation loss: 1.264594166175179.
epoch: 2994, train loss: 1.2180932705555487, validation loss: 1.267671419226605.
epoch: 2995, train loss: 1.2142106371188381, validation loss: 1.2522997026858123.
epoch: 2996, train loss: 1.220341449483819, validation loss: 1.246796587239141.
epoch: 2997, train loss: 1.228571712423902, validation loss: 1.271874982377757.
epoch: 2998, train loss: 1.216887073779325, validation loss: 1.2968305712160857.
epoch: 2999, train loss: 1.2152059526618468, validation loss: 1.2791364711263906.
epoch: 3000, train loss: 1.2175215657697904, validation loss: 1.2900102034859036.
best validation loss 1.2377756626709648 at epoch 2213.
