seed:  666
number of classes: 10
how to merge clusters:  [[0, 9], [1, 5], 2, [3, 8], 4, 6, 7]
whether to further subcluster data according to chemical reaction: False
number of epochs to train: 2000
learning rate decay to half at epoch 1000.
begin to select hard pairs at epoch 200
batch size: 96
number of hardest positive pairs for each mini-batch:  128
number of hardest negative pairs for each mini-batch:  128
number of workers to load data:  36
similar margin of contrastive loss: 0.0
dissimilar margin of contrastive loss: 2.0
device:  cuda
number of classes after merging:  7
number of pockets in training set:  10527
number of pockets in validation set:  2254
number of pockets in test set:  2263
model architecture:
SelectiveSiameseNet(
  (embedding_net): EmbeddingNet(
    (set2set): Set2Set(32, 64)
    (conv1): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=11, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=11, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=32, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=32, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=32, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=32, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv4): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=32, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=32, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.003
    weight_decay: 0.0005
)
loss function:
SelectiveContrastiveLoss(similar_margin=0.0, dissimilar_margin=2.0, num_pos_pair=128, num_neg_pair=128)
epoch: 1, train loss: 0.8919269021497954, validation loss: 0.8597954770793086.
epoch: 2, train loss: 0.8377458152421023, validation loss: 0.7826247992722885.
epoch: 3, train loss: 0.7878657563017049, validation loss: 0.7947863392207933.
epoch: 4, train loss: 0.8147141074915545, validation loss: 0.8603013520655425.
epoch: 5, train loss: 0.7804196053141848, validation loss: 0.7918327658072762.
epoch: 6, train loss: 0.7597336670674315, validation loss: 0.8688470228858616.
epoch: 7, train loss: 0.7478896535317833, validation loss: 0.7658947991288226.
epoch: 8, train loss: 0.7102270238443252, validation loss: 0.797407575275587.
epoch: 9, train loss: 0.768983653105727, validation loss: 0.7664982495100602.
epoch: 10, train loss: 0.7477178636494033, validation loss: 0.8786146174306455.
epoch: 11, train loss: 0.728062564900162, validation loss: 0.7374725030816119.
epoch: 12, train loss: 0.732450559872006, validation loss: 0.7962213676908741.
epoch: 13, train loss: 0.7198697864462477, validation loss: 0.7673238956409952.
epoch: 14, train loss: 0.7070561144330086, validation loss: 0.7739574416824009.
epoch: 15, train loss: 0.7453395636803514, validation loss: 0.7434572072132773.
epoch: 16, train loss: 0.6987606544013417, validation loss: 0.6722285760485608.
epoch: 17, train loss: 0.6851174552506263, validation loss: 0.7382686747157056.
epoch: 18, train loss: 0.6991854985372736, validation loss: 0.685842285985532.
epoch: 19, train loss: 0.6984016044971046, validation loss: 0.7874718852665114.
epoch: 20, train loss: 0.7117273408338565, validation loss: 0.7702798804511195.
epoch: 21, train loss: 0.7087266871688562, validation loss: 0.7486926472705343.
epoch: 22, train loss: 0.7112503975903223, validation loss: 0.8354249363360198.
epoch: 23, train loss: 0.7187507398631594, validation loss: 0.6758067348729009.
epoch: 24, train loss: 0.6850385857284615, validation loss: 0.7607845223468283.
epoch: 25, train loss: 0.6937253365822889, validation loss: 0.6549107302790103.
epoch: 26, train loss: 0.6931109600657717, validation loss: 0.6471938115099202.
epoch: 27, train loss: 0.6698171154621544, validation loss: 0.7451326095539591.
epoch: 28, train loss: 0.714206173879291, validation loss: 0.6999579771705295.
epoch: 29, train loss: 0.6848127549394555, validation loss: 0.7085432967414027.
epoch: 30, train loss: 0.7011352504065277, validation loss: 0.6920262354871501.
epoch: 31, train loss: 0.672091644291484, validation loss: 0.7882883989292643.
epoch: 32, train loss: 0.7108407794335566, validation loss: 0.8517659928487695.
epoch: 33, train loss: 0.6955097530959943, validation loss: 0.794893697552059.
epoch: 34, train loss: 0.673309872183231, validation loss: 0.72246297546055.
epoch: 35, train loss: 0.70821601480519, validation loss: 0.6856038661106773.
epoch: 36, train loss: 0.6572773084727996, validation loss: 0.7261862314265707.
epoch: 37, train loss: 0.6743841729032884, validation loss: 0.7343679251878158.
epoch: 38, train loss: 0.6763290754698832, validation loss: 0.7156784210516058.
epoch: 39, train loss: 0.6376685724345916, validation loss: 0.7281865594179734.
epoch: 40, train loss: 0.682093849149319, validation loss: 0.6781667639379916.
epoch: 41, train loss: 0.6882162608137918, validation loss: 0.6674283250518467.
epoch: 42, train loss: 0.6643519688636885, validation loss: 0.6894926623157833.
epoch: 43, train loss: 0.6421310466910721, validation loss: 0.8027222039906875.
epoch: 44, train loss: 0.6714278987241448, validation loss: 0.6684439700582753.
epoch: 45, train loss: 0.6825275057499561, validation loss: 0.6660506569820902.
epoch: 46, train loss: 0.6653672866865036, validation loss: 0.7411222613376119.
epoch: 47, train loss: 0.6403996695619111, validation loss: 0.6966387862744539.
epoch: 48, train loss: 0.6848098939165063, validation loss: 0.6685992634814718.
epoch: 49, train loss: 0.6797791060504563, validation loss: 0.6668383427288221.
epoch: 50, train loss: 0.6431491052338837, validation loss: 0.7267255510972894.
epoch: 51, train loss: 0.6720515697374256, validation loss: 0.6677075391230376.
epoch: 52, train loss: 0.6805001160967241, validation loss: 0.7535978426104006.
epoch: 53, train loss: 0.665989238734639, validation loss: 0.7379792747290238.
epoch: 54, train loss: 0.6544159259818015, validation loss: 0.7198648789654607.
epoch: 55, train loss: 0.6464579788916701, validation loss: 0.7179589232672816.
epoch: 56, train loss: 0.65531460735776, validation loss: 0.709438470394715.
epoch: 57, train loss: 0.6672448740092987, validation loss: 0.6418272632619609.
epoch: 58, train loss: 0.6611943100023707, validation loss: 0.6789985765581545.
epoch: 59, train loss: 0.6483467910267892, validation loss: 0.6948394788348157.
epoch: 60, train loss: 0.638353874923986, validation loss: 0.6927157795947531.
epoch: 61, train loss: 0.6638885307202645, validation loss: 0.7002789844637332.
epoch: 62, train loss: 0.658344313092188, validation loss: 0.7068002405373947.
epoch: 63, train loss: 0.6640076560711642, validation loss: 0.6017723329689192.
epoch: 64, train loss: 0.6233050101393953, validation loss: 0.6777074142642643.
epoch: 65, train loss: 0.6281565904890726, validation loss: 0.7277742235556893.
epoch: 66, train loss: 0.6361073370373577, validation loss: 0.7284693329230599.
epoch: 67, train loss: 0.6569475003885566, validation loss: 0.7672237131906592.
epoch: 68, train loss: 0.6822656712947636, validation loss: 0.7206959128379822.
epoch: 69, train loss: 0.6466219663073164, validation loss: 0.6259410757085552.
epoch: 70, train loss: 0.6170478575273391, validation loss: 0.6632131700930388.
epoch: 71, train loss: 0.6460378793401456, validation loss: 0.6201434329799984.
epoch: 72, train loss: 0.6245298951590826, validation loss: 0.6339071885399197.
epoch: 73, train loss: 0.6438591381825438, validation loss: 0.7440841230361358.
epoch: 74, train loss: 0.6211156675574976, validation loss: 0.6604933324067489.
epoch: 75, train loss: 0.6314030095524744, validation loss: 0.6733433772688326.
epoch: 76, train loss: 0.6435627614686249, validation loss: 0.7064933945303378.
epoch: 77, train loss: 0.6253695255572643, validation loss: 0.6368789517361185.
epoch: 78, train loss: 0.6410886276205745, validation loss: 0.6466763822928719.
epoch: 79, train loss: 0.6254227486772275, validation loss: 0.7239180220210034.
epoch: 80, train loss: 0.6491402155215588, validation loss: 0.7508081184781116.
epoch: 81, train loss: 0.6364122342079057, validation loss: 0.6990795990695124.
epoch: 82, train loss: 0.6624769240344336, validation loss: 0.6731773109539695.
epoch: 83, train loss: 0.618302703723995, validation loss: 0.6775430078091829.
epoch: 84, train loss: 0.6476031484407022, validation loss: 0.6297106043152187.
epoch: 85, train loss: 0.6465004504820623, validation loss: 0.6656248284422833.
epoch: 86, train loss: 0.6287123317565393, validation loss: 0.7612609215404676.
epoch: 87, train loss: 0.6543283407841254, validation loss: 0.6038372296354045.
epoch: 88, train loss: 0.6295808840782271, validation loss: 0.6505171773226365.
epoch: 89, train loss: 0.6185381628504587, validation loss: 0.613704765620439.
epoch: 90, train loss: 0.6268965517162183, validation loss: 0.6374102714269058.
epoch: 91, train loss: 0.6061108317397056, validation loss: 0.7492945971696273.
epoch: 92, train loss: 0.6043409172001235, validation loss: 0.707741045433542.
epoch: 93, train loss: 0.6248747974360754, validation loss: 0.5907628730587338.
epoch: 94, train loss: 0.6195489053332478, validation loss: 0.6712051746637925.
epoch: 95, train loss: 0.6040498133099407, validation loss: 0.7490011259265568.
epoch: 96, train loss: 0.6571681332697562, validation loss: 0.7177220770846242.
epoch: 97, train loss: 0.6260202838740218, validation loss: 0.5956456492776456.
epoch: 98, train loss: 0.6291292837453545, validation loss: 0.6527324487333712.
epoch: 99, train loss: 0.6281055788928216, validation loss: 0.6541502268418021.
epoch: 100, train loss: 0.6021140116617221, validation loss: 0.7195530961389127.
epoch: 101, train loss: 0.644955484418694, validation loss: 0.6498558430568032.
epoch: 102, train loss: 0.5986372853091003, validation loss: 0.7102184438187144.
epoch: 103, train loss: 0.6219462323079415, validation loss: 0.7280346219954283.
epoch: 104, train loss: 0.6033996313536932, validation loss: 0.7371288693469503.
epoch: 105, train loss: 0.6216511075649787, validation loss: 0.6463412979374761.
epoch: 106, train loss: 0.6404406097503977, validation loss: 0.6634104161158852.
epoch: 107, train loss: 0.6307353295317484, validation loss: 0.7431723371795986.
epoch: 108, train loss: 0.6232582836522969, validation loss: 0.6462843638399373.
epoch: 109, train loss: 0.60670377491811, validation loss: 0.6610061318978019.
epoch: 110, train loss: 0.6009728238670105, validation loss: 0.7603626821352087.
epoch: 111, train loss: 0.5998554617986767, validation loss: 0.703972894212474.
epoch: 112, train loss: 0.6188461299336284, validation loss: 0.6665855503600576.
epoch: 113, train loss: 0.6210883019167349, validation loss: 0.7375648928725201.
epoch: 114, train loss: 0.5818338785149636, validation loss: 0.7718658071497212.
epoch: 115, train loss: 0.6115901174895261, validation loss: 0.5894054511319036.
epoch: 116, train loss: 0.6026552141806402, validation loss: 0.6728418586046799.
epoch: 117, train loss: 0.5860728006297296, validation loss: 0.5860317038453143.
epoch: 118, train loss: 0.5845048766617381, validation loss: 0.6139114965563235.
epoch: 119, train loss: 0.6398794145212261, validation loss: 0.6063906679982725.
epoch: 120, train loss: 0.6078893427455098, validation loss: 0.5806882005670796.
epoch: 121, train loss: 0.6533784956560222, validation loss: 0.651521965213444.
epoch: 122, train loss: 0.6294709845967249, validation loss: 0.5928594210873479.
epoch: 123, train loss: 0.6019138414925391, validation loss: 0.5997894134210504.
epoch: 124, train loss: 0.6369567734932681, validation loss: 0.6396917156551195.
epoch: 125, train loss: 0.6352056237535739, validation loss: 0.622659437034441.
epoch: 126, train loss: 0.6143025403175879, validation loss: 0.702511613783629.
epoch: 127, train loss: 0.6206231368791073, validation loss: 0.5922825880672621.
epoch: 128, train loss: 0.6032708549718244, validation loss: 0.6424492662367614.
epoch: 129, train loss: 0.6079486411645871, validation loss: 0.6006590322307919.
epoch: 130, train loss: 0.6090532407301281, validation loss: 0.6072538767171942.
epoch: 131, train loss: 0.5712010261662509, validation loss: 0.6827043165331301.
epoch: 132, train loss: 0.5856330679097307, validation loss: 0.6185537343439849.
epoch: 133, train loss: 0.59237054646562, validation loss: 0.6783268555350925.
epoch: 134, train loss: 0.597092622737272, validation loss: 0.6511984156525653.
epoch: 135, train loss: 0.6288348269571952, validation loss: 0.5970708896284518.
epoch: 136, train loss: 0.5897363744197636, validation loss: 0.6906590474688489.
epoch: 137, train loss: 0.593028208531371, validation loss: 0.5819229613179746.
epoch: 138, train loss: 0.5941095425995118, validation loss: 0.6305070493532263.
epoch: 139, train loss: 0.5901761713924758, validation loss: 0.582287033614905.
epoch: 140, train loss: 0.5877177622340141, validation loss: 0.6918777953023496.
epoch: 141, train loss: 0.6083225818402177, validation loss: 0.7581526896227961.
epoch: 142, train loss: 0.5918709947428572, validation loss: 0.6565062170443328.
epoch: 143, train loss: 0.6139812027915902, validation loss: 0.6469050412592681.
epoch: 144, train loss: 0.6027828031176821, validation loss: 0.7374416965505352.
epoch: 145, train loss: 0.6042959490500459, validation loss: 0.6542625751184381.
epoch: 146, train loss: 0.6221164309103554, validation loss: 0.6882820945719014.
epoch: 147, train loss: 0.5834804740520793, validation loss: 0.649397734714591.
epoch: 148, train loss: 0.5971228178214589, validation loss: 0.5946848236996195.
epoch: 149, train loss: 0.5954592586110491, validation loss: 0.575530838707219.
epoch: 150, train loss: 0.5967226679171991, validation loss: 0.5626837507538174.
epoch: 151, train loss: 0.5998375645471276, validation loss: 0.6847043866696565.
epoch: 152, train loss: 0.5974053281162857, validation loss: 0.574908971786499.
epoch: 153, train loss: 0.584765389698361, validation loss: 0.6365285619445469.
epoch: 154, train loss: 0.5899782221798503, validation loss: 0.6662282736405082.
epoch: 155, train loss: 0.6064273460742531, validation loss: 0.6933555330919183.
epoch: 156, train loss: 0.5577758263557329, validation loss: 0.6371570229530334.
epoch: 157, train loss: 0.5919784427782812, validation loss: 0.5949408386064612.
epoch: 158, train loss: 0.5820133418118189, validation loss: 0.6547373753526936.
epoch: 159, train loss: 0.5907066934699312, validation loss: 0.5964688697586888.
epoch: 160, train loss: 0.5825077948767111, validation loss: 0.6026997786501179.
epoch: 161, train loss: 0.5801138763034016, validation loss: 0.5514236092567444.
epoch: 162, train loss: 0.5759083625920322, validation loss: 0.5997129782386448.
epoch: 163, train loss: 0.5752849969842019, validation loss: 0.5953344884126083.
epoch: 164, train loss: 0.6352333453817105, validation loss: 0.6289727117704309.
epoch: 165, train loss: 0.5981827208755213, validation loss: 0.5419260989064756.
epoch: 166, train loss: 0.5807139189965135, validation loss: 0.6316972465618796.
epoch: 167, train loss: 0.5906883152799869, validation loss: 0.5785485804080963.
epoch: 168, train loss: 0.5842101543868353, validation loss: 0.5817029631656149.
epoch: 169, train loss: 0.5458835355185587, validation loss: 0.5655135460521864.
epoch: 170, train loss: 0.5415849029471022, validation loss: 0.5951019097929415.
epoch: 171, train loss: 0.5408681390482352, validation loss: 0.5864571630954742.
epoch: 172, train loss: 0.5949374177587141, validation loss: 0.632357798192812.
epoch: 173, train loss: 0.562681609200775, validation loss: 0.5984372315199479.
epoch: 174, train loss: 0.5611397722445497, validation loss: 0.6664780235808828.
epoch: 175, train loss: 0.5796055934571345, validation loss: 0.6265131131462429.
epoch: 176, train loss: 0.6420761778813984, validation loss: 0.7193551180155381.
epoch: 177, train loss: 0.6196144545843841, validation loss: 0.5611719242904497.
epoch: 178, train loss: 0.5861869905519923, validation loss: 0.6236299081988956.
epoch: 179, train loss: 0.5726511565917128, validation loss: 0.5582728554373202.
epoch: 180, train loss: 0.5927984755520427, validation loss: 0.5447179079055786.
epoch: 181, train loss: 0.6091048977243791, validation loss: 0.6489124596118927.
epoch: 182, train loss: 0.5678166470943241, validation loss: 0.6106071238932402.
epoch: 183, train loss: 0.6257894080166423, validation loss: 0.6595209253870923.
epoch: 184, train loss: 0.5863073465474155, validation loss: 0.5724769649298295.
epoch: 185, train loss: 0.6172292232513428, validation loss: 0.6340380272139674.
epoch: 186, train loss: 0.5667714655672739, validation loss: 0.6911901624306388.
epoch: 187, train loss: 0.5808375704725948, validation loss: 0.6577657383421193.
epoch: 188, train loss: 0.5335886477056994, validation loss: 0.574809017388717.
epoch: 189, train loss: 0.5573734520772181, validation loss: 0.6626220747180607.
epoch: 190, train loss: 0.5808520284267741, validation loss: 0.6651884550633638.
epoch: 191, train loss: 0.5971680365571188, validation loss: 0.619007910075395.
epoch: 192, train loss: 0.5841213940480433, validation loss: 0.5385683230731798.
epoch: 193, train loss: 0.5704164558320964, validation loss: 0.527101021098054.
epoch: 194, train loss: 0.5863768723579722, validation loss: 0.6016874676165374.
epoch: 195, train loss: 0.5915871486751312, validation loss: 0.6215321823306705.
epoch: 196, train loss: 0.5752109942633078, validation loss: 0.5209999784179355.
epoch: 197, train loss: 0.5649411254519716, validation loss: 0.5466910082360973.
epoch: 198, train loss: 0.5697099249297326, validation loss: 0.5715452704740607.
epoch: 199, train loss: 0.5653421106415057, validation loss: 0.6851647781289142.
epoch: 200, train loss: 1.7669689622494058, validation loss: 1.600968345351841.
epoch: 201, train loss: 1.5416147829195774, validation loss: 1.5200770886048027.
epoch: 202, train loss: 1.4644988676823607, validation loss: 1.4465266155159993.
epoch: 203, train loss: 1.4223470611309788, validation loss: 1.4233638100002124.
epoch: 204, train loss: 1.398533879070107, validation loss: 1.4040541493374368.
epoch: 205, train loss: 1.3755637647908763, validation loss: 1.3839657513991646.
epoch: 206, train loss: 1.3653058907307616, validation loss: 1.3747084037117336.
epoch: 207, train loss: 1.352126977859287, validation loss: 1.3581073957940806.
epoch: 208, train loss: 1.3411713543288204, validation loss: 1.3605567787004553.
epoch: 209, train loss: 1.335539417529325, validation loss: 1.3461171129475469.
epoch: 210, train loss: 1.3300206814337214, validation loss: 1.346088549365168.
epoch: 211, train loss: 1.3283073267805467, validation loss: 1.3396042637203052.
epoch: 212, train loss: 1.3206823233070724, validation loss: 1.3377569965694263.
epoch: 213, train loss: 1.3188517071785184, validation loss: 1.3290775340536367.
epoch: 214, train loss: 1.3175719768629162, validation loss: 1.3348755836486816.
epoch: 215, train loss: 1.3214998059316512, validation loss: 1.3334176281224126.
epoch: 216, train loss: 1.3166737862683218, validation loss: 1.3410338267036106.
epoch: 217, train loss: 1.3191378969664966, validation loss: 1.3173167705535889.
epoch: 218, train loss: 1.3113410035404591, validation loss: 1.3322994294373884.
epoch: 219, train loss: 1.3067262861706794, validation loss: 1.319472592809926.
epoch: 220, train loss: 1.3061644659129852, validation loss: 1.3248071722362353.
epoch: 221, train loss: 1.3055316483208892, validation loss: 1.322039044421652.
epoch: 222, train loss: 1.3041933075003667, validation loss: 1.314774803493334.
epoch: 223, train loss: 1.3004489316852814, validation loss: 1.3254512030145396.
epoch: 224, train loss: 1.299546706567117, validation loss: 1.312914666922196.
epoch: 225, train loss: 1.3036569127249062, validation loss: 1.3301031589508057.
epoch: 226, train loss: 1.3045510578592983, validation loss: 1.3145981767903203.
epoch: 227, train loss: 1.300564016770879, validation loss: 1.3077253051426099.
epoch: 228, train loss: 1.2964875348117373, validation loss: 1.311384563860686.
epoch: 229, train loss: 1.3017599735784968, validation loss: 1.3306228181590205.
epoch: 230, train loss: 1.3036839852639295, validation loss: 1.3391164541244507.
epoch: 231, train loss: 1.3000463269172458, validation loss: 1.3235876612041308.
epoch: 232, train loss: 1.295886337210279, validation loss: 1.339277982711792.
epoch: 233, train loss: 1.3060063123703003, validation loss: 1.3194554370382559.
epoch: 234, train loss: 1.3019105688147588, validation loss: 1.3203662893046504.
epoch: 235, train loss: 1.2954347122699843, validation loss: 1.3147859366043755.
epoch: 236, train loss: 1.2871913505256722, validation loss: 1.2988835262215657.
epoch: 237, train loss: 1.2879526932305152, validation loss: 1.3015315429024075.
epoch: 238, train loss: 1.2917272727423852, validation loss: 1.3071595274883767.
epoch: 239, train loss: 1.2930570239320807, validation loss: 1.3009270170460576.
epoch: 240, train loss: 1.2855272938352111, validation loss: 1.31522624388985.
epoch: 241, train loss: 1.294595750100022, validation loss: 1.3047745020493218.
epoch: 242, train loss: 1.2966777042511406, validation loss: 1.2930158739504607.
epoch: 243, train loss: 1.2920940075445613, validation loss: 1.2988003647845725.
epoch: 244, train loss: 1.2909603556361766, validation loss: 1.3220126836196235.
epoch: 245, train loss: 1.2938283145974536, validation loss: 1.3223241360291191.
epoch: 246, train loss: 1.2833853325712572, validation loss: 1.2849412379057512.
epoch: 247, train loss: 1.2855075335283892, validation loss: 1.2950841551241667.
epoch: 248, train loss: 1.2855074252557317, validation loss: 1.288660484811534.
epoch: 249, train loss: 1.2832125414402114, validation loss: 1.3015920753064363.
epoch: 250, train loss: 1.2847078393358704, validation loss: 1.3230193905208423.
epoch: 251, train loss: 1.2955519376544777, validation loss: 1.31221328092658.
epoch: 252, train loss: 1.2897476931230738, validation loss: 1.309282484261886.
epoch: 253, train loss: 1.2893171901002936, validation loss: 1.3105662698331086.
epoch: 254, train loss: 1.2877346091314192, validation loss: 1.3123492313467937.
epoch: 255, train loss: 1.2863404860190295, validation loss: 1.2864064444666323.
epoch: 256, train loss: 1.2892436040650814, validation loss: 1.2999107008394988.
epoch: 257, train loss: 1.2892372039479947, validation loss: 1.3035686378893645.
epoch: 258, train loss: 1.2854706912959388, validation loss: 1.3014379947081856.
epoch: 259, train loss: 1.2889565819994024, validation loss: 1.3112233669861504.
epoch: 260, train loss: 1.2937331385568742, validation loss: 1.2859145143757695.
epoch: 261, train loss: 1.2944293514304204, validation loss: 1.3069756393847258.
epoch: 262, train loss: 1.2860884950795304, validation loss: 1.31777314517809.
epoch: 263, train loss: 1.2908139677222716, validation loss: 1.2981342336405879.
epoch: 264, train loss: 1.2874868473875414, validation loss: 1.3052538944327312.
epoch: 265, train loss: 1.2867913978909133, validation loss: 1.2983079319414885.
epoch: 266, train loss: 1.2791884043894777, validation loss: 1.2814538789832073.
epoch: 267, train loss: 1.2774012919959672, validation loss: 1.2921477556228638.
epoch: 268, train loss: 1.2799372333999073, validation loss: 1.289851603300675.
epoch: 269, train loss: 1.2816035211633106, validation loss: 1.2914956911750461.
epoch: 270, train loss: 1.3062585034501661, validation loss: 1.2968838007553765.
epoch: 271, train loss: 1.285410259841779, validation loss: 1.2936094273691592.
epoch: 272, train loss: 1.2834294334464116, validation loss: 1.291451448979585.
epoch: 273, train loss: 1.284064557574211, validation loss: 1.2887377168821252.
epoch: 274, train loss: 1.281041932762216, validation loss: 1.2891060995019001.
epoch: 275, train loss: 1.28085908102333, validation loss: 1.297776248144067.
epoch: 276, train loss: 1.28376382862756, validation loss: 1.2848784405252207.
epoch: 277, train loss: 1.287001318887833, validation loss: 1.2951143876365994.
epoch: 278, train loss: 1.2775630338476338, validation loss: 1.2824929226999697.
epoch: 279, train loss: 1.2755778218628069, validation loss: 1.3000805585280708.
epoch: 280, train loss: 1.2793804155577213, validation loss: 1.2910384458044302.
epoch: 281, train loss: 1.2788365794978012, validation loss: 1.2943606843119082.
epoch: 282, train loss: 1.2806552134522604, validation loss: 1.3064475214999656.
epoch: 283, train loss: 1.2809218047955715, validation loss: 1.2933692776638528.
epoch: 284, train loss: 1.2844617585523412, validation loss: 1.2894675783489062.
epoch: 285, train loss: 1.2897089719772339, validation loss: 1.3195028097733208.
epoch: 286, train loss: 1.2808972444009343, validation loss: 1.2836949099665103.
epoch: 287, train loss: 1.2812330810301895, validation loss: 1.2994949765827344.
epoch: 288, train loss: 1.2772709000001259, validation loss: 1.2961622891218767.
epoch: 289, train loss: 1.2780756097321118, validation loss: 1.2874574609424756.
epoch: 290, train loss: 1.2803707275915583, validation loss: 1.291333379952804.
epoch: 291, train loss: 1.2757039376355093, validation loss: 1.279726064723471.
epoch: 292, train loss: 1.2727615636423093, validation loss: 1.3086922583372698.
epoch: 293, train loss: 1.2813418053705758, validation loss: 1.2943452596664429.
epoch: 294, train loss: 1.277043612725144, validation loss: 1.2838711583096047.
epoch: 295, train loss: 1.2755741394987894, validation loss: 1.2838496021602466.
epoch: 296, train loss: 1.274505033405549, validation loss: 1.2882275840510493.
epoch: 297, train loss: 1.2754741568084156, validation loss: 1.2863160371780396.
epoch: 298, train loss: 1.2770733166178432, validation loss: 1.2976646941641103.
epoch: 299, train loss: 1.2802160169006487, validation loss: 1.295741081237793.
epoch: 300, train loss: 1.2843400349310778, validation loss: 1.2981549760569697.
epoch: 301, train loss: 1.284689980909365, validation loss: 1.2982717545136162.
epoch: 302, train loss: 1.2830366432119946, validation loss: 1.3178388139475947.
epoch: 303, train loss: 1.2851731120993237, validation loss: 1.2897095161935557.
epoch: 304, train loss: 1.2805025818151072, validation loss: 1.3077080301616504.
epoch: 305, train loss: 1.2851024505195268, validation loss: 1.313278809837673.
epoch: 306, train loss: 1.286509320276593, validation loss: 1.302836122720138.
epoch: 307, train loss: 1.2873371555170883, validation loss: 1.30996078511943.
epoch: 308, train loss: 1.3018361297222452, validation loss: 1.3357751524966697.
epoch: 309, train loss: 1.3105437394675858, validation loss: 1.339458890583204.
epoch: 310, train loss: 1.305171250203334, validation loss: 1.3216865581014883.
epoch: 311, train loss: 1.3072526728341338, validation loss: 1.3200106257977693.
epoch: 312, train loss: 1.3004692191377691, validation loss: 1.3266283947488535.
epoch: 313, train loss: 1.3047077108960632, validation loss: 1.3106153892434163.
epoch: 314, train loss: 1.2991570234298706, validation loss: 1.3179591997810032.
epoch: 315, train loss: 1.299962001109342, validation loss: 1.3026757810426794.
epoch: 316, train loss: 1.2968196125205504, validation loss: 1.3197224554808245.
epoch: 317, train loss: 1.2950268568248924, validation loss: 1.3166200648183408.
epoch: 318, train loss: 1.294056028401086, validation loss: 1.3174569192139998.
epoch: 319, train loss: 1.289786162726376, validation loss: 1.3140378931294316.
epoch: 320, train loss: 1.2944653220132951, validation loss: 1.3090502749318662.
epoch: 321, train loss: 1.292021468145038, validation loss: 1.3069071873374607.
epoch: 322, train loss: 1.2866763631138234, validation loss: 1.3267166044401086.
epoch: 323, train loss: 1.2910410111103583, validation loss: 1.2999367040136587.
epoch: 324, train loss: 1.2896823390908199, validation loss: 1.3124390788700269.
epoch: 325, train loss: 1.285642411730705, validation loss: 1.2906273033307947.
epoch: 326, train loss: 1.2815071541234988, validation loss: 1.2890949145607327.
epoch: 327, train loss: 1.3127275880323637, validation loss: 1.3152202937913977.
epoch: 328, train loss: 1.2963367875562894, validation loss: 1.3036059763120569.
epoch: 329, train loss: 1.2896673712161704, validation loss: 1.3002851631330408.
epoch: 330, train loss: 1.2873875460493456, validation loss: 1.306542852650518.
epoch: 331, train loss: 1.289267665749296, validation loss: 1.296454237854999.
epoch: 332, train loss: 1.2916518296670476, validation loss: 1.3127564969270125.
epoch: 333, train loss: 1.289386770047179, validation loss: 1.3147073932315991.
epoch: 334, train loss: 1.2940505480547564, validation loss: 1.3266936229622883.
epoch: 335, train loss: 1.287483425315367, validation loss: 1.2997804828312085.
epoch: 336, train loss: 1.2876542555082828, validation loss: 1.2908061690952466.
epoch: 337, train loss: 1.2822489410365394, validation loss: 1.2887594596199368.
epoch: 338, train loss: 1.283718033668098, validation loss: 1.291276885115582.
epoch: 339, train loss: 1.2837906857149317, validation loss: 1.295156681019327.
epoch: 340, train loss: 1.2868359920081742, validation loss: 1.304929811021556.
epoch: 341, train loss: 1.2966856737749293, validation loss: 1.3394106263699739.
epoch: 342, train loss: 1.2983428983513368, validation loss: 1.3133843567060388.
epoch: 343, train loss: 1.2964850161053718, validation loss: 1.2973722582278044.
epoch: 344, train loss: 1.2922201605018127, validation loss: 1.3045717218647832.
epoch: 345, train loss: 1.2899574314782378, validation loss: 1.2881065036939539.
epoch: 346, train loss: 1.283455955872842, validation loss: 1.2939201904379802.
epoch: 347, train loss: 1.2852763451567484, validation loss: 1.3063237459763237.
epoch: 348, train loss: 1.2807399778191102, validation loss: 1.2948456277018008.
epoch: 349, train loss: 1.2808230109171037, validation loss: 1.2930168690888777.
epoch: 350, train loss: 1.2868219428106185, validation loss: 1.3178309565005095.
epoch: 351, train loss: 1.2897202607688554, validation loss: 1.296266478040944.
epoch: 352, train loss: 1.2871304531709864, validation loss: 1.2956994668297146.
epoch: 353, train loss: 1.282159960598027, validation loss: 1.3133673305096834.
epoch: 354, train loss: 1.2846455442796059, validation loss: 1.2928414863088857.
epoch: 355, train loss: 1.2835759405696063, validation loss: 1.3000521037889563.
epoch: 356, train loss: 1.2846411630647991, validation loss: 1.300144216288691.
epoch: 357, train loss: 1.2831005131432769, validation loss: 1.2898738125096196.
epoch: 358, train loss: 1.282997061353211, validation loss: 1.3093947327655295.
epoch: 359, train loss: 1.2781692808921183, validation loss: 1.2867077537204907.
epoch: 360, train loss: 1.278709709097486, validation loss: 1.2944012569344563.
epoch: 361, train loss: 1.2757890990021032, validation loss: 1.2846072756725808.
epoch: 362, train loss: 1.277523974759863, validation loss: 1.292846290961556.
epoch: 363, train loss: 1.277324476373305, validation loss: 1.2876657403033713.
epoch: 364, train loss: 1.278614598676699, validation loss: 1.292034879974697.
epoch: 365, train loss: 1.2762850260515826, validation loss: 1.2871911266575689.
epoch: 366, train loss: 1.2762132631529362, validation loss: 1.2961445269377336.
epoch: 367, train loss: 1.2785546353103918, validation loss: 1.2962677634280662.
epoch: 368, train loss: 1.2780531940110234, validation loss: 1.3012828930564548.
epoch: 369, train loss: 1.2883267774494416, validation loss: 1.3004606910373853.
epoch: 370, train loss: 1.2854970332679398, validation loss: 1.3020608995271765.
epoch: 371, train loss: 1.288668097706016, validation loss: 1.3025965016821157.
epoch: 372, train loss: 1.2860595578447394, validation loss: 1.3007374276285586.
epoch: 373, train loss: 1.28847495350269, validation loss: 1.3051444032917852.
epoch: 374, train loss: 1.2813910169338962, validation loss: 1.303440254667531.
epoch: 375, train loss: 1.282238768875052, validation loss: 1.295199611912603.
epoch: 376, train loss: 1.281524900996357, validation loss: 1.2917199756788171.
epoch: 377, train loss: 1.2789535609953995, validation loss: 1.2879058122634888.
epoch: 378, train loss: 1.2788876109166976, validation loss: 1.3033750627351843.
epoch: 379, train loss: 1.2792219350097376, validation loss: 1.2845700460931528.
epoch: 380, train loss: 1.280781072214109, validation loss: 1.2889812303626018.
epoch: 381, train loss: 1.2802364574659855, validation loss: 1.312319532684658.
epoch: 382, train loss: 1.2769356659792979, validation loss: 1.2898183698239534.
epoch: 383, train loss: 1.2911984811135389, validation loss: 1.322000011153843.
epoch: 384, train loss: 1.2913281305120625, validation loss: 1.2951491967491482.
epoch: 385, train loss: 1.2780514080590064, validation loss: 1.287244921145232.
epoch: 386, train loss: 1.2728719208218635, validation loss: 1.2969055227611377.
epoch: 387, train loss: 1.2722357030308575, validation loss: 1.28490105919216.
epoch: 388, train loss: 1.2742814908333875, validation loss: 1.2848267140595808.
epoch: 389, train loss: 1.2714315674720553, validation loss: 1.282349679781043.
epoch: 390, train loss: 1.2747156248180145, validation loss: 1.2842879969140757.
epoch: 391, train loss: 1.2728921142193155, validation loss: 1.285734114439591.
epoch: 392, train loss: 1.2699635378811338, validation loss: 1.2909929700519727.
epoch: 393, train loss: 1.2755906702181614, validation loss: 1.2876662119575168.
epoch: 394, train loss: 1.2782787434551695, validation loss: 1.2948471566905146.
epoch: 395, train loss: 1.2740577973357035, validation loss: 1.2860284007113914.
epoch: 396, train loss: 1.2740021430024313, validation loss: 1.2853251591972683.
epoch: 397, train loss: 1.2788856926314327, validation loss: 1.2890929035518481.
epoch: 398, train loss: 1.2775003680395425, validation loss: 1.307072452876879.
epoch: 399, train loss: 1.28076621698677, validation loss: 1.3049801899039226.
epoch: 400, train loss: 1.2795822259482987, validation loss: 1.2945555655852607.
epoch: 401, train loss: 1.2800203014951232, validation loss: 1.2936379235723745.
epoch: 402, train loss: 1.2998122042472209, validation loss: 1.3082901602206023.
epoch: 403, train loss: 1.286860660675469, validation loss: 1.2972757971805076.
epoch: 404, train loss: 1.2843599406951065, validation loss: 1.31212840391242.
epoch: 405, train loss: 1.2806111617919502, validation loss: 1.286250290663346.
epoch: 406, train loss: 1.2780510384008426, validation loss: 1.28902486614559.
epoch: 407, train loss: 1.2755586608834224, validation loss: 1.3189748421959255.
epoch: 408, train loss: 1.2748355920161676, validation loss: 1.2879713825557544.
epoch: 409, train loss: 1.274214828779938, validation loss: 1.2925002523090527.
epoch: 410, train loss: 1.274387989569148, validation loss: 1.28461608161097.
epoch: 411, train loss: 1.2735529558374248, validation loss: 1.284554730290952.
epoch: 412, train loss: 1.2745118414590118, validation loss: 1.287708323934804.
epoch: 413, train loss: 1.270697372768997, validation loss: 1.284526607264643.
epoch: 414, train loss: 1.268854206855144, validation loss: 1.2772020827169004.
epoch: 415, train loss: 1.2723387895374123, validation loss: 1.2846637860588406.
epoch: 416, train loss: 1.27385090687953, validation loss: 1.296909254530202.
epoch: 417, train loss: 1.2765429938605073, validation loss: 1.2916355858678403.
epoch: 418, train loss: 1.2752654650889406, validation loss: 1.2874721651491912.
epoch: 419, train loss: 1.270665637943723, validation loss: 1.2943796437719595.
epoch: 420, train loss: 1.27472324546324, validation loss: 1.2949124108190122.
epoch: 421, train loss: 1.2729238326396417, validation loss: 1.2766953810401585.
epoch: 422, train loss: 1.2737002733650558, validation loss: 1.2818809125734412.
epoch: 423, train loss: 1.2697983816129352, validation loss: 1.2781488532605378.
epoch: 424, train loss: 1.2690207991031333, validation loss: 1.2981628386870674.
epoch: 425, train loss: 1.2722653609897019, validation loss: 1.284655415493509.
epoch: 426, train loss: 1.2762479913344078, validation loss: 1.308252655941507.
epoch: 427, train loss: 1.2777386083515412, validation loss: 1.3015145478041277.
epoch: 428, train loss: 1.2785036410760442, validation loss: 1.2919559841570647.
epoch: 429, train loss: 1.2722312211990356, validation loss: 1.285995416019274.
epoch: 430, train loss: 1.2716780857208672, validation loss: 1.299208050188811.
epoch: 431, train loss: 1.2730682399294793, validation loss: 1.2922064117763354.
epoch: 432, train loss: 1.2731810622259017, validation loss: 1.285823925681736.
epoch: 433, train loss: 1.2803752837924782, validation loss: 1.2863884749619856.
epoch: 434, train loss: 1.2807071394876604, validation loss: 1.3006800361301587.
epoch: 435, train loss: 1.2805501605392595, validation loss: 1.2929628102675728.
epoch: 436, train loss: 1.2766561037903532, validation loss: 1.2825033820193747.
epoch: 437, train loss: 1.273447834023642, validation loss: 1.2757478537766829.
epoch: 438, train loss: 1.2736259206719356, validation loss: 1.3106488559557044.
epoch: 439, train loss: 1.2779767338289034, validation loss: 1.2939687500829282.
epoch: 440, train loss: 1.2756632796121299, validation loss: 1.2904752648395041.
epoch: 441, train loss: 1.2747375833878822, validation loss: 1.2851200725721277.
epoch: 442, train loss: 1.269582458592336, validation loss: 1.2791979312896729.
epoch: 443, train loss: 1.270246222478534, validation loss: 1.2840189985606982.
epoch: 444, train loss: 1.2734979456717814, validation loss: 1.3006287294885386.
epoch: 445, train loss: 1.274209727934741, validation loss: 1.2834855318069458.
epoch: 446, train loss: 1.2740010690251622, validation loss: 1.2875602348991062.
epoch: 447, train loss: 1.26990322782359, validation loss: 1.2903334835301274.
epoch: 448, train loss: 1.267431928477156, validation loss: 1.2771175063174705.
epoch: 449, train loss: 1.2715509561223721, validation loss: 1.2782816420430723.
epoch: 450, train loss: 1.2706903776991259, validation loss: 1.2863355408544126.
epoch: 451, train loss: 1.270341389769808, validation loss: 1.2877522188684214.
epoch: 452, train loss: 1.277345352216598, validation loss: 1.2909041539482449.
epoch: 453, train loss: 1.2738548101635154, validation loss: 1.2833211059155671.
epoch: 454, train loss: 1.2721449956981414, validation loss: 1.2839387447937676.
epoch: 455, train loss: 1.2672538472971786, validation loss: 1.2801995899366296.
epoch: 456, train loss: 1.2693330115134562, validation loss: 1.291352401609006.
epoch: 457, train loss: 1.2694707212098149, validation loss: 1.2862586508626523.
epoch: 458, train loss: 1.2730284054344947, validation loss: 1.279886701832647.
epoch: 459, train loss: 1.2716392355227688, validation loss: 1.279739753059719.
epoch: 460, train loss: 1.2719806826442754, validation loss: 1.282606990441032.
epoch: 461, train loss: 1.2697297783072936, validation loss: 1.2877095108446868.
epoch: 462, train loss: 1.2711380676392021, validation loss: 1.285226407258407.
epoch: 463, train loss: 1.2670193123161246, validation loss: 1.2734758594761724.
epoch: 464, train loss: 1.2669168229496808, validation loss: 1.2860509416331416.
epoch: 465, train loss: 1.2707115991399922, validation loss: 1.2803078838016675.
epoch: 466, train loss: 1.2722726283817116, validation loss: 1.2885636402213054.
epoch: 467, train loss: 1.2720768604803523, validation loss: 1.2830784269001172.
epoch: 468, train loss: 1.2708944990000595, validation loss: 1.2886987924575806.
epoch: 469, train loss: 1.2703829019441517, validation loss: 1.287437967632128.
epoch: 470, train loss: 1.272150433391606, validation loss: 1.2955600230590156.
epoch: 471, train loss: 1.268638289302861, validation loss: 1.2841877159865007.
epoch: 472, train loss: 1.2682487384988628, validation loss: 1.30096551646357.
epoch: 473, train loss: 1.272269045541046, validation loss: 1.2899077094119529.
epoch: 474, train loss: 1.2705421600866755, validation loss: 1.2860299504321555.
epoch: 475, train loss: 1.272450534575576, validation loss: 1.2771572652070418.
epoch: 476, train loss: 1.2678963492769715, validation loss: 1.2858225210853245.
epoch: 477, train loss: 1.2697885386440733, validation loss: 1.2810602395430855.
epoch: 478, train loss: 1.2685101841567854, validation loss: 1.2790869578071262.
epoch: 479, train loss: 1.2692717729358498, validation loss: 1.2755540557529614.
epoch: 480, train loss: 1.2674534036478866, validation loss: 1.2822406965753306.
epoch: 481, train loss: 1.2956818090666324, validation loss: 1.3371483243030051.
epoch: 482, train loss: 1.2992922756650032, validation loss: 1.2931887170542842.
epoch: 483, train loss: 1.2878235895699317, validation loss: 1.288375382838042.
epoch: 484, train loss: 1.279993857812444, validation loss: 1.3036662547484688.
epoch: 485, train loss: 1.2825091355437532, validation loss: 1.2930755252423494.
epoch: 486, train loss: 1.276228730831671, validation loss: 1.2829257353492405.
epoch: 487, train loss: 1.2706955518197576, validation loss: 1.2816923442094221.
epoch: 488, train loss: 1.2696984896966077, validation loss: 1.2794988932816878.
epoch: 489, train loss: 1.2655373078967453, validation loss: 1.2752815381340359.
epoch: 490, train loss: 1.2679735115908701, validation loss: 1.2798571690269138.
epoch: 491, train loss: 1.2689725926163, validation loss: 1.2813313940297002.
epoch: 492, train loss: 1.2675189600078338, validation loss: 1.289227827735569.
epoch: 493, train loss: 1.26629589566397, validation loss: 1.2901646002479221.
epoch: 494, train loss: 1.2659042636188893, validation loss: 1.2827624756356943.
epoch: 495, train loss: 1.2646825237011692, validation loss: 1.2754941867745442.
epoch: 496, train loss: 1.2667474801387262, validation loss: 1.2783865617669148.
epoch: 497, train loss: 1.2688289093315055, validation loss: 1.2773794557737268.
epoch: 498, train loss: 1.2653817572724928, validation loss: 1.2750942707061768.
epoch: 499, train loss: 1.2646287154713902, validation loss: 1.2780412539191868.
epoch: 500, train loss: 1.2664953754582535, validation loss: 1.2780467841936194.
epoch: 501, train loss: 1.2673431645839586, validation loss: 1.2758954815242602.
epoch: 502, train loss: 1.2718389176447458, validation loss: 1.284476357957591.
epoch: 503, train loss: 1.2726967925325445, validation loss: 1.2875308679497761.
epoch: 504, train loss: 1.2696644767708736, validation loss: 1.2806521809619407.
epoch: 505, train loss: 1.2681460413364096, validation loss: 1.278294283410777.
epoch: 506, train loss: 1.2726500985819265, validation loss: 1.293417013209799.
epoch: 507, train loss: 1.2690975316073916, validation loss: 1.3322702490765115.
epoch: 508, train loss: 1.2675361600490884, validation loss: 1.2761965160784514.
epoch: 509, train loss: 1.2678828239440918, validation loss: 1.286779522895813.
epoch: 510, train loss: 1.2691520846218145, validation loss: 1.2790343813274219.
epoch: 511, train loss: 1.2672507828528727, validation loss: 1.2823566457499629.
epoch: 512, train loss: 1.266101593271308, validation loss: 1.2819284407988838.
epoch: 513, train loss: 1.267511550439607, validation loss: 1.283279740292093.
epoch: 514, train loss: 1.272265102885185, validation loss: 1.2758270916731462.
epoch: 515, train loss: 1.2694133957591625, validation loss: 1.2800730155861897.
epoch: 516, train loss: 1.265733887296204, validation loss: 1.286127401434857.
epoch: 517, train loss: 1.2654714584350586, validation loss: 1.28606218877046.
epoch: 518, train loss: 1.2671528464063593, validation loss: 1.319004800008691.
epoch: 519, train loss: 1.2700822145567028, validation loss: 1.287495986275051.
epoch: 520, train loss: 1.2668006234212752, validation loss: 1.2812898988309114.
epoch: 521, train loss: 1.2651537755213746, validation loss: 1.278588849565257.
epoch: 522, train loss: 1.2731355975527283, validation loss: 1.2792292833328247.
epoch: 523, train loss: 1.2695508582876363, validation loss: 1.2839027124902476.
epoch: 524, train loss: 1.2673498709267432, validation loss: 1.2810430215752644.
epoch: 525, train loss: 1.266765732283986, validation loss: 1.3020356219747793.
epoch: 526, train loss: 1.2660246125055015, validation loss: 1.2779223141462908.
epoch: 527, train loss: 1.2677144752729923, validation loss: 1.2873494314110798.
epoch: 528, train loss: 1.2683557753169208, validation loss: 1.2908879570339038.
epoch: 529, train loss: 1.269910634110827, validation loss: 1.2815524857977163.
epoch: 530, train loss: 1.265241567147981, validation loss: 1.2816039893938147.
epoch: 531, train loss: 1.264727783859323, validation loss: 1.2782046276590098.
epoch: 532, train loss: 1.2702780797940876, validation loss: 1.2834177898324055.
epoch: 533, train loss: 1.2672126829077344, validation loss: 1.2864592023517774.
epoch: 534, train loss: 1.2661395018253851, validation loss: 1.2873728119808694.
epoch: 535, train loss: 1.2678780927570588, validation loss: 1.2889537500298542.
epoch: 536, train loss: 1.268163906324894, validation loss: 1.273348709811335.
epoch: 537, train loss: 1.2631953987506552, validation loss: 1.2922198046808657.
epoch: 538, train loss: 1.2706615257700649, validation loss: 1.2800722381343013.
epoch: 539, train loss: 1.2681986891895258, validation loss: 1.2924777217533276.
epoch: 540, train loss: 1.2722066094022277, validation loss: 1.2920152363569841.
epoch: 541, train loss: 1.2723126192705347, validation loss: 1.2847295273905215.
epoch: 542, train loss: 1.2689994650149563, validation loss: 1.2806222438812256.
epoch: 543, train loss: 1.2686658397727055, validation loss: 1.2782858765643577.
epoch: 544, train loss: 1.2668400215446403, validation loss: 1.288295751032622.
epoch: 545, train loss: 1.2672239476387654, validation loss: 1.3007012916647869.
epoch: 546, train loss: 1.263258172831404, validation loss: 1.2943768915922746.
epoch: 547, train loss: 1.2656598867626365, validation loss: 1.2775089015131411.
epoch: 548, train loss: 1.2648612599854077, validation loss: 1.278795009074004.
epoch: 549, train loss: 1.2647821728242647, validation loss: 1.306454881377842.
epoch: 550, train loss: 1.266874873310054, validation loss: 1.2884594824003137.
epoch: 551, train loss: 1.2687035449054263, validation loss: 1.2852095831995425.
epoch: 552, train loss: 1.2651479025499537, validation loss: 1.278164962063665.
epoch: 553, train loss: 1.2613609777678043, validation loss: 1.2891449772793313.
epoch: 554, train loss: 1.266699802984885, validation loss: 1.2915496878002002.
epoch: 555, train loss: 1.2654925551983194, validation loss: 1.2831986727921858.
epoch: 556, train loss: 1.2676135673435456, validation loss: 1.2858823796977168.
epoch: 557, train loss: 1.2685746151372927, validation loss: 1.288403516230376.
epoch: 558, train loss: 1.2807424582472635, validation loss: 1.2946704781573752.
epoch: 559, train loss: 1.2728831385253767, validation loss: 1.2921681974245154.
epoch: 560, train loss: 1.2689136594807335, validation loss: 1.286185570385145.
epoch: 561, train loss: 1.2670817058020776, validation loss: 1.2763170366701873.
epoch: 562, train loss: 1.2679214904067713, validation loss: 1.2821729286857273.
epoch: 563, train loss: 1.2673139692446507, validation loss: 1.283559648886971.
epoch: 564, train loss: 1.2655176963281194, validation loss: 1.273198920747508.
epoch: 565, train loss: 1.263169003189157, validation loss: 1.2804317267044731.
epoch: 566, train loss: 1.2617030909302038, validation loss: 1.2770579742348713.
epoch: 567, train loss: 1.2671829801086987, validation loss: 1.2862706858178843.
epoch: 568, train loss: 1.2673202993672923, validation loss: 1.2794097247331038.
epoch: 569, train loss: 1.2678590859841863, validation loss: 1.2765573625979216.
epoch: 570, train loss: 1.2637751660215746, validation loss: 1.2878980792087058.
epoch: 571, train loss: 1.2650146025036453, validation loss: 1.2836425770883975.
epoch: 572, train loss: 1.264525283367262, validation loss: 1.2785502413044805.
epoch: 573, train loss: 1.266659991456828, validation loss: 1.2816079906795337.
epoch: 574, train loss: 1.2692157434760978, validation loss: 1.288046790205914.
epoch: 575, train loss: 1.265705457521141, validation loss: 1.2871094475621763.
epoch: 576, train loss: 1.2693324909297699, validation loss: 1.2928035000096196.
epoch: 577, train loss: 1.269074992302361, validation loss: 1.2761415554129558.
epoch: 578, train loss: 1.2647272042178233, validation loss: 1.2729506388954495.
epoch: 579, train loss: 1.2706671012650936, validation loss: 1.2906559083772742.
epoch: 580, train loss: 1.2676472412336857, validation loss: 1.2958241960276728.
epoch: 581, train loss: 1.2620849040670132, validation loss: 1.2681000180866406.
epoch: 582, train loss: 1.2650872140849403, validation loss: 1.2777300606603208.
epoch: 583, train loss: 1.2641730046053545, validation loss: 1.2666133020235144.
epoch: 584, train loss: 1.263870427367884, validation loss: 1.2730605913245159.
epoch: 585, train loss: 1.2676882656342392, validation loss: 1.2754130467124607.
epoch: 586, train loss: 1.2664282912508062, validation loss: 1.2846127126527869.
epoch: 587, train loss: 1.2685672810318274, validation loss: 1.2883609636970188.
epoch: 588, train loss: 1.265858795664726, validation loss: 1.311362598253333.
epoch: 589, train loss: 1.2656859618808152, validation loss: 1.275578929030377.
epoch: 590, train loss: 1.2655134102620116, validation loss: 1.2794130625932112.
epoch: 591, train loss: 1.2634392397119365, validation loss: 1.2784869308057039.
epoch: 592, train loss: 1.2618212426474336, validation loss: 1.2773452167925627.
epoch: 593, train loss: 1.258740734616551, validation loss: 1.2710068899652232.
epoch: 594, train loss: 1.2622281214512816, validation loss: 1.2776070211244666.
epoch: 595, train loss: 1.265026679826439, validation loss: 1.2788497935170713.
epoch: 596, train loss: 1.2697622590108748, validation loss: 1.27343691950259.
epoch: 597, train loss: 1.2786550357801105, validation loss: 1.2887479481489763.
epoch: 598, train loss: 1.2688543927778893, validation loss: 1.2791177967320317.
epoch: 599, train loss: 1.2661935976885874, validation loss: 1.2901468795278799.
epoch: 600, train loss: 1.2676152570532002, validation loss: 1.2786437635836394.
epoch: 601, train loss: 1.2663380388819843, validation loss: 1.2798683591510938.
epoch: 602, train loss: 1.2714229559679644, validation loss: 1.2790065433668054.
epoch: 603, train loss: 1.2641389293408176, validation loss: 1.2863246928090635.
epoch: 604, train loss: 1.2672085543291285, validation loss: 1.2764191161031309.
epoch: 605, train loss: 1.263391138216771, validation loss: 1.2696043874906457.
epoch: 606, train loss: 1.2623137837156244, validation loss: 1.273332269295402.
epoch: 607, train loss: 1.2624552676437097, validation loss: 1.2754109424093496.
epoch: 608, train loss: 1.2623018004478666, validation loss: 1.2854946540749592.
epoch: 609, train loss: 1.2645486254210865, validation loss: 1.2865544246590657.
epoch: 610, train loss: 1.2620747712774014, validation loss: 1.278067796126656.
epoch: 611, train loss: 1.2616269052575488, validation loss: 1.2788409616636194.
epoch: 612, train loss: 1.262084453477772, validation loss: 1.271881948346677.
epoch: 613, train loss: 1.261348695929991, validation loss: 1.2731979100600532.
epoch: 614, train loss: 1.260991197113597, validation loss: 1.2734109266944553.
epoch: 615, train loss: 1.2616383526303352, validation loss: 1.2824303015418674.
epoch: 616, train loss: 1.266320376221193, validation loss: 1.273169035496919.
epoch: 617, train loss: 1.263123848022671, validation loss: 1.293880758078202.
epoch: 618, train loss: 1.2619839348924269, validation loss: 1.277968396311221.
epoch: 619, train loss: 1.2625322188806096, validation loss: 1.2787260179934294.
epoch: 620, train loss: 1.2655452774205338, validation loss: 1.31912594774495.
epoch: 621, train loss: 1.2692267741632024, validation loss: 1.2825439183608345.
epoch: 622, train loss: 1.2652331984371221, validation loss: 1.28144589714382.
epoch: 623, train loss: 1.2615048852535562, validation loss: 1.273719160453133.
epoch: 624, train loss: 1.2597283190543498, validation loss: 1.2800305304319963.
epoch: 625, train loss: 1.2646101177285571, validation loss: 1.2778710437857586.
epoch: 626, train loss: 1.2640093193141693, validation loss: 1.2942923773889956.
epoch: 627, train loss: 1.2622274160385132, validation loss: 1.2975323614866838.
epoch: 628, train loss: 1.2599425939244961, validation loss: 1.2821700780288032.
epoch: 629, train loss: 1.2741551377357694, validation loss: 1.315886025843413.
epoch: 630, train loss: 1.2909962835661861, validation loss: 1.3115120296892913.
epoch: 631, train loss: 1.274470784248562, validation loss: 1.3021310360535332.
epoch: 632, train loss: 1.281471514920576, validation loss: 1.3110448795816172.
epoch: 633, train loss: 1.283244067375813, validation loss: 1.289616698804109.
epoch: 634, train loss: 1.274321220336704, validation loss: 1.2859415437864221.
epoch: 635, train loss: 1.2695545319023482, validation loss: 1.2788990269536558.
epoch: 636, train loss: 1.2675610485426876, validation loss: 1.2723317975583284.
epoch: 637, train loss: 1.2638612438779357, validation loss: 1.2805864551792974.
epoch: 638, train loss: 1.2634873040225527, validation loss: 1.2791558815085369.
epoch: 639, train loss: 1.2631048160955447, validation loss: 1.2831729287686555.
epoch: 640, train loss: 1.2671561459882543, validation loss: 1.2761640963347063.
epoch: 641, train loss: 1.2644522299460315, validation loss: 1.2819581446440325.
epoch: 642, train loss: 1.2622090698382176, validation loss: 1.2718414586523306.
epoch: 643, train loss: 1.2630057827048344, validation loss: 1.2811306818671848.
epoch: 644, train loss: 1.2621066537472085, validation loss: 1.2716371442960657.
epoch: 645, train loss: 1.2595476054270334, validation loss: 1.2727495483730151.
epoch: 646, train loss: 1.2630691637686633, validation loss: 1.2754197949948518.
epoch: 647, train loss: 1.2627817928244214, validation loss: 1.275351187457209.
epoch: 648, train loss: 1.2621499321876315, validation loss: 1.269694167634715.
epoch: 649, train loss: 1.2620103512335261, validation loss: 1.2893814574117246.
epoch: 650, train loss: 1.2614439113424458, validation loss: 1.270400264988775.
epoch: 651, train loss: 1.2583544221493081, validation loss: 1.2691076942112134.
epoch: 652, train loss: 1.2604021129258183, validation loss: 1.2710135812344758.
epoch: 653, train loss: 1.261572818143652, validation loss: 1.2754154101662014.
epoch: 654, train loss: 1.2621649077179236, validation loss: 1.279745894929637.
epoch: 655, train loss: 1.2631401206375261, validation loss: 1.2708605424217556.
epoch: 656, train loss: 1.260770854599979, validation loss: 1.300242138945538.
epoch: 657, train loss: 1.2592333402108709, validation loss: 1.2701890053956404.
epoch: 658, train loss: 1.2598477722307957, validation loss: 1.2735682725906372.
epoch: 659, train loss: 1.258937912249784, validation loss: 1.2769690907519797.
epoch: 660, train loss: 1.260710100515173, validation loss: 1.2723665133766506.
epoch: 661, train loss: 1.2585060804262074, validation loss: 1.2741419595220815.
epoch: 662, train loss: 1.2557737903857449, validation loss: 1.2672991597134133.
epoch: 663, train loss: 1.2598228574892796, validation loss: 1.2782352903614873.
epoch: 664, train loss: 1.2576124088479839, validation loss: 1.2847852084947669.
epoch: 665, train loss: 1.2613243433313632, validation loss: 1.2708603402842646.
epoch: 666, train loss: 1.2562402968012958, validation loss: 1.2706323862075806.
epoch: 667, train loss: 1.2606722203963394, validation loss: 1.2769526709680972.
epoch: 668, train loss: 1.262506894015391, validation loss: 1.2785534703213235.
epoch: 669, train loss: 1.2627167154889587, validation loss: 1.2787662122560584.
epoch: 670, train loss: 1.258644853163203, validation loss: 1.2715073305627573.
epoch: 671, train loss: 1.2599072532916287, validation loss: 1.274824163188105.
epoch: 672, train loss: 1.262455992742416, validation loss: 1.2778884276099827.
epoch: 673, train loss: 1.2625149871231218, validation loss: 1.2750366200571475.
epoch: 674, train loss: 1.2670561884521345, validation loss: 1.2850415810294773.
epoch: 675, train loss: 1.2637351401355288, validation loss: 1.281467774639959.
epoch: 676, train loss: 1.263167094746861, validation loss: 1.2749980843585471.
epoch: 677, train loss: 1.2614560794392857, validation loss: 1.2857720800068067.
epoch: 678, train loss: 1.260974550465925, validation loss: 1.2813894748687744.
epoch: 679, train loss: 1.2628396552637082, validation loss: 1.2745095491409302.
epoch: 680, train loss: 1.2606572918935652, validation loss: 1.263580146043197.
epoch: 681, train loss: 1.2646976009421391, validation loss: 1.2776269912719727.
epoch: 682, train loss: 1.2600898184907545, validation loss: 1.2918806853501692.
epoch: 683, train loss: 1.2632264117582128, validation loss: 1.2789131973100745.
epoch: 684, train loss: 1.2611042786081996, validation loss: 1.2765004012895667.
epoch: 685, train loss: 1.2609186467774418, validation loss: 1.2789859460747761.
epoch: 686, train loss: 1.2596194098848816, validation loss: 1.2871990877649058.
epoch: 687, train loss: 1.25778531262634, validation loss: 1.27868376089179.
epoch: 688, train loss: 1.2623817636332382, validation loss: 1.2839095022367395.
epoch: 689, train loss: 1.2624616262015946, validation loss: 1.2738867894462917.
epoch: 690, train loss: 1.2602956557492597, validation loss: 1.2724243609801582.
epoch: 691, train loss: 1.2600483883411513, validation loss: 1.297484962836556.
epoch: 692, train loss: 1.2658804283229583, validation loss: 1.2725536564122075.
epoch: 693, train loss: 1.2633148344284897, validation loss: 1.2825116592904795.
epoch: 694, train loss: 1.2628702865828068, validation loss: 1.2793307045231694.
epoch: 695, train loss: 1.2623371717033036, validation loss: 1.2778825656227444.
epoch: 696, train loss: 1.2629805682995998, validation loss: 1.2791321692259416.
epoch: 697, train loss: 1.2621665678986715, validation loss: 1.2793555363364841.
epoch: 698, train loss: 1.2592674198500606, validation loss: 1.268163598102072.
epoch: 699, train loss: 1.2654314347363393, validation loss: 1.2797749094341113.
epoch: 700, train loss: 1.2632103972478743, validation loss: 1.2816580637641575.
epoch: 701, train loss: 1.2607996376282578, validation loss: 1.269669180331023.
epoch: 702, train loss: 1.2586267071032742, validation loss: 1.2752100229263306.
epoch: 703, train loss: 1.257217705796618, validation loss: 1.2688958230225935.
epoch: 704, train loss: 1.259723645831467, validation loss: 1.2718825858572256.
epoch: 705, train loss: 1.2669903313348052, validation loss: 1.2858384536660237.
epoch: 706, train loss: 1.2603256002478642, validation loss: 1.2746724564096201.
epoch: 707, train loss: 1.2595911343163306, validation loss: 1.2673601845036382.
epoch: 708, train loss: 1.2586780195936151, validation loss: 1.2711273742758709.
epoch: 709, train loss: 1.2570762645213975, validation loss: 1.2773464503495588.
epoch: 710, train loss: 1.261230823096879, validation loss: 1.2891038967215496.
epoch: 711, train loss: 1.2611701357255287, validation loss: 1.289156929306362.
epoch: 712, train loss: 1.259357049924518, validation loss: 1.2756875701572583.
epoch: 713, train loss: 1.2567851062214703, validation loss: 1.2706852633020151.
epoch: 714, train loss: 1.2591328052205777, validation loss: 1.2715998939845874.
epoch: 715, train loss: 1.2606068444908212, validation loss: 1.2699877179187278.
epoch: 716, train loss: 1.2588797053065868, validation loss: 1.2818108175111853.
epoch: 717, train loss: 1.2616947156573655, validation loss: 1.2773857894151106.
epoch: 718, train loss: 1.2614909979181552, validation loss: 1.2940546377845432.
epoch: 719, train loss: 1.2629557738610364, validation loss: 1.2782712812009065.
epoch: 720, train loss: 1.2644341473185687, validation loss: 1.27453467120295.
epoch: 721, train loss: 1.2584354221274, validation loss: 1.2822161083636077.
epoch: 722, train loss: 1.2629264505631332, validation loss: 1.3275436940400496.
epoch: 723, train loss: 1.2663963048829945, validation loss: 1.2753799998241921.
epoch: 724, train loss: 1.2632202609963374, validation loss: 1.274884415709454.
epoch: 725, train loss: 1.2587551523786071, validation loss: 1.275710256203361.
epoch: 726, train loss: 1.2591758375867792, validation loss: 1.2798809020415596.
epoch: 727, train loss: 1.2603069893810728, validation loss: 1.2788068989048833.
epoch: 728, train loss: 1.259453111832295, validation loss: 1.2778602683025857.
epoch: 729, train loss: 1.261156968020518, validation loss: 1.2858923258988753.
epoch: 730, train loss: 1.2613073543671074, validation loss: 1.272024356800577.
epoch: 731, train loss: 1.2644964117522632, validation loss: 1.2911562971446826.
epoch: 732, train loss: 1.2662883275145784, validation loss: 1.2805460173150767.
epoch: 733, train loss: 1.2607763065110653, validation loss: 1.2749188879261846.
epoch: 734, train loss: 1.2603796097116733, validation loss: 1.2711284782575525.
epoch: 735, train loss: 1.260798518810797, validation loss: 1.2796108152555383.
epoch: 736, train loss: 1.258597127888181, validation loss: 1.26607418578604.
epoch: 737, train loss: 1.274121013256388, validation loss: 1.2804385060849397.
epoch: 738, train loss: 1.2694048170649677, validation loss: 1.284328564353611.
epoch: 739, train loss: 1.2619283035260822, validation loss: 1.2729158194168755.
epoch: 740, train loss: 1.2626409891548507, validation loss: 1.2775571916414343.
epoch: 741, train loss: 1.2581068200802585, validation loss: 1.2777786617693694.
epoch: 742, train loss: 1.260825789302861, validation loss: 1.2698526175125786.
epoch: 743, train loss: 1.258614446045062, validation loss: 1.2759173745694368.
epoch: 744, train loss: 1.2592783925730153, validation loss: 1.2695948092833809.
epoch: 745, train loss: 1.2588103386240268, validation loss: 1.2704287715580151.
epoch: 746, train loss: 1.2636174083849705, validation loss: 1.2717156202896782.
epoch: 747, train loss: 1.258940292060922, validation loss: 1.2724939740222434.
epoch: 748, train loss: 1.25954218523218, validation loss: 1.2799495976904165.
epoch: 749, train loss: 1.261758556059741, validation loss: 1.2732582092285156.
epoch: 750, train loss: 1.261169168927254, validation loss: 1.2740873098373413.
epoch: 751, train loss: 1.277973787500224, validation loss: 1.3070500415304434.
epoch: 752, train loss: 1.2762822022131823, validation loss: 1.2966031354406606.
epoch: 753, train loss: 1.2699399803756575, validation loss: 1.2781169880991397.
epoch: 754, train loss: 1.2617494130353315, validation loss: 1.2797001030134119.
epoch: 755, train loss: 1.2592550702051286, validation loss: 1.2823231894036997.
epoch: 756, train loss: 1.2585622126903009, validation loss: 1.2752610082211702.
epoch: 757, train loss: 1.2615198892190915, validation loss: 1.267070656237395.
epoch: 758, train loss: 1.2622591869546733, validation loss: 1.272460320721502.
epoch: 759, train loss: 1.2606091925857263, validation loss: 1.2769187533337136.
epoch: 760, train loss: 1.2613322887945613, validation loss: 1.2648017821104631.
epoch: 761, train loss: 1.2577082093702543, validation loss: 1.278657545214114.
epoch: 762, train loss: 1.2618710699431392, validation loss: 1.2728222764056663.
epoch: 763, train loss: 1.2615916991452558, validation loss: 1.2714419831400332.
epoch: 764, train loss: 1.2593536420699654, validation loss: 1.2710150169289631.
epoch: 765, train loss: 1.260532836301611, validation loss: 1.2791948681292327.
epoch: 766, train loss: 1.2588955842026877, validation loss: 1.2778686233188794.
epoch: 767, train loss: 1.2613870813212265, validation loss: 1.2805160439532737.
epoch: 768, train loss: 1.2571943221835915, validation loss: 1.263140963471454.
epoch: 769, train loss: 1.255949838445821, validation loss: 1.2928212259126746.
epoch: 770, train loss: 1.2583262887569742, validation loss: 1.2728416764217874.
epoch: 771, train loss: 1.2590895202181756, validation loss: 1.2763382403746895.
epoch: 772, train loss: 1.2607071476245144, validation loss: 1.2935785677122034.
epoch: 773, train loss: 1.2613840387501847, validation loss: 1.2772546643796174.
epoch: 774, train loss: 1.2599522422213074, validation loss: 1.2858993851620217.
epoch: 775, train loss: 1.2666714410169408, validation loss: 1.2898331776909207.
epoch: 776, train loss: 1.26126656401048, validation loss: 1.2762582768564639.
epoch: 777, train loss: 1.2614347923786269, validation loss: 1.2709445175917253.
epoch: 778, train loss: 1.2584490633885794, validation loss: 1.2741376472556072.
epoch: 779, train loss: 1.2597715384369597, validation loss: 1.2760354643282683.
epoch: 780, train loss: 1.255715562662947, validation loss: 1.2902506071588267.
epoch: 781, train loss: 1.2597679151307553, validation loss: 1.2789439170256904.
epoch: 782, train loss: 1.257206366696489, validation loss: 1.274720362994982.
epoch: 783, train loss: 1.2570814462976718, validation loss: 1.2865196414615796.
epoch: 784, train loss: 1.2559290555639004, validation loss: 1.2666207448295925.
epoch: 785, train loss: 1.2547400238317088, validation loss: 1.261255409406579.
epoch: 786, train loss: 1.2566452649755215, validation loss: 1.2689056448314502.
epoch: 787, train loss: 1.2572577196523684, validation loss: 1.2789188778918723.
epoch: 788, train loss: 1.2640800333898001, validation loss: 1.2799838988677315.
epoch: 789, train loss: 1.2642239813410907, validation loss: 1.2710623326508894.
epoch: 790, train loss: 1.259052482220011, validation loss: 1.2659362399059793.
epoch: 791, train loss: 1.2587254834831307, validation loss: 1.2757752874623174.
epoch: 792, train loss: 1.2584653655323415, validation loss: 1.2719844113225522.
epoch: 793, train loss: 1.2570595795955133, validation loss: 1.2694033747134001.
epoch: 794, train loss: 1.259728378112163, validation loss: 1.284647392190021.
epoch: 795, train loss: 1.256451583783561, validation loss: 1.2802652949872224.
epoch: 796, train loss: 1.257995119882286, validation loss: 1.2833712360133296.
epoch: 797, train loss: 1.2587799347868753, validation loss: 1.2762727530106255.
epoch: 798, train loss: 1.2585973214665684, validation loss: 1.2852361098579739.
epoch: 799, train loss: 1.2614415326249708, validation loss: 1.2750638412392659.
epoch: 800, train loss: 1.2578107577945115, validation loss: 1.283853847047557.
epoch: 801, train loss: 1.2604159051125203, validation loss: 1.2887035452801248.
epoch: 802, train loss: 1.256098107460442, validation loss: 1.282516749008842.
epoch: 803, train loss: 1.2629234309590192, validation loss: 1.2882226135419763.
epoch: 804, train loss: 1.2614344456873903, validation loss: 1.2850309454876443.
epoch: 805, train loss: 1.2623639708265253, validation loss: 1.2677434993826824.
epoch: 806, train loss: 1.2562763548772269, validation loss: 1.2797949158627053.
epoch: 807, train loss: 1.260210728426592, validation loss: 1.2734331773675007.
epoch: 808, train loss: 1.2599281127299737, validation loss: 1.2803570757741514.
epoch: 809, train loss: 1.259713348992374, validation loss: 1.2722020149230957.
epoch: 810, train loss: 1.2583893635951051, validation loss: 1.2804083461346834.
epoch: 811, train loss: 1.2585272603078719, validation loss: 1.2658588056978972.
epoch: 812, train loss: 1.2550419011247267, validation loss: 1.2805125972499019.
epoch: 813, train loss: 1.2603030467252119, validation loss: 1.2732059437295664.
epoch: 814, train loss: 1.256924038633294, validation loss: 1.2689604292745176.
epoch: 815, train loss: 1.2558908462524414, validation loss: 1.2820863153623498.
epoch: 816, train loss: 1.2575475972726804, validation loss: 1.2939765453338623.
epoch: 817, train loss: 1.2585028945852856, validation loss: 1.2777989999107693.
epoch: 818, train loss: 1.2568390544401395, validation loss: 1.269751673159392.
epoch: 819, train loss: 1.2586700763177434, validation loss: 1.2819840648899907.
epoch: 820, train loss: 1.2589908225820698, validation loss: 1.2767377418020498.
epoch: 821, train loss: 1.259410763005598, validation loss: 1.2802016268605771.
epoch: 822, train loss: 1.2623542142570565, validation loss: 1.2697222854780115.
epoch: 823, train loss: 1.2574866419538446, validation loss: 1.2840670347213745.
epoch: 824, train loss: 1.2548810538895634, validation loss: 1.2703929569410242.
epoch: 825, train loss: 1.2580583358029707, validation loss: 1.2682665897452312.
epoch: 826, train loss: 1.2578765503857114, validation loss: 1.2753663322199946.
epoch: 827, train loss: 1.2557938394196537, validation loss: 1.2729354526685632.
epoch: 828, train loss: 1.2587193655311515, validation loss: 1.2772348445394766.
epoch: 829, train loss: 1.2575139496304573, validation loss: 1.2706060824186907.
epoch: 830, train loss: 1.2560158038358076, validation loss: 1.2784312704335088.
epoch: 831, train loss: 1.257538321915023, validation loss: 1.266533224479012.
epoch: 832, train loss: 1.2573314303651861, validation loss: 1.2857372138811194.
epoch: 833, train loss: 1.257386786128403, validation loss: 1.2833956687346748.
epoch: 834, train loss: 1.2600302105649897, validation loss: 1.2816404622534048.
epoch: 835, train loss: 1.26544249823334, validation loss: 1.2768810521001401.
epoch: 836, train loss: 1.2567213467501719, validation loss: 1.273017924764882.
epoch: 837, train loss: 1.2602849126955784, validation loss: 1.2686536674914153.
epoch: 838, train loss: 1.2565229999909706, validation loss: 1.2639170107634172.
epoch: 839, train loss: 1.2538068032045977, validation loss: 1.2699010216671487.
epoch: 840, train loss: 1.2554824636616837, validation loss: 1.270321099654488.
epoch: 841, train loss: 1.256683407573525, validation loss: 1.27895042170649.
epoch: 842, train loss: 1.2582043814002921, validation loss: 1.274518609046936.
epoch: 843, train loss: 1.2617587868226778, validation loss: 1.2821098358734795.
epoch: 844, train loss: 1.2590142980628056, validation loss: 1.2782979011535645.
epoch: 845, train loss: 1.2563033300802249, validation loss: 1.2758632898330688.
epoch: 846, train loss: 1.260197449167934, validation loss: 1.2702004857685254.
epoch: 847, train loss: 1.256643686819514, validation loss: 1.2830000338347063.
epoch: 848, train loss: 1.256709283645, validation loss: 1.2865376938944277.
epoch: 849, train loss: 1.2588625271385963, validation loss: 1.2663775164148081.
epoch: 850, train loss: 1.2561049669160755, validation loss: 1.2723642846812373.
epoch: 851, train loss: 1.2565388067052998, validation loss: 1.2635237496832143.
epoch: 852, train loss: 1.2565279860015308, validation loss: 1.2767528347347095.
epoch: 853, train loss: 1.2596624947469168, validation loss: 1.2788688566373743.
epoch: 854, train loss: 1.2604607649899404, validation loss: 1.2908354738484258.
epoch: 855, train loss: 1.2634766101837158, validation loss: 1.2780493601508762.
epoch: 856, train loss: 1.2569097433615168, validation loss: 1.270422919936802.
epoch: 857, train loss: 1.2558177129937969, validation loss: 1.268312060314676.
epoch: 858, train loss: 1.260887807662334, validation loss: 1.2734732316887898.
epoch: 859, train loss: 1.2619359526065512, validation loss: 1.2732213113618933.
epoch: 860, train loss: 1.2621526160371412, validation loss: 1.278708209162173.
epoch: 861, train loss: 1.2681932580580406, validation loss: 1.273973153985065.
epoch: 862, train loss: 1.259577370564872, validation loss: 1.2656601667404175.
epoch: 863, train loss: 1.2570501303454058, validation loss: 1.2834539568942527.
epoch: 864, train loss: 1.2575322794258048, validation loss: 1.2704817574957143.
epoch: 865, train loss: 1.2573723902396106, validation loss: 1.2665480634440547.
epoch: 866, train loss: 1.2584950333341547, validation loss: 1.2689853595650715.
epoch: 867, train loss: 1.2586430737731653, validation loss: 1.2819452389426853.
epoch: 868, train loss: 1.281621713157094, validation loss: 1.2966184253277986.
epoch: 869, train loss: 1.2680950908485902, validation loss: 1.300164704737456.
epoch: 870, train loss: 1.2606639872997178, validation loss: 1.274663261745287.
epoch: 871, train loss: 1.2588199967638067, validation loss: 1.271485852158588.
epoch: 872, train loss: 1.2564916993499895, validation loss: 1.2628462936567224.
epoch: 873, train loss: 1.2551975129941189, validation loss: 1.2887556656547214.
epoch: 874, train loss: 1.2555846675820308, validation loss: 1.27098650517671.
epoch: 875, train loss: 1.2570307407904109, validation loss: 1.284304634384487.
epoch: 876, train loss: 1.2566331100026402, validation loss: 1.2678825751594875.
epoch: 877, train loss: 1.2574720076464732, validation loss: 1.2697547726009204.
epoch: 878, train loss: 1.2550103664398193, validation loss: 1.2772382601447727.
epoch: 879, train loss: 1.2565811369397224, validation loss: 1.2683367521866509.
epoch: 880, train loss: 1.2557052942590976, validation loss: 1.2623742559681768.
epoch: 881, train loss: 1.2572085048080583, validation loss: 1.2752979009047798.
epoch: 882, train loss: 1.2580335588630187, validation loss: 1.2725115858990212.
epoch: 883, train loss: 1.255954584944139, validation loss: 1.274083857950957.
epoch: 884, train loss: 1.2602151927598026, validation loss: 1.285668274630671.
epoch: 885, train loss: 1.2582822545952754, validation loss: 1.274925190469493.
epoch: 886, train loss: 1.255398777646756, validation loss: 1.275969323904618.
epoch: 887, train loss: 1.2541637912802739, validation loss: 1.276964078778806.
epoch: 888, train loss: 1.2609337218310854, validation loss: 1.3177901921064958.
epoch: 889, train loss: 1.2647067483412016, validation loss: 1.2804092998089998.
epoch: 890, train loss: 1.2581905170318184, validation loss: 1.285927062449248.
epoch: 891, train loss: 1.2552756967894527, validation loss: 1.2640154672705608.
epoch: 892, train loss: 1.2568783049189716, validation loss: 1.2661100159520688.
epoch: 893, train loss: 1.2532471965212342, validation loss: 1.2804034585538118.
epoch: 894, train loss: 1.252361345728603, validation loss: 1.2638772415078205.
epoch: 895, train loss: 1.261276616962678, validation loss: 1.2909393777018008.
epoch: 896, train loss: 1.2607674915856177, validation loss: 1.2675682202629421.
epoch: 897, train loss: 1.2568912495166884, validation loss: 1.2695956644804582.
epoch: 898, train loss: 1.2552768670090841, validation loss: 1.26490667073623.
epoch: 899, train loss: 1.2540123484550265, validation loss: 1.2631115602410359.
epoch: 900, train loss: 1.255965607975601, validation loss: 1.2764148349347322.
epoch: 901, train loss: 1.2586669823445311, validation loss: 1.2789834841437961.
epoch: 902, train loss: 1.2598644987158818, validation loss: 1.2833475444627844.
epoch: 903, train loss: 1.25845649811106, validation loss: 1.2708008185676907.
epoch: 904, train loss: 1.2516433405219962, validation loss: 1.2627083892407625.
epoch: 905, train loss: 1.2537643023587148, validation loss: 1.2723146884337715.
epoch: 906, train loss: 1.255032381880174, validation loss: 1.2727655535158904.
epoch: 907, train loss: 1.2557598046206553, validation loss: 1.274189135302668.
epoch: 908, train loss: 1.2576302891477533, validation loss: 1.2689073293105415.
epoch: 909, train loss: 1.2558484919574282, validation loss: 1.2876468482224837.
epoch: 910, train loss: 1.2576947693431049, validation loss: 1.2751191854476929.
epoch: 911, train loss: 1.2517995265645718, validation loss: 1.2632046523301497.
epoch: 912, train loss: 1.2531605773015853, validation loss: 1.2708288120186848.
epoch: 913, train loss: 1.2564209962109907, validation loss: 1.269261562305948.
epoch: 914, train loss: 1.2545379334633504, validation loss: 1.2811059588971345.
epoch: 915, train loss: 1.256834187638869, validation loss: 1.2868694688962854.
epoch: 916, train loss: 1.2524686100286082, validation loss: 1.270212323769279.
epoch: 917, train loss: 1.254602318510003, validation loss: 1.2746790595676587.
epoch: 918, train loss: 1.2554009201329783, validation loss: 1.2823801455290422.
epoch: 919, train loss: 1.2578829111309227, validation loss: 1.2735872942468394.
epoch: 920, train loss: 1.256249648715378, validation loss: 1.2762720947680266.
epoch: 921, train loss: 1.2647904988822587, validation loss: 1.2923702157062034.
epoch: 922, train loss: 1.263655160545209, validation loss: 1.2849344170611838.
epoch: 923, train loss: 1.2628877523842208, validation loss: 1.2762520624243694.
epoch: 924, train loss: 1.2619383499163006, validation loss: 1.2728182388388591.
epoch: 925, train loss: 1.2600403346052957, validation loss: 1.2728136052256045.
epoch: 926, train loss: 1.2610882826901357, validation loss: 1.2699461760728255.
epoch: 927, train loss: 1.256764678780092, validation loss: 1.3536181812701018.
epoch: 928, train loss: 1.2830342491832347, validation loss: 1.2804974732191667.
epoch: 929, train loss: 1.2659568885050783, validation loss: 1.2680111553357996.
epoch: 930, train loss: 1.2597712683021476, validation loss: 1.2684429158335147.
epoch: 931, train loss: 1.2577877088424263, validation loss: 1.2690798925316853.
epoch: 932, train loss: 1.2582345752541078, validation loss: 1.2651039983915247.
epoch: 933, train loss: 1.2557152673738812, validation loss: 1.2776985945908919.
epoch: 934, train loss: 1.2565814136365139, validation loss: 1.2692783241686614.
epoch: 935, train loss: 1.2583843010281204, validation loss: 1.2726507497870403.
epoch: 936, train loss: 1.2570975187721602, validation loss: 1.263267563736957.
epoch: 937, train loss: 1.2577823903582512, validation loss: 1.2723835706710815.
epoch: 938, train loss: 1.2581852893216894, validation loss: 1.2740163543949956.
epoch: 939, train loss: 1.2573676798321785, validation loss: 1.2671692786009416.
epoch: 940, train loss: 1.2568084635865797, validation loss: 1.2776985479437786.
epoch: 941, train loss: 1.2593241470669387, validation loss: 1.2724899105403735.
epoch: 942, train loss: 1.2581325900664024, validation loss: 1.2698489427566528.
epoch: 943, train loss: 1.2565223919142277, validation loss: 1.2742728513220083.
epoch: 944, train loss: 1.2594777640946415, validation loss: 1.2837063851563826.
epoch: 945, train loss: 1.2624239145068947, validation loss: 1.2766478424486907.
epoch: 946, train loss: 1.2584087553374264, validation loss: 1.2812745052835215.
epoch: 947, train loss: 1.2588267676327207, validation loss: 1.2803622225056523.
epoch: 948, train loss: 1.2600086435265498, validation loss: 1.2722165118093076.
epoch: 949, train loss: 1.2573746366238376, validation loss: 1.2732857776724773.
epoch: 950, train loss: 1.2569742454301327, validation loss: 1.2636236885319585.
epoch: 951, train loss: 1.254851481236449, validation loss: 1.2672584989796514.
epoch: 952, train loss: 1.2536710435097371, validation loss: 1.2625879619432532.
epoch: 953, train loss: 1.2553723372450662, validation loss: 1.2762216951536096.
epoch: 954, train loss: 1.2652599713124266, validation loss: 1.2959194960801497.
epoch: 955, train loss: 1.2683348776003636, validation loss: 1.284281637357629.
epoch: 956, train loss: 1.2606737799600725, validation loss: 1.2909311315287715.
epoch: 957, train loss: 1.2587330199162894, validation loss: 1.2878235474876736.
epoch: 958, train loss: 1.259516921612101, validation loss: 1.277247465175131.
epoch: 959, train loss: 1.2544550578528588, validation loss: 1.2800582854644111.
epoch: 960, train loss: 1.2537593360340924, validation loss: 1.301742004311603.
epoch: 961, train loss: 1.2553131602226046, validation loss: 1.2830669413442197.
epoch: 962, train loss: 1.2602311164960949, validation loss: 1.2642436908638996.
epoch: 963, train loss: 1.2574891431615987, validation loss: 1.2697608885557756.
epoch: 964, train loss: 1.2584070218812435, validation loss: 1.290810025256613.
epoch: 965, train loss: 1.2738122174499231, validation loss: 1.2701411661894426.
epoch: 966, train loss: 1.2636217589772076, validation loss: 1.281717290049014.
epoch: 967, train loss: 1.2596213697293484, validation loss: 1.2771402390106865.
epoch: 968, train loss: 1.2583563655888268, validation loss: 1.2703422981759775.
epoch: 969, train loss: 1.2552891871251097, validation loss: 1.267524885094684.
epoch: 970, train loss: 1.2562482914793383, validation loss: 1.274827760198842.
epoch: 971, train loss: 1.2562902225266903, validation loss: 1.2728232352629951.
epoch: 972, train loss: 1.2542776066228885, validation loss: 1.2781431260316267.
epoch: 973, train loss: 1.2544162809301953, validation loss: 1.2758897853934246.
epoch: 974, train loss: 1.2553726751869971, validation loss: 1.2659963939500891.
epoch: 975, train loss: 1.2554074722692508, validation loss: 1.2853751856347788.
epoch: 976, train loss: 1.257677774910533, validation loss: 1.2626219469568003.
epoch: 977, train loss: 1.2613602450134558, validation loss: 1.2684625957323157.
epoch: 978, train loss: 1.2595361941451326, validation loss: 1.2647678230119788.
epoch: 979, train loss: 1.2534288080460434, validation loss: 1.260176648264346.
epoch: 980, train loss: 1.2557636925933557, validation loss: 1.2655128499735957.
epoch: 981, train loss: 1.2571308776872967, validation loss: 1.2833913305531377.
epoch: 982, train loss: 1.2538517155778517, validation loss: 1.2702470551366392.
epoch: 983, train loss: 1.2547236101342998, validation loss: 1.2722833001095315.
epoch: 984, train loss: 1.2572977925659319, validation loss: 1.2894805669784546.
epoch: 985, train loss: 1.2554751711154202, validation loss: 1.2699566094771675.
epoch: 986, train loss: 1.2546930750575633, validation loss: 1.2759688418844473.
epoch: 987, train loss: 1.2581141640286926, validation loss: 1.2644320881885032.
epoch: 988, train loss: 1.2560092429502294, validation loss: 1.266237481780674.
epoch: 989, train loss: 1.2531970859667576, validation loss: 1.2609603871469912.
epoch: 990, train loss: 1.2526309883922613, validation loss: 1.2882417233093926.
epoch: 991, train loss: 1.2565476533469804, validation loss: 1.2636978937231975.
epoch: 992, train loss: 1.26243361529954, validation loss: 1.2649408008741296.
epoch: 993, train loss: 1.255161526006296, validation loss: 1.261148416477701.
epoch: 994, train loss: 1.253498298312546, validation loss: 1.2591271296791409.
epoch: 995, train loss: 1.253389639591952, validation loss: 1.278020055397697.
epoch: 996, train loss: 1.2556819303320088, validation loss: 1.2645988878996477.
epoch: 997, train loss: 1.2557915175726655, validation loss: 1.275841184284376.
epoch: 998, train loss: 1.2582553253261322, validation loss: 1.2659838666086611.
epoch: 999, train loss: 1.2579697425212335, validation loss: 1.2772163619165835.
epoch: 1000, train loss: 1.248265599985735, validation loss: 1.249782665916111.
epoch: 1001, train loss: 1.2424768898465217, validation loss: 1.2536017894744873.
epoch: 1002, train loss: 1.2399601170776087, validation loss: 1.2488569073055102.
epoch: 1003, train loss: 1.238835355557433, validation loss: 1.2506572992905327.
epoch: 1004, train loss: 1.2387054732086462, validation loss: 1.2475510421006575.
epoch: 1005, train loss: 1.2369928753704107, validation loss: 1.247072898823282.
epoch: 1006, train loss: 1.2379519523830589, validation loss: 1.2494988441467285.
epoch: 1007, train loss: 1.2369554961493257, validation loss: 1.242950843728107.
epoch: 1008, train loss: 1.2359571850627935, validation loss: 1.2481044427208279.
epoch: 1009, train loss: 1.238289491845927, validation loss: 1.2539146620294321.
epoch: 1010, train loss: 1.2395580536728605, validation loss: 1.2489345747491587.
epoch: 1011, train loss: 1.2378953979649674, validation loss: 1.2463641270347263.
epoch: 1012, train loss: 1.235072844619051, validation loss: 1.2473874765893687.
epoch: 1013, train loss: 1.2366647359428056, validation loss: 1.2462344636087832.
epoch: 1014, train loss: 1.235403478692431, validation loss: 1.2504966155342434.
epoch: 1015, train loss: 1.2359515330113402, validation loss: 1.253574366154878.
epoch: 1016, train loss: 1.2374169553091767, validation loss: 1.2461116728575334.
epoch: 1017, train loss: 1.235733653427264, validation loss: 1.245298401169155.
epoch: 1018, train loss: 1.2362438757485206, validation loss: 1.2440042392067288.
epoch: 1019, train loss: 1.2341206128444147, validation loss: 1.2472909533459207.
epoch: 1020, train loss: 1.236543270426059, validation loss: 1.2535373335299285.
epoch: 1021, train loss: 1.2360445425051068, validation loss: 1.2486758905908335.
epoch: 1022, train loss: 1.2365039062062535, validation loss: 1.2482101295305335.
epoch: 1023, train loss: 1.2356786848208225, validation loss: 1.250933051109314.
epoch: 1024, train loss: 1.2357285252404868, validation loss: 1.252149664837381.
epoch: 1025, train loss: 1.2354146679607005, validation loss: 1.2538813559905342.
epoch: 1026, train loss: 1.2345737875054736, validation loss: 1.2484592458476191.
epoch: 1027, train loss: 1.2371512706126642, validation loss: 1.2550509390623674.
epoch: 1028, train loss: 1.2366112295640719, validation loss: 1.2482965562654578.
epoch: 1029, train loss: 1.2370828805713479, validation loss: 1.2422553560008174.
epoch: 1030, train loss: 1.2381830062341252, validation loss: 1.2581545062687085.
epoch: 1031, train loss: 1.2382704785110754, validation loss: 1.2616578392360522.
epoch: 1032, train loss: 1.2369550510284004, validation loss: 1.248813095300094.
epoch: 1033, train loss: 1.2350873640917857, validation loss: 1.2511681525603584.
epoch: 1034, train loss: 1.2357395384289802, validation loss: 1.2468050873797873.
epoch: 1035, train loss: 1.2374701817101295, validation loss: 1.2457635143528814.
epoch: 1036, train loss: 1.2350359466097771, validation loss: 1.2517603480297586.
epoch: 1037, train loss: 1.2333282057298434, validation loss: 1.2469972942186438.
epoch: 1038, train loss: 1.2336196975970486, validation loss: 1.2485885775607566.
epoch: 1039, train loss: 1.2331538758146654, validation loss: 1.2565317050270413.
epoch: 1040, train loss: 1.2381613823251987, validation loss: 1.2758099410844885.
epoch: 1041, train loss: 1.2453737838552632, validation loss: 1.250500886336617.
epoch: 1042, train loss: 1.2353596096738764, validation loss: 1.260267620501311.
epoch: 1043, train loss: 1.2336039269736054, validation loss: 1.2464387831480608.
epoch: 1044, train loss: 1.2327609160624513, validation loss: 1.2426901226458342.
epoch: 1045, train loss: 1.2349333916235408, validation loss: 1.2447389105091924.
epoch: 1046, train loss: 1.2319191530210163, validation loss: 1.2479325481083081.
epoch: 1047, train loss: 1.2347089686524977, validation loss: 1.2492257978605188.
epoch: 1048, train loss: 1.2348817729075021, validation loss: 1.252371881319129.
epoch: 1049, train loss: 1.2331388281026017, validation loss: 1.2495296105094578.
epoch: 1050, train loss: 1.2338885068893433, validation loss: 1.2482153540072234.
epoch: 1051, train loss: 1.2355308751447485, validation loss: 1.247815728187561.
epoch: 1052, train loss: 1.2344374886346519, validation loss: 1.2569225508233774.
epoch: 1053, train loss: 1.2347965284225044, validation loss: 1.2441653324210125.
epoch: 1054, train loss: 1.2363967676775172, validation loss: 1.2473410367965698.
epoch: 1055, train loss: 1.235609166119077, validation loss: 1.2474338801010796.
epoch: 1056, train loss: 1.2314256079700014, validation loss: 1.2461276780004087.
epoch: 1057, train loss: 1.2356265914549522, validation loss: 1.247753433559252.
epoch: 1058, train loss: 1.2366758945885055, validation loss: 1.2462048375088235.
epoch: 1059, train loss: 1.2334941680278253, validation loss: 1.2442240922347358.
epoch: 1060, train loss: 1.231165240664001, validation loss: 1.2433069322420203.
epoch: 1061, train loss: 1.2317164676998733, validation loss: 1.2512142969214397.
epoch: 1062, train loss: 1.2329092517905278, validation loss: 1.2459469100703364.
epoch: 1063, train loss: 1.2309389497162004, validation loss: 1.2502420829690022.
epoch: 1064, train loss: 1.2355572860175317, validation loss: 1.2573871560718701.
epoch: 1065, train loss: 1.2346871883497326, validation loss: 1.2499570587406987.
epoch: 1066, train loss: 1.234963561416766, validation loss: 1.2497568026832913.
epoch: 1067, train loss: 1.2365571501058177, validation loss: 1.2478426176568735.
epoch: 1068, train loss: 1.2316838666933392, validation loss: 1.2468487957249517.
epoch: 1069, train loss: 1.2330572266097461, validation loss: 1.2497933118239692.
epoch: 1070, train loss: 1.233464689429747, validation loss: 1.2539546126904695.
epoch: 1071, train loss: 1.2347215479667033, validation loss: 1.2484146149262139.
epoch: 1072, train loss: 1.230658436040266, validation loss: 1.2436103613480278.
epoch: 1073, train loss: 1.2321327541946272, validation loss: 1.2501575376676477.
epoch: 1074, train loss: 1.2314931712019335, validation loss: 1.256578170734903.
epoch: 1075, train loss: 1.2321857629566018, validation loss: 1.2425003881039827.
epoch: 1076, train loss: 1.235560892918788, validation loss: 1.2443280012711235.
epoch: 1077, train loss: 1.230909111302927, validation loss: 1.2468765870384548.
epoch: 1078, train loss: 1.2339436745424883, validation loss: 1.2528710054314656.
epoch: 1079, train loss: 1.2295553596741562, validation loss: 1.2472507124361785.
epoch: 1080, train loss: 1.2317574942877534, validation loss: 1.2476560862168022.
epoch: 1081, train loss: 1.232152577933915, validation loss: 1.243969720342885.
epoch: 1082, train loss: 1.2330586057190502, validation loss: 1.251245581585428.
epoch: 1083, train loss: 1.2322196883892795, validation loss: 1.2597521232522053.
epoch: 1084, train loss: 1.2356378255634133, validation loss: 1.2586242271506267.
epoch: 1085, train loss: 1.237240744293283, validation loss: 1.2427212518194448.
epoch: 1086, train loss: 1.2293467127948725, validation loss: 1.242053923399552.
epoch: 1087, train loss: 1.2343436501441745, validation loss: 1.245961360309435.
epoch: 1088, train loss: 1.231502144708546, validation loss: 1.2473072642865388.
epoch: 1089, train loss: 1.234003787740655, validation loss: 1.246709460797517.
epoch: 1090, train loss: 1.2336726385519046, validation loss: 1.2590051267458044.
epoch: 1091, train loss: 1.230138871647896, validation loss: 1.2454442977905273.
epoch: 1092, train loss: 1.2329285954116682, validation loss: 1.2510039339894834.
epoch: 1093, train loss: 1.2319567083218776, validation loss: 1.2656118403310361.
epoch: 1094, train loss: 1.2339215464548234, validation loss: 1.2522045633067256.
epoch: 1095, train loss: 1.2336721890563265, validation loss: 1.2601388485535332.
epoch: 1096, train loss: 1.2308049256648492, validation loss: 1.2456680484440015.
epoch: 1097, train loss: 1.235045540223428, validation loss: 1.2766636402710625.
epoch: 1098, train loss: 1.2371968271535472, validation loss: 1.24197474769924.
epoch: 1099, train loss: 1.2334538731006308, validation loss: 1.2456376967222795.
epoch: 1100, train loss: 1.233952585710298, validation loss: 1.2565074329790862.
epoch: 1101, train loss: 1.2338935924232552, validation loss: 1.247606178988581.
epoch: 1102, train loss: 1.2307524724837837, validation loss: 1.2451807416003684.
epoch: 1103, train loss: 1.2303799314236423, validation loss: 1.2428490493608557.
epoch: 1104, train loss: 1.2299761509676592, validation loss: 1.246866189915201.
epoch: 1105, train loss: 1.2316675722052197, validation loss: 1.246876079103221.
epoch: 1106, train loss: 1.2360874928465677, validation loss: 1.252953430880671.
epoch: 1107, train loss: 1.2347115792265726, validation loss: 1.2514137599779211.
epoch: 1108, train loss: 1.2302816756274721, validation loss: 1.2500247177870378.
epoch: 1109, train loss: 1.2293431441718286, validation loss: 1.25004824348118.
epoch: 1110, train loss: 1.2326384553121865, validation loss: 1.2500545978546143.
epoch: 1111, train loss: 1.2323053189373891, validation loss: 1.2507800278456316.
epoch: 1112, train loss: 1.2295020818710327, validation loss: 1.243044930955638.
epoch: 1113, train loss: 1.232240128954616, validation loss: 1.2424329467441724.
epoch: 1114, train loss: 1.2333168830346624, validation loss: 1.2526782232782114.
epoch: 1115, train loss: 1.2354701035613314, validation loss: 1.264184428297955.
epoch: 1116, train loss: 1.2360764916883695, validation loss: 1.2439518959625908.
epoch: 1117, train loss: 1.232556231524966, validation loss: 1.2412383971006975.
epoch: 1118, train loss: 1.2331082711526014, validation loss: 1.2448667080506035.
epoch: 1119, train loss: 1.2321727516454295, validation loss: 1.2467117827871572.
epoch: 1120, train loss: 1.2307523423378621, validation loss: 1.2406922164170637.
epoch: 1121, train loss: 1.2317054151395046, validation loss: 1.2447558278622834.
epoch: 1122, train loss: 1.2317315022879785, validation loss: 1.241086332694344.
epoch: 1123, train loss: 1.2320486449320383, validation loss: 1.2501507012740425.
epoch: 1124, train loss: 1.2336318569445828, validation loss: 1.2432802189951357.
epoch: 1125, train loss: 1.229605398046861, validation loss: 1.242724035097205.
epoch: 1126, train loss: 1.2289135477958468, validation loss: 1.2414709640585857.
epoch: 1127, train loss: 1.2309068342961302, validation loss: 1.2419086383736653.
epoch: 1128, train loss: 1.2303976695471948, validation loss: 1.2543829627659009.
epoch: 1129, train loss: 1.2317017743346887, validation loss: 1.2464046633761863.
epoch: 1130, train loss: 1.232782978530324, validation loss: 1.2458452608274377.
epoch: 1131, train loss: 1.2281316967185485, validation loss: 1.2475567434145056.
epoch: 1132, train loss: 1.2337556793055404, validation loss: 1.251212503599084.
epoch: 1133, train loss: 1.2352407809791215, validation loss: 1.2507242275320964.
epoch: 1134, train loss: 1.2296844600537502, validation loss: 1.2416711216387541.
epoch: 1135, train loss: 1.2335200408183107, validation loss: 1.2396703543870344.
epoch: 1136, train loss: 1.2274036265294486, validation loss: 1.2457941770553589.
epoch: 1137, train loss: 1.227491539552671, validation loss: 1.2399372950844143.
epoch: 1138, train loss: 1.2283445399835569, validation loss: 1.248925691065581.
epoch: 1139, train loss: 1.2360477480319663, validation loss: 1.2486410918443098.
epoch: 1140, train loss: 1.2301996727602198, validation loss: 1.2491145393122798.
epoch: 1141, train loss: 1.2349896540335559, validation loss: 1.266358468843543.
epoch: 1142, train loss: 1.2353683819464587, validation loss: 1.2454601681750754.
epoch: 1143, train loss: 1.2317046626992183, validation loss: 1.2467285342838452.
epoch: 1144, train loss: 1.226038927331977, validation loss: 1.2704328194908474.
epoch: 1145, train loss: 1.235867993547282, validation loss: 1.2660484417625095.
epoch: 1146, train loss: 1.2322462698735228, validation loss: 1.2482209568438323.
epoch: 1147, train loss: 1.232184818031591, validation loss: 1.2391524988672007.
epoch: 1148, train loss: 1.229065211541062, validation loss: 1.244082388670548.
epoch: 1149, train loss: 1.2314055217515438, validation loss: 1.2431230959684954.
epoch: 1150, train loss: 1.2300666100388273, validation loss: 1.2417951303979624.
epoch: 1151, train loss: 1.2354639035846116, validation loss: 1.2457867964454319.
epoch: 1152, train loss: 1.2303198849389312, validation loss: 1.2456583510274473.
epoch: 1153, train loss: 1.2301180625180586, validation loss: 1.2547970854717752.
epoch: 1154, train loss: 1.2283196328976833, validation loss: 1.2480050740034685.
epoch: 1155, train loss: 1.2276624605196331, validation loss: 1.258822482565175.
epoch: 1156, train loss: 1.231457978213599, validation loss: 1.2441972545955493.
epoch: 1157, train loss: 1.2341457288199609, validation loss: 1.2458272705907407.
epoch: 1158, train loss: 1.2321380868964238, validation loss: 1.2458691545154736.
epoch: 1159, train loss: 1.2292097806930542, validation loss: 1.242926343627598.
epoch: 1160, train loss: 1.227508739593926, validation loss: 1.2426097963167273.
epoch: 1161, train loss: 1.2275312220284698, validation loss: 1.2505569458007812.
epoch: 1162, train loss: 1.2305938213243397, validation loss: 1.2505484508431477.
epoch: 1163, train loss: 1.231666130757113, validation loss: 1.2591759277426677.
epoch: 1164, train loss: 1.2278416780156827, validation loss: 1.2403982463090315.
epoch: 1165, train loss: 1.2286572686029136, validation loss: 1.2469892346340676.
epoch: 1166, train loss: 1.228637215194352, validation loss: 1.2435808596403704.
epoch: 1167, train loss: 1.229248850717457, validation loss: 1.2478859942892324.
epoch: 1168, train loss: 1.2271314301622023, validation loss: 1.2491151716398157.
epoch: 1169, train loss: 1.2367594176476155, validation loss: 1.2475299161413442.
epoch: 1170, train loss: 1.2301883489713756, validation loss: 1.2486288443855618.
epoch: 1171, train loss: 1.2291584441421228, validation loss: 1.245938928230949.
epoch: 1172, train loss: 1.2282327883834139, validation loss: 1.2464736544567605.
epoch: 1173, train loss: 1.2275759780078852, validation loss: 1.2473679625469705.
epoch: 1174, train loss: 1.2375711005762082, validation loss: 1.2532581246417502.
epoch: 1175, train loss: 1.2314714543316343, validation loss: 1.241954233335412.
epoch: 1176, train loss: 1.23034394115483, validation loss: 1.2626041847726572.
epoch: 1177, train loss: 1.2311357511292904, validation loss: 1.245566487312317.
epoch: 1178, train loss: 1.2295844456471434, validation loss: 1.248266769492108.
epoch: 1179, train loss: 1.2307238611606284, validation loss: 1.2444475059923918.
epoch: 1180, train loss: 1.241451631992235, validation loss: 1.2719790313554846.
epoch: 1181, train loss: 1.2366207958361424, validation loss: 1.244877172553021.
epoch: 1182, train loss: 1.2430501290417593, validation loss: 1.2592453697453374.
epoch: 1183, train loss: 1.2350130660818257, validation loss: 1.247546672821045.
epoch: 1184, train loss: 1.23124251562521, validation loss: 1.272499934486721.
epoch: 1185, train loss: 1.2349750787839977, validation loss: 1.2483164538507876.
epoch: 1186, train loss: 1.2283214035384151, validation loss: 1.253771362097367.
epoch: 1187, train loss: 1.2279122597580656, validation loss: 1.2417335354763528.
epoch: 1188, train loss: 1.2263145610826824, validation loss: 1.2573360982148543.
epoch: 1189, train loss: 1.2263742182232917, validation loss: 1.2420502123625383.
epoch: 1190, train loss: 1.2270777138001328, validation loss: 1.2404585299284563.
epoch: 1191, train loss: 1.2256784515643337, validation loss: 1.2580627151157544.
epoch: 1192, train loss: 1.2332032743943941, validation loss: 1.2726048542105632.
epoch: 1193, train loss: 1.2411528191435228, validation loss: 1.2472804888435032.
epoch: 1194, train loss: 1.2307472010271265, validation loss: 1.2474815949149753.
epoch: 1195, train loss: 1.2457246856951931, validation loss: 1.2514216640721196.
epoch: 1196, train loss: 1.2298574797604063, validation loss: 1.2511216661204463.
epoch: 1197, train loss: 1.2307321675326846, validation loss: 1.253986560780069.
epoch: 1198, train loss: 1.2308771785246122, validation loss: 1.2459531659665315.
epoch: 1199, train loss: 1.2289868779138688, validation loss: 1.250788134077321.
epoch: 1200, train loss: 1.2300112914601598, validation loss: 1.2519305996272876.
epoch: 1201, train loss: 1.2293510043292963, validation loss: 1.2476065469824749.
epoch: 1202, train loss: 1.2252723241071088, validation loss: 1.2403789033060488.
epoch: 1203, train loss: 1.229802717856311, validation loss: 1.2455481601798015.
epoch: 1204, train loss: 1.2340776285993944, validation loss: 1.2379490914552107.
epoch: 1205, train loss: 1.2285347061419705, validation loss: 1.2445464911668196.
epoch: 1206, train loss: 1.2271072733292885, validation loss: 1.2437703505806301.
epoch: 1207, train loss: 1.2253314289477988, validation loss: 1.2581330382305642.
epoch: 1208, train loss: 1.2302280128549, validation loss: 1.246931335200434.
epoch: 1209, train loss: 1.224561714251107, validation loss: 1.2702249133068582.
epoch: 1210, train loss: 1.2355155244879765, validation loss: 1.2477112853008767.
epoch: 1211, train loss: 1.2328997084853845, validation loss: 1.2385537054227747.
epoch: 1212, train loss: 1.2293109139171214, validation loss: 1.2405897275261257.
epoch: 1213, train loss: 1.2457352898536471, validation loss: 1.249329862387284.
epoch: 1214, train loss: 1.2357571792165074, validation loss: 1.2440540324086728.
epoch: 1215, train loss: 1.2290460068151492, validation loss: 1.241128392841505.
epoch: 1216, train loss: 1.2254133651015955, validation loss: 1.2419508540112039.
epoch: 1217, train loss: 1.2276067722828017, validation loss: 1.243812576584194.
epoch: 1218, train loss: 1.2262025338794114, validation loss: 1.2434860208760137.
epoch: 1219, train loss: 1.2265221055494535, validation loss: 1.2424528909766155.
epoch: 1220, train loss: 1.231424126056356, validation loss: 1.248055919356968.
epoch: 1221, train loss: 1.2248852373263157, validation loss: 1.2396763874136882.
epoch: 1222, train loss: 1.2321277703713933, validation loss: 1.247117130652718.
epoch: 1223, train loss: 1.2254830631641074, validation loss: 1.2488494334013567.
epoch: 1224, train loss: 1.2376608564219345, validation loss: 1.2459580328153528.
epoch: 1225, train loss: 1.2310386502414667, validation loss: 1.2525022703668345.
epoch: 1226, train loss: 1.231318098689438, validation loss: 1.2469634232313738.
epoch: 1227, train loss: 1.2303119525996917, validation loss: 1.265789622845857.
epoch: 1228, train loss: 1.234557618788623, validation loss: 1.2412850597630376.
epoch: 1229, train loss: 1.2432271515557525, validation loss: 1.2496717338976653.
epoch: 1230, train loss: 1.2306582599604896, validation loss: 1.2426846649335779.
epoch: 1231, train loss: 1.230254032196255, validation loss: 1.2466007471084595.
epoch: 1232, train loss: 1.2283358048955235, validation loss: 1.2438020706176758.
epoch: 1233, train loss: 1.2346927966546575, validation loss: 1.2452220035635906.
epoch: 1234, train loss: 1.2275564254970726, validation loss: 1.2428285298140154.
epoch: 1235, train loss: 1.229957621031945, validation loss: 1.2572035478508992.
epoch: 1236, train loss: 1.2297667199318563, validation loss: 1.2406621964081475.
epoch: 1237, train loss: 1.2282418898486216, validation loss: 1.2425246083218118.
epoch: 1238, train loss: 1.226431940673688, validation loss: 1.244358498117198.
epoch: 1239, train loss: 1.228927815726044, validation loss: 1.2650708167449287.
epoch: 1240, train loss: 1.2303463034673567, validation loss: 1.2406356023705525.
epoch: 1241, train loss: 1.2277000037901993, validation loss: 1.248583788457124.
epoch: 1242, train loss: 1.225333345045737, validation loss: 1.2436108900153118.
epoch: 1243, train loss: 1.230687210319239, validation loss: 1.251895697220512.
epoch: 1244, train loss: 1.23117138923855, validation loss: 1.2436383185179338.
epoch: 1245, train loss: 1.2271274339168443, validation loss: 1.2507941722869873.
epoch: 1246, train loss: 1.2329942633252624, validation loss: 1.244822647260583.
epoch: 1247, train loss: 1.229742724961097, validation loss: 1.2402760412382043.
epoch: 1248, train loss: 1.228430647368825, validation loss: 1.2437966284544573.
epoch: 1249, train loss: 1.2260962298157019, validation loss: 1.2404134480849556.
epoch: 1250, train loss: 1.2257643588092348, validation loss: 1.2460980052533357.
epoch: 1251, train loss: 1.2299129602012284, validation loss: 1.258104894472205.
epoch: 1252, train loss: 1.2343649732957191, validation loss: 1.238321858903636.
epoch: 1253, train loss: 1.2280188372375769, validation loss: 1.239360897437386.
epoch: 1254, train loss: 1.2285374140520708, validation loss: 1.2406386396159297.
epoch: 1255, train loss: 1.2242912469653908, validation loss: 1.2473889848460322.
epoch: 1256, train loss: 1.2268727591278357, validation loss: 1.2996311239574267.
epoch: 1257, train loss: 1.2394179138568564, validation loss: 1.2517646136491194.
epoch: 1258, train loss: 1.2399834897540032, validation loss: 1.2491739625516145.
epoch: 1259, train loss: 1.2353491870635147, validation loss: 1.242986772371375.
epoch: 1260, train loss: 1.2307543338985618, validation loss: 1.2405929928240569.
epoch: 1261, train loss: 1.2278785869615887, validation loss: 1.2422553300857544.
epoch: 1262, train loss: 1.2262618508907632, validation loss: 1.2421091846797778.
epoch: 1263, train loss: 1.2300965840663385, validation loss: 1.2395490926244985.
epoch: 1264, train loss: 1.2258875370025635, validation loss: 1.2428838118262913.
epoch: 1265, train loss: 1.2299176246748058, validation loss: 1.2467538740323938.
epoch: 1266, train loss: 1.229294048536808, validation loss: 1.2477431971093882.
epoch: 1267, train loss: 1.2272905581588045, validation loss: 1.241241973379384.
epoch: 1268, train loss: 1.223213871684643, validation loss: 1.2360165430151897.
epoch: 1269, train loss: 1.229594540158543, validation loss: 1.2401990838672803.
epoch: 1270, train loss: 1.2289123032071174, validation loss: 1.243051668872004.
epoch: 1271, train loss: 1.2296478431159203, validation loss: 1.2398909330368042.
epoch: 1272, train loss: 1.235531729295713, validation loss: 1.250223978706028.
epoch: 1273, train loss: 1.2275184589788455, validation loss: 1.2481819961381995.
epoch: 1274, train loss: 1.2277565483653217, validation loss: 1.2417923263881518.
epoch: 1275, train loss: 1.230735527266056, validation loss: 1.2526752119478972.
epoch: 1276, train loss: 1.2297053730815923, validation loss: 1.2453395439230877.
epoch: 1277, train loss: 1.2261789009111737, validation loss: 1.2412003952523936.
epoch: 1278, train loss: 1.229655627810627, validation loss: 1.2687384978584622.
epoch: 1279, train loss: 1.234732811604071, validation loss: 1.2436901745588884.
epoch: 1280, train loss: 1.228747052883883, validation loss: 1.2731101305588433.
epoch: 1281, train loss: 1.22910308619158, validation loss: 1.243111869563227.
epoch: 1282, train loss: 1.2243688511192252, validation loss: 1.244669566983762.
epoch: 1283, train loss: 1.2275949333785872, validation loss: 1.250493453896564.
epoch: 1284, train loss: 1.2328754138509068, validation loss: 1.259374069130939.
epoch: 1285, train loss: 1.233704930051751, validation loss: 1.2640511160311492.
epoch: 1286, train loss: 1.2323223636784684, validation loss: 1.2453201594560042.
epoch: 1287, train loss: 1.2293500429993376, validation loss: 1.2472917774449224.
epoch: 1288, train loss: 1.2309208791190331, validation loss: 1.2458588299543962.
epoch: 1289, train loss: 1.225390282245951, validation loss: 1.2442453788674397.
epoch: 1290, train loss: 1.226527176865744, validation loss: 1.2437184841736504.
epoch: 1291, train loss: 1.2355981113713816, validation loss: 1.2464904318685117.
epoch: 1292, train loss: 1.229341476335438, validation loss: 1.253125118172687.
epoch: 1293, train loss: 1.2286613928068668, validation loss: 1.2455810878587805.
epoch: 1294, train loss: 1.2248503188474462, validation loss: 1.2536917458409849.
epoch: 1295, train loss: 1.2300622889754969, validation loss: 1.2431996853455254.
epoch: 1296, train loss: 1.2305004443597356, validation loss: 1.2468540616657422.
epoch: 1297, train loss: 1.2260472413596757, validation loss: 1.255004037981448.
epoch: 1298, train loss: 1.2245019783667468, validation loss: 1.2409628059553064.
epoch: 1299, train loss: 1.2272238129869513, validation loss: 1.2447147887686025.
epoch: 1300, train loss: 1.2351634054008973, validation loss: 1.2462417872055718.
epoch: 1301, train loss: 1.2306901971134572, validation loss: 1.2437535109727278.
epoch: 1302, train loss: 1.2250958571740247, validation loss: 1.2398602547852888.
epoch: 1303, train loss: 1.2245777878192587, validation loss: 1.2385400689166526.
epoch: 1304, train loss: 1.226949359298846, validation loss: 1.2417307314665422.
epoch: 1305, train loss: 1.23106396635738, validation loss: 1.2443516980046812.
epoch: 1306, train loss: 1.2339861174242213, validation loss: 1.2454311847686768.
epoch: 1307, train loss: 1.2275864826429874, validation loss: 1.2444531140120134.
epoch: 1308, train loss: 1.2314436796608321, validation loss: 1.2439575298972751.
epoch: 1309, train loss: 1.2315344449576981, validation loss: 1.240019528762154.
epoch: 1310, train loss: 1.229556045400987, validation loss: 1.2462291562038919.
epoch: 1311, train loss: 1.2286182270137542, validation loss: 1.250534897265227.
epoch: 1312, train loss: 1.2306552830092403, validation loss: 1.2517793904180112.
epoch: 1313, train loss: 1.2341825141819245, validation loss: 1.2447548275408538.
epoch: 1314, train loss: 1.2296770942320518, validation loss: 1.2419824237408845.
epoch: 1315, train loss: 1.2231090429725997, validation loss: 1.247699779012929.
epoch: 1316, train loss: 1.2252666939289198, validation loss: 1.2468830709872039.
epoch: 1317, train loss: 1.225529913508564, validation loss: 1.2573339161665544.
epoch: 1318, train loss: 1.2336031767206455, validation loss: 1.2426771599313486.
epoch: 1319, train loss: 1.2271065755721626, validation loss: 1.2375321699225383.
epoch: 1320, train loss: 1.2279388160880553, validation loss: 1.2447779282279636.
epoch: 1321, train loss: 1.2292066484416297, validation loss: 1.2492677491644155.
epoch: 1322, train loss: 1.2278577614268031, validation loss: 1.2454384565353394.
epoch: 1323, train loss: 1.2235582990383884, validation loss: 1.252610191054966.
epoch: 1324, train loss: 1.2299832554038512, validation loss: 1.2396690586338872.
epoch: 1325, train loss: 1.2293062745977978, validation loss: 1.2750300117160962.
epoch: 1326, train loss: 1.2250946355522225, validation loss: 1.2439632882242617.
epoch: 1327, train loss: 1.2271385685019536, validation loss: 1.2525922578314077.
epoch: 1328, train loss: 1.2361564340941402, validation loss: 1.2530430244362873.
epoch: 1329, train loss: 1.2285126567980564, validation loss: 1.242853449738544.
epoch: 1330, train loss: 1.22781024722878, validation loss: 1.2486688935238381.
epoch: 1331, train loss: 1.2309719345985202, validation loss: 1.2473323500674705.
epoch: 1332, train loss: 1.2264771024021535, validation loss: 1.2423634580943896.
epoch: 1333, train loss: 1.230418895362714, validation loss: 1.2410242194714753.
epoch: 1334, train loss: 1.2282930590690824, validation loss: 1.2473612505456675.
epoch: 1335, train loss: 1.2310270661607794, validation loss: 1.2496125387108845.
epoch: 1336, train loss: 1.2271731184163224, validation loss: 1.2426935123360676.
epoch: 1337, train loss: 1.2266128686589932, validation loss: 1.2420159992964372.
epoch: 1338, train loss: 1.2262762402175764, validation loss: 1.2475383540858394.
epoch: 1339, train loss: 1.2258031346382352, validation loss: 1.2458513145861418.
epoch: 1340, train loss: 1.2271649968733482, validation loss: 1.2657272090082583.
epoch: 1341, train loss: 1.230374506854136, validation loss: 1.2472325356110283.
epoch: 1342, train loss: 1.2346516705434256, validation loss: 1.2592214138611504.
epoch: 1343, train loss: 1.2349063661120354, validation loss: 1.2763733760170315.
epoch: 1344, train loss: 1.2378192855677475, validation loss: 1.2459814548492432.
epoch: 1345, train loss: 1.2278719517069125, validation loss: 1.25063999839451.
epoch: 1346, train loss: 1.2332246052015812, validation loss: 1.2407623736754707.
epoch: 1347, train loss: 1.2295151019315107, validation loss: 1.2384339778319648.
epoch: 1348, train loss: 1.2250719825062184, validation loss: 1.2471899053324824.
epoch: 1349, train loss: 1.2337748238799768, validation loss: 1.2891985644464907.
epoch: 1350, train loss: 1.2363565525877367, validation loss: 1.248771019603895.
epoch: 1351, train loss: 1.228401674043148, validation loss: 1.24025587413622.
epoch: 1352, train loss: 1.2285990671280327, validation loss: 1.2469199429387632.
epoch: 1353, train loss: 1.2254622310673424, validation loss: 1.241202017535334.
epoch: 1354, train loss: 1.2237089752057277, validation loss: 1.2483068911925606.
epoch: 1355, train loss: 1.2301595976593298, validation loss: 1.2656581090844197.
epoch: 1356, train loss: 1.2271729456175358, validation loss: 1.241067445796469.
epoch: 1357, train loss: 1.226708717302445, validation loss: 1.2487090307733286.
epoch: 1358, train loss: 1.2285924318733565, validation loss: 1.2457996451336404.
epoch: 1359, train loss: 1.2240525812184044, validation loss: 1.27759021261464.
epoch: 1360, train loss: 1.2270935062968402, validation loss: 1.2648105206696882.
epoch: 1361, train loss: 1.2349087043639717, validation loss: 1.2635372047838958.
epoch: 1362, train loss: 1.2376590617206118, validation loss: 1.2580792541089265.
epoch: 1363, train loss: 1.2413361881851057, validation loss: 1.2425338910973591.
epoch: 1364, train loss: 1.232750141292537, validation loss: 1.2406603823537412.
epoch: 1365, train loss: 1.2296986984550407, validation loss: 1.2379637697468633.
epoch: 1366, train loss: 1.2290582077218852, validation loss: 1.2607609759206357.
epoch: 1367, train loss: 1.2266921023710058, validation loss: 1.2481271805970564.
epoch: 1368, train loss: 1.2378409827521089, validation loss: 1.2486221738483594.
epoch: 1369, train loss: 1.2302058705496133, validation loss: 1.2452170693356057.
epoch: 1370, train loss: 1.2275923042122376, validation loss: 1.2396718004475469.
epoch: 1371, train loss: 1.225481596561747, validation loss: 1.2425306465314783.
epoch: 1372, train loss: 1.2237541445898354, validation loss: 1.2455142995585566.
epoch: 1373, train loss: 1.2330461554571028, validation loss: 1.2408871080564416.
epoch: 1374, train loss: 1.226905620426213, validation loss: 1.2422555218572202.
epoch: 1375, train loss: 1.2223263803972018, validation loss: 1.3025910491528718.
epoch: 1376, train loss: 1.2329033744444542, validation loss: 1.2477674276932427.
epoch: 1377, train loss: 1.2237702323756088, validation loss: 1.2470963571382605.
epoch: 1378, train loss: 1.2248858825876079, validation loss: 1.2412757355233897.
epoch: 1379, train loss: 1.22409961529828, validation loss: 1.2394290903340215.
epoch: 1380, train loss: 1.2359151741780272, validation loss: 1.2809737246969473.
epoch: 1381, train loss: 1.230613446016924, validation loss: 1.3210755586624146.
epoch: 1382, train loss: 1.2295771181036572, validation loss: 1.24506239787392.
epoch: 1383, train loss: 1.228700802960527, validation loss: 1.2502103629319563.
epoch: 1384, train loss: 1.2296082546951574, validation loss: 1.2367870548497075.
epoch: 1385, train loss: 1.2234611030018658, validation loss: 1.2463085858718208.
epoch: 1386, train loss: 1.2261159605936174, validation loss: 1.2448924468911213.
epoch: 1387, train loss: 1.22452573601259, validation loss: 1.2430604592613552.
epoch: 1388, train loss: 1.2257545070910671, validation loss: 1.247201919555664.
epoch: 1389, train loss: 1.2218435073117597, validation loss: 1.2482824532882026.
epoch: 1390, train loss: 1.229409335950099, validation loss: 1.2526404805805371.
epoch: 1391, train loss: 1.2352421918046583, validation loss: 1.2916629988214243.
epoch: 1392, train loss: 1.2398866404087172, validation loss: 1.2486346338106238.
epoch: 1393, train loss: 1.2306390082070586, validation loss: 1.2379877411800881.
epoch: 1394, train loss: 1.229665381099106, validation loss: 1.248221174530361.
epoch: 1395, train loss: 1.2323948341772097, validation loss: 1.2507979507031648.
epoch: 1396, train loss: 1.232106401285994, validation loss: 1.2467625452124553.
epoch: 1397, train loss: 1.2360775711339549, validation loss: 1.2448582960211712.
epoch: 1398, train loss: 1.231896695740726, validation loss: 1.2378835781760837.
epoch: 1399, train loss: 1.2291845181666383, validation loss: 1.269129297007685.
epoch: 1400, train loss: 1.2288355039894034, validation loss: 1.2469924170037974.
epoch: 1401, train loss: 1.229415953706164, validation loss: 1.240683244622272.
epoch: 1402, train loss: 1.2231805116758434, validation loss: 1.2506038987118264.
epoch: 1403, train loss: 1.2258945944112376, validation loss: 1.2495317873747454.
epoch: 1404, train loss: 1.2270896412910672, validation loss: 1.240530770757924.
epoch: 1405, train loss: 1.2224082771791231, validation loss: 1.2537037652471792.
epoch: 1406, train loss: 1.2246774752205665, validation loss: 1.251356752022453.
epoch: 1407, train loss: 1.223677576135058, validation loss: 1.2403681226398633.
epoch: 1408, train loss: 1.2243792365450379, validation loss: 1.2486588954925537.
epoch: 1409, train loss: 1.235592488848835, validation loss: 1.241847214491471.
epoch: 1410, train loss: 1.2339282495166184, validation loss: 1.2507073775581692.
epoch: 1411, train loss: 1.2280383416272085, validation loss: 1.24071378811546.
epoch: 1412, train loss: 1.2341003133616317, validation loss: 1.2558429655821428.
epoch: 1413, train loss: 1.2286074609931457, validation loss: 1.2467244189718496.
epoch: 1414, train loss: 1.2300945695387113, validation loss: 1.2449923701908276.
epoch: 1415, train loss: 1.2231181236582065, validation loss: 1.2349164641421775.
epoch: 1416, train loss: 1.2225008634252286, validation loss: 1.262072153713392.
epoch: 1417, train loss: 1.2248702956995834, validation loss: 1.2677349525949229.
epoch: 1418, train loss: 1.2327538247502179, validation loss: 1.243243025696796.
epoch: 1419, train loss: 1.2318488818789841, validation loss: 1.26579459335493.
epoch: 1420, train loss: 1.2322008161369813, validation loss: 1.2515285481577334.
epoch: 1421, train loss: 1.2240984669519126, validation loss: 1.245174563449362.
epoch: 1422, train loss: 1.2277354833182939, validation loss: 1.2432078589563784.
epoch: 1423, train loss: 1.2286315861098263, validation loss: 1.2437874908032625.
epoch: 1424, train loss: 1.2236952628564397, validation loss: 1.2463847606078438.
epoch: 1425, train loss: 1.2208620375449504, validation loss: 1.2456271907557612.
epoch: 1426, train loss: 1.2241284759766464, validation loss: 1.2388318206952966.
epoch: 1427, train loss: 1.228478812296456, validation loss: 1.2407219772753508.
epoch: 1428, train loss: 1.2231738370492917, validation loss: 1.2417496598285178.
epoch: 1429, train loss: 1.2213326211369366, validation loss: 1.2478984076043833.
epoch: 1430, train loss: 1.2225209135528003, validation loss: 1.2470677106276802.
epoch: 1431, train loss: 1.2387654190763422, validation loss: 1.2568290700083193.
epoch: 1432, train loss: 1.2405591459449279, validation loss: 1.24602064360743.
epoch: 1433, train loss: 1.2278095724385814, validation loss: 1.2432542002719382.
epoch: 1434, train loss: 1.2252950515222112, validation loss: 1.2649524574694426.
epoch: 1435, train loss: 1.2244754789072438, validation loss: 1.2719591337701548.
epoch: 1436, train loss: 1.2256178155951543, validation loss: 1.249622562657232.
epoch: 1437, train loss: 1.2235647472766562, validation loss: 1.2547627635624097.
epoch: 1438, train loss: 1.2250409651240077, validation loss: 1.2512903317161228.
epoch: 1439, train loss: 1.228136240889173, validation loss: 1.2440721781357476.
epoch: 1440, train loss: 1.2224952244977338, validation loss: 1.2485285012618355.
epoch: 1441, train loss: 1.227991815007061, validation loss: 1.2507818626320881.
epoch: 1442, train loss: 1.2330156892811486, validation loss: 1.2536303841549417.
epoch: 1443, train loss: 1.2255997231247229, validation loss: 1.248200385466866.
epoch: 1444, train loss: 1.2219732223300759, validation loss: 1.2486530697864036.
epoch: 1445, train loss: 1.2208590966845871, validation loss: 1.238604364187821.
epoch: 1446, train loss: 1.226855030847252, validation loss: 1.241508442422618.
epoch: 1447, train loss: 1.2333149527191023, validation loss: 1.2559723439423933.
epoch: 1448, train loss: 1.2354735442257803, validation loss: 1.2516674736271733.
epoch: 1449, train loss: 1.232060258541632, validation loss: 1.2542184798613838.
epoch: 1450, train loss: 1.2299945288841878, validation loss: 1.2468233937802522.
epoch: 1451, train loss: 1.2267396559409045, validation loss: 1.241770044617031.
epoch: 1452, train loss: 1.2243308517911018, validation loss: 1.2468318680058355.
epoch: 1453, train loss: 1.2266014661263982, validation loss: 1.2376863230829653.
epoch: 1454, train loss: 1.2224622144611603, validation loss: 1.2375578569329304.
epoch: 1455, train loss: 1.2260558670813884, validation loss: 1.2408540041550347.
epoch: 1456, train loss: 1.2215678505941268, validation loss: 1.244481755339581.
epoch: 1457, train loss: 1.2329782761565042, validation loss: 1.2415577017742654.
epoch: 1458, train loss: 1.2254090134156954, validation loss: 1.264137625694275.
epoch: 1459, train loss: 1.2257260620047192, validation loss: 1.2712508284527322.
epoch: 1460, train loss: 1.22705879561398, validation loss: 1.2436268796091494.
epoch: 1461, train loss: 1.230543947001116, validation loss: 1.2576387654180112.
epoch: 1462, train loss: 1.2267945523655743, validation loss: 1.2388206979502803.
epoch: 1463, train loss: 1.2309227831866763, validation loss: 1.2454060523406318.
epoch: 1464, train loss: 1.2258676203019028, validation loss: 1.2509047829586526.
epoch: 1465, train loss: 1.2262326774247196, validation loss: 1.2493720210116843.
epoch: 1466, train loss: 1.225877494986998, validation loss: 1.2398508217023767.
epoch: 1467, train loss: 1.2270298463488938, validation loss: 1.2430868615274844.
epoch: 1468, train loss: 1.2316175742980537, validation loss: 1.2498764628949373.
epoch: 1469, train loss: 1.2277159439314396, validation loss: 1.2430810669194097.
epoch: 1470, train loss: 1.2280658024166702, validation loss: 1.2400865762130073.
epoch: 1471, train loss: 1.225183960494645, validation loss: 1.2469806411991948.
epoch: 1472, train loss: 1.2239949571976967, validation loss: 1.2452391178711602.
epoch: 1473, train loss: 1.2296283485692576, validation loss: 1.2414053315701692.
epoch: 1474, train loss: 1.2222272420148237, validation loss: 1.235933516336524.
epoch: 1475, train loss: 1.2658220573302803, validation loss: 1.2684043231217756.
epoch: 1476, train loss: 1.2459227688815615, validation loss: 1.2466235057167385.
epoch: 1477, train loss: 1.2313384976955728, validation loss: 1.2458871188371077.
epoch: 1478, train loss: 1.2295087083764034, validation loss: 1.2498364863188371.
epoch: 1479, train loss: 1.2281428761438493, validation loss: 1.2467576887296594.
epoch: 1480, train loss: 1.2270909974334436, validation loss: 1.2446176487466563.
epoch: 1481, train loss: 1.2247406998905568, validation loss: 1.2438099591628364.
epoch: 1482, train loss: 1.2233699844517838, validation loss: 1.2401213542274807.
epoch: 1483, train loss: 1.2250985650841248, validation loss: 1.2388699884000032.
epoch: 1484, train loss: 1.2230897037261124, validation loss: 1.2693928272827812.
epoch: 1485, train loss: 1.2303356522813849, validation loss: 1.2413465458413828.
epoch: 1486, train loss: 1.2256795178859605, validation loss: 1.2472680962604026.
epoch: 1487, train loss: 1.2257729287541241, validation loss: 1.258889016897782.
epoch: 1488, train loss: 1.2322694128806437, validation loss: 1.26110229284867.
epoch: 1489, train loss: 1.2321050473309438, validation loss: 1.2463043254354726.
epoch: 1490, train loss: 1.2247932777492279, validation loss: 1.2566596995229307.
epoch: 1491, train loss: 1.2279445162606895, validation loss: 1.247205843096194.
epoch: 1492, train loss: 1.2319247011744647, validation loss: 1.252608112666918.
epoch: 1493, train loss: 1.225549229788124, validation loss: 1.2362325295158054.
epoch: 1494, train loss: 1.2217764187296596, validation loss: 1.2458562643631645.
epoch: 1495, train loss: 1.2257249202203313, validation loss: 1.2407169808512148.
epoch: 1496, train loss: 1.2230106996833732, validation loss: 1.2472278346186099.
epoch: 1497, train loss: 1.2234055197567022, validation loss: 1.2439154490180637.
epoch: 1498, train loss: 1.226726977103347, validation loss: 1.2539275262666785.
epoch: 1499, train loss: 1.2268674362690077, validation loss: 1.250426349432572.
epoch: 1500, train loss: 1.2246035643673818, validation loss: 1.2496709460797517.
epoch: 1501, train loss: 1.226269314048487, validation loss: 1.243765167568041.
epoch: 1502, train loss: 1.2212918548408997, validation loss: 1.243834526642509.
epoch: 1503, train loss: 1.2507782660493063, validation loss: 1.2528091254441633.
epoch: 1504, train loss: 1.231270358103131, validation loss: 1.2435394162717073.
epoch: 1505, train loss: 1.2254207309232938, validation loss: 1.247310555499533.
epoch: 1506, train loss: 1.232761068081637, validation loss: 1.2505479947380398.
epoch: 1507, train loss: 1.2258244720074014, validation loss: 1.25160042617632.
epoch: 1508, train loss: 1.2228696215043373, validation loss: 1.2589994513470193.
epoch: 1509, train loss: 1.222914531690265, validation loss: 1.2452436944712764.
epoch: 1510, train loss: 1.2271668823487167, validation loss: 1.239680756693301.
epoch: 1511, train loss: 1.2237682014430336, validation loss: 1.2385744582051816.
epoch: 1512, train loss: 1.2262212956717256, validation loss: 1.2497051384138025.
epoch: 1513, train loss: 1.229340265650268, validation loss: 1.2683132990546848.
epoch: 1514, train loss: 1.2308534427520332, validation loss: 1.2731246429940928.
epoch: 1515, train loss: 1.2269517489529531, validation loss: 1.2499031761418218.
epoch: 1516, train loss: 1.2250064327082504, validation loss: 1.2515082100163335.
epoch: 1517, train loss: 1.2220219964281134, validation loss: 1.249334200568821.
epoch: 1518, train loss: 1.220238531401398, validation loss: 1.2624785537305085.
epoch: 1519, train loss: 1.2259169970083674, validation loss: 1.2413955408593882.
epoch: 1520, train loss: 1.2233543505362414, validation loss: 1.2461758074553118.
epoch: 1521, train loss: 1.2275491143585344, validation loss: 1.2449921110401982.
epoch: 1522, train loss: 1.2198217396342426, validation loss: 1.2408131827478823.
epoch: 1523, train loss: 1.2221652630272262, validation loss: 1.2396860433661419.
epoch: 1524, train loss: 1.227076377343694, validation loss: 1.2924109749172046.
epoch: 1525, train loss: 1.2438493846753322, validation loss: 1.2449183671370796.
epoch: 1526, train loss: 1.2279243370808592, validation loss: 1.250497968300529.
epoch: 1527, train loss: 1.2258731148658542, validation loss: 1.238910021989242.
epoch: 1528, train loss: 1.2207720082834226, validation loss: 1.2443676409514055.
epoch: 1529, train loss: 1.2301979710202697, validation loss: 1.2551187069519707.
epoch: 1530, train loss: 1.2280433374807376, validation loss: 1.2480777087418928.
epoch: 1531, train loss: 1.2238906107911276, validation loss: 1.2540451910184778.
epoch: 1532, train loss: 1.2207073191983984, validation loss: 1.2434454223384028.
epoch: 1533, train loss: 1.2264850959865325, validation loss: 1.2504073951555335.
epoch: 1534, train loss: 1.2282906497290376, validation loss: 1.2714544949324236.
epoch: 1535, train loss: 1.222236542526735, validation loss: 1.2570732261823572.
epoch: 1536, train loss: 1.2289544628300797, validation loss: 1.2433762135712996.
epoch: 1537, train loss: 1.224603220957135, validation loss: 1.2441832500955332.
epoch: 1538, train loss: 1.225579577848452, validation loss: 1.2469314595927363.
epoch: 1539, train loss: 1.2287022684692244, validation loss: 1.2483367142469988.
epoch: 1540, train loss: 1.2310815743350108, validation loss: 1.2464779148931089.
epoch: 1541, train loss: 1.2269607333961976, validation loss: 1.2373644839162412.
epoch: 1542, train loss: 1.2249374313092014, validation loss: 1.2520950721657795.
epoch: 1543, train loss: 1.2227560314563437, validation loss: 1.2428496661393538.
epoch: 1544, train loss: 1.2251568584267152, validation loss: 1.2513132043506787.
epoch: 1545, train loss: 1.2280476224531822, validation loss: 1.2404828382574993.
epoch: 1546, train loss: 1.225978388698823, validation loss: 1.2433899381886357.
epoch: 1547, train loss: 1.2311622429331508, validation loss: 1.2449463035749353.
epoch: 1548, train loss: 1.2243548106709752, validation loss: 1.2402099733767302.
epoch: 1549, train loss: 1.2252477090293115, validation loss: 1.237191132877184.
epoch: 1550, train loss: 1.2222562951779148, validation loss: 1.2358498158662214.
epoch: 1551, train loss: 1.2260424740817568, validation loss: 1.2424725967904795.
epoch: 1552, train loss: 1.2215865981688194, validation loss: 1.2469073741332344.
epoch: 1553, train loss: 1.23195155607451, validation loss: 1.2433870305185732.
epoch: 1554, train loss: 1.2211471194521002, validation loss: 1.2458527347315913.
epoch: 1555, train loss: 1.225441082901911, validation loss: 1.24120323036028.
epoch: 1556, train loss: 1.2296451811396747, validation loss: 1.244737754697385.
epoch: 1557, train loss: 1.230375589580711, validation loss: 1.2471827113110086.
epoch: 1558, train loss: 1.2242555016771368, validation loss: 1.242013236750727.
epoch: 1559, train loss: 1.2299285536512323, validation loss: 1.2486068787782088.
epoch: 1560, train loss: 1.2295800994295594, validation loss: 1.2503582809282385.
epoch: 1561, train loss: 1.2222962116976397, validation loss: 1.2350750643274058.
epoch: 1562, train loss: 1.2233469770589005, validation loss: 1.2370330509932146.
epoch: 1563, train loss: 1.222232450039015, validation loss: 1.259406478508659.
epoch: 1564, train loss: 1.233688521822658, validation loss: 1.2532868696295696.
epoch: 1565, train loss: 1.2273967178589706, validation loss: 1.2453373618747876.
epoch: 1566, train loss: 1.2270092297037807, validation loss: 1.245854528053947.
epoch: 1567, train loss: 1.2268013188598352, validation loss: 1.2374645989874136.
epoch: 1568, train loss: 1.2219906739138682, validation loss: 1.2420864779016245.
epoch: 1569, train loss: 1.220604124419186, validation loss: 1.2367447977480681.
epoch: 1570, train loss: 1.2321665658863312, validation loss: 1.2585489076116811.
epoch: 1571, train loss: 1.2385828691885012, validation loss: 1.244721251985301.
epoch: 1572, train loss: 1.2269986474185908, validation loss: 1.2397645556408425.
epoch: 1573, train loss: 1.225713574558223, validation loss: 1.2562604572462.
epoch: 1574, train loss: 1.2257497715293815, validation loss: 1.2438191071800564.
epoch: 1575, train loss: 1.2250787511878056, validation loss: 1.2415536538414333.
epoch: 1576, train loss: 1.22278327898148, validation loss: 1.2446065674657407.
epoch: 1577, train loss: 1.2273301356429354, validation loss: 1.2615645139113716.
epoch: 1578, train loss: 1.2345348979354998, validation loss: 1.2439370880956235.
epoch: 1579, train loss: 1.22572914176031, validation loss: 1.257965036060499.
epoch: 1580, train loss: 1.2346416449328081, validation loss: 1.2512085230454155.
epoch: 1581, train loss: 1.2247647057979478, validation loss: 1.2419162936832593.
epoch: 1582, train loss: 1.219215138242879, validation loss: 1.2406845092773438.
epoch: 1583, train loss: 1.227869020689518, validation loss: 1.2391203019929968.
epoch: 1584, train loss: 1.2225569169455712, validation loss: 1.239464951598126.
epoch: 1585, train loss: 1.2190184429151203, validation loss: 1.239226211672244.
epoch: 1586, train loss: 1.2203044038300122, validation loss: 1.2424248197804326.
epoch: 1587, train loss: 1.2220283549859983, validation loss: 1.2700529461321624.
epoch: 1588, train loss: 1.2362005426249374, validation loss: 1.2445505805637525.
epoch: 1589, train loss: 1.223182576511978, validation loss: 1.2614122421845146.
epoch: 1590, train loss: 1.2254647355560864, validation loss: 1.2452352254287056.
epoch: 1591, train loss: 1.2210042706323325, validation loss: 1.2451972183973894.
epoch: 1592, train loss: 1.2262474046934635, validation loss: 1.2384537302929421.
epoch: 1593, train loss: 1.2219456368630086, validation loss: 1.2373830546503481.
epoch: 1594, train loss: 1.220731258392334, validation loss: 1.2469482370044873.
epoch: 1595, train loss: 1.2175932936712142, validation loss: 1.2418154892714128.
epoch: 1596, train loss: 1.229081646018072, validation loss: 1.2405548303023628.
epoch: 1597, train loss: 1.2259756129816037, validation loss: 1.2468658789344456.
epoch: 1598, train loss: 1.22535514503444, validation loss: 1.2442524070325105.
epoch: 1599, train loss: 1.2199172219005199, validation loss: 1.2412082371504412.
epoch: 1600, train loss: 1.2212403378355394, validation loss: 1.2544545919998833.
epoch: 1601, train loss: 1.2298785568377293, validation loss: 1.2408002666805102.
epoch: 1602, train loss: 1.221856612677968, validation loss: 1.2413514852523804.
epoch: 1603, train loss: 1.2207871084913202, validation loss: 1.2466680485269297.
epoch: 1604, train loss: 1.2236279828832783, validation loss: 1.310061568799226.
epoch: 1605, train loss: 1.2239956680787814, validation loss: 1.2482041742490686.
epoch: 1606, train loss: 1.225316639340252, validation loss: 1.2661032728526904.
epoch: 1607, train loss: 1.2223876933439062, validation loss: 1.2408238027406775.
epoch: 1608, train loss: 1.2211867002172208, validation loss: 1.3294542405916296.
epoch: 1609, train loss: 1.2293760678090087, validation loss: 1.2418058229529338.
epoch: 1610, train loss: 1.2253942249018117, validation loss: 1.2537112132362698.
epoch: 1611, train loss: 1.22484613558568, validation loss: 1.2387345148169475.
epoch: 1612, train loss: 1.222196926764392, validation loss: 1.2389155367146367.
epoch: 1613, train loss: 1.2219950004455147, validation loss: 1.2476882779079934.
epoch: 1614, train loss: 1.217921823536584, validation loss: 1.2426217794418335.
epoch: 1615, train loss: 1.2241916350268442, validation loss: 1.2468647749527642.
epoch: 1616, train loss: 1.2212264209712318, validation loss: 1.2486200384471728.
epoch: 1617, train loss: 1.2344215889589503, validation loss: 1.2448020499685537.
epoch: 1618, train loss: 1.2285058957721116, validation loss: 1.2391993066538936.
epoch: 1619, train loss: 1.222656815423878, validation loss: 1.240087374396946.
epoch: 1620, train loss: 1.2355322750336533, validation loss: 1.2497192310250325.
epoch: 1621, train loss: 1.2283841962114386, validation loss: 1.2547055068223372.
epoch: 1622, train loss: 1.2248009662015722, validation loss: 1.2388315148975537.
epoch: 1623, train loss: 1.2290298326299824, validation loss: 1.252314541650855.
epoch: 1624, train loss: 1.221109733669036, validation loss: 1.2540787043778792.
epoch: 1625, train loss: 1.2258765085027852, validation loss: 1.2477555430453757.
epoch: 1626, train loss: 1.2250365007907973, validation loss: 1.263941801112631.
epoch: 1627, train loss: 1.228235109136739, validation loss: 1.2461700905924258.
epoch: 1628, train loss: 1.223480715664155, validation loss: 1.2409506621568098.
epoch: 1629, train loss: 1.2314128175787968, validation loss: 1.2444476252016814.
epoch: 1630, train loss: 1.2233395445237465, validation loss: 1.2424763855726824.
epoch: 1631, train loss: 1.2275607848386152, validation loss: 1.2581303948941438.
epoch: 1632, train loss: 1.2296056353717768, validation loss: 1.244845431783925.
epoch: 1633, train loss: 1.225405437137009, validation loss: 1.2435334247091543.
epoch: 1634, train loss: 1.2217540205071826, validation loss: 1.237756003504214.
epoch: 1635, train loss: 1.224958146384003, validation loss: 1.2403167952661929.
epoch: 1636, train loss: 1.2150024077214232, validation loss: 1.251033549723418.
epoch: 1637, train loss: 1.2277527872575533, validation loss: 1.266078891961471.
epoch: 1638, train loss: 1.2254247545102321, validation loss: 1.2668430494225544.
epoch: 1639, train loss: 1.2265029959722396, validation loss: 1.2667732549750286.
epoch: 1640, train loss: 1.2314958244288734, validation loss: 1.2467681998791902.
epoch: 1641, train loss: 1.2248994976008705, validation loss: 1.239282058632892.
epoch: 1642, train loss: 1.2220264968522099, validation loss: 1.2433728394301042.
epoch: 1643, train loss: 1.2205225721411748, validation loss: 1.2411510477895322.
epoch: 1644, train loss: 1.2268693108077442, validation loss: 1.2389949301014775.
epoch: 1645, train loss: 1.2261544914420592, validation loss: 1.2403495881868445.
epoch: 1646, train loss: 1.2222801184435503, validation loss: 1.2732391305591748.
epoch: 1647, train loss: 1.2297548952452633, validation loss: 1.251660943031311.
epoch: 1648, train loss: 1.219360414994966, validation loss: 1.2497033865555474.
epoch: 1649, train loss: 1.222154774797072, validation loss: 1.2418239427649456.
epoch: 1650, train loss: 1.2254889547278027, validation loss: 1.242552083471547.
epoch: 1651, train loss: 1.2190878117850068, validation loss: 1.232748964558477.
epoch: 1652, train loss: 1.2378289349582217, validation loss: 1.2457080923992654.
epoch: 1653, train loss: 1.2216230860543906, validation loss: 1.2412877393805462.
epoch: 1654, train loss: 1.2581572346731063, validation loss: 1.2694186697835508.
epoch: 1655, train loss: 1.2407056486934698, validation loss: 1.2453150904696921.
epoch: 1656, train loss: 1.22814802948488, validation loss: 1.2475457087807034.
epoch: 1657, train loss: 1.2290958209868965, validation loss: 1.2502260778261267.
epoch: 1658, train loss: 1.2294922892106783, validation loss: 1.2428614160288936.
epoch: 1659, train loss: 1.2209726681403064, validation loss: 1.2489412401033484.
epoch: 1660, train loss: 1.227316760141915, validation loss: 1.2522599489792534.
epoch: 1661, train loss: 1.2239089252751902, validation loss: 1.2375109195709229.
epoch: 1662, train loss: 1.2348720054014013, validation loss: 1.2458141005557517.
epoch: 1663, train loss: 1.2296214781769919, validation loss: 1.255301444426827.
epoch: 1664, train loss: 1.223907740837937, validation loss: 1.3069749759591145.
epoch: 1665, train loss: 1.2278349618299291, validation loss: 1.2419471222421397.
epoch: 1666, train loss: 1.2244223771838967, validation loss: 1.2408766798351123.
epoch: 1667, train loss: 1.2199809179393524, validation loss: 1.255202029062354.
epoch: 1668, train loss: 1.2219342627656569, validation loss: 1.2452711333399233.
epoch: 1669, train loss: 1.2241408540568222, validation loss: 1.2408200087754622.
epoch: 1670, train loss: 1.2215315705045648, validation loss: 1.242392228997272.
epoch: 1671, train loss: 1.221333834009433, validation loss: 1.2473222017288208.
epoch: 1672, train loss: 1.2255231251410388, validation loss: 1.240254080813864.
epoch: 1673, train loss: 1.2220351553838187, validation loss: 1.2406781549039094.
epoch: 1674, train loss: 1.2232322539758245, validation loss: 1.2533678231032.
epoch: 1675, train loss: 1.222846047593913, validation loss: 1.241177164989969.
epoch: 1676, train loss: 1.2332923915408074, validation loss: 1.2477277258168096.
epoch: 1677, train loss: 1.227225016016479, validation loss: 1.252386818761411.
epoch: 1678, train loss: 1.2199164235263789, validation loss: 1.2409951997839885.
epoch: 1679, train loss: 1.2208681576842562, validation loss: 1.2416695356369019.
epoch: 1680, train loss: 1.2327852588181103, validation loss: 1.2608558509660803.
epoch: 1681, train loss: 1.2248979839709921, validation loss: 1.241461199262868.
epoch: 1682, train loss: 1.2218595819735745, validation loss: 1.2374226943306301.
epoch: 1683, train loss: 1.2233569764216012, validation loss: 1.2459494290144548.
epoch: 1684, train loss: 1.2245148070361636, validation loss: 1.2427833080291748.
epoch: 1685, train loss: 1.2201426565100293, validation loss: 1.2356383593186089.
epoch: 1686, train loss: 1.2245732283373492, validation loss: 1.2442288035931794.
epoch: 1687, train loss: 1.222398909953756, validation loss: 1.2448954219403474.
epoch: 1688, train loss: 1.2230402253089694, validation loss: 1.2417133217272551.
epoch: 1689, train loss: 1.2306053988430479, validation loss: 1.2529304494028506.
epoch: 1690, train loss: 1.229628964301643, validation loss: 1.2432324368020762.
epoch: 1691, train loss: 1.2453570365905762, validation loss: 1.2795482096464739.
epoch: 1692, train loss: 1.2402680554521193, validation loss: 1.246569934098617.
epoch: 1693, train loss: 1.225838520111294, validation loss: 1.2329250263131184.
epoch: 1694, train loss: 1.222226597847195, validation loss: 1.2404264470805293.
epoch: 1695, train loss: 1.226147508402483, validation loss: 1.2388534856879192.
epoch: 1696, train loss: 1.2222127159801097, validation loss: 1.2431260710177214.
epoch: 1697, train loss: 1.2268488450881538, validation loss: 1.2458401555600374.
epoch: 1698, train loss: 1.2231323817454347, validation loss: 1.2453482669332754.
epoch: 1699, train loss: 1.2195325652393727, validation loss: 1.2388160747030508.
epoch: 1700, train loss: 1.2334883858304504, validation loss: 1.2381459630053977.
epoch: 1701, train loss: 1.2268223860941896, validation loss: 1.2529584687689077.
epoch: 1702, train loss: 1.2288919785700807, validation loss: 1.2394083531006523.
epoch: 1703, train loss: 1.2236142869389386, validation loss: 1.251967165781104.
epoch: 1704, train loss: 1.2249249580803268, validation loss: 1.2443580316460652.
epoch: 1705, train loss: 1.2304747881145652, validation loss: 1.2560662445814714.
epoch: 1706, train loss: 1.2245487926203176, validation loss: 1.2580620361411052.
epoch: 1707, train loss: 1.229424264452873, validation loss: 1.241388025491134.
epoch: 1708, train loss: 1.2216609727352037, validation loss: 1.2482907979384712.
epoch: 1709, train loss: 1.2336770558575971, validation loss: 1.248529693354731.
epoch: 1710, train loss: 1.2265183849072239, validation loss: 1.238821760467861.
epoch: 1711, train loss: 1.2197782184005876, validation loss: 1.243230348048003.
epoch: 1712, train loss: 1.2246949213360427, validation loss: 1.2351778331010237.
epoch: 1713, train loss: 1.2256354235727853, validation loss: 1.250620556914288.
epoch: 1714, train loss: 1.227521786995984, validation loss: 1.2501100560893184.
epoch: 1715, train loss: 1.222063131288651, validation loss: 1.2375760544901309.
epoch: 1716, train loss: 1.2231423198629956, validation loss: 1.2398558440415755.
epoch: 1717, train loss: 1.2248305213560753, validation loss: 1.2467178002647732.
epoch: 1718, train loss: 1.2197826171140058, validation loss: 1.2395269611607427.
epoch: 1719, train loss: 1.2230255363184377, validation loss: 1.24822155289028.
epoch: 1720, train loss: 1.224314935710452, validation loss: 1.2476909627085147.
epoch: 1721, train loss: 1.2277664974195148, validation loss: 1.2446335709613303.
epoch: 1722, train loss: 1.2198422556623407, validation loss: 1.2588544980339382.
epoch: 1723, train loss: 1.2282427450932494, validation loss: 1.2498798577681831.
epoch: 1724, train loss: 1.2255966411818058, validation loss: 1.2402726567309836.
epoch: 1725, train loss: 1.2273677565635892, validation loss: 1.2774930881417317.
epoch: 1726, train loss: 1.2358549100543381, validation loss: 1.2508360147476196.
epoch: 1727, train loss: 1.2305291300519892, validation loss: 1.2439295312632686.
epoch: 1728, train loss: 1.2235610233534366, validation loss: 1.2432976598324983.
epoch: 1729, train loss: 1.2230940586930021, validation loss: 1.2400978181673132.
epoch: 1730, train loss: 1.2207591249308456, validation loss: 1.2539639110150544.
epoch: 1731, train loss: 1.224039627871382, validation loss: 1.2571416004844334.
epoch: 1732, train loss: 1.2283245926603266, validation loss: 1.2468844755836155.
epoch: 1733, train loss: 1.2302570211777992, validation loss: 1.2562012568764065.
epoch: 1734, train loss: 1.2257428191123751, validation loss: 1.2405259298241658.
epoch: 1735, train loss: 1.2216695776773154, validation loss: 1.2449622724367224.
epoch: 1736, train loss: 1.2267972088735037, validation loss: 1.2435366174449092.
epoch: 1737, train loss: 1.2276408420790226, validation loss: 1.2446730707002722.
epoch: 1738, train loss: 1.2261876064703006, validation loss: 1.2410238255625186.
epoch: 1739, train loss: 1.2279582165796823, validation loss: 1.251125719236291.
epoch: 1740, train loss: 1.2216260662866294, validation loss: 1.25457879771357.
epoch: 1741, train loss: 1.2264528230789604, validation loss: 1.2389989313871965.
epoch: 1742, train loss: 1.2256529768672557, validation loss: 1.2563522950462673.
epoch: 1743, train loss: 1.2325374653579992, validation loss: 1.251605308574179.
epoch: 1744, train loss: 1.2252222496435183, validation loss: 1.2413827802823938.
epoch: 1745, train loss: 1.2260628227793842, validation loss: 1.2479612568150396.
epoch: 1746, train loss: 1.2297297431788314, validation loss: 1.253559314686319.
epoch: 1747, train loss: 1.224845137071172, validation loss: 1.2496536762818047.
epoch: 1748, train loss: 1.2224399551339107, validation loss: 1.2376587909200918.
epoch: 1749, train loss: 1.2227036701429874, validation loss: 1.2493120846541033.
epoch: 1750, train loss: 1.2452088649119806, validation loss: 1.2518559227819028.
epoch: 1751, train loss: 1.2322237557227458, validation loss: 1.2489849018013996.
epoch: 1752, train loss: 1.22442102104152, validation loss: 1.2344208489293638.
epoch: 1753, train loss: 1.2195745105043463, validation loss: 1.249120012573574.
epoch: 1754, train loss: 1.2201035821109736, validation loss: 1.2419998749442722.
epoch: 1755, train loss: 1.2232823809352489, validation loss: 1.2794878223667974.
epoch: 1756, train loss: 1.224183476299321, validation loss: 1.2492433527241582.
epoch: 1757, train loss: 1.2274365687589033, validation loss: 1.2458971376004426.
epoch: 1758, train loss: 1.2239928322100857, validation loss: 1.2409672944442085.
epoch: 1759, train loss: 1.2352151695741427, validation loss: 1.2765975827756135.
epoch: 1760, train loss: 1.2393255660293299, validation loss: 1.2388926329820051.
epoch: 1761, train loss: 1.2267381849638912, validation loss: 1.2431752474411675.
epoch: 1762, train loss: 1.2219157448602378, validation loss: 1.2519783092581707.
epoch: 1763, train loss: 1.2258938025990758, validation loss: 1.2588527047115823.
epoch: 1764, train loss: 1.2351927232304845, validation loss: 1.2479955839074177.
epoch: 1765, train loss: 1.2292220505005722, validation loss: 1.2481704794842263.
epoch: 1766, train loss: 1.22759877104278, validation loss: 1.2520957615064539.
epoch: 1767, train loss: 1.2242270664337578, validation loss: 1.2648115624552188.
epoch: 1768, train loss: 1.223941461755595, validation loss: 1.2439850672431614.
epoch: 1769, train loss: 1.2220211247785375, validation loss: 1.2456700179887854.
epoch: 1770, train loss: 1.2246712336846448, validation loss: 1.2401678406673928.
epoch: 1771, train loss: 1.2323844137541744, validation loss: 1.257037525591643.
epoch: 1772, train loss: 1.224808286089416, validation loss: 1.239926172339398.
epoch: 1773, train loss: 1.2216390054160302, validation loss: 1.2457099375517473.
epoch: 1774, train loss: 1.2227062500944925, validation loss: 1.2439960811449133.
epoch: 1775, train loss: 1.2199214029749599, validation loss: 1.2425008286600527.
epoch: 1776, train loss: 1.2214872651143904, validation loss: 1.2414795108463452.
epoch: 1777, train loss: 1.2230605411967006, validation loss: 1.2417294357133948.
epoch: 1778, train loss: 1.2203090322127037, validation loss: 1.2501646643099578.
epoch: 1779, train loss: 1.2291582986849163, validation loss: 1.2476315342861672.
epoch: 1780, train loss: 1.2210886751839873, validation loss: 1.2385657922081326.
epoch: 1781, train loss: 1.2207224598718345, validation loss: 1.2460975543312405.
epoch: 1782, train loss: 1.2297504046641359, validation loss: 1.2520250185676243.
epoch: 1783, train loss: 1.2256914202226412, validation loss: 1.2585048312726228.
epoch: 1784, train loss: 1.2307681774874346, validation loss: 1.2660033184549082.
epoch: 1785, train loss: 1.2264740576437854, validation loss: 1.25521807566933.
epoch: 1786, train loss: 1.2227890021210417, validation loss: 1.244789895804032.
epoch: 1787, train loss: 1.227865742980887, validation loss: 1.258540568144425.
epoch: 1788, train loss: 1.221578286328447, validation loss: 1.2484954025434412.
epoch: 1789, train loss: 1.2201717031111412, validation loss: 1.2715050344881804.
epoch: 1790, train loss: 1.223953921860511, validation loss: 1.2480693951897.
epoch: 1791, train loss: 1.222414721042738, validation loss: 1.246965387593145.
epoch: 1792, train loss: 1.2285907006045, validation loss: 1.2363257822783098.
epoch: 1793, train loss: 1.2190596827673257, validation loss: 1.2382916937703672.
epoch: 1794, train loss: 1.2223330790843439, validation loss: 1.247883905535159.
epoch: 1795, train loss: 1.225156560950323, validation loss: 1.2505310151887976.
epoch: 1796, train loss: 1.2212886493140405, validation loss: 1.2398199257643328.
epoch: 1797, train loss: 1.2248439165430332, validation loss: 1.2457203554070515.
epoch: 1798, train loss: 1.221842551450117, validation loss: 1.2387683650721675.
epoch: 1799, train loss: 1.2284653558643586, validation loss: 1.2428522576456484.
epoch: 1800, train loss: 1.2249709684914405, validation loss: 1.2477790583734927.
epoch: 1801, train loss: 1.2256994980190872, validation loss: 1.2774442900782046.
epoch: 1802, train loss: 1.2268667571041563, validation loss: 1.2454673051834106.
epoch: 1803, train loss: 1.2201974085711558, validation loss: 1.2620928442996482.
epoch: 1804, train loss: 1.2188839464012635, validation loss: 1.2415731523347937.
epoch: 1805, train loss: 1.2197712189560637, validation loss: 1.2593916343606038.
epoch: 1806, train loss: 1.2366934828801985, validation loss: 1.2583498902942822.
epoch: 1807, train loss: 1.2301343591935043, validation loss: 1.2500167255816252.
epoch: 1808, train loss: 1.2199484077068643, validation loss: 1.254478273184403.
epoch: 1809, train loss: 1.2269834903402066, validation loss: 1.24288184746452.
epoch: 1810, train loss: 1.2240131502851435, validation loss: 1.2536326180333677.
epoch: 1811, train loss: 1.22401338104808, validation loss: 1.2732883121656335.
epoch: 1812, train loss: 1.2306659145092746, validation loss: 1.294806806937508.
epoch: 1813, train loss: 1.2206469686753159, validation loss: 1.2549919615621152.
epoch: 1814, train loss: 1.233157246484669, validation loss: 1.2635352559711621.
epoch: 1815, train loss: 1.2242132031589472, validation loss: 1.2375731727351313.
epoch: 1816, train loss: 1.2322860321867357, validation loss: 1.2477110520653103.
epoch: 1817, train loss: 1.255941898450939, validation loss: 1.2557725854541943.
epoch: 1818, train loss: 1.236123790434741, validation loss: 1.2486252888389255.
epoch: 1819, train loss: 1.2282462459091747, validation loss: 1.2446232619492903.
epoch: 1820, train loss: 1.228170083203447, validation loss: 1.2414443907530412.
epoch: 1821, train loss: 1.2196226076248589, validation loss: 1.2541990176491116.
epoch: 1822, train loss: 1.224883553084977, validation loss: 1.2437632602194082.
epoch: 1823, train loss: 1.2233118135994727, validation loss: 1.241122048834096.
epoch: 1824, train loss: 1.220822324446582, validation loss: 1.2390860215477322.
epoch: 1825, train loss: 1.2295449895596287, validation loss: 1.245465408200803.
epoch: 1826, train loss: 1.2221607976003523, validation loss: 1.2494773709255715.
epoch: 1827, train loss: 1.2268258792544724, validation loss: 1.2432369201079658.
epoch: 1828, train loss: 1.2283101442757003, validation loss: 1.2482938455498738.
epoch: 1829, train loss: 1.2368175086625126, validation loss: 1.2508195275845735.
epoch: 1830, train loss: 1.2372142699880337, validation loss: 1.2532985210418701.
epoch: 1831, train loss: 1.2289528890487251, validation loss: 1.244503404783166.
epoch: 1832, train loss: 1.2279809177468677, validation loss: 1.2409394668496174.
epoch: 1833, train loss: 1.2256496411944748, validation loss: 1.2469397316808286.
epoch: 1834, train loss: 1.2233784045648137, validation loss: 1.251879826835964.
epoch: 1835, train loss: 1.2276779402286635, validation loss: 1.245706117671469.
epoch: 1836, train loss: 1.2266050883389394, validation loss: 1.2478581718776538.
epoch: 1837, train loss: 1.222920483405437, validation loss: 1.2503271102905273.
epoch: 1838, train loss: 1.2221260147357205, validation loss: 1.2379480444866677.
epoch: 1839, train loss: 1.2173206128111673, validation loss: 1.2444567732189014.
epoch: 1840, train loss: 1.2186737312089413, validation loss: 1.2540932375451792.
epoch: 1841, train loss: 1.232315203465453, validation loss: 1.245172205178634.
epoch: 1842, train loss: 1.2285494520029892, validation loss: 1.2441784143447876.
epoch: 1843, train loss: 1.22147060534276, validation loss: 1.2421299996583357.
epoch: 1844, train loss: 1.2228396977853337, validation loss: 1.2433504902798196.
epoch: 1845, train loss: 1.222676713532264, validation loss: 1.2593608368997988.
epoch: 1846, train loss: 1.235744421635199, validation loss: 1.2587784839713054.
epoch: 1847, train loss: 1.2311567713361267, validation loss: 1.2477208427760913.
epoch: 1848, train loss: 1.2362188724202847, validation loss: 1.2529226697009543.
epoch: 1849, train loss: 1.2266401216524456, validation loss: 1.2347621865894483.
epoch: 1850, train loss: 1.2248662316471064, validation loss: 1.2370653048805569.
epoch: 1851, train loss: 1.2179203963060992, validation loss: 1.2637448362682178.
epoch: 1852, train loss: 1.226003097831656, validation loss: 1.2413515733635945.
epoch: 1853, train loss: 1.2255750227411952, validation loss: 1.2653132055116736.
epoch: 1854, train loss: 1.2305264068306039, validation loss: 1.2462255021800166.
epoch: 1855, train loss: 1.2236520544104619, validation loss: 1.2465797248093977.
epoch: 1856, train loss: 1.2239826009907853, validation loss: 1.2548054301220437.
epoch: 1857, train loss: 1.2308947001028498, validation loss: 1.2347826750382134.
epoch: 1858, train loss: 1.2260515908582494, validation loss: 1.2496968766917353.
epoch: 1859, train loss: 1.2209792126209364, validation loss: 1.2370838134185127.
epoch: 1860, train loss: 1.227961307271905, validation loss: 1.2544618430344954.
epoch: 1861, train loss: 1.235025765698984, validation loss: 1.2452721543934033.
epoch: 1862, train loss: 1.2201711595605274, validation loss: 1.2388184277907661.
epoch: 1863, train loss: 1.2298821363974055, validation loss: 1.2374259544455486.
epoch: 1864, train loss: 1.2188683781055136, validation loss: 1.245293871216152.
epoch: 1865, train loss: 1.2297812897130984, validation loss: 1.2389758721641873.
epoch: 1866, train loss: 1.2234502910474025, validation loss: 1.2459185278933982.
epoch: 1867, train loss: 1.2275155312424406, validation loss: 1.2389434057733286.
epoch: 1868, train loss: 1.2199717738212796, validation loss: 1.2499469829642254.
epoch: 1869, train loss: 1.2450131845036778, validation loss: 1.250637349875077.
epoch: 1870, train loss: 1.2321963813326775, validation loss: 1.273770378983539.
epoch: 1871, train loss: 1.2314319446546222, validation loss: 1.2563576283662214.
epoch: 1872, train loss: 1.2234318726653353, validation loss: 1.2528027658877166.
epoch: 1873, train loss: 1.2248033394507312, validation loss: 1.2441548731016077.
epoch: 1874, train loss: 1.2259286849870594, validation loss: 1.2474603341973347.
epoch: 1875, train loss: 1.2198808521305748, validation loss: 1.281342889951623.
epoch: 1876, train loss: 1.2250380570735406, validation loss: 1.2437595906464949.
epoch: 1877, train loss: 1.2219836219735103, validation loss: 1.2406844470811926.
epoch: 1878, train loss: 1.224585597668219, validation loss: 1.2400101371433423.
epoch: 1879, train loss: 1.221883832861524, validation loss: 1.246525095856708.
epoch: 1880, train loss: 1.226587451926065, validation loss: 1.251592376957769.
epoch: 1881, train loss: 1.2286137604932172, validation loss: 1.234929364660512.
epoch: 1882, train loss: 1.2234993057513455, validation loss: 1.2426601337349934.
epoch: 1883, train loss: 1.2192137810068393, validation loss: 1.2601332146188486.
epoch: 1884, train loss: 1.2286796340154946, validation loss: 1.2585723762926848.
epoch: 1885, train loss: 1.2309901747134848, validation loss: 1.2429644698682039.
epoch: 1886, train loss: 1.2206289440120033, validation loss: 1.2353756375934766.
epoch: 1887, train loss: 1.218875871885807, validation loss: 1.2414189317952031.
epoch: 1888, train loss: 1.2360076335592007, validation loss: 1.2408757779909216.
epoch: 1889, train loss: 1.223017972543699, validation loss: 1.2458338115526282.
epoch: 1890, train loss: 1.2241261552233216, validation loss: 1.2461129167805547.
epoch: 1891, train loss: 1.2251125388189192, validation loss: 1.250776187233303.
epoch: 1892, train loss: 1.221091163267783, validation loss: 1.2374227150626804.
epoch: 1893, train loss: 1.2289229139275508, validation loss: 1.2714852042820142.
epoch: 1894, train loss: 1.2261650092011198, validation loss: 1.253616504047228.
epoch: 1895, train loss: 1.2256001255927829, validation loss: 1.2547517652096956.
epoch: 1896, train loss: 1.2233623178727036, validation loss: 1.243769697521044.
epoch: 1897, train loss: 1.227408453958844, validation loss: 1.2468188534612241.
epoch: 1898, train loss: 1.2266165346180626, validation loss: 1.2440699494403342.
epoch: 1899, train loss: 1.2269866860240972, validation loss: 1.2525687321372654.
epoch: 1900, train loss: 1.222716254925509, validation loss: 1.2403520708498748.
epoch: 1901, train loss: 1.2260863616925861, validation loss: 1.2361730388973071.
epoch: 1902, train loss: 1.2355401581580485, validation loss: 1.2348978312119194.
epoch: 1903, train loss: 1.2211222418951333, validation loss: 1.2329163395840188.
epoch: 1904, train loss: 1.2211737348399032, validation loss: 1.2672752401103144.
epoch: 1905, train loss: 1.289665572140195, validation loss: 1.3491595050562983.
epoch: 1906, train loss: 1.3098031807383266, validation loss: 1.3007518208545188.
epoch: 1907, train loss: 1.2874431774156903, validation loss: 1.2895995948625647.
epoch: 1908, train loss: 1.2791495399737576, validation loss: 1.283102237659952.
epoch: 1909, train loss: 1.2758990537135972, validation loss: 1.2888641512912253.
epoch: 1910, train loss: 1.2730163313926908, validation loss: 1.2786874667457913.
epoch: 1911, train loss: 1.2670787682227038, validation loss: 1.2766436234764431.
epoch: 1912, train loss: 1.2630523618208158, validation loss: 1.2753842550775278.
epoch: 1913, train loss: 1.2614911619676363, validation loss: 1.2687154697335286.
epoch: 1914, train loss: 1.2605461549321446, validation loss: 1.2726616496625154.
epoch: 1915, train loss: 1.259051245286924, validation loss: 1.2661009923271511.
epoch: 1916, train loss: 1.2555968017753112, validation loss: 1.2616817173750505.
epoch: 1917, train loss: 1.2522019071316501, validation loss: 1.2607930639515752.
epoch: 1918, train loss: 1.249037308430453, validation loss: 1.2524011808892954.
epoch: 1919, train loss: 1.247817356652076, validation loss: 1.252075713613759.
epoch: 1920, train loss: 1.2409417312079614, validation loss: 1.255865470222805.
epoch: 1921, train loss: 1.2400155909564516, validation loss: 1.2409017293349556.
epoch: 1922, train loss: 1.2394277480764126, validation loss: 1.2443334019702414.
epoch: 1923, train loss: 1.2615434828154537, validation loss: 1.2608941793441772.
epoch: 1924, train loss: 1.2464202423708155, validation loss: 1.2502089376034944.
epoch: 1925, train loss: 1.240034549608143, validation loss: 1.2508131680281267.
epoch: 1926, train loss: 1.2383694101911071, validation loss: 1.2495464708494104.
epoch: 1927, train loss: 1.2360502612700157, validation loss: 1.2466120097948157.
epoch: 1928, train loss: 1.232469408883961, validation loss: 1.2444260120391846.
epoch: 1929, train loss: 1.2338410692477444, validation loss: 1.247214395066966.
epoch: 1930, train loss: 1.23501571055946, validation loss: 1.24752574381621.
epoch: 1931, train loss: 1.2340711125540078, validation loss: 1.2458035790401956.
epoch: 1932, train loss: 1.234067482685824, validation loss: 1.2485849183538686.
epoch: 1933, train loss: 1.2398799548455335, validation loss: 1.2466983639675637.
epoch: 1934, train loss: 1.2324043763886898, validation loss: 1.2423871289128843.
epoch: 1935, train loss: 1.2320701332267272, validation loss: 1.25078458889671.
epoch: 1936, train loss: 1.2305843884791803, validation loss: 1.239885874416517.
epoch: 1937, train loss: 1.2285660199069102, validation loss: 1.2531560452088066.
epoch: 1938, train loss: 1.2313573010470888, validation loss: 1.2396233600118887.
epoch: 1939, train loss: 1.2273890556545433, validation loss: 1.2436317309089329.
epoch: 1940, train loss: 1.2325293317847295, validation loss: 1.244540530702342.
epoch: 1941, train loss: 1.2447701889440554, validation loss: 1.2534404319265615.
epoch: 1942, train loss: 1.23656084778112, validation loss: 1.2472657742707625.
epoch: 1943, train loss: 1.2324645420826903, validation loss: 1.244421212569527.
epoch: 1944, train loss: 1.2312488949626959, validation loss: 1.2385207518287327.
epoch: 1945, train loss: 1.2279892503668408, validation loss: 1.2736578454142031.
epoch: 1946, train loss: 1.2373512327124219, validation loss: 1.24707976113195.
epoch: 1947, train loss: 1.2311692401903485, validation loss: 1.2858045412146526.
epoch: 1948, train loss: 1.2357939842644088, validation loss: 1.2512327277142068.
epoch: 1949, train loss: 1.2305648961198439, validation loss: 1.2843146790628848.
epoch: 1950, train loss: 1.241083813369821, validation loss: 1.2408363663631936.
epoch: 1951, train loss: 1.227890641317455, validation loss: 1.23674868500751.
epoch: 1952, train loss: 1.23173295904737, validation loss: 1.2606042623519897.
epoch: 1953, train loss: 1.2320719454266609, validation loss: 1.2571178208226743.
epoch: 1954, train loss: 1.2378356642679338, validation loss: 1.2506400191265603.
epoch: 1955, train loss: 1.2308330721811418, validation loss: 1.243975737820501.
epoch: 1956, train loss: 1.2376765931418183, validation loss: 1.2503076066141543.
epoch: 1957, train loss: 1.231828772693599, validation loss: 1.2403544861337412.
epoch: 1958, train loss: 1.2260167686217422, validation loss: 1.2449472468832266.
epoch: 1959, train loss: 1.2258242773353507, validation loss: 1.241944618847059.
epoch: 1960, train loss: 1.2336304319014244, validation loss: 1.2432422378788823.
epoch: 1961, train loss: 1.227213783001681, validation loss: 1.2645034530888433.
epoch: 1962, train loss: 1.2306000048961114, validation loss: 1.2485255106635715.
epoch: 1963, train loss: 1.2262079431376327, validation loss: 1.2530554481174634.
epoch: 1964, train loss: 1.2278981679076448, validation loss: 1.2521860081216563.
epoch: 1965, train loss: 1.2333055286232484, validation loss: 1.2441881584084553.
epoch: 1966, train loss: 1.2300350819158992, validation loss: 1.2419142878573874.
epoch: 1967, train loss: 1.228845239779271, validation loss: 1.2495496584021526.
epoch: 1968, train loss: 1.230154820538442, validation loss: 1.2444744835729185.
epoch: 1969, train loss: 1.2245621932755917, validation loss: 1.267752916916557.
epoch: 1970, train loss: 1.2336890883401994, validation loss: 1.255002296489218.
epoch: 1971, train loss: 1.2288502334454738, validation loss: 1.2587106953496519.
epoch: 1972, train loss: 1.2294320382109476, validation loss: 1.2444167137145996.
epoch: 1973, train loss: 1.228630436669796, validation loss: 1.2407276578571484.
epoch: 1974, train loss: 1.2274149087590909, validation loss: 1.2423108867976977.
epoch: 1975, train loss: 1.2238991719867112, validation loss: 1.2409385961035024.
epoch: 1976, train loss: 1.226901126564096, validation loss: 1.2427648098572441.
epoch: 1977, train loss: 1.2288457297403879, validation loss: 1.242959623751433.
epoch: 1978, train loss: 1.225584795715612, validation loss: 1.24582098359647.
epoch: 1979, train loss: 1.2281014536498884, validation loss: 1.245951823566271.
epoch: 1980, train loss: 1.227449185257658, validation loss: 1.2374387824017068.
epoch: 1981, train loss: 1.232039900001036, validation loss: 1.254535286322884.
epoch: 1982, train loss: 1.2285660122512678, validation loss: 1.2392029917758445.
epoch: 1983, train loss: 1.2276873621371909, validation loss: 1.2536097816799.
epoch: 1984, train loss: 1.2263737009205948, validation loss: 1.238723848177039.
epoch: 1985, train loss: 1.2258427996154224, validation loss: 1.2531940522401228.
epoch: 1986, train loss: 1.2354100931675063, validation loss: 1.2513936343400374.
epoch: 1987, train loss: 1.2290441158714644, validation loss: 1.2443559273429539.
epoch: 1988, train loss: 1.227358816960536, validation loss: 1.2350497867750085.
epoch: 1989, train loss: 1.2261291632958509, validation loss: 1.23651689550151.
epoch: 1990, train loss: 1.223133043411675, validation loss: 1.24632656055948.
epoch: 1991, train loss: 1.220447491068359, validation loss: 1.2410703171854434.
epoch: 1992, train loss: 1.2248255517504631, validation loss: 1.2703628280888433.
epoch: 1993, train loss: 1.233558263253728, validation loss: 1.240129398263019.
epoch: 1994, train loss: 1.2251124382019043, validation loss: 1.2458913067112798.
epoch: 1995, train loss: 1.2200035523930821, validation loss: 1.2439484129781309.
epoch: 1996, train loss: 1.2359837862329746, validation loss: 1.2525694629420405.
epoch: 1997, train loss: 1.2246478599145871, validation loss: 1.2443042319753896.
epoch: 1998, train loss: 1.2237864459326508, validation loss: 1.245214783627054.
epoch: 1999, train loss: 1.2224807608018227, validation loss: 1.238146134044813.
epoch: 2000, train loss: 1.2194864520239175, validation loss: 1.2400802425716235.
best validation loss 0.5209999784179355 at epoch 196.
