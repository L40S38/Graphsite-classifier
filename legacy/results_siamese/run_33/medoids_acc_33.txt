how to merge clusters:  [[0, 9], [1, 5], 2, [3, 8], 4, 6, 7]
computing evaluation metrics for train
embedding path:  ../embeddings/run_33/train_embedding.npy
label path:  ../embeddings/run_33/train_label.npy
{} report:  train
              precision    recall  f1-score   support

           0       0.87      0.73      0.79      4597
           1       0.51      0.44      0.47      1699
           2       0.84      0.84      0.84       810
           3       0.40      0.54      0.46      1373
           4       0.66      0.88      0.75       737
           5       0.79      0.93      0.85       677
           6       0.66      0.82      0.73       634

    accuracy                           0.69     10527
   macro avg       0.67      0.74      0.70     10527
weighted avg       0.72      0.69      0.70     10527

top-3 train acc: 0.9566828156169849
----------------------------------------------------------
computing evaluation metrics for val
embedding path:  ../embeddings/run_33/val_embedding.npy
label path:  ../embeddings/run_33/val_label.npy
{} report:  val
              precision    recall  f1-score   support

           0       0.84      0.73      0.78       985
           1       0.51      0.41      0.45       364
           2       0.82      0.82      0.82       173
           3       0.38      0.49      0.43       294
           4       0.66      0.84      0.74       158
           5       0.78      0.93      0.85       145
           6       0.66      0.87      0.75       135

    accuracy                           0.68      2254
   macro avg       0.66      0.73      0.69      2254
weighted avg       0.70      0.68      0.69      2254

top-3 val acc: 0.958740017746229
----------------------------------------------------------
computing evaluation metrics for test
embedding path:  ../embeddings/run_33/test_embedding.npy
label path:  ../embeddings/run_33/test_label.npy
{} report:  test
              precision    recall  f1-score   support

           0       0.87      0.73      0.79       986
           1       0.50      0.42      0.45       365
           2       0.81      0.81      0.81       175
           3       0.39      0.56      0.46       295
           4       0.72      0.87      0.79       159
           5       0.77      0.92      0.84       146
           6       0.65      0.82      0.72       137

    accuracy                           0.69      2263
   macro avg       0.67      0.73      0.70      2263
weighted avg       0.71      0.69      0.70      2263

top-3 test acc: 0.9580203269995581
----------------------------------------------------------
