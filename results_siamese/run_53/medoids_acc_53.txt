computing evaluation metrics for train
embedding path:  ../embeddings/run_53/train_embedding.npy
label path:  ../embeddings/run_53/train_label.npy
{} report:  train
              precision    recall  f1-score   support

           0       0.98      0.94      0.96      5074
           1       0.65      0.68      0.67      2200
           2       0.92      0.84      0.88       810
           3       0.79      0.74      0.76      1840
           4       0.82      0.64      0.72       737
           5       0.81      0.87      0.84       677
           6       0.51      0.78      0.61       634
           7       0.43      0.48      0.45       500

    accuracy                           0.81     12472
   macro avg       0.74      0.75      0.74     12472
weighted avg       0.83      0.81      0.82     12472

top-3 train acc: 0.9584669660038486
----------------------------------------------------------
computing evaluation metrics for val
embedding path:  ../embeddings/run_53/val_embedding.npy
label path:  ../embeddings/run_53/val_label.npy
{} report:  val
              precision    recall  f1-score   support

           0       0.92      0.87      0.89      1087
           1       0.57      0.59      0.58       471
           2       0.76      0.76      0.76       173
           3       0.71      0.65      0.68       394
           4       0.79      0.68      0.73       158
           5       0.77      0.75      0.76       145
           6       0.43      0.69      0.53       135
           7       0.25      0.31      0.28       105

    accuracy                           0.73      2668
   macro avg       0.65      0.66      0.65      2668
weighted avg       0.75      0.73      0.74      2668

top-3 val acc: 0.9081709145427287
----------------------------------------------------------
computing evaluation metrics for test
embedding path:  ../embeddings/run_53/test_embedding.npy
label path:  ../embeddings/run_53/test_label.npy
{} report:  test
              precision    recall  f1-score   support

           0       0.91      0.85      0.88      1088
           1       0.53      0.56      0.54       472
           2       0.84      0.75      0.79       175
           3       0.66      0.62      0.64       395
           4       0.79      0.63      0.70       159
           5       0.79      0.82      0.81       146
           6       0.44      0.69      0.54       137
           7       0.27      0.34      0.30       108

    accuracy                           0.72      2680
   macro avg       0.65      0.66      0.65      2680
weighted avg       0.74      0.72      0.72      2680

top-3 test acc: 0.9014925373134328
----------------------------------------------------------
