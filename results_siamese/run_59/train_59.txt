seed:  666
number of classes (from original clusters): 24
how to merge clusters:  [[0, 9, 12], [1, 5, 11], 2, [3, 8, 13], 4, 6, 7, [10, 16], 15, 17, 18, 19, 20, 21, 22, 23]
whether to further subcluster data according to chemical reaction: False
positive training pair sampling threshold:  16000
negative training pair sampling threshold:  4500
number of epochs to train: 40
learning rate decay to half at epoch 25.
batch size: 256
similar margin of contrastive loss: 0.0
dissimilar margin of contrastive loss: 2.0
number of workers to load data:  36
device:  cuda
number of gpus:  2
features to use:  ['r', 'theta', 'phi', 'sasa', 'charge', 'hydrophobicity', 'binding_probability', 'sequence_entropy']
number of classes after merging:  16
number of pockets in training set:  15714
number of pockets in validation set:  3361
number of pockets in test set:  3382
first 5 pockets in train set of cluster 0 before merging (to verify reproducibility):
['6brxA00', '4c0lA00', '3rs8A02', '4nk4F00', '5fogD00']
number of train positive pairs: 256000
number of train negative pairs: 540000
model architecture:
ResidualSiameseNet(
  (embedding_net): ResidualEmbeddingNet(
    (conv1): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=8, out_features=64, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=64, out_features=64, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=8, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (rb_2): ResidualBlock(
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=64, out_features=64, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=64, out_features=64, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=64, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (rb_3): ResidualBlock(
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=64, out_features=64, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=64, out_features=64, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=64, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (rb_4): ResidualBlock(
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=64, out_features=64, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=64, out_features=64, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=64, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (rb_5): ResidualBlock(
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=64, out_features=64, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=64, out_features=64, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=64, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (rb_6): ResidualBlock(
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=64, out_features=64, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=64, out_features=64, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=64, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (rb_7): ResidualBlock(
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=64, out_features=64, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=64, out_features=64, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=64, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (rb_8): ResidualBlock(
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=64, out_features=64, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=64, out_features=64, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=64, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (bn_8): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (set2set): Set2Set(64, 128)
  )
)
optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.003
    weight_decay: 0.0005
)
loss function:
ContrastiveLoss(similar_margin=0.0, dissimilar_margin=2.0, normalize=True, mean=True)
epoch: 1, train loss: 0.6769690096294461, train acc: 0.7422680412371134, validation acc: 0.635525141326986.
epoch: 2, train loss: 0.5901155026306459, train acc: 0.753913707521955, validation acc: 0.6584349895864327.
epoch: 3, train loss: 0.5595940048658669, train acc: 0.751304569173985, validation acc: 0.648318952692651.
epoch: 4, train loss: 0.5422494205685716, train acc: 0.7498409061982945, validation acc: 0.6364177328176138.
epoch: 5, train loss: 0.5299512539676685, train acc: 0.752640957108311, validation acc: 0.648318952692651.
epoch: 6, train loss: 0.5190169058085686, train acc: 0.7540409825633193, validation acc: 0.6393930377863731.
epoch: 7, train loss: 0.513621188187719, train acc: 0.7703321878579611, validation acc: 0.6593275810770604.
epoch: 8, train loss: 0.5068411882582622, train acc: 0.738513427516864, validation acc: 0.6301695923832192.
epoch: 9, train loss: 0.5022429227493516, train acc: 0.7705867379406899, validation acc: 0.6480214221957751.
epoch: 10, train loss: 0.4992382589560657, train acc: 0.750668193967163, validation acc: 0.6316572448675989.
epoch: 11, train loss: 0.5001880187892435, train acc: 0.7592592592592593, validation acc: 0.6501041356739066.
epoch: 12, train loss: 0.4953086664784494, train acc: 0.7462135675194095, validation acc: 0.6268967569175841.
epoch: 13, train loss: 0.4904028387788552, train acc: 0.7586228840524373, validation acc: 0.6328473668551027.
epoch: 14, train loss: 0.4884078348533592, train acc: 0.7633956981036019, validation acc: 0.6343350193394823.
epoch: 15, train loss: 0.4861979494430312, train acc: 0.7418862161130202, validation acc: 0.6224337994644451.
epoch: 16, train loss: 0.4839328340597488, train acc: 0.7626956853760978, validation acc: 0.6221362689675691.
epoch: 17, train loss: 0.4833116068911912, train acc: 0.7456408298332697, validation acc: 0.6191609639988099.
epoch: 18, train loss: 0.4798287698084386, train acc: 0.7607229222349497, validation acc: 0.6316572448675989.
epoch: 19, train loss: 0.48018991784713977, train acc: 0.7602138220694922, validation acc: 0.6373103243082416.
epoch: 20, train loss: 0.47614360971307035, train acc: 0.7342497136311569, validation acc: 0.6084498661112764.
epoch: 21, train loss: 0.47538296739779523, train acc: 0.7495227185948835, validation acc: 0.6283844094019637.
epoch: 22, train loss: 0.47497976426742783, train acc: 0.7573501336387934, validation acc: 0.6307646533769712.
epoch: 23, train loss: 0.4748146909972531, train acc: 0.768995799923635, validation acc: 0.6343350193394823.
epoch: 24, train loss: 0.4721569659458333, train acc: 0.7483136057019218, validation acc: 0.6111276405831598.
epoch: 25, train loss: 0.430710111618042, train acc: 0.7807051037291587, validation acc: 0.6349300803332342.
epoch: 26, train loss: 0.42450874093788954, train acc: 0.7736413389334351, validation acc: 0.6173757810175543.
epoch: 27, train loss: 0.4217370094797719, train acc: 0.7711594756268296, validation acc: 0.6206486164831895.
epoch: 28, train loss: 0.41911332165895393, train acc: 0.7666412116583938, validation acc: 0.6170782505206783.
epoch: 29, train loss: 0.4149915138608846, train acc: 0.772941326205931, validation acc: 0.6105325795894079.
epoch: 30, train loss: 0.4126859920731741, train acc: 0.777205040091638, validation acc: 0.6158881285331747.
epoch: 31, train loss: 0.41135632717190074, train acc: 0.7809596538118875, validation acc: 0.6248140434394526.
epoch: 32, train loss: 0.4103646620170555, train acc: 0.7798778159602902, validation acc: 0.6307646533769712.
epoch: 33, train loss: 0.4081059853826935, train acc: 0.7775868652157312, validation acc: 0.6170782505206783.
epoch: 34, train loss: 0.4071172313594339, train acc: 0.7848415425735014, validation acc: 0.631359714370723.
epoch: 35, train loss: 0.4100198320455887, train acc: 0.7724322260404735, validation acc: 0.6173757810175543.
epoch: 36, train loss: 0.4055126773316656, train acc: 0.7811505663739341, validation acc: 0.6289794703957156.
epoch: 37, train loss: 0.4045848655317297, train acc: 0.7804505536464299, validation acc: 0.6292770008925915.
epoch: 38, train loss: 0.41735384340142484, train acc: 0.7793050782741504, validation acc: 0.6123177625706635.
epoch: 39, train loss: 0.40323537497784023, train acc: 0.7868779432353316, validation acc: 0.6331448973519785.
epoch: 40, train loss: 0.4006142303236765, train acc: 0.7773323151330024, validation acc: 0.6123177625706635.
best validation acc 0.6593275810770604 at epoch 7.
