computing evaluation metrics for train
embedding path:  ../embeddings/run_49/train_embedding.npy
label path:  ../embeddings/run_49/train_label.npy
{} report:  train
              precision    recall  f1-score   support

           0       0.93      0.90      0.92      5074
           1       0.58      0.59      0.59      2200
           2       0.96      0.97      0.97       810
           3       0.65      0.63      0.64      1840
           4       0.95      0.97      0.96       737
           5       0.95      0.99      0.97       677
           6       0.81      0.98      0.89       634
           7       0.88      0.97      0.92       500

    accuracy                           0.82     12472
   macro avg       0.84      0.88      0.86     12472
weighted avg       0.83      0.82      0.82     12472

top-3 train acc: 0.9834028223220013
----------------------------------------------------------
computing evaluation metrics for val
embedding path:  ../embeddings/run_49/val_embedding.npy
label path:  ../embeddings/run_49/val_label.npy
{} report:  val
              precision    recall  f1-score   support

           0       0.88      0.85      0.87      1087
           1       0.48      0.54      0.51       471
           2       0.83      0.80      0.82       173
           3       0.60      0.54      0.57       394
           4       0.76      0.77      0.76       158
           5       0.84      0.91      0.87       145
           6       0.65      0.76      0.70       135
           7       0.62      0.50      0.55       105

    accuracy                           0.73      2668
   macro avg       0.71      0.71      0.71      2668
weighted avg       0.73      0.73      0.73      2668

top-3 val acc: 0.9257871064467766
----------------------------------------------------------
computing evaluation metrics for test
embedding path:  ../embeddings/run_49/test_embedding.npy
label path:  ../embeddings/run_49/test_label.npy
{} report:  test
              precision    recall  f1-score   support

           0       0.89      0.86      0.88      1088
           1       0.47      0.49      0.48       472
           2       0.85      0.82      0.84       175
           3       0.58      0.59      0.59       395
           4       0.83      0.75      0.79       159
           5       0.84      0.90      0.87       146
           6       0.63      0.78      0.69       137
           7       0.50      0.44      0.47       108

    accuracy                           0.73      2680
   macro avg       0.70      0.71      0.70      2680
weighted avg       0.73      0.73      0.73      2680

top-3 test acc: 0.9257462686567164
----------------------------------------------------------
