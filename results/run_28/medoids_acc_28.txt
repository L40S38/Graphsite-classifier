how to merge clusters:  [[0, 9], [1, 5], 2, [3, 8], 4, 6, 7]
computing evaluation metrics for train
embedding path:  ../embeddings/run_28/train_embedding.npy
label path:  ../embeddings/run_28/train_label.npy
{} report:  train
              precision    recall  f1-score   support

           0       0.92      0.81      0.86      4597
           1       0.49      0.60      0.54      1699
           2       0.92      0.93      0.93       810
           3       0.65      0.65      0.65      1373
           4       0.92      0.89      0.90       737
           5       0.91      0.96      0.94       677
           6       0.72      0.91      0.80       634

    accuracy                           0.78     10527
   macro avg       0.79      0.82      0.80     10527
weighted avg       0.80      0.78      0.79     10527

top-3 train acc: 
----------------------------------------------------------
computing evaluation metrics for val
embedding path:  ../embeddings/run_28/val_embedding.npy
label path:  ../embeddings/run_28/val_label.npy
{} report:  val
              precision    recall  f1-score   support

           0       0.92      0.83      0.87       985
           1       0.51      0.57      0.54       364
           2       0.92      0.90      0.91       173
           3       0.65      0.66      0.65       294
           4       0.91      0.91      0.91       158
           5       0.91      0.95      0.93       145
           6       0.74      0.97      0.84       135

    accuracy                           0.79      2254
   macro avg       0.79      0.83      0.81      2254
weighted avg       0.81      0.79      0.80      2254

top-3 val acc: 
----------------------------------------------------------
computing evaluation metrics for test
embedding path:  ../embeddings/run_28/test_embedding.npy
label path:  ../embeddings/run_28/test_label.npy
{} report:  test
              precision    recall  f1-score   support

           0       0.93      0.82      0.87       986
           1       0.49      0.61      0.55       365
           2       0.92      0.89      0.91       175
           3       0.68      0.63      0.65       295
           4       0.90      0.93      0.91       159
           5       0.88      0.97      0.92       146
           6       0.69      0.91      0.78       137

    accuracy                           0.79      2263
   macro avg       0.79      0.82      0.80      2263
weighted avg       0.81      0.79      0.79      2263

top-3 test acc: 
----------------------------------------------------------
