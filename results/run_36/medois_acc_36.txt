how to merge clusters:  [[0, 9], [1, 5], 2, [3, 8], 4, 6, 7]
computing evaluation metrics for train
embedding path:  ../embeddings/run_36/train_embedding.npy
label path:  ../embeddings/run_36/train_label.npy
{} report:  train
              precision    recall  f1-score   support

           0       0.89      0.87      0.88      4597
           1       0.54      0.46      0.50      1699
           2       0.89      0.88      0.89       810
           3       0.53      0.55      0.54      1373
           4       0.85      0.87      0.86       737
           5       0.84      0.96      0.90       677
           6       0.71      0.88      0.78       634

    accuracy                           0.77     10527
   macro avg       0.75      0.78      0.76     10527
weighted avg       0.77      0.77      0.77     10527

top-3 train acc: 0.9677970931889427
----------------------------------------------------------
computing evaluation metrics for val
embedding path:  ../embeddings/run_36/val_embedding.npy
label path:  ../embeddings/run_36/val_label.npy
{} report:  val
              precision    recall  f1-score   support

           0       0.90      0.88      0.89       985
           1       0.55      0.47      0.51       364
           2       0.85      0.87      0.86       173
           3       0.51      0.56      0.54       294
           4       0.85      0.83      0.84       158
           5       0.86      0.97      0.91       145
           6       0.70      0.87      0.78       135

    accuracy                           0.77      2254
   macro avg       0.75      0.78      0.76      2254
weighted avg       0.77      0.77      0.77      2254

top-3 val acc: 0.9631765749778172
----------------------------------------------------------
computing evaluation metrics for test
embedding path:  ../embeddings/run_36/test_embedding.npy
label path:  ../embeddings/run_36/test_label.npy
{} report:  test
              precision    recall  f1-score   support

           0       0.88      0.86      0.87       986
           1       0.48      0.40      0.44       365
           2       0.92      0.89      0.90       175
           3       0.52      0.56      0.54       295
           4       0.77      0.84      0.80       159
           5       0.84      0.95      0.89       146
           6       0.69      0.86      0.76       137

    accuracy                           0.75      2263
   macro avg       0.73      0.77      0.74      2263
weighted avg       0.75      0.75      0.75      2263

top-3 test acc: 0.965974370304905
----------------------------------------------------------
