how to merge clusters:  [[0, 9], [1, 5], 2, [3, 8], 4, 6, 7]
computing evaluation metrics for train
embedding path:  ../embeddings/run_31/train_embedding.npy
label path:  ../embeddings/run_31/train_label.npy
{} report:  train
              precision    recall  f1-score   support

           0       0.91      0.71      0.79      4597
           1       0.45      0.49      0.47      1699
           2       0.86      0.86      0.86       810
           3       0.46      0.57      0.51      1373
           4       0.72      0.87      0.79       737
           5       0.84      0.92      0.88       677
           6       0.58      0.86      0.69       634

    accuracy                           0.70     10527
   macro avg       0.69      0.75      0.71     10527
weighted avg       0.73      0.70      0.71     10527

top-3 train acc: 0.9543079699819512
----------------------------------------------------------
computing evaluation metrics for val
embedding path:  ../embeddings/run_31/val_embedding.npy
label path:  ../embeddings/run_31/val_label.npy
{} report:  val
              precision    recall  f1-score   support

           0       0.90      0.69      0.79       985
           1       0.47      0.53      0.50       364
           2       0.86      0.87      0.86       173
           3       0.43      0.54      0.48       294
           4       0.71      0.91      0.80       158
           5       0.86      0.94      0.89       145
           6       0.64      0.86      0.73       135

    accuracy                           0.70      2254
   macro avg       0.70      0.76      0.72      2254
weighted avg       0.74      0.70      0.71      2254

top-3 val acc: 0.95075421472937
----------------------------------------------------------
computing evaluation metrics for test
embedding path:  ../embeddings/run_31/test_embedding.npy
label path:  ../embeddings/run_31/test_label.npy
{} report:  test
              precision    recall  f1-score   support

           0       0.91      0.72      0.80       986
           1       0.49      0.55      0.51       365
           2       0.89      0.89      0.89       175
           3       0.50      0.62      0.55       295
           4       0.69      0.86      0.77       159
           5       0.89      0.92      0.91       146
           6       0.62      0.86      0.72       137

    accuracy                           0.72      2263
   macro avg       0.71      0.77      0.74      2263
weighted avg       0.75      0.72      0.73      2263

top-3 test acc: 0.9558108705258507
----------------------------------------------------------
