how to merge clusters:  [[0, 9], [1, 5], 2, [3, 8], 4, 6, 7]
computing evaluation metrics for train
embedding path:  ../embeddings/run_30/train_embedding.npy
label path:  ../embeddings/run_30/train_label.npy
{} report:  train
              precision    recall  f1-score   support

           0       0.92      0.75      0.83      4597
           1       0.41      0.48      0.44      1699
           2       0.88      0.95      0.91       810
           3       0.55      0.68      0.61      1373
           4       0.88      0.92      0.90       737
           5       0.91      0.94      0.92       677
           6       0.76      0.90      0.82       634

    accuracy                           0.74     10527
   macro avg       0.76      0.80      0.78     10527
weighted avg       0.77      0.74      0.75     10527

top-3 train acc: 0.9755865868718533
----------------------------------------------------------
computing evaluation metrics for val
embedding path:  ../embeddings/run_30/val_embedding.npy
label path:  ../embeddings/run_30/val_label.npy
{} report:  val
              precision    recall  f1-score   support

           0       0.93      0.72      0.81       985
           1       0.40      0.47      0.43       364
           2       0.87      0.94      0.90       173
           3       0.53      0.73      0.62       294
           4       0.87      0.94      0.90       158
           5       0.94      0.96      0.95       145
           6       0.78      0.90      0.83       135

    accuracy                           0.74      2254
   macro avg       0.76      0.81      0.78      2254
weighted avg       0.77      0.74      0.75      2254

top-3 val acc: 0.9720496894409938
----------------------------------------------------------
computing evaluation metrics for test
embedding path:  ../embeddings/run_30/test_embedding.npy
label path:  ../embeddings/run_30/test_label.npy
{} report:  test
              precision    recall  f1-score   support

           0       0.93      0.72      0.81       986
           1       0.39      0.49      0.44       365
           2       0.85      0.96      0.90       175
           3       0.52      0.66      0.58       295
           4       0.87      0.91      0.89       159
           5       0.95      0.94      0.94       146
           6       0.73      0.91      0.81       137

    accuracy                           0.73      2263
   macro avg       0.75      0.80      0.77      2263
weighted avg       0.77      0.73      0.74      2263

top-3 test acc: 0.9717189571365444
----------------------------------------------------------
