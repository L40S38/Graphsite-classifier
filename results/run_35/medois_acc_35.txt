how to merge clusters:  [[0, 9], [1, 5], 2, [3, 8], 4, 6, 7]
computing evaluation metrics for train
embedding path:  ../embeddings/run_35/train_embedding.npy
label path:  ../embeddings/run_35/train_label.npy
{} report:  train
              precision    recall  f1-score   support

           0       0.93      0.83      0.88      4597
           1       0.55      0.64      0.59      1699
           2       0.94      0.93      0.93       810
           3       0.70      0.74      0.72      1373
           4       0.94      0.93      0.93       737
           5       0.93      0.95      0.94       677
           6       0.75      0.92      0.83       634

    accuracy                           0.82     10527
   macro avg       0.82      0.85      0.83     10527
weighted avg       0.83      0.82      0.82     10527

top-3 train acc: 0.9747316424432412
----------------------------------------------------------
computing evaluation metrics for val
embedding path:  ../embeddings/run_35/val_embedding.npy
label path:  ../embeddings/run_35/val_label.npy
{} report:  val
              precision    recall  f1-score   support

           0       0.94      0.83      0.88       985
           1       0.54      0.64      0.58       364
           2       0.96      0.92      0.94       173
           3       0.72      0.74      0.73       294
           4       0.91      0.94      0.92       158
           5       0.91      0.97      0.94       145
           6       0.75      0.92      0.82       135

    accuracy                           0.82      2254
   macro avg       0.82      0.85      0.83      2254
weighted avg       0.83      0.82      0.82      2254

top-3 val acc: 0.9773735581188997
----------------------------------------------------------
computing evaluation metrics for test
embedding path:  ../embeddings/run_35/test_embedding.npy
label path:  ../embeddings/run_35/test_label.npy
{} report:  test
              precision    recall  f1-score   support

           0       0.95      0.81      0.88       986
           1       0.53      0.67      0.59       365
           2       0.93      0.91      0.92       175
           3       0.71      0.71      0.71       295
           4       0.92      0.95      0.93       159
           5       0.93      0.95      0.94       146
           6       0.71      0.92      0.80       137

    accuracy                           0.81      2263
   macro avg       0.81      0.85      0.82      2263
weighted avg       0.83      0.81      0.82      2263

top-3 test acc: 0.9664162615996464
----------------------------------------------------------
