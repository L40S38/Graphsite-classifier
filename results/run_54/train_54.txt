seed:  666
using pretrained model: ../trained_models/trained_model_49.pt
number of classes: 14
max number of 1000 pockets sampled from each merged class.
how to merge clusters:  [[0, 9, 12], [1, 5, 11], 2, [3, 8, 13], 4, 6, 7, 10]
whether to further subcluster data according to chemical reaction: False
number of epochs to train: 60
learning rate decay to half at epoch 30.
begin to select hard pairs at epoch 1
batch size: 128
number of hardest positive pairs for each mini-batch:  192
number of hardest negative pairs for each mini-batch:  256
number of workers to load data:  36
similar margin of contrastive loss: 0.0
dissimilar margin of contrastive loss: 2.0
device:  cuda
first 5 pockets in cluster 0 before merging (to verify reproducibility):
['4tmkA00', '3lv8A00', '3d54A00', '2hs0A00', '4dz6D00']
number of classes after merging:  8
number of pockets in training set:  12475
number of pockets in validation set:  2670
number of pockets in test set:  2681
model architecture:
SelectiveSiameseNet(
  (embedding_net): ResidualEmbeddingNet(
    (conv1): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=8, out_features=48, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=48, out_features=48, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=8, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (rb_2): ResidualBlock(
      (bn1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=48, out_features=48, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=48, out_features=48, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=48, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (rb_3): ResidualBlock(
      (bn1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=48, out_features=48, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=48, out_features=48, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=48, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (rb_4): ResidualBlock(
      (bn1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=48, out_features=48, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=48, out_features=48, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=48, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (rb_5): ResidualBlock(
      (bn1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=48, out_features=48, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=48, out_features=48, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=48, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (rb_6): ResidualBlock(
      (bn1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=48, out_features=48, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=48, out_features=48, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=48, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (rb_7): ResidualBlock(
      (bn1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=48, out_features=48, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=48, out_features=48, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=48, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (rb_8): ResidualBlock(
      (bn1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=48, out_features=48, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=48, out_features=48, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=48, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (bn_8): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (set2set): Set2Set(48, 96)
  )
)
optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.003
    weight_decay: 0.0005
)
loss function:
SelectiveContrastiveLoss(similar_margin=0.0, dissimilar_margin=2.0, num_pos_pair=192, num_neg_pair=256)
epoch: 1, train loss: 1.910477432495651, train acc: 0.7981505102040817, validation acc: 0.71328125.
epoch: 2, train loss: 1.5013517819062614, train acc: 0.8215880102040817, validation acc: 0.71328125.
epoch: 3, train loss: 1.4312289073932971, train acc: 0.8419961734693877, validation acc: 0.72578125.
epoch: 4, train loss: 1.389086453629652, train acc: 0.8541135204081632, validation acc: 0.7328125.
epoch: 5, train loss: 1.3612819704995558, train acc: 0.8547512755102041, validation acc: 0.7265625.
epoch: 6, train loss: 1.337286523757801, train acc: 0.8700573979591837, validation acc: 0.74296875.
epoch: 7, train loss: 1.3253898648409386, train acc: 0.8778698979591837, validation acc: 0.73828125.
epoch: 8, train loss: 1.3094864308660301, train acc: 0.8730867346938775, validation acc: 0.74453125.
epoch: 9, train loss: 1.2950340165341214, train acc: 0.8861607142857143, validation acc: 0.7484375.
epoch: 10, train loss: 1.288115095466636, train acc: 0.8745216836734694, validation acc: 0.738671875.
epoch: 11, train loss: 1.282441217072156, train acc: 0.8808992346938775, validation acc: 0.74140625.
epoch: 12, train loss: 1.2711227850733275, train acc: 0.8756377551020408, validation acc: 0.7546875.
epoch: 13, train loss: 1.2697237643139008, train acc: 0.8773915816326531, validation acc: 0.75078125.
epoch: 14, train loss: 1.2674063802112991, train acc: 0.8781887755102041, validation acc: 0.737890625.
epoch: 15, train loss: 1.2615199742442318, train acc: 0.8872767857142857, validation acc: 0.74609375.
epoch: 16, train loss: 1.2555170809909832, train acc: 0.8845663265306123, validation acc: 0.7640625.
epoch: 17, train loss: 1.2577452367665816, train acc: 0.8899872448979592, validation acc: 0.754296875.
epoch: 18, train loss: 1.2525060114290554, train acc: 0.8928571428571429, validation acc: 0.748046875.
epoch: 19, train loss: 1.247041324137251, train acc: 0.8860012755102041, validation acc: 0.754296875.
epoch: 20, train loss: 1.2478977653792578, train acc: 0.8896683673469388, validation acc: 0.76171875.
epoch: 21, train loss: 1.2489569833605352, train acc: 0.8864795918367347, validation acc: 0.7484375.
epoch: 22, train loss: 1.2366423759794096, train acc: 0.8875956632653061, validation acc: 0.7578125.
epoch: 23, train loss: 1.246968497340255, train acc: 0.8863201530612245, validation acc: 0.755078125.
epoch: 24, train loss: 1.2438706517567093, train acc: 0.8708545918367347, validation acc: 0.74921875.
epoch: 25, train loss: 1.2448209534581132, train acc: 0.8743622448979592, validation acc: 0.745703125.
epoch: 26, train loss: 1.2440309051869562, train acc: 0.884406887755102, validation acc: 0.7359375.
epoch: 27, train loss: 1.2389916817578908, train acc: 0.8729272959183674, validation acc: 0.744921875.
epoch: 28, train loss: 1.239947686042452, train acc: 0.8949298469387755, validation acc: 0.764453125.
epoch: 29, train loss: 1.2414632886213741, train acc: 0.8960459183673469, validation acc: 0.75234375.
epoch: 30, train loss: 1.2128687266358134, train acc: 0.9072066326530612, validation acc: 0.748828125.
epoch: 31, train loss: 1.2037113122967866, train acc: 0.9175701530612245, validation acc: 0.774609375.
epoch: 32, train loss: 1.204279674385449, train acc: 0.9175701530612245, validation acc: 0.761328125.
epoch: 33, train loss: 1.198129086730779, train acc: 0.9119897959183674, validation acc: 0.775390625.
epoch: 34, train loss: 1.1948309194937392, train acc: 0.9167729591836735, validation acc: 0.767578125.
epoch: 35, train loss: 1.20101557806699, train acc: 0.9231505102040817, validation acc: 0.773046875.
epoch: 36, train loss: 1.198032589069956, train acc: 0.8997130102040817, validation acc: 0.769921875.
epoch: 37, train loss: 1.1906089435165894, train acc: 0.9083227040816326, validation acc: 0.765625.
epoch: 38, train loss: 1.1936688770705688, train acc: 0.9135841836734694, validation acc: 0.776171875.
epoch: 39, train loss: 1.194942149059418, train acc: 0.9209183673469388, validation acc: 0.783203125.
epoch: 40, train loss: 1.1921360444049447, train acc: 0.9059311224489796, validation acc: 0.776171875.
epoch: 41, train loss: 1.1916731425694056, train acc: 0.9194834183673469, validation acc: 0.765625.
epoch: 42, train loss: 1.1934275557626441, train acc: 0.9154974489795918, validation acc: 0.75859375.
epoch: 43, train loss: 1.196583813202972, train acc: 0.8923788265306123, validation acc: 0.75078125.
epoch: 44, train loss: 1.1920267291388775, train acc: 0.9139030612244898, validation acc: 0.766796875.
epoch: 45, train loss: 1.191927617909957, train acc: 0.9162946428571429, validation acc: 0.766796875.
epoch: 46, train loss: 1.1877490897220355, train acc: 0.9044961734693877, validation acc: 0.76875.
epoch: 47, train loss: 1.191308494211981, train acc: 0.9217155612244898, validation acc: 0.774609375.
epoch: 48, train loss: 1.1920132039239733, train acc: 0.9193239795918368, validation acc: 0.775390625.
epoch: 49, train loss: 1.1927961038083446, train acc: 0.9196428571428571, validation acc: 0.778125.
epoch: 50, train loss: 1.1830990752395318, train acc: 0.8837691326530612, validation acc: 0.759765625.
epoch: 51, train loss: 1.2056814769266646, train acc: 0.9162946428571429, validation acc: 0.756640625.
epoch: 52, train loss: 1.191613718650084, train acc: 0.9178890306122449, validation acc: 0.784375.
epoch: 53, train loss: 1.1795737291564052, train acc: 0.9075255102040817, validation acc: 0.79296875.
epoch: 54, train loss: 1.1946673657386713, train acc: 0.9083227040816326, validation acc: 0.771875.
epoch: 55, train loss: 1.1827467898933255, train acc: 0.9180484693877551, validation acc: 0.7703125.
epoch: 56, train loss: 1.1841033832672385, train acc: 0.9257015306122449, validation acc: 0.755078125.
epoch: 57, train loss: 1.1802452660163012, train acc: 0.9172512755102041, validation acc: 0.774609375.
epoch: 58, train loss: 1.1868914682037977, train acc: 0.9091198979591837, validation acc: 0.769140625.
epoch: 59, train loss: 1.1870895154969685, train acc: 0.9285714285714286, validation acc: 0.773046875.
epoch: 60, train loss: 1.1866599700193712, train acc: 0.9201211734693877, validation acc: 0.771875.
best validation acc 0.79296875 at epoch 53.
