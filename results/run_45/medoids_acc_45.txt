computing evaluation metrics for train
embedding path:  ../embeddings/run_45/train_embedding.npy
label path:  ../embeddings/run_45/train_label.npy
{} report:  train
              precision    recall  f1-score   support

           0       0.92      0.80      0.85      5074
           1       0.49      0.43      0.46      2200
           2       0.86      0.86      0.86       810
           3       0.54      0.56      0.55      1840
           4       0.73      0.84      0.78       737
           5       0.85      0.97      0.90       677
           6       0.72      0.80      0.76       634
           7       0.32      0.73      0.45       500

    accuracy                           0.71     12472
   macro avg       0.68      0.75      0.70     12472
weighted avg       0.73      0.71      0.72     12472

top-3 train acc: 0.906109685695959
----------------------------------------------------------
computing evaluation metrics for val
embedding path:  ../embeddings/run_45/val_embedding.npy
label path:  ../embeddings/run_45/val_label.npy
{} report:  val
              precision    recall  f1-score   support

           0       0.92      0.80      0.85      1087
           1       0.52      0.46      0.49       471
           2       0.83      0.87      0.85       173
           3       0.55      0.55      0.55       394
           4       0.73      0.87      0.79       158
           5       0.82      0.93      0.87       145
           6       0.74      0.84      0.79       135
           7       0.29      0.65      0.40       105

    accuracy                           0.71      2668
   macro avg       0.68      0.75      0.70      2668
weighted avg       0.74      0.71      0.72      2668

top-3 val acc: 0.9100449775112444
----------------------------------------------------------
computing evaluation metrics for test
embedding path:  ../embeddings/run_45/test_embedding.npy
label path:  ../embeddings/run_45/test_label.npy
{} report:  test
              precision    recall  f1-score   support

           0       0.93      0.79      0.85      1088
           1       0.53      0.46      0.49       472
           2       0.84      0.88      0.86       175
           3       0.58      0.60      0.59       395
           4       0.72      0.86      0.79       159
           5       0.83      0.98      0.90       146
           6       0.70      0.80      0.75       137
           7       0.28      0.62      0.39       108

    accuracy                           0.72      2680
   macro avg       0.68      0.75      0.70      2680
weighted avg       0.75      0.72      0.73      2680

top-3 test acc: 0.9108208955223881
----------------------------------------------------------
