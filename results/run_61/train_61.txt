seed:  666
number of classes (from original clusters): 19
how to merge clusters:  [[0, 9, 12], [1, 5, 11], 2, [3, 8, 13], 4, 6, 7, [10, 16], 15, 17, 18]
whether to further subcluster data according to chemical reaction: False
positive training pair sampling threshold:  16000
negative training pair sampling threshold:  4800
number of epochs to train: 40
learning rate decay to half at epoch 25.
batch size: 256
similar margin of contrastive loss: 0.0
dissimilar margin of contrastive loss: 2.0
number of workers to load data:  36
device:  cuda
number of gpus:  2
features to use:  ['r', 'theta', 'phi', 'sasa', 'charge', 'hydrophobicity', 'binding_probability', 'sequence_entropy']
number of classes after merging:  11
number of pockets in training set:  14097
number of pockets in validation set:  3016
number of pockets in test set:  3031
first 5 pockets in train set of cluster 0 before merging (to verify reproducibility):
['6brxA00', '4c0lA00', '3rs8A02', '4nk4F00', '5fogD00']
first 5 pockets in val set of cluster 0 before merging (to verify reproducibility):
['4d86A00', '4u00A00', '1pujA00', '3nt5A00', '4j1nB01']
first 5 pockets in test set of cluster 0 before merging (to verify reproducibility):
['4k28A00', '6hwlB00', '3upqA01', '2p2bA00', '1h5rB02']
number of train positive pairs: 176000
number of train negative pairs: 264000
model architecture:
JKSiameseNet(
  (embedding_net): JKEmbeddingNet(
    (conv0): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=8, out_features=48, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=48, out_features=48, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=8, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn0): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv1): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=48, out_features=48, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=48, out_features=48, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=48, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=48, out_features=48, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=48, out_features=48, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=48, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=48, out_features=48, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=48, out_features=48, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=48, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn3): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv4): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=48, out_features=48, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=48, out_features=48, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=48, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn4): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (set2set): Set2Set(48, 96)
  )
)
optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.003
    weight_decay: 0.0005
)
loss function:
ContrastiveLoss(similar_margin=0.0, dissimilar_margin=2.0, normalize=True, mean=True)
epoch: 1, train loss: 0.9610269648118452, train acc: 0.6597857700219905, validation acc: 0.5169098143236074.
epoch: 2, train loss: 0.7406414832722057, train acc: 0.7635667163226219, validation acc: 0.6621352785145889.
epoch: 3, train loss: 0.6251930673946033, train acc: 0.7760516421933745, validation acc: 0.6820291777188329.
epoch: 4, train loss: 0.5698399505268443, train acc: 0.7953465276299923, validation acc: 0.7059018567639257.
epoch: 5, train loss: 0.5332354632984508, train acc: 0.7862665815421721, validation acc: 0.6909814323607427.
epoch: 6, train loss: 0.506516524366899, train acc: 0.8108108108108109, validation acc: 0.6992705570291777.
epoch: 7, train loss: 0.487076832112399, train acc: 0.8093211321557778, validation acc: 0.7002652519893899.
epoch: 8, train loss: 0.47418089095028965, train acc: 0.8133645456480102, validation acc: 0.6999336870026526.
epoch: 9, train loss: 0.4661181818008423, train acc: 0.8060580265304674, validation acc: 0.6886604774535809.
epoch: 10, train loss: 0.46151735038757324, train acc: 0.8153507838547208, validation acc: 0.7032493368700266.
epoch: 11, train loss: 0.4552676528237083, train acc: 0.8164857771156984, validation acc: 0.7151856763925729.
epoch: 12, train loss: 0.4488775654359297, train acc: 0.8159182804852096, validation acc: 0.7029177718832891.
epoch: 13, train loss: 0.4433367507240989, train acc: 0.8133645456480102, validation acc: 0.7045755968169761.
epoch: 14, train loss: 0.44403990807966753, train acc: 0.8291835142228843, validation acc: 0.7181697612732095.
epoch: 15, train loss: 0.4350287194858898, train acc: 0.8200326310562531, validation acc: 0.7039124668435013.
epoch: 16, train loss: 0.4354309538927945, train acc: 0.813932042278499, validation acc: 0.6886604774535809.
epoch: 17, train loss: 0.43214526275287973, train acc: 0.8098176917074554, validation acc: 0.696949602122016.
epoch: 18, train loss: 0.42597934556440875, train acc: 0.8243597928637298, validation acc: 0.7059018567639257.
epoch: 19, train loss: 0.42706282092007725, train acc: 0.8247854153365964, validation acc: 0.7125331564986738.
epoch: 20, train loss: 0.42461167966669255, train acc: 0.8245726041001632, validation acc: 0.7151856763925729.
epoch: 21, train loss: 0.42259833226637405, train acc: 0.8072639568702561, validation acc: 0.6899867374005305.
epoch: 22, train loss: 0.41899156079725786, train acc: 0.8179754557707314, validation acc: 0.7145225464190982.
epoch: 23, train loss: 0.4203553998600353, train acc: 0.8293963254593176, validation acc: 0.7112068965517241.
epoch: 24, train loss: 0.4147925817836415, train acc: 0.8227991771298858, validation acc: 0.7068965517241379.
epoch: 25, train loss: 0.3732260920437899, train acc: 0.8415975030148258, validation acc: 0.7042440318302388.
epoch: 26, train loss: 0.37144424083016137, train acc: 0.8461374760587359, validation acc: 0.7125331564986738.
epoch: 27, train loss: 0.3709953151182695, train acc: 0.8521671277576789, validation acc: 0.7214854111405835.
epoch: 28, train loss: 0.367052047105269, train acc: 0.8489749592111797, validation acc: 0.7065649867374005.
epoch: 29, train loss: 0.3632548650568182, train acc: 0.8535149322550898, validation acc: 0.7201591511936339.
epoch: 30, train loss: 0.3654049751108343, train acc: 0.8496133929204795, validation acc: 0.7204907161803713.
epoch: 31, train loss: 0.3602288186680187, train acc: 0.8598992693480882, validation acc: 0.7264588859416445.
epoch: 32, train loss: 0.3637774884484031, train acc: 0.8530183727034121, validation acc: 0.7254641909814323.
epoch: 33, train loss: 0.3592222594347867, train acc: 0.8359934737887493, validation acc: 0.7012599469496021.
epoch: 34, train loss: 0.3591574085929177, train acc: 0.8474143434773356, validation acc: 0.7244694960212201.
epoch: 35, train loss: 0.36274316987124355, train acc: 0.8525927502305455, validation acc: 0.7208222811671088.
epoch: 36, train loss: 0.35628849652030253, train acc: 0.8525218131517344, validation acc: 0.7151856763925729.
epoch: 37, train loss: 0.3596353425112638, train acc: 0.8571327232744556, validation acc: 0.7145225464190982.
epoch: 38, train loss: 0.35624241593967787, train acc: 0.8535149322550898, validation acc: 0.7204907161803713.
epoch: 39, train loss: 0.35595308371457185, train acc: 0.8595445839540328, validation acc: 0.7244694960212201.
epoch: 40, train loss: 0.355442576824535, train acc: 0.8584095906930552, validation acc: 0.730106100795756.
best validation acc 0.730106100795756 at epoch 40.
