how to merge clusters:  [[0, 9], [1, 5], 2, [3, 8], 4, 6, 7]
computing evaluation metrics for train
embedding path:  ../embeddings/run_39/train_embedding.npy
label path:  ../embeddings/run_39/train_label.npy
{} report:  train
              precision    recall  f1-score   support

           0       0.89      0.93      0.91      4597
           1       0.54      0.57      0.56      1699
           2       0.79      0.55      0.65       810
           3       0.62      0.61      0.61      1373
           4       0.71      0.58      0.64       737
           5       0.64      0.68      0.66       677
           6       0.50      0.57      0.53       631

    accuracy                           0.74     10524
   macro avg       0.67      0.64      0.65     10524
weighted avg       0.74      0.74      0.73     10524

top-3 train acc: 0.927023945267959
----------------------------------------------------------
computing evaluation metrics for val
embedding path:  ../embeddings/run_39/val_embedding.npy
label path:  ../embeddings/run_39/val_label.npy
{} report:  val
              precision    recall  f1-score   support

           0       0.88      0.92      0.90       985
           1       0.53      0.59      0.56       364
           2       0.83      0.59      0.69       173
           3       0.64      0.61      0.62       294
           4       0.72      0.50      0.59       158
           5       0.61      0.64      0.63       145
           6       0.52      0.57      0.54       133

    accuracy                           0.74      2252
   macro avg       0.68      0.63      0.65      2252
weighted avg       0.74      0.74      0.73      2252

top-3 val acc: 0.9356127886323268
----------------------------------------------------------
computing evaluation metrics for test
embedding path:  ../embeddings/run_39/test_embedding.npy
label path:  ../embeddings/run_39/test_label.npy
{} report:  test
              precision    recall  f1-score   support

           0       0.90      0.94      0.92       986
           1       0.58      0.62      0.60       365
           2       0.77      0.56      0.65       175
           3       0.65      0.64      0.64       295
           4       0.73      0.57      0.64       159
           5       0.71      0.69      0.70       146
           6       0.53      0.60      0.56       134

    accuracy                           0.76      2260
   macro avg       0.69      0.66      0.67      2260
weighted avg       0.76      0.76      0.75      2260

top-3 test acc: 0.9389380530973451
----------------------------------------------------------
