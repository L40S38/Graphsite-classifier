how to merge clusters:  [[0, 9], [1, 5], 2, [3, 8], 4, 6, 7]
computing evaluation metrics for train
embedding path:  ../embeddings/run_38/train_embedding.npy
label path:  ../embeddings/run_38/train_label.npy
{} report:  train
              precision    recall  f1-score   support

           0       0.93      0.64      0.76      4597
           1       0.37      0.45      0.41      1699
           2       0.40      0.60      0.48       810
           3       0.29      0.43      0.35      1373
           4       0.50      0.57      0.53       737
           5       0.54      0.55      0.54       677
           6       0.47      0.39      0.43       631

    accuracy                           0.55     10524
   macro avg       0.50      0.52      0.50     10524
weighted avg       0.63      0.55      0.58     10524

top-3 train acc: 0.8665906499429875
----------------------------------------------------------
computing evaluation metrics for val
embedding path:  ../embeddings/run_38/val_embedding.npy
label path:  ../embeddings/run_38/val_label.npy
{} report:  val
              precision    recall  f1-score   support

           0       0.94      0.65      0.77       985
           1       0.34      0.40      0.37       364
           2       0.37      0.59      0.46       173
           3       0.28      0.39      0.33       294
           4       0.48      0.56      0.52       158
           5       0.49      0.55      0.52       145
           6       0.43      0.38      0.40       133

    accuracy                           0.54      2252
   macro avg       0.48      0.50      0.48      2252
weighted avg       0.62      0.54      0.57      2252

top-3 val acc: 0.8641207815275311
----------------------------------------------------------
computing evaluation metrics for test
embedding path:  ../embeddings/run_38/test_embedding.npy
label path:  ../embeddings/run_38/test_label.npy
{} report:  test
              precision    recall  f1-score   support

           0       0.92      0.67      0.77       986
           1       0.39      0.44      0.41       365
           2       0.39      0.55      0.45       175
           3       0.30      0.42      0.35       295
           4       0.57      0.64      0.60       159
           5       0.53      0.61      0.57       146
           6       0.43      0.40      0.41       134

    accuracy                           0.57      2260
   macro avg       0.50      0.53      0.51      2260
weighted avg       0.63      0.57      0.59      2260

top-3 test acc: 0.8690265486725663
----------------------------------------------------------
