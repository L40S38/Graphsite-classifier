how to merge clusters:  [[0, 9], [1, 5], 2, [3, 8], 4, 6, 7]
computing evaluation metrics for train
embedding path:  ../embeddings/run_34/train_embedding.npy
label path:  ../embeddings/run_34/train_label.npy
{} report:  train
              precision    recall  f1-score   support

           0       0.89      0.78      0.83      4597
           1       0.39      0.27      0.32      1699
           2       0.68      0.85      0.76       810
           3       0.48      0.55      0.51      1373
           4       0.60      0.81      0.69       737
           5       0.82      0.89      0.85       677
           6       0.55      0.86      0.67       634

    accuracy                           0.69     10527
   macro avg       0.63      0.72      0.66     10527
weighted avg       0.69      0.69      0.68     10527

top-3 train acc: 0.9373040752351097
----------------------------------------------------------
computing evaluation metrics for val
embedding path:  ../embeddings/run_34/val_embedding.npy
label path:  ../embeddings/run_34/val_label.npy
{} report:  val
              precision    recall  f1-score   support

           0       0.88      0.77      0.82       985
           1       0.39      0.26      0.31       364
           2       0.64      0.80      0.71       173
           3       0.47      0.52      0.49       294
           4       0.58      0.88      0.70       158
           5       0.76      0.88      0.82       145
           6       0.58      0.82      0.68       135

    accuracy                           0.68      2254
   macro avg       0.61      0.71      0.65      2254
weighted avg       0.68      0.68      0.67      2254

top-3 val acc: 0.9476486246672582
----------------------------------------------------------
computing evaluation metrics for test
embedding path:  ../embeddings/run_34/test_embedding.npy
label path:  ../embeddings/run_34/test_label.npy
{} report:  test
              precision    recall  f1-score   support

           0       0.89      0.77      0.83       986
           1       0.38      0.28      0.32       365
           2       0.72      0.83      0.77       175
           3       0.47      0.57      0.51       295
           4       0.63      0.82      0.71       159
           5       0.83      0.90      0.86       146
           6       0.57      0.89      0.70       137

    accuracy                           0.69      2263
   macro avg       0.64      0.72      0.67      2263
weighted avg       0.70      0.69      0.69      2263

top-3 test acc: 0.9447635881573133
----------------------------------------------------------
