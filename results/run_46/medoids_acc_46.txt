computing evaluation metrics for train
embedding path:  ../embeddings/run_46/train_embedding.npy
label path:  ../embeddings/run_46/train_label.npy
{} report:  train
              precision    recall  f1-score   support

           0       0.93      0.64      0.76      5074
           1       0.51      0.25      0.34      2200
           2       0.79      0.82      0.81       810
           3       0.60      0.63      0.61      1840
           4       0.89      0.83      0.86       737
           5       0.77      0.94      0.85       677
           6       0.73      0.87      0.79       634
           7       0.39      0.47      0.42       503
           8       0.24      0.65      0.35       433
           9       0.70      0.92      0.79       421
          10       0.25      0.72      0.37       403
          11       0.38      0.89      0.53       401
          12       0.78      0.95      0.86       395

    accuracy                           0.64     14528
   macro avg       0.61      0.74      0.64     14528
weighted avg       0.71      0.64      0.65     14528

top-3 train acc: 0.8730038546255506
----------------------------------------------------------
computing evaluation metrics for val
embedding path:  ../embeddings/run_46/val_embedding.npy
label path:  ../embeddings/run_46/val_label.npy
{} report:  val
              precision    recall  f1-score   support

           0       0.92      0.63      0.75      1087
           1       0.52      0.29      0.37       471
           2       0.80      0.84      0.82       173
           3       0.62      0.64      0.63       394
           4       0.91      0.83      0.87       158
           5       0.76      0.94      0.84       145
           6       0.79      0.86      0.82       135
           7       0.41      0.48      0.44       107
           8       0.26      0.68      0.37        92
           9       0.69      0.98      0.81        90
          10       0.24      0.71      0.36        86
          11       0.38      0.89      0.53        85
          12       0.79      0.91      0.85        81

    accuracy                           0.65      3104
   macro avg       0.62      0.74      0.65      3104
weighted avg       0.72      0.65      0.66      3104

top-3 val acc: 0.8759664948453608
----------------------------------------------------------
computing evaluation metrics for test
embedding path:  ../embeddings/run_46/test_embedding.npy
label path:  ../embeddings/run_46/test_label.npy
{} report:  test
              precision    recall  f1-score   support

           0       0.93      0.60      0.73      1088
           1       0.56      0.25      0.35       472
           2       0.78      0.85      0.82       175
           3       0.59      0.66      0.62       395
           4       0.88      0.81      0.84       159
           5       0.73      0.92      0.82       146
           6       0.70      0.84      0.76       137
           7       0.38      0.43      0.41       109
           8       0.26      0.71      0.38        94
           9       0.67      0.97      0.79        91
          10       0.23      0.74      0.35        88
          11       0.36      0.80      0.49        87
          12       0.80      0.92      0.85        83

    accuracy                           0.63      3124
   macro avg       0.61      0.73      0.63      3124
weighted avg       0.72      0.63      0.64      3124

top-3 test acc: 0.8693982074263764
----------------------------------------------------------
