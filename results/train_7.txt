number of classes: 60
number of epochs to train: 50
batch size: 256
number of workers to load data:  36
device:  cuda
number of gpus:  2
number of pockets in training set:  22527
number of pockets in validation set:  4806
number of pockets in test set:  4890
number of train positive pairs: 180000
number of train negative pairs: 177000
number of validation positive pairs: 47172
number of validation negative pairs: 44250
model architecture:
SiameseNet(
  (embedding_net): EmbeddingNet(
    (conv1): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=5, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=5, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=5, out_features=5, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=32, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=32, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv4): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=32, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.003
    weight_decay: 0.0005
)
loss function:
ContrastiveLoss(margin=2.0, normalize=True, mean=True)
train loss: 0.855722837432092, validation loss: 0.8548286139061423.
train loss: 0.7945689317719276, validation loss: 0.7988407693891164.
train loss: 0.76111618563441, validation loss: 0.7763882046785251.
train loss: 0.7373055824258414, validation loss: 0.7587245789195105.
train loss: 0.7202041279341327, validation loss: 0.7759659051483095.
train loss: 0.7056543139716824, validation loss: 0.748623004527863.
train loss: 0.6958558961670606, validation loss: 0.7441369530899633.
train loss: 0.6860283260826303, validation loss: 0.7461167985793004.
train loss: 0.6789643017851672, validation loss: 0.7499606020743562.
train loss: 0.6742799606536951, validation loss: 0.7359020998163373.
train loss: 0.6693132031865481, validation loss: 0.7279907097711839.
train loss: 0.66540978721811, validation loss: 0.7395084063399845.
train loss: 0.6611814500824744, validation loss: 0.7313651014612034.
train loss: 0.6574317127302581, validation loss: 0.7312799730672476.
train loss: 0.6563156262566061, validation loss: 0.7221379018153795.
train loss: 0.6528194807036584, validation loss: 0.7290334988406058.
train loss: 0.6492339492071243, validation loss: 0.7270885653711826.
train loss: 0.6479153013256084, validation loss: 0.7279869986384718.
train loss: 0.6468918743186972, validation loss: 0.7270808344984103.
train loss: 0.6438878561922816, validation loss: 0.721493284322227.
train loss: 0.6408156475847174, validation loss: 0.7234926526896092.
train loss: 0.639007865414232, validation loss: 0.7206687414013213.
train loss: 0.6362127960803462, validation loss: 0.7221860370509556.
train loss: 0.636267664206796, validation loss: 0.7227673065852499.
train loss: 0.6336073355581247, validation loss: 0.7091536951170422.
train loss: 0.6326531700754032, validation loss: 0.7237341006362173.
train loss: 0.6318169934782996, validation loss: 0.7181311519714851.
train loss: 0.6321882902300324, validation loss: 0.7132467350137041.
train loss: 0.6291807971174309, validation loss: 0.7252271690234294.
train loss: 0.6272536544586096, validation loss: 0.7082147079400678.
train loss: 0.627166282311875, validation loss: 0.7297488006019647.
train loss: 0.6265479673284109, validation loss: 0.7148917174960494.
train loss: 0.6246531251324993, validation loss: 0.7309879352132038.
train loss: 0.6229391651954972, validation loss: 0.7132430180393169.
train loss: 0.6229609080082228, validation loss: 0.7199676547720495.
train loss: 0.6203988443155583, validation loss: 0.7197737583942266.
train loss: 0.6211933526431813, validation loss: 0.7152629644581647.
train loss: 0.619437702403349, validation loss: 0.7114571608924586.
train loss: 0.6184535002508084, validation loss: 0.7186292080129077.
train loss: 0.618357503874963, validation loss: 0.7075622898078523.
train loss: 0.6175777240614263, validation loss: 0.7081902742161585.
train loss: 0.6165932488321256, validation loss: 0.7172994302995527.
train loss: 0.6151902444876877, validation loss: 0.7146993422904118.
train loss: 0.615701833196047, validation loss: 0.7194474252342502.
train loss: 0.6159751460398613, validation loss: 0.7216989543457726.
train loss: 0.6142152006859873, validation loss: 0.724569245863544.
train loss: 0.6147399915166262, validation loss: 0.7209445228751076.
train loss: 0.614244484952184, validation loss: 0.7139255076125879.
train loss: 0.6136002723416026, validation loss: 0.7143755001875852.
train loss: 0.6119011825005881, validation loss: 0.701599824431427.
best validation loss 0.701599824431427 at epoch 50.
