how to merge clusters:  [[0, 9], [1, 5], 2, [3, 8], 4, 6, 7]
computing evaluation metrics for train
embedding path:  ../embeddings/run_29/train_embedding.npy
label path:  ../embeddings/run_29/train_label.npy
{} report:  train
              precision    recall  f1-score   support

           0       0.90      0.75      0.82      4597
           1       0.40      0.43      0.41      1699
           2       0.84      0.89      0.86       810
           3       0.52      0.66      0.58      1373
           4       0.83      0.92      0.87       737
           5       0.88      0.95      0.91       677
           6       0.75      0.87      0.80       634

    accuracy                           0.73     10527
   macro avg       0.73      0.78      0.75     10527
weighted avg       0.75      0.73      0.73     10527

top-3 train acc: 0.9686520376175548
----------------------------------------------------------
computing evaluation metrics for val
embedding path:  ../embeddings/run_29/val_embedding.npy
label path:  ../embeddings/run_29/val_label.npy
{} report:  val
              precision    recall  f1-score   support

           0       0.91      0.77      0.83       985
           1       0.39      0.42      0.41       364
           2       0.85      0.92      0.88       173
           3       0.52      0.65      0.58       294
           4       0.84      0.90      0.87       158
           5       0.91      0.97      0.94       145
           6       0.78      0.89      0.83       135

    accuracy                           0.74      2254
   macro avg       0.74      0.79      0.76      2254
weighted avg       0.76      0.74      0.74      2254

top-3 val acc: 0.9711623779946761
----------------------------------------------------------
computing evaluation metrics for test
embedding path:  ../embeddings/run_29/test_embedding.npy
label path:  ../embeddings/run_29/test_label.npy
{} report:  test
              precision    recall  f1-score   support

           0       0.90      0.74      0.81       986
           1       0.36      0.39      0.38       365
           2       0.82      0.92      0.87       175
           3       0.54      0.64      0.59       295
           4       0.79      0.91      0.84       159
           5       0.90      0.97      0.93       146
           6       0.66      0.88      0.76       137

    accuracy                           0.72      2263
   macro avg       0.71      0.78      0.74      2263
weighted avg       0.74      0.72      0.72      2263

top-3 test acc: 0.9690676093680954
----------------------------------------------------------
