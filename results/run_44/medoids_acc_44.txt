how to merge clusters:  [[0, 9], [1, 5], 2, [3, 8], 4, 6, 7]
computing evaluation metrics for train
embedding path:  ../embeddings/run_44/train_embedding.npy
label path:  ../embeddings/run_44/train_label.npy
{} report:  train
              precision    recall  f1-score   support

           0       0.94      0.68      0.79      4597
           1       0.58      0.40      0.48      1699
           2       0.88      0.85      0.87       810
           3       0.57      0.44      0.50      1373
           4       0.81      0.90      0.85       737
           5       0.84      0.96      0.90       677
           6       0.78      0.81      0.80       634
           7       0.52      0.80      0.63       503
           8       0.15      0.37      0.22       500
           9       0.40      0.89      0.55       476
          10       0.47      0.87      0.61       466

    accuracy                           0.67     12472
   macro avg       0.63      0.72      0.65     12472
weighted avg       0.74      0.67      0.69     12472

top-3 train acc: 0.8788486209108403
----------------------------------------------------------
computing evaluation metrics for val
embedding path:  ../embeddings/run_44/val_embedding.npy
label path:  ../embeddings/run_44/val_label.npy
{} report:  val
              precision    recall  f1-score   support

           0       0.95      0.69      0.80       985
           1       0.58      0.40      0.47       364
           2       0.91      0.83      0.86       173
           3       0.54      0.40      0.46       294
           4       0.85      0.91      0.88       158
           5       0.79      0.97      0.87       145
           6       0.79      0.86      0.82       135
           7       0.55      0.76      0.64       107
           8       0.15      0.39      0.22       107
           9       0.42      0.90      0.57       102
          10       0.45      0.86      0.59        98

    accuracy                           0.67      2668
   macro avg       0.64      0.72      0.65      2668
weighted avg       0.74      0.67      0.69      2668

top-3 val acc: 0.8793103448275862
----------------------------------------------------------
computing evaluation metrics for test
embedding path:  ../embeddings/run_44/test_embedding.npy
label path:  ../embeddings/run_44/test_label.npy
{} report:  test
              precision    recall  f1-score   support

           0       0.96      0.69      0.80       986
           1       0.53      0.35      0.42       365
           2       0.90      0.89      0.89       175
           3       0.62      0.49      0.55       295
           4       0.82      0.92      0.86       159
           5       0.85      0.97      0.91       146
           6       0.83      0.83      0.83       137
           7       0.55      0.76      0.64       109
           8       0.10      0.27      0.15       108
           9       0.42      0.95      0.58       103
          10       0.50      0.91      0.64       101

    accuracy                           0.67      2684
   macro avg       0.64      0.73      0.66      2684
weighted avg       0.75      0.67      0.69      2684

top-3 test acc: 0.8953055141579732
----------------------------------------------------------
