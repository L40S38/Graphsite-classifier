number of classes: 60
number of epochs to train: 50
batch size: 64
number of workers to load data:  36
device:  cuda
number of gpus:  2
number of pockets in training set:  22527
number of pockets in validation set:  4806
number of pockets in test set:  4890
number of train positive pairs: 180000
number of train negative pairs: 177000
number of validation positive pairs: 47172
number of validation negative pairs: 44250
model architecture:
SiameseNet(
  (embedding_net): EmbeddingNet(
    (conv1): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=5, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=5, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=5, out_features=5, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=32, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=32, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv4): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=32, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0002
)
loss function:
ContrastiveLoss(margin=2.0, normalize=False, mean=True)
train loss: 565.8222253818032, validation loss: 13.080954065815455.
train loss: 4.186320052801394, validation loss: 2.4615303961367108.
train loss: 1.2345999689930294, validation loss: 2.526308943829903.
train loss: 0.9087774887832941, validation loss: 0.8887558912224772.
train loss: 0.8365504840028052, validation loss: 0.8311794787395634.
train loss: 0.7895576750277137, validation loss: 0.7894480550185621.
train loss: 0.7566194674441127, validation loss: 0.7767162706879551.
train loss: 0.7330768512170188, validation loss: 0.7686507061949571.
train loss: 0.7137605451215215, validation loss: 0.7739329978050096.
train loss: 0.6993856742014738, validation loss: 0.7696999192709882.
train loss: 0.6890082539416829, validation loss: 0.773865465913296.
train loss: 0.6780545036518941, validation loss: 0.7640483698309041.
train loss: 0.6685986650450891, validation loss: 0.764837317255914.
train loss: 0.6610209387450658, validation loss: 0.7509170390232133.
train loss: 0.6539320814309, validation loss: 0.7424630619102566.
train loss: 0.6488484178217185, validation loss: 0.7375684182031714.
train loss: 0.6430428022657122, validation loss: 0.7396226139247609.
train loss: 0.6403068074512215, validation loss: 0.7533174482516116.
train loss: 0.6350998233934076, validation loss: 0.7498527473946583.
train loss: 0.6318486601137647, validation loss: 0.7569945918658575.
train loss: 0.6284031474757261, validation loss: 0.7537427591235936.
train loss: 0.6246880374074985, validation loss: 0.7343354946709877.
train loss: 0.6227796049946163, validation loss: 0.7738685144957408.
