seed:  666
number of classes: 10
how to merge clusters:  [[0, 9], [1, 5], 2, [3, 8], 4, 6, 7]
whether to further subcluster data according to chemical reaction: False
number of epochs to train: 3200
learning rate decay to half at epoch 2400.
begin to select hard pairs at epoch 1200
batch size: 96
number of hardest positive pairs for each mini-batch:  128
number of hardest negative pairs for each mini-batch:  128
number of workers to load data:  36
similar margin of contrastive loss: 0.0
dissimilar margin of contrastive loss: 2.0
device:  cuda
number of classes after merging:  7
number of pockets in training set:  10527
number of pockets in validation set:  2254
number of pockets in test set:  2263
model architecture:
SelectiveSiameseNet(
  (embedding_net): EmbeddingNet(
    (set2set): Set2Set(32, 64)
    (conv1): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=11, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=11, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=32, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=32, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=32, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=32, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv4): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=32, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=32, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.003
    weight_decay: 0.0005
)
loss function:
SelectiveContrastiveLoss(similar_margin=0.0, dissimilar_margin=2.0, num_pos_pair=128, num_neg_pair=128)
epoch: 1, train loss: 0.8916578752185227, validation loss: 0.9759255129358043.
epoch: 2, train loss: 0.7691759519073942, validation loss: 0.9144810749136884.
epoch: 3, train loss: 0.7840715329581445, validation loss: 0.8271070861298105.
epoch: 4, train loss: 0.7974941757840848, validation loss: 0.7579499625641367.
epoch: 5, train loss: 0.7712160567624853, validation loss: 0.8786687773206959.
epoch: 6, train loss: 0.748189768933375, validation loss: 0.7474084833393926.
epoch: 7, train loss: 0.764078548468581, validation loss: 0.8197649704373401.
epoch: 8, train loss: 0.77101505704976, validation loss: 0.7742805195891339.
epoch: 9, train loss: 0.7808554812308846, validation loss: 0.8164648983789526.
epoch: 10, train loss: 0.742357910773076, validation loss: 0.7148834117080854.
epoch: 11, train loss: 0.7651205117549371, validation loss: 0.81913154280704.
epoch: 12, train loss: 0.7335718730720905, validation loss: 0.779310545195704.
epoch: 13, train loss: 0.728504254183638, validation loss: 0.9402795330337856.
epoch: 14, train loss: 0.7047601254708177, validation loss: 0.7568262880263121.
epoch: 15, train loss: 0.6905749322624382, validation loss: 0.7175903462845347.
epoch: 16, train loss: 0.7780568949673154, validation loss: 0.7495543568030648.
epoch: 17, train loss: 0.7255509287939159, validation loss: 0.8000954402529675.
epoch: 18, train loss: 0.7198957866484966, validation loss: 0.7602192033892092.
epoch: 19, train loss: 0.6960946832774976, validation loss: 0.7443859810414521.
epoch: 20, train loss: 0.6798838316847425, validation loss: 0.8708499825519064.
epoch: 21, train loss: 0.6977565140899168, validation loss: 0.7230783441792363.
epoch: 22, train loss: 0.7074115145097085, validation loss: 0.8216393304907758.
epoch: 23, train loss: 0.6905965258222108, validation loss: 0.7051633570505225.
epoch: 24, train loss: 0.6835137646679484, validation loss: 0.7400608373724896.
epoch: 25, train loss: 0.7170404685199807, validation loss: 0.7617956192597098.
epoch: 26, train loss: 0.6663954315382407, validation loss: 0.7794844274935515.
epoch: 27, train loss: 0.7091617452988931, validation loss: 0.6934962609539861.
epoch: 28, train loss: 0.7103027813478348, validation loss: 0.768764219854189.
epoch: 29, train loss: 0.7186923289517744, validation loss: 0.6522071141263713.
epoch: 30, train loss: 0.6866035267300562, validation loss: 0.7169158562369968.
epoch: 31, train loss: 0.6814726651261706, validation loss: 0.6650558075179225.
epoch: 32, train loss: 0.693397329214516, validation loss: 0.7932104727496272.
epoch: 33, train loss: 0.7116096703284377, validation loss: 0.7240303884381833.
epoch: 34, train loss: 0.6660966154085387, validation loss: 0.9069183416988539.
epoch: 35, train loss: 0.7060441601713863, validation loss: 0.7758418010628741.
epoch: 36, train loss: 0.6744898691636707, validation loss: 0.6874072188916414.
epoch: 37, train loss: 0.681748638185886, validation loss: 0.734150758256083.
epoch: 38, train loss: 0.6668144401607163, validation loss: 0.6838320104972176.
epoch: 39, train loss: 0.6691351737997947, validation loss: 0.6871882832568624.
epoch: 40, train loss: 0.6766985627489353, validation loss: 0.6872415775838105.
epoch: 41, train loss: 0.6440788726194189, validation loss: 0.7225122374037037.
epoch: 42, train loss: 0.6811434366834273, validation loss: 0.6553609202737394.
epoch: 43, train loss: 0.6706703502103823, validation loss: 0.7027119683182758.
epoch: 44, train loss: 0.6960617763186814, validation loss: 0.7199598356433536.
epoch: 45, train loss: 0.6759563277073957, validation loss: 0.7563645165899525.
epoch: 46, train loss: 0.6780205155731341, validation loss: 0.6933374469694884.
epoch: 47, train loss: 0.65142529656034, validation loss: 0.7030267987562262.
epoch: 48, train loss: 0.6868182951157246, validation loss: 0.8324239331742992.
epoch: 49, train loss: 0.6836509264390404, validation loss: 0.789781312579694.
epoch: 50, train loss: 0.6539127181429382, validation loss: 0.7102789827015089.
epoch: 51, train loss: 0.6544572563346372, validation loss: 0.6462439013564069.
epoch: 52, train loss: 0.6419461503488209, validation loss: 0.6887860984905906.
epoch: 53, train loss: 0.6519111709310375, validation loss: 0.7657433994438337.
epoch: 54, train loss: 0.6833070885697636, validation loss: 0.735644659270411.
epoch: 55, train loss: 0.6597727816039269, validation loss: 0.7102775651475658.
epoch: 56, train loss: 0.7008824780446674, validation loss: 0.8931222843087238.
epoch: 57, train loss: 0.6830170064344319, validation loss: 0.6653107987797778.
epoch: 58, train loss: 0.6765048807367272, validation loss: 0.7630774301031361.
epoch: 59, train loss: 0.6834026039193529, validation loss: 0.715124883081602.
epoch: 60, train loss: 0.6769159709641693, validation loss: 0.7296577549499014.
epoch: 61, train loss: 0.6784041250517608, validation loss: 0.7536543517009072.
epoch: 62, train loss: 0.6589915246591656, validation loss: 0.6869758497113767.
epoch: 63, train loss: 0.6325994527668034, validation loss: 0.9272522200708804.
epoch: 64, train loss: 0.6527497530530352, validation loss: 0.7100589301275171.
epoch: 65, train loss: 0.6712110280443769, validation loss: 0.6387087741623754.
epoch: 66, train loss: 0.6996178952378964, validation loss: 0.7151278464690499.
epoch: 67, train loss: 0.6410509867405673, validation loss: 0.6433573520701864.
epoch: 68, train loss: 0.6426652207833912, validation loss: 0.6736346288867618.
epoch: 69, train loss: 0.6512543744997147, validation loss: 0.6387041159298109.
epoch: 70, train loss: 0.6531689831423103, validation loss: 0.7385088399700497.
epoch: 71, train loss: 0.6713233242887969, validation loss: 0.8032018905100615.
epoch: 72, train loss: 0.6902940289689861, validation loss: 0.717177970253903.
epoch: 73, train loss: 0.6254980296169946, validation loss: 0.6359226612941079.
epoch: 74, train loss: 0.6311764976847063, validation loss: 0.5999887507894764.
epoch: 75, train loss: 0.6499340731069583, validation loss: 0.6128762014534163.
epoch: 76, train loss: 0.6276977961763329, validation loss: 0.6296836578327677.
epoch: 77, train loss: 0.6474536465942313, validation loss: 0.7043587941190471.
epoch: 78, train loss: 0.6754291560671745, validation loss: 0.7458178971124731.
epoch: 79, train loss: 0.6900504357224211, validation loss: 0.7025206749853881.
epoch: 80, train loss: 0.668098386547981, validation loss: 0.6885409497696421.
epoch: 81, train loss: 0.6552949039214248, validation loss: 0.7348846300788547.
epoch: 82, train loss: 0.6824631040249396, validation loss: 0.6539917160635409.
epoch: 83, train loss: 0.6524152990874894, validation loss: 0.636515929647114.
epoch: 84, train loss: 0.654146671295166, validation loss: 0.6486988417480303.
epoch: 85, train loss: 0.6757697175948991, validation loss: 0.6958242058753967.
epoch: 86, train loss: 0.6509886444161791, validation loss: 0.6740625241528386.
epoch: 87, train loss: 0.6624661596543199, validation loss: 0.7582937828872515.
epoch: 88, train loss: 0.6693936296559255, validation loss: 0.6273014376992765.
epoch: 89, train loss: 0.6216445868715234, validation loss: 0.6858996062175088.
epoch: 90, train loss: 0.6222318296038777, validation loss: 0.6768161369406659.
epoch: 91, train loss: 0.6354895097400071, validation loss: 0.6448652679505555.
epoch: 92, train loss: 0.635068051038532, validation loss: 0.6058942286864571.
epoch: 93, train loss: 0.6537960188104472, validation loss: 0.6406939496164736.
epoch: 94, train loss: 0.6456955753335165, validation loss: 0.6585635840892792.
epoch: 95, train loss: 0.6464902528929054, validation loss: 0.6476216225520425.
epoch: 96, train loss: 0.6753636363449447, validation loss: 0.7394436494163845.
epoch: 97, train loss: 0.604838451934517, validation loss: 0.6983788946400518.
epoch: 98, train loss: 0.6026806147820359, validation loss: 0.8248673975467682.
epoch: 99, train loss: 0.6338661660295014, validation loss: 0.6788979172706604.
epoch: 100, train loss: 0.6370191035467551, validation loss: 0.7032238711481509.
epoch: 101, train loss: 0.6381037623510448, validation loss: 0.6055534391299539.
epoch: 102, train loss: 0.6700670686336833, validation loss: 0.6994845543218695.
epoch: 103, train loss: 0.6077966244395719, validation loss: 0.7252213255218838.
epoch: 104, train loss: 0.6386485433359759, validation loss: 0.6983634039111759.
epoch: 105, train loss: 0.6532682486630361, validation loss: 0.6461059606593588.
epoch: 106, train loss: 0.5984151346967854, validation loss: 0.6775257030259008.
epoch: 107, train loss: 0.6434620435631603, validation loss: 0.6809014976024628.
epoch: 108, train loss: 0.6921982707780435, validation loss: 0.650850517594296.
epoch: 109, train loss: 0.6515258490492445, validation loss: 0.8629232541374539.
epoch: 110, train loss: 0.6135905879899997, validation loss: 0.6624785545079604.
epoch: 111, train loss: 0.6495066916723864, validation loss: 0.6214509152847788.
epoch: 112, train loss: 0.658290269177988, validation loss: 0.9107453175213026.
epoch: 113, train loss: 0.6651849692020941, validation loss: 0.6306575627430625.
epoch: 114, train loss: 0.6188611522180225, validation loss: 0.6675215324629908.
epoch: 115, train loss: 0.6358543724641887, validation loss: 0.6004370399143385.
epoch: 116, train loss: 0.6359046875336848, validation loss: 0.6920151490232219.
epoch: 117, train loss: 0.6229127418557439, validation loss: 0.6197275454583375.
epoch: 118, train loss: 0.6664135086973872, validation loss: 0.6482421263404514.
epoch: 119, train loss: 0.6473368931254115, validation loss: 0.6440365158993265.
epoch: 120, train loss: 0.6000161764271762, validation loss: 0.6250337738057842.
epoch: 121, train loss: 0.6284385607876909, validation loss: 0.630970756644788.
epoch: 122, train loss: 0.6353852221178352, validation loss: 0.7279276018557341.
epoch: 123, train loss: 0.611542041695446, validation loss: 0.6278481664864913.
epoch: 124, train loss: 0.5821585972374732, validation loss: 0.7271653802498527.
epoch: 125, train loss: 0.6327745846105278, validation loss: 0.70076675389124.
epoch: 126, train loss: 0.6413080167332921, validation loss: 0.6606998301070669.
epoch: 127, train loss: 0.6720200949305788, validation loss: 0.6777167864467787.
epoch: 128, train loss: 0.6033320735900773, validation loss: 0.6849361411903215.
epoch: 129, train loss: 0.6622324003538954, validation loss: 0.7447632369787797.
epoch: 130, train loss: 0.582254527085418, validation loss: 0.6381382372068323.
epoch: 131, train loss: 0.6281115628710581, validation loss: 0.8287549744481626.
epoch: 132, train loss: 0.667922100069326, validation loss: 0.698075136412745.
epoch: 133, train loss: 0.6528427032155728, validation loss: 0.69545084497203.
epoch: 134, train loss: 0.6224253784625902, validation loss: 0.6450039899867513.
epoch: 135, train loss: 0.6091575444838323, validation loss: 0.6322620524012524.
epoch: 136, train loss: 0.6098532028701327, validation loss: 0.6104962164941041.
epoch: 137, train loss: 0.657974413502107, validation loss: 0.6866858031438745.
epoch: 138, train loss: 0.6377551982162195, validation loss: 0.8047962629276774.
epoch: 139, train loss: 0.606315395974238, validation loss: 0.777637656616128.
epoch: 140, train loss: 0.6124409013385073, validation loss: 0.6029185056686401.
epoch: 141, train loss: 0.5952663033380421, validation loss: 0.6492800958778547.
epoch: 142, train loss: 0.6331027027117003, validation loss: 0.7023963150770768.
epoch: 143, train loss: 0.6232261809460614, validation loss: 0.6527823818766553.
epoch: 144, train loss: 0.6277567156411092, validation loss: 0.5397873145082722.
epoch: 145, train loss: 0.64627088838761, validation loss: 0.6842840495316879.
epoch: 146, train loss: 0.6584183111650135, validation loss: 0.5930609314338021.
epoch: 147, train loss: 0.6152174270481144, validation loss: 0.6153381181799847.
epoch: 148, train loss: 0.5709059681367437, validation loss: 0.6971923721873242.
epoch: 149, train loss: 0.5928064948375072, validation loss: 0.682380744944448.
epoch: 150, train loss: 0.5904422790632335, validation loss: 0.7525810949180437.
epoch: 151, train loss: 0.6086449346957951, validation loss: 0.6702741099440533.
epoch: 152, train loss: 0.5886415721626457, validation loss: 0.6699335588061291.
epoch: 153, train loss: 0.6005858076274941, validation loss: 0.6110672652721405.
epoch: 154, train loss: 0.6380309776975475, validation loss: 0.7698613664378291.
epoch: 155, train loss: 0.6053762176168074, validation loss: 0.6164008599260579.
epoch: 156, train loss: 0.5894834391020853, validation loss: 0.6271906222986139.
epoch: 157, train loss: 0.6052599120030709, validation loss: 0.6462645064229551.
epoch: 158, train loss: 0.6309385340694987, validation loss: 0.6065916924372964.
epoch: 159, train loss: 0.6392963143116838, validation loss: 0.6776775484499724.
epoch: 160, train loss: 0.6211770103065246, validation loss: 0.6355139366958452.
epoch: 161, train loss: 0.5864866075165774, validation loss: 0.767736967491067.
epoch: 162, train loss: 0.6273944252127901, validation loss: 0.6857666373252869.
epoch: 163, train loss: 0.611054939414383, validation loss: 0.6841458691203076.
epoch: 164, train loss: 0.646798486283066, validation loss: 0.6840680539608002.
epoch: 165, train loss: 0.5752334135388015, validation loss: 0.6526754939037821.
epoch: 166, train loss: 0.6107299070839488, validation loss: 0.6731231640214506.
epoch: 167, train loss: 0.6387453738155715, validation loss: 0.6298707905022994.
epoch: 168, train loss: 0.5978396770057328, validation loss: 0.6304085500862288.
epoch: 169, train loss: 0.5970943955653304, validation loss: 0.5669475055259207.
epoch: 170, train loss: 0.611337126805148, validation loss: 0.6603491176729617.
epoch: 171, train loss: 0.6118734733227196, validation loss: 0.7252957134143166.
epoch: 172, train loss: 0.5936980038334471, validation loss: 0.6317347806432972.
epoch: 173, train loss: 0.6043739105583331, validation loss: 0.6282266054464423.
epoch: 174, train loss: 0.6218242732756728, validation loss: 0.5932087444740793.
epoch: 175, train loss: 0.5963743833500311, validation loss: 0.6007494213788406.
epoch: 176, train loss: 0.5690547118493177, validation loss: 0.6645377926204515.
epoch: 177, train loss: 0.6027114757704078, validation loss: 0.836074533669845.
epoch: 178, train loss: 0.5790222262570618, validation loss: 0.6084365248680115.
epoch: 179, train loss: 0.5918659484441128, validation loss: 0.6583479215269503.
epoch: 180, train loss: 0.592523479133571, validation loss: 0.6321845339692157.
epoch: 181, train loss: 0.6125291640605401, validation loss: 0.7315052177595056.
epoch: 182, train loss: 0.5926614591014494, validation loss: 0.6636743104976156.
epoch: 183, train loss: 0.601742206363503, validation loss: 0.5812366682550182.
epoch: 184, train loss: 0.5690218967582108, validation loss: 0.7400646507740021.
epoch: 185, train loss: 0.5931263237918188, validation loss: 0.605985886376837.
epoch: 186, train loss: 0.6144306260511416, validation loss: 0.7001727663952372.
epoch: 187, train loss: 0.5714906456820462, validation loss: 0.7553704406904138.
epoch: 188, train loss: 0.6001627442486789, validation loss: 0.6592572914517444.
epoch: 189, train loss: 0.5772386165933872, validation loss: 0.5982437742793042.
epoch: 190, train loss: 0.561822922404753, validation loss: 0.7128782090933427.
epoch: 191, train loss: 0.6025872019999617, validation loss: 0.6138111003067183.
epoch: 192, train loss: 0.5888718738468415, validation loss: 0.6797469400841257.
epoch: 193, train loss: 0.5666686144717242, validation loss: 0.5798581709032473.
epoch: 194, train loss: 0.5776948334153639, validation loss: 0.5746932133384373.
epoch: 195, train loss: 0.5710223740940794, validation loss: 0.7463012337684631.
epoch: 196, train loss: 0.5877775101486696, validation loss: 0.577201054148052.
epoch: 197, train loss: 0.6247583089071677, validation loss: 0.7234471531017966.
epoch: 198, train loss: 0.5977978711828179, validation loss: 0.6044184785822163.
epoch: 199, train loss: 0.5997587863458406, validation loss: 0.6745989698430767.
epoch: 200, train loss: 0.5561062857645367, validation loss: 0.5622150120527848.
epoch: 201, train loss: 0.60883642281961, validation loss: 0.5899898072947627.
epoch: 202, train loss: 0.5718918262271706, validation loss: 0.5266587164091028.
epoch: 203, train loss: 0.5847748553534167, validation loss: 0.5650621354579926.
epoch: 204, train loss: 0.5602041950466436, validation loss: 0.6749531419380851.
epoch: 205, train loss: 0.5409468532702245, validation loss: 0.6426655663096387.
epoch: 206, train loss: 0.5450632725286921, validation loss: 0.643476418826891.
epoch: 207, train loss: 0.5546444102164803, validation loss: 0.5658355627370917.
epoch: 208, train loss: 0.5773143341781897, validation loss: 0.5747220645780149.
epoch: 209, train loss: 0.609273251316963, validation loss: 0.615034001029056.
epoch: 210, train loss: 0.596457683165139, validation loss: 0.5844228384287461.
epoch: 211, train loss: 0.5932444178183144, validation loss: 0.7046727952749833.
epoch: 212, train loss: 0.6016547376409583, validation loss: 0.7030385901098666.
epoch: 213, train loss: 0.5624638656410602, validation loss: 0.5353299223858378.
epoch: 214, train loss: 0.5929579300071122, validation loss: 0.6136979564376499.
epoch: 215, train loss: 0.5614277471642976, validation loss: 0.7753131985664368.
epoch: 216, train loss: 0.6204323918994413, validation loss: 0.6980070121910261.
epoch: 217, train loss: 0.5577106106718746, validation loss: 0.7301009051177813.
epoch: 218, train loss: 0.5559752326492869, validation loss: 0.5955778891625612.
epoch: 219, train loss: 0.5631868260989495, validation loss: 0.7772965625576351.
epoch: 220, train loss: 0.5876788242694435, validation loss: 0.605021621869958.
epoch: 221, train loss: 0.569559847542999, validation loss: 0.6983340447363646.
epoch: 222, train loss: 0.5938955244668033, validation loss: 0.5678572369658429.
epoch: 223, train loss: 0.577496862739598, validation loss: 0.6662120819091797.
epoch: 224, train loss: 0.580296669531306, validation loss: 0.6042561867962712.
epoch: 225, train loss: 0.6079302346761074, validation loss: 0.6111018554024075.
epoch: 226, train loss: 0.6187888438548517, validation loss: 0.6211332419644231.
epoch: 227, train loss: 0.5786046388499234, validation loss: 0.5886595508326655.
epoch: 228, train loss: 0.5762969192561753, validation loss: 0.6834616181643113.
epoch: 229, train loss: 0.5758512435703103, validation loss: 0.5999967339246169.
epoch: 230, train loss: 0.5950917265283953, validation loss: 0.6239506887352985.
epoch: 231, train loss: 0.5480801037965565, validation loss: 0.5944525560607081.
epoch: 232, train loss: 0.5723946538813617, validation loss: 0.5841160973776942.
epoch: 233, train loss: 0.6079773976715332, validation loss: 0.6300540436869082.
epoch: 234, train loss: 0.5629239615497239, validation loss: 0.5820649149625198.
epoch: 235, train loss: 0.561699932321496, validation loss: 0.6938352597796399.
epoch: 236, train loss: 0.6078856778801034, validation loss: 0.5853744006675222.
epoch: 237, train loss: 0.5457350762065397, validation loss: 0.56096550822258.
epoch: 238, train loss: 0.5989990488651695, validation loss: 0.6288553774356842.
epoch: 239, train loss: 0.5563561889009738, validation loss: 0.7951046357984128.
epoch: 240, train loss: 0.5602870638217401, validation loss: 0.6080734030060146.
epoch: 241, train loss: 0.5406192528818725, validation loss: 0.6121731905833535.
epoch: 242, train loss: 0.5429572408352423, validation loss: 0.5691734720831332.
epoch: 243, train loss: 0.5669279969340071, validation loss: 0.5388178462567537.
epoch: 244, train loss: 0.5340865844980293, validation loss: 0.5897973322350046.
epoch: 245, train loss: 0.5545576638584837, validation loss: 0.6771473366281261.
epoch: 246, train loss: 0.5350861270493323, validation loss: 0.6941998911940533.
epoch: 247, train loss: 0.5585788275123736, validation loss: 0.7692122899967692.
epoch: 248, train loss: 0.5693800201930037, validation loss: 0.6427894869576329.
epoch: 249, train loss: 0.5753206226530425, validation loss: 0.5666328072547913.
epoch: 250, train loss: 0.5734466713502866, validation loss: 0.646336133065431.
epoch: 251, train loss: 0.5610145918273051, validation loss: 0.6430352407953014.
epoch: 252, train loss: 0.5186433317737842, validation loss: 0.5964434133923572.
epoch: 253, train loss: 0.5831723557699711, validation loss: 0.5338963309059972.
epoch: 254, train loss: 0.564359394918888, validation loss: 0.6765099193738855.
epoch: 255, train loss: 0.536910523241813, validation loss: 0.7359798641308494.
epoch: 256, train loss: 0.5519414333575362, validation loss: 0.6138384121915569.
epoch: 257, train loss: 0.5794799464558242, validation loss: 0.5954040509203206.
epoch: 258, train loss: 0.5504925579106043, validation loss: 0.6840035306370776.
epoch: 259, train loss: 0.5737890262122548, validation loss: 0.6943319569463315.
epoch: 260, train loss: 0.5492483309102715, validation loss: 0.6657879235951797.
epoch: 261, train loss: 0.5656469022735543, validation loss: 0.5838797662569128.
epoch: 262, train loss: 0.5779164222949141, validation loss: 0.5782715859620468.
epoch: 263, train loss: 0.5293085903202722, validation loss: 0.5912081249382185.
epoch: 264, train loss: 0.559273425592195, validation loss: 0.6573382227317147.
epoch: 265, train loss: 0.5717596988612359, validation loss: 0.6784685111564138.
epoch: 266, train loss: 0.5692672788276585, validation loss: 0.6731327111306398.
epoch: 267, train loss: 0.6189854951626664, validation loss: 0.7032336748164633.
epoch: 268, train loss: 0.5715933059333661, validation loss: 0.635109859964122.
epoch: 269, train loss: 0.5666096169467366, validation loss: 0.5875886873058651.
epoch: 270, train loss: 0.5859528194873704, validation loss: 0.534163905226666.
epoch: 271, train loss: 0.5802737950185023, validation loss: 0.6665421685446864.
epoch: 272, train loss: 0.5252295798117962, validation loss: 0.6148163695698199.
epoch: 273, train loss: 0.5593251085609471, validation loss: 0.5633610318536344.
epoch: 274, train loss: 0.5427430531847368, validation loss: 0.5917577212271483.
epoch: 275, train loss: 0.5805110498032439, validation loss: 0.6033144113810166.
epoch: 276, train loss: 0.5758839203130215, validation loss: 0.6995627906011499.
epoch: 277, train loss: 0.5678079076316378, validation loss: 0.6040615918843643.
epoch: 278, train loss: 0.7060159108507524, validation loss: 0.7727132491443468.
epoch: 279, train loss: 0.5999761978420642, validation loss: 0.6167130716468977.
epoch: 280, train loss: 0.5868907825115623, validation loss: 0.6079631007235983.
epoch: 281, train loss: 0.5862336516927141, validation loss: 0.5652558052021525.
epoch: 282, train loss: 0.5680740172163062, validation loss: 0.6136478004248246.
epoch: 283, train loss: 0.5680866942766609, validation loss: 0.6063801529614822.
epoch: 284, train loss: 0.5759223376939057, validation loss: 0.6175329037334608.
epoch: 285, train loss: 0.5528138195155957, validation loss: 0.7815768044927845.
epoch: 286, train loss: 0.5622416196066305, validation loss: 0.581206906100978.
epoch: 287, train loss: 0.549604014109034, validation loss: 0.5866891968509426.
epoch: 288, train loss: 0.5320865257617531, validation loss: 0.5489026191441909.
epoch: 289, train loss: 0.5068595365646782, validation loss: 0.577975692956344.
epoch: 290, train loss: 0.574113137404853, validation loss: 0.6428851316804471.
epoch: 291, train loss: 0.5461902839875002, validation loss: 0.5464473379694897.
epoch: 292, train loss: 0.5479802934948458, validation loss: 0.7763609147590139.
epoch: 293, train loss: 0.5675061924741902, validation loss: 0.6261363612568897.
epoch: 294, train loss: 0.5695826763953638, validation loss: 0.5909371427867723.
epoch: 295, train loss: 0.5804626531557205, validation loss: 0.6300230414971061.
epoch: 296, train loss: 0.5701603233267408, validation loss: 0.5918408761853757.
epoch: 297, train loss: 0.5419794744854673, validation loss: 0.5514028214890024.
epoch: 298, train loss: 0.5496056470849099, validation loss: 0.610114319169003.
epoch: 299, train loss: 0.5523955102907409, validation loss: 0.5838129533373791.
epoch: 300, train loss: 0.5328479759190061, validation loss: 0.586802144413409.
epoch: 301, train loss: 0.5317771244759953, validation loss: 0.6768075460972993.
epoch: 302, train loss: 0.5641715231291745, validation loss: 0.7136366211849711.
epoch: 303, train loss: 0.5584653602280748, validation loss: 0.6382303782131361.
epoch: 304, train loss: 0.5968457970323913, validation loss: 0.5452899246112161.
epoch: 305, train loss: 0.5342651947375832, validation loss: 0.5502394632152889.
epoch: 306, train loss: 0.5424919672515414, validation loss: 0.5705409335053485.
epoch: 307, train loss: 0.5596373196041912, validation loss: 0.6187442113523898.
epoch: 308, train loss: 0.5774466567630068, validation loss: 0.5609219242697177.
epoch: 309, train loss: 0.5401476041986308, validation loss: 0.5804331315600354.
epoch: 310, train loss: 0.5184286953112401, validation loss: 0.7436053506706072.
epoch: 311, train loss: 0.554862156647061, validation loss: 0.5955496015756027.
epoch: 312, train loss: 0.5257363853924865, validation loss: 0.545168293559033.
epoch: 313, train loss: 0.5218712031294447, validation loss: 0.5634698958500571.
epoch: 314, train loss: 0.6000897537130828, validation loss: 0.7999208206715791.
epoch: 315, train loss: 0.5620217667807133, validation loss: 0.6173477989176045.
epoch: 316, train loss: 0.5208234990682077, validation loss: 0.5700371816106464.
epoch: 317, train loss: 0.5233019568504543, validation loss: 0.6098141436991484.
epoch: 318, train loss: 0.564239710159258, validation loss: 0.6626472524974657.
epoch: 319, train loss: 0.5146645004049354, validation loss: 0.603692889213562.
epoch: 320, train loss: 0.5076290878954284, validation loss: 0.5525956348232601.
epoch: 321, train loss: 0.5385012938341963, validation loss: 0.5587300878504048.
epoch: 322, train loss: 0.5350730886699957, validation loss: 0.7263314490732939.
epoch: 323, train loss: 0.5422068372232105, validation loss: 0.6503182131311168.
epoch: 324, train loss: 0.5417098729708872, validation loss: 0.6324357753214629.
epoch: 325, train loss: 0.5392237281033753, validation loss: 0.7248711961766948.
epoch: 326, train loss: 0.581696901026122, validation loss: 0.6311664581298828.
epoch: 327, train loss: 0.5518602884690696, validation loss: 0.5184453673984694.
epoch: 328, train loss: 0.5662086873973181, validation loss: 0.586106155877528.
epoch: 329, train loss: 0.5331763759118702, validation loss: 0.7126604525939279.
epoch: 330, train loss: 0.5309344156893021, validation loss: 0.6353247230467589.
epoch: 331, train loss: 0.5902155656880195, validation loss: 0.6256548425425654.
epoch: 332, train loss: 0.5443165474528566, validation loss: 0.5854014663592629.
epoch: 333, train loss: 0.5241455959344129, validation loss: 0.6013731593671052.
epoch: 334, train loss: 0.5241915401789027, validation loss: 0.6155786747517793.
epoch: 335, train loss: 0.5540212409211955, validation loss: 0.620126397713371.
epoch: 336, train loss: 0.5090792742344218, validation loss: 0.614261903192686.
epoch: 337, train loss: 0.5594446907896514, validation loss: 0.6029351075058398.
epoch: 338, train loss: 0.5398673076148427, validation loss: 0.6773077560507733.
epoch: 339, train loss: 0.5308699877163686, validation loss: 0.5437887738580289.
epoch: 340, train loss: 0.5397783897885489, validation loss: 0.6234217454557833.
epoch: 341, train loss: 0.5589770633693135, validation loss: 0.5744938928148021.
epoch: 342, train loss: 0.538882967392239, validation loss: 0.5918686739776445.
epoch: 343, train loss: 0.5200203648947794, validation loss: 0.560925551082777.
epoch: 344, train loss: 0.5236128213208749, validation loss: 0.6073073058024697.
epoch: 345, train loss: 0.546356241090582, validation loss: 0.5438447853793269.
epoch: 346, train loss: 0.5341175672931409, validation loss: 0.6135022795718649.
epoch: 347, train loss: 0.5459387604523143, validation loss: 0.6432000618913899.
epoch: 348, train loss: 0.5392399791183822, validation loss: 0.667079394278319.
epoch: 349, train loss: 0.5469335589660417, validation loss: 0.6585433781147003.
epoch: 350, train loss: 0.5833644931196073, validation loss: 0.5738063765608746.
epoch: 351, train loss: 0.5572009552782828, validation loss: 0.64525659058405.
epoch: 352, train loss: 0.542823550624585, validation loss: 0.5852118536182072.
epoch: 353, train loss: 0.5381880133250437, validation loss: 0.5241021954494974.
epoch: 354, train loss: 0.5243875116383264, validation loss: 0.6017492633798848.
epoch: 355, train loss: 0.5427246084180447, validation loss: 0.4909469951754031.
epoch: 356, train loss: 0.5480198575816023, validation loss: 0.5926789330399554.
epoch: 357, train loss: 0.5198515071234572, validation loss: 0.6464918333551158.
epoch: 358, train loss: 0.5450178865992695, validation loss: 0.6263600523057191.
epoch: 359, train loss: 0.5097128386617801, validation loss: 0.5041197914144268.
epoch: 360, train loss: 0.547589011421991, validation loss: 0.5422493750634401.
epoch: 361, train loss: 0.5317070675552438, validation loss: 0.6252115666866302.
epoch: 362, train loss: 0.527926001253478, validation loss: 0.51993695160617.
epoch: 363, train loss: 0.5209468521109415, validation loss: 0.585734828658726.
epoch: 364, train loss: 0.5301063585718837, validation loss: 0.591949049545371.
epoch: 365, train loss: 0.4845088247312318, validation loss: 0.5997387313324473.
epoch: 366, train loss: 0.5618723387565088, validation loss: 0.6414132817931797.
epoch: 367, train loss: 0.5579389180612127, validation loss: 0.5476873031129008.
epoch: 368, train loss: 0.526400846352271, validation loss: 0.5648549600787784.
epoch: 369, train loss: 0.5603724685283976, validation loss: 0.5390598462975543.
epoch: 370, train loss: 0.569282929148149, validation loss: 0.5927883166333904.
epoch: 371, train loss: 0.5376967440504546, validation loss: 0.7329980342284493.
epoch: 372, train loss: 0.5593876019803756, validation loss: 0.6605475467184315.
epoch: 373, train loss: 0.5400340442263752, validation loss: 0.5912382175093112.
epoch: 374, train loss: 0.5315873417832436, validation loss: 0.6588700193425884.
epoch: 375, train loss: 0.5319840746735214, validation loss: 0.6083971352680869.
epoch: 376, train loss: 0.5855511180851438, validation loss: 0.5258195179960002.
epoch: 377, train loss: 0.5463096652555903, validation loss: 0.6430766141932943.
epoch: 378, train loss: 0.5178226590703386, validation loss: 0.6072638579036879.
epoch: 379, train loss: 0.5367490348465945, validation loss: 0.5798214440760405.
epoch: 380, train loss: 0.5200792499091647, validation loss: 0.5786264629467673.
epoch: 381, train loss: 0.5226318940110163, validation loss: 0.6243127117986265.
epoch: 382, train loss: 0.5518153722679943, validation loss: 0.5418225656385007.
epoch: 383, train loss: 0.5592293758457954, validation loss: 0.6416747077651646.
epoch: 384, train loss: 0.5380179295572666, validation loss: 0.5557866031708925.
epoch: 385, train loss: 0.5106094212980445, validation loss: 0.6053526181241741.
epoch: 386, train loss: 0.5546562876723228, validation loss: 0.6715823645177095.
epoch: 387, train loss: 0.5141515500775171, validation loss: 0.5376277242017828.
epoch: 388, train loss: 0.5263018984039989, validation loss: 0.5417275221451469.
epoch: 389, train loss: 0.529995760786424, validation loss: 0.5640888551007146.
epoch: 390, train loss: 0.5388354183337011, validation loss: 0.6106499394644862.
epoch: 391, train loss: 0.5122111778740489, validation loss: 0.5176699628000674.
epoch: 392, train loss: 0.5425370584387298, validation loss: 0.5630165221898452.
epoch: 393, train loss: 0.4848768067195875, validation loss: 0.5762236448733703.
epoch: 394, train loss: 0.5808172567721901, validation loss: 0.5904072225093842.
epoch: 395, train loss: 0.5745264179662827, validation loss: 0.6750480325325675.
epoch: 396, train loss: 0.5390966675423701, validation loss: 0.592161010140958.
epoch: 397, train loss: 0.573461144342335, validation loss: 0.6446848420993142.
epoch: 398, train loss: 0.5499268403840721, validation loss: 0.607035905122757.
epoch: 399, train loss: 0.5494909357587132, validation loss: 0.5949258882066478.
epoch: 400, train loss: 0.5128555009397892, validation loss: 0.5396912512571915.
epoch: 401, train loss: 0.5552680776753557, validation loss: 0.5969477593898773.
epoch: 402, train loss: 0.5275320349209899, validation loss: 0.6557123013164686.
epoch: 403, train loss: 0.5478559307275562, validation loss: 0.6253545750742373.
epoch: 404, train loss: 0.4912951069140653, validation loss: 0.5630129329536272.
epoch: 405, train loss: 0.5136947801353735, validation loss: 0.528281446384347.
epoch: 406, train loss: 0.551941415722217, validation loss: 0.6140074639216714.
epoch: 407, train loss: 0.5596980371879875, validation loss: 0.6131350760874541.
epoch: 408, train loss: 0.5502984120484886, validation loss: 0.592217074788135.
epoch: 409, train loss: 0.5335945318871682, validation loss: 0.5931910302328027.
epoch: 410, train loss: 0.556308782975608, validation loss: 0.5979531977487647.
epoch: 411, train loss: 0.5218207625620955, validation loss: 0.5885394967120626.
epoch: 412, train loss: 0.5007019294511288, validation loss: 0.6145130953063136.
epoch: 413, train loss: 0.5309950738051615, validation loss: 0.529788973538772.
epoch: 414, train loss: 0.5240939785854533, validation loss: 0.6596328732760056.
epoch: 415, train loss: 0.536351889371872, validation loss: 0.5944471760936405.
epoch: 416, train loss: 0.5224682013376043, validation loss: 0.6155859517014545.
epoch: 417, train loss: 0.5404428227232136, validation loss: 0.5245324943376624.
epoch: 418, train loss: 0.5593228515135039, validation loss: 0.6806890148183574.
epoch: 419, train loss: 0.5364071785583409, validation loss: 0.6042403202989827.
epoch: 420, train loss: 0.511760914134323, validation loss: 0.714600990647855.
epoch: 421, train loss: 0.5289708105249142, validation loss: 0.605376185282417.
epoch: 422, train loss: 0.5411592776622247, validation loss: 0.5681119327959807.
epoch: 423, train loss: 0.5351690187913563, validation loss: 0.6281786094541135.
epoch: 424, train loss: 0.5145737334675745, validation loss: 0.4943887552489405.
epoch: 425, train loss: 0.5242458379596745, validation loss: 0.5685559977655825.
epoch: 426, train loss: 0.5519457641271276, validation loss: 0.6174035059369128.
epoch: 427, train loss: 0.5050047548539048, validation loss: 0.5501309788745382.
epoch: 428, train loss: 0.49727899382967466, validation loss: 0.6076379794141521.
epoch: 429, train loss: 0.5371358657101972, validation loss: 0.6614612379799718.
epoch: 430, train loss: 0.5356324734764362, validation loss: 0.5337232934392017.
epoch: 431, train loss: 0.5212421754904843, validation loss: 0.583265007837959.
epoch: 432, train loss: 0.5430647036351195, validation loss: 0.6100359299908513.
epoch: 433, train loss: 0.5443494690394183, validation loss: 0.506982094567755.
epoch: 434, train loss: 0.531025927274599, validation loss: 0.5688799982485564.
epoch: 435, train loss: 0.49660058688679964, validation loss: 0.5911439916361934.
epoch: 436, train loss: 0.5434301811347314, validation loss: 0.7067743487980055.
epoch: 437, train loss: 0.509360577261776, validation loss: 0.5809223522310671.
epoch: 438, train loss: 0.5317675147308122, validation loss: 0.6832380489162777.
epoch: 439, train loss: 0.5473102943612895, validation loss: 0.5997358897457952.
epoch: 440, train loss: 0.5551595489639755, validation loss: 0.635657875434212.
epoch: 441, train loss: 0.5508892506087592, validation loss: 0.5473302149254343.
epoch: 442, train loss: 0.5421072020443207, validation loss: 0.5369469406812087.
epoch: 443, train loss: 0.5156437829820388, validation loss: 0.5424986157728278.
epoch: 444, train loss: 0.5054556046604016, validation loss: 0.615156492461329.
epoch: 445, train loss: 0.5270042459078885, validation loss: 0.8576224044613217.
epoch: 446, train loss: 0.5829950617540867, validation loss: 0.5763770419618358.
epoch: 447, train loss: 0.505559324808077, validation loss: 0.5382566542729087.
epoch: 448, train loss: 0.5228107380210807, validation loss: 0.6874637759250143.
epoch: 449, train loss: 0.5053545054766017, validation loss: 0.5873556182436321.
epoch: 450, train loss: 0.5324600105165341, validation loss: 0.5588299347006757.
epoch: 451, train loss: 0.5173691579508125, validation loss: 0.5629099477892336.
epoch: 452, train loss: 0.5548953547937061, validation loss: 0.4800503856461981.
epoch: 453, train loss: 0.5495817338654755, validation loss: 0.6370494210201761.
epoch: 454, train loss: 0.5174375468984657, validation loss: 0.7051969960979794.
epoch: 455, train loss: 0.4888813736241892, validation loss: 0.7742637978947681.
epoch: 456, train loss: 0.5469636304662862, validation loss: 0.5397212401680325.
epoch: 457, train loss: 0.49823909081997125, validation loss: 0.5931481369163679.
epoch: 458, train loss: 0.5002280522923951, validation loss: 0.5501240932423136.
epoch: 459, train loss: 0.46795834095106215, validation loss: 0.549262101235597.
epoch: 460, train loss: 0.534563380917278, validation loss: 0.546657216289769.
epoch: 461, train loss: 0.48054505255791025, validation loss: 0.5219354538813882.
epoch: 462, train loss: 0.5410334696190073, validation loss: 0.6506725808848506.
epoch: 463, train loss: 0.6075051117927657, validation loss: 0.7577010639335798.
epoch: 464, train loss: 0.5814025505967096, validation loss: 0.5994356157987014.
epoch: 465, train loss: 0.5296346580763476, validation loss: 0.5311515383098436.
epoch: 466, train loss: 0.5416706827802396, validation loss: 0.5788189198659814.
epoch: 467, train loss: 0.5539500326465029, validation loss: 0.5724634981673696.
epoch: 468, train loss: 0.507021258867115, validation loss: 0.4959270396958227.
epoch: 469, train loss: 0.5345744929455836, validation loss: 0.582102533267892.
epoch: 470, train loss: 0.5494492753930048, validation loss: 0.5651733577251434.
epoch: 471, train loss: 0.5024027760149142, validation loss: 0.5351421962613645.
epoch: 472, train loss: 0.5261627461658706, validation loss: 0.6753354020740675.
epoch: 473, train loss: 0.5021978387045204, validation loss: 0.5873525097318317.
epoch: 474, train loss: 0.5387570110209491, validation loss: 0.6620434159817903.
epoch: 475, train loss: 0.4938805587247971, validation loss: 0.6750552628351294.
epoch: 476, train loss: 0.532131554063307, validation loss: 0.5958414907040803.
epoch: 477, train loss: 0.5546436205916448, validation loss: 0.6199410972387894.
epoch: 478, train loss: 0.5363009726509042, validation loss: 0.533165240417356.
epoch: 479, train loss: 0.4968344176854562, validation loss: 0.5640181834283082.
epoch: 480, train loss: 0.4947384162506926, validation loss: 0.6025212951328444.
epoch: 481, train loss: 0.5460309207166006, validation loss: 0.5860810655614604.
epoch: 482, train loss: 0.5303934470776024, validation loss: 0.5903880000114441.
epoch: 483, train loss: 0.5231561816613609, validation loss: 0.5610161773536516.
epoch: 484, train loss: 0.510826146383898, validation loss: 0.5368644789509152.
epoch: 485, train loss: 0.5433867372777483, validation loss: 0.6741619861644247.
epoch: 486, train loss: 0.493117100875312, validation loss: 0.6074520569780598.
epoch: 487, train loss: 0.49826451151742845, validation loss: 0.5329069210135419.
epoch: 488, train loss: 0.526168982506892, validation loss: 0.5560722571352253.
epoch: 489, train loss: 0.4984217394109166, validation loss: 0.5807332577912704.
epoch: 490, train loss: 0.5047034751111215, validation loss: 0.5880100584548452.
epoch: 491, train loss: 0.5332957522584758, validation loss: 0.6125453645768373.
epoch: 492, train loss: 0.5243410025167903, validation loss: 0.6394407425237738.
epoch: 493, train loss: 0.5177992948698341, validation loss: 0.6090915565905364.
epoch: 494, train loss: 0.5741496036905761, validation loss: 0.5838368923767753.
epoch: 495, train loss: 0.537155634766325, validation loss: 0.6484632077424423.
epoch: 496, train loss: 0.512741454970946, validation loss: 0.5381368191345878.
epoch: 497, train loss: 0.5287250788933641, validation loss: 0.6110313340373661.
epoch: 498, train loss: 0.5055215241165336, validation loss: 0.5748531611069388.
epoch: 499, train loss: 0.5264259579531644, validation loss: 0.5828212175680243.
epoch: 500, train loss: 0.4718594732907934, validation loss: 0.6156935614088307.
epoch: 501, train loss: 0.48536705013808856, validation loss: 0.6231730204561482.
epoch: 502, train loss: 0.5020069388348029, validation loss: 0.6592385768890381.
epoch: 503, train loss: 0.4881723759644622, validation loss: 0.5988956249278524.
epoch: 504, train loss: 0.5418161302804947, validation loss: 0.511087452587874.
epoch: 505, train loss: 0.5031789006716615, validation loss: 0.601681289465531.
epoch: 506, train loss: 0.5072516544696388, validation loss: 0.6955787876377935.
epoch: 507, train loss: 0.5518231022795406, validation loss: 0.5644823856975721.
epoch: 508, train loss: 0.5404179827609193, validation loss: 0.6029904121937959.
epoch: 509, train loss: 0.4966170850696914, validation loss: 0.5768110143101733.
epoch: 510, train loss: 0.47474353945036546, validation loss: 0.5669033423714016.
epoch: 511, train loss: 0.5346461034149205, validation loss: 0.642136521961378.
epoch: 512, train loss: 0.5075298465720011, validation loss: 0.6321332052997921.
epoch: 513, train loss: 0.5017650597686067, validation loss: 0.8506026475325875.
epoch: 514, train loss: 0.5963955283711809, validation loss: 0.6197718148646147.
epoch: 515, train loss: 0.5431686697203085, validation loss: 0.5780723198600437.
epoch: 516, train loss: 0.4994783904574333, validation loss: 0.603454756995906.
epoch: 517, train loss: 0.5250291179079528, validation loss: 0.5486979912156644.
epoch: 518, train loss: 0.5208468251272079, validation loss: 0.5147735191428143.
epoch: 519, train loss: 0.526314737736632, validation loss: 0.5262386358302572.
epoch: 520, train loss: 0.47540734940712603, validation loss: 0.5773759056692538.
epoch: 521, train loss: 0.5380697808134447, validation loss: 0.6801235066807788.
epoch: 522, train loss: 0.5212625675245163, validation loss: 0.6844678547071374.
epoch: 523, train loss: 0.5342778087755956, validation loss: 0.5217369315416917.
epoch: 524, train loss: 0.538311804106476, validation loss: 0.596319370943567.
epoch: 525, train loss: 0.5024796576674925, validation loss: 0.6192865812260172.
epoch: 526, train loss: 0.5136132970315601, validation loss: 0.6157233728014905.
epoch: 527, train loss: 0.47720228641405016, validation loss: 0.5683816036452418.
epoch: 528, train loss: 0.48542421112913603, validation loss: 0.5808978871158932.
epoch: 529, train loss: 0.5098148283608462, validation loss: 0.5702749801718671.
epoch: 530, train loss: 0.5158073882991021, validation loss: 0.5402558420015418.
epoch: 531, train loss: 0.5714202318169656, validation loss: 0.5154675802458888.
epoch: 532, train loss: 0.5324524200837547, validation loss: 0.5455124430034471.
epoch: 533, train loss: 0.525952251405891, validation loss: 0.5893968278947084.
epoch: 534, train loss: 0.5291191809767977, validation loss: 0.5637769776841869.
epoch: 535, train loss: 0.5109831880812251, validation loss: 0.5664473176002502.
epoch: 536, train loss: 0.4996451318537423, validation loss: 0.5171591846839242.
epoch: 537, train loss: 0.4894621456981799, validation loss: 0.5480968433877696.
epoch: 538, train loss: 0.506772937304383, validation loss: 0.5998288380063098.
epoch: 539, train loss: 0.515827572127001, validation loss: 0.5571864636048026.
epoch: 540, train loss: 0.5053653488738821, validation loss: 0.49699911863907525.
epoch: 541, train loss: 0.5383802905268625, validation loss: 0.5988549564195715.
epoch: 542, train loss: 0.5041497822748412, validation loss: 0.512556536042172.
epoch: 543, train loss: 0.5492059492736782, validation loss: 0.5544952063456826.
epoch: 544, train loss: 0.5277269514055427, validation loss: 0.5029496071131333.
epoch: 545, train loss: 0.4795108339108458, validation loss: 0.5543627557547196.
epoch: 546, train loss: 0.5179172297683331, validation loss: 0.5503854427648627.
epoch: 547, train loss: 0.49560397808704904, validation loss: 0.6080356175484865.
epoch: 548, train loss: 0.5157225265962269, validation loss: 0.6353250042251919.
epoch: 549, train loss: 0.5102660623165446, validation loss: 0.5612393980440886.
epoch: 550, train loss: 0.5072601262582551, validation loss: 0.560175693553427.
epoch: 551, train loss: 0.5199058416786544, validation loss: 0.4478645363579626.
epoch: 552, train loss: 0.4838969290529916, validation loss: 0.5067194583623306.
epoch: 553, train loss: 0.5457988594650128, validation loss: 0.5820476088834845.
epoch: 554, train loss: 0.5618242728053977, validation loss: 0.6021774981332861.
epoch: 555, train loss: 0.4887507620754592, validation loss: 0.548893487971762.
epoch: 556, train loss: 0.5000596455204378, validation loss: 0.5901371266530908.
epoch: 557, train loss: 0.5120828321220678, validation loss: 0.5281580492206241.
epoch: 558, train loss: 0.519103550172727, validation loss: 0.5619636812935704.
epoch: 559, train loss: 0.5338076845221563, validation loss: 0.6651426709216574.
epoch: 560, train loss: 0.49438930514755597, validation loss: 0.541430828363999.
epoch: 561, train loss: 0.5137545607232172, validation loss: 0.6049645918866863.
epoch: 562, train loss: 0.5132866809400943, validation loss: 0.5022117949050405.
epoch: 563, train loss: 0.5029589673247906, validation loss: 0.6147021793800852.
epoch: 564, train loss: 0.5038752723997886, validation loss: 0.5641564519509025.
epoch: 565, train loss: 0.5282029699568355, validation loss: 0.6844574899777122.
epoch: 566, train loss: 0.5898388845658084, validation loss: 0.5365489889746127.
epoch: 567, train loss: 0.5201601186476716, validation loss: 0.6496116207993549.
epoch: 568, train loss: 0.5370673075181629, validation loss: 0.5351986664792766.
epoch: 569, train loss: 0.4949314117158225, validation loss: 0.5295089314813199.
epoch: 570, train loss: 0.5095923888847369, validation loss: 0.5470304890819218.
epoch: 571, train loss: 0.4853320902367251, validation loss: 0.5359164865120597.
epoch: 572, train loss: 0.4943665292011489, validation loss: 0.6625419025835784.
epoch: 573, train loss: 0.5017377805272374, validation loss: 0.5775840528633284.
epoch: 574, train loss: 0.48994702811634866, validation loss: 0.6061306310736615.
epoch: 575, train loss: 0.5616544403067423, validation loss: 0.5768527919831483.
epoch: 576, train loss: 0.5683595985174179, validation loss: 0.4921094412389009.
epoch: 577, train loss: 0.5114270586759673, validation loss: 0.4887656712013742.
epoch: 578, train loss: 0.5162523224813129, validation loss: 0.501520186662674.
epoch: 579, train loss: 0.5127652577303965, validation loss: 0.5519071493459784.
epoch: 580, train loss: 0.5255869013180426, validation loss: 0.4377209064753159.
epoch: 581, train loss: 0.4709511222915912, validation loss: 0.6889906072098276.
epoch: 582, train loss: 0.5289168325039225, validation loss: 0.6734072255051654.
epoch: 583, train loss: 0.5529014822266517, validation loss: 0.5644173984942229.
epoch: 584, train loss: 0.47205911713455795, validation loss: 0.5308029055595398.
epoch: 585, train loss: 0.5120525289019313, validation loss: 0.5374092012643814.
epoch: 586, train loss: 0.5158287815817999, validation loss: 0.5579410273095836.
epoch: 587, train loss: 0.5292259765054108, validation loss: 0.6093221656654192.
epoch: 588, train loss: 0.5215994544805737, validation loss: 0.5838725890802301.
epoch: 589, train loss: 0.5386522525767667, validation loss: 0.529271116723185.
epoch: 590, train loss: 0.4964866651854384, validation loss: 0.620532821054044.
epoch: 591, train loss: 0.5251962049018353, validation loss: 0.584568440914154.
epoch: 592, train loss: 0.5066354210497043, validation loss: 0.5471446591874828.
epoch: 593, train loss: 0.5313083340815448, validation loss: 0.5431646911994271.
epoch: 594, train loss: 0.48724362636924884, validation loss: 0.557072920643765.
epoch: 595, train loss: 0.5083615615827228, validation loss: 0.5486432715602543.
epoch: 596, train loss: 0.49026370882441145, validation loss: 0.5951160646003225.
epoch: 597, train loss: 0.47667084470254567, validation loss: 0.6238818894261899.
epoch: 598, train loss: 0.4966863161380138, validation loss: 0.5455035956009574.
epoch: 599, train loss: 0.5269830505782311, validation loss: 0.5830390168272931.
epoch: 600, train loss: 0.4949805282671517, validation loss: 0.6285053284271903.
epoch: 601, train loss: 0.5313028132696764, validation loss: 0.6692077012165732.
epoch: 602, train loss: 0.5538318846203866, validation loss: 0.5646375249261442.
epoch: 603, train loss: 0.5472298699234603, validation loss: 0.5838224784187649.
epoch: 604, train loss: 0.5472788992551488, validation loss: 0.6363306784111521.
epoch: 605, train loss: 0.5158473184896172, validation loss: 0.5045719211516173.
epoch: 606, train loss: 0.520970672779127, validation loss: 0.5655809589054274.
epoch: 607, train loss: 0.5116291896465721, validation loss: 0.48951669750006305.
epoch: 608, train loss: 0.523091246638823, validation loss: 0.5634560753469882.
epoch: 609, train loss: 0.4936618891057618, validation loss: 0.5910566164099652.
epoch: 610, train loss: 0.5140372878367748, validation loss: 0.5566964862139329.
epoch: 611, train loss: 0.4738546760257231, validation loss: 0.6175189549508302.
epoch: 612, train loss: 0.4811673495200796, validation loss: 0.52738832520402.
epoch: 613, train loss: 0.5021009603771595, validation loss: 0.5242882817983627.
epoch: 614, train loss: 0.4799147748619045, validation loss: 0.6199658059555552.
epoch: 615, train loss: 0.4891386954882823, validation loss: 0.5342815868232561.
epoch: 616, train loss: 0.4823770017252056, validation loss: 0.5180847476357999.
epoch: 617, train loss: 0.5139882520798149, validation loss: 0.565799549869869.
epoch: 618, train loss: 0.48820572517333777, validation loss: 0.49188015771948773.
epoch: 619, train loss: 0.493213026348604, validation loss: 0.6346820929776067.
epoch: 620, train loss: 0.4784532587189193, validation loss: 0.5267228587813999.
epoch: 621, train loss: 0.5086375029262052, validation loss: 0.5489568697369617.
epoch: 622, train loss: 0.5078397179962298, validation loss: 0.5596505999565125.
epoch: 623, train loss: 0.5082781310748616, validation loss: 0.5366466887619185.
epoch: 624, train loss: 0.4741214114591616, validation loss: 0.5231342542430629.
epoch: 625, train loss: 0.6587021402809599, validation loss: 0.9256393313407898.
epoch: 626, train loss: 0.7542920205571236, validation loss: 0.7338491004446278.
epoch: 627, train loss: 0.7367213849627644, validation loss: 0.670269074647323.
epoch: 628, train loss: 0.6853748117018184, validation loss: 0.6817622171795886.
epoch: 629, train loss: 0.6567488178747509, validation loss: 0.5999759280163309.
epoch: 630, train loss: 0.628230314189141, validation loss: 0.6916099398032479.
epoch: 631, train loss: 0.6045645404299465, validation loss: 0.6435017417306486.
epoch: 632, train loss: 0.5789540019057212, validation loss: 0.6879709350026172.
epoch: 633, train loss: 0.6152814930185265, validation loss: 0.6119288478208624.
epoch: 634, train loss: 0.5683940657235067, validation loss: 0.6094833029353101.
epoch: 635, train loss: 0.5345521402468375, validation loss: 0.5751459715159043.
epoch: 636, train loss: 0.5518496364628503, validation loss: 0.6537675922331603.
epoch: 637, train loss: 0.5354739877335523, validation loss: 0.5369644385317097.
epoch: 638, train loss: 0.5590374915424837, validation loss: 0.5875780854536139.
epoch: 639, train loss: 0.5069486481060675, validation loss: 0.5694249544454657.
epoch: 640, train loss: 0.5377602625057238, validation loss: 0.5442816161591074.
epoch: 641, train loss: 0.5372728366370595, validation loss: 0.7347600641457931.
epoch: 642, train loss: 0.5158742539106159, validation loss: 0.5827076875645182.
epoch: 643, train loss: 0.5054968350797618, validation loss: 0.6025907915571461.
epoch: 644, train loss: 0.5219498391545146, validation loss: 0.5435223190680795.
epoch: 645, train loss: 0.5299380924723563, validation loss: 0.5597378086784611.
epoch: 646, train loss: 0.5185035233377316, validation loss: 0.5843012890090113.
epoch: 647, train loss: 0.5080648934075592, validation loss: 0.5633370280265808.
epoch: 648, train loss: 0.5283908094834844, validation loss: 0.5362502401289733.
epoch: 649, train loss: 0.5172886745918781, validation loss: 0.6696935710699662.
epoch: 650, train loss: 0.4877551959468684, validation loss: 0.5426335645758588.
epoch: 651, train loss: 0.49584937560448955, validation loss: 0.5122250642465509.
epoch: 652, train loss: 0.5201457860546375, validation loss: 0.5544469952583313.
epoch: 653, train loss: 0.649211596595038, validation loss: 0.6981909223224806.
epoch: 654, train loss: 0.6397763192653656, validation loss: 0.6376984313778256.
epoch: 655, train loss: 0.5880411319229581, validation loss: 0.605655497830847.
epoch: 656, train loss: 0.5822204840839456, validation loss: 0.6279202103614807.
epoch: 657, train loss: 0.5529886437665432, validation loss: 0.5466743513293888.
epoch: 658, train loss: 0.5102581991515028, validation loss: 0.5818686083607052.
epoch: 659, train loss: 0.5208250809153285, validation loss: 0.6610136420830436.
epoch: 660, train loss: 0.5425608648892937, validation loss: 0.5399315305378126.
epoch: 661, train loss: 0.5189087189939043, validation loss: 0.5894018722617108.
epoch: 662, train loss: 0.5109662099168935, validation loss: 0.5969200082447218.
epoch: 663, train loss: 0.5350615114247034, validation loss: 0.6462547856828441.
epoch: 664, train loss: 0.5349600289119493, validation loss: 0.5116559046766033.
epoch: 665, train loss: 0.5035377738125827, validation loss: 0.5702173904232357.
epoch: 666, train loss: 0.5102157759557077, validation loss: 0.5805870605551678.
epoch: 667, train loss: 0.5129109704439793, validation loss: 0.5306031678033911.
epoch: 668, train loss: 0.5194571137154868, validation loss: 0.5102735848530479.
epoch: 669, train loss: 0.5195200473343561, validation loss: 0.5372905277687571.
epoch: 670, train loss: 0.48896148527434113, validation loss: 0.5683121370232623.
epoch: 671, train loss: 0.5029991318326478, validation loss: 0.5944131405457206.
epoch: 672, train loss: 0.5496329043163072, validation loss: 0.5437158747859623.
epoch: 673, train loss: 0.5175655146531009, validation loss: 0.5181777671627377.
epoch: 674, train loss: 0.49250630897666337, validation loss: 0.5604609678620878.
epoch: 675, train loss: 0.5545787334168722, validation loss: 0.5705047210921412.
epoch: 676, train loss: 0.5019405279137673, validation loss: 0.564748754967814.
epoch: 677, train loss: 0.4941383036998434, validation loss: 0.5376364446204641.
epoch: 678, train loss: 0.47923532634153276, validation loss: 0.6629158012245012.
epoch: 679, train loss: 0.526788988107935, validation loss: 0.49613327306249866.
epoch: 680, train loss: 0.5234426261361586, validation loss: 0.7747095913990684.
epoch: 681, train loss: 0.5769125776826789, validation loss: 0.5202034958030867.
epoch: 682, train loss: 0.4756543424424775, validation loss: 0.6492127050524172.
epoch: 683, train loss: 0.5183443123594337, validation loss: 0.5413569658994675.
epoch: 684, train loss: 0.47560912794476257, validation loss: 0.6261205854623214.
epoch: 685, train loss: 0.5233435830391875, validation loss: 0.7880277659582056.
epoch: 686, train loss: 0.5111521971881936, validation loss: 0.5210909234440845.
epoch: 687, train loss: 0.49116443863155645, validation loss: 0.5050866927789606.
epoch: 688, train loss: 0.5187962865884151, validation loss: 0.6171328244001969.
epoch: 689, train loss: 0.5425645643417988, validation loss: 0.5835462458755659.
epoch: 690, train loss: 0.5177737165481673, validation loss: 0.5304510722989622.
epoch: 691, train loss: 0.5310073273444395, validation loss: 0.5755073680825855.
epoch: 692, train loss: 0.5204184704690898, validation loss: 0.6750002244244451.
epoch: 693, train loss: 0.5128530917364523, validation loss: 0.4873361036829326.
epoch: 694, train loss: 0.5252906090896065, validation loss: 0.5806984473829684.
epoch: 695, train loss: 0.5076602758890992, validation loss: 0.477272418530091.
epoch: 696, train loss: 0.5179155987063679, validation loss: 0.5270810839922532.
epoch: 697, train loss: 0.49071679380508737, validation loss: 0.5897627991178761.
epoch: 698, train loss: 0.46669419465261863, validation loss: 0.6039439491603685.
epoch: 699, train loss: 0.5141568092304633, validation loss: 0.6705391795738883.
epoch: 700, train loss: 0.4707867120384076, validation loss: 0.5411454465078271.
epoch: 701, train loss: 0.5372511393159901, validation loss: 0.6875757458417312.
epoch: 702, train loss: 0.5040491600649073, validation loss: 0.5363731319489686.
epoch: 703, train loss: 0.4859890057406294, validation loss: 0.5865972080956334.
epoch: 704, train loss: 0.4916753870084745, validation loss: 0.5195118370263473.
epoch: 705, train loss: 0.5372019541372947, validation loss: 0.5673058032989502.
epoch: 706, train loss: 0.5661799988341988, validation loss: 0.5316098526768063.
epoch: 707, train loss: 0.49265226393664646, validation loss: 0.5524334013462067.
epoch: 708, train loss: 0.5541619695381287, validation loss: 0.5328758410785509.
epoch: 709, train loss: 0.48089375121330996, validation loss: 0.6590505462625752.
epoch: 710, train loss: 0.4924353871050231, validation loss: 0.5395394213821577.
epoch: 711, train loss: 0.5149806409800818, validation loss: 0.617340984551803.
epoch: 712, train loss: 0.5051346183370012, validation loss: 0.5877707283134046.
epoch: 713, train loss: 0.4917984960276052, validation loss: 0.5387944592081982.
epoch: 714, train loss: 0.4902551742868686, validation loss: 0.5034226865872092.
epoch: 715, train loss: 0.5157650864999229, validation loss: 0.713396844656571.
epoch: 716, train loss: 0.5071302873825808, validation loss: 0.5784880421731783.
epoch: 717, train loss: 0.5043387711048126, validation loss: 0.6764226983422819.
epoch: 718, train loss: 0.5623606094800004, validation loss: 0.5441113878851351.
epoch: 719, train loss: 0.5221558932317506, validation loss: 0.6061603699041449.
epoch: 720, train loss: 0.5319410718362266, validation loss: 0.5625473014686418.
epoch: 721, train loss: 0.5326006170533119, validation loss: 0.5461446474427762.
epoch: 722, train loss: 0.5208909460984239, validation loss: 0.5741113139235455.
epoch: 723, train loss: 0.4924590323769718, validation loss: 0.6058343441590018.
epoch: 724, train loss: 0.5064423260612225, validation loss: 0.5659283457890801.
epoch: 725, train loss: 0.5140750513437691, validation loss: 0.507879552633866.
epoch: 726, train loss: 0.48679965201320996, validation loss: 0.5274432651374651.
epoch: 727, train loss: 0.5079840075805646, validation loss: 0.5554043326688849.
epoch: 728, train loss: 0.5766393908666908, validation loss: 0.5660568216572637.
epoch: 729, train loss: 0.5540140252047723, validation loss: 0.5675289410611858.
epoch: 730, train loss: 0.5667355305284535, validation loss: 0.513699532850929.
epoch: 731, train loss: 0.4993574653470188, validation loss: 0.607437234857808.
epoch: 732, train loss: 0.48964701100773766, validation loss: 0.6375368418900863.
epoch: 733, train loss: 0.5128748237813284, validation loss: 0.5398934794508893.
epoch: 734, train loss: 0.5193066447973251, validation loss: 0.5328128674755925.
epoch: 735, train loss: 0.46326161989378273, validation loss: 0.5339918641940408.
epoch: 736, train loss: 0.46005676563726655, validation loss: 0.5639382406421329.
epoch: 737, train loss: 0.5232753478879228, validation loss: 0.5964037866696067.
epoch: 738, train loss: 0.4954355274318555, validation loss: 0.5978321873623392.
epoch: 739, train loss: 0.5230184919243559, validation loss: 0.572601458300715.
epoch: 740, train loss: 0.5036164524905179, validation loss: 0.6136489465184833.
epoch: 741, train loss: 0.48411535751928975, validation loss: 0.5471816062927246.
epoch: 742, train loss: 0.5099491403190368, validation loss: 0.6005747525588326.
epoch: 743, train loss: 0.5586350833604096, validation loss: 0.5588781976181528.
epoch: 744, train loss: 0.4977994342462732, validation loss: 0.6235681746316992.
epoch: 745, train loss: 0.5084932271493684, validation loss: 0.56881157859512.
epoch: 746, train loss: 0.48970256376703947, validation loss: 0.5390575968700907.
epoch: 747, train loss: 0.4948887431293453, validation loss: 0.576680944017742.
epoch: 748, train loss: 0.5072731967639486, validation loss: 0.5799937986809275.
epoch: 749, train loss: 0.497109311983126, validation loss: 0.4874134115550829.
epoch: 750, train loss: 0.5248685703365081, validation loss: 0.6284704687802688.
epoch: 751, train loss: 0.5125329467134738, validation loss: 0.5404328509517338.
epoch: 752, train loss: 0.5253788651129522, validation loss: 0.563368981299193.
epoch: 753, train loss: 0.48163760186882193, validation loss: 0.5099929221298384.
epoch: 754, train loss: 0.526662640341925, validation loss: 0.5513982617336771.
epoch: 755, train loss: 0.49404218751902973, validation loss: 0.7273085531981095.
epoch: 756, train loss: 0.4797063446646437, validation loss: 0.5134132348972819.
epoch: 757, train loss: 0.5401578510026319, validation loss: 0.5528048315773839.
epoch: 758, train loss: 0.4832569945842848, validation loss: 0.5439346756624139.
epoch: 759, train loss: 0.47846883890825676, validation loss: 0.5864912038264067.
epoch: 760, train loss: 0.5118351662104282, validation loss: 0.6113625972167306.
epoch: 761, train loss: 0.5017945218250293, validation loss: 0.5727976223696833.
epoch: 762, train loss: 0.4966932241249522, validation loss: 0.5437506748282391.
epoch: 763, train loss: 0.48088071133018634, validation loss: 0.6268585168797037.
epoch: 764, train loss: 0.5324820068177827, validation loss: 0.6018079746028652.
epoch: 765, train loss: 0.5135814224908112, validation loss: 0.48903826138247614.
epoch: 766, train loss: 0.4691581333722543, validation loss: 0.5892790050610252.
epoch: 767, train loss: 0.4618805095963522, validation loss: 0.5617030016753984.
epoch: 768, train loss: 0.5259955068793866, validation loss: 0.4431336677592734.
epoch: 769, train loss: 0.4636087866004454, validation loss: 0.6158147557922031.
epoch: 770, train loss: 0.49412036953716104, validation loss: 0.6722985713378243.
epoch: 771, train loss: 0.47979593194952797, validation loss: 0.584005752335424.
epoch: 772, train loss: 0.4451278561572416, validation loss: 0.49402530880078027.
epoch: 773, train loss: 0.49579770056479566, validation loss: 0.5847761754108511.
epoch: 774, train loss: 0.5424723183616585, validation loss: 0.606411090363627.
epoch: 775, train loss: 0.5230747820860749, validation loss: 0.6149707190368486.
epoch: 776, train loss: 0.499831365199264, validation loss: 0.508722195158834.
epoch: 777, train loss: 0.4724208414554596, validation loss: 0.5625233196693918.
epoch: 778, train loss: 0.4820822232633556, validation loss: 0.5582080289073612.
epoch: 779, train loss: 0.49993006338220125, validation loss: 0.5513106765954391.
epoch: 780, train loss: 0.4759288925096529, validation loss: 0.561841774245967.
epoch: 781, train loss: 0.5079075113075588, validation loss: 0.5813087127778841.
epoch: 782, train loss: 0.4960657691736834, validation loss: 0.7011986167534537.
epoch: 783, train loss: 0.5504365758884937, validation loss: 0.6123432219028473.
epoch: 784, train loss: 0.49761290834584365, validation loss: 0.5089247019394584.
epoch: 785, train loss: 0.48945687246431996, validation loss: 0.5285191872845525.
epoch: 786, train loss: 0.5098788293950055, validation loss: 0.5490622559319371.
epoch: 787, train loss: 0.45044438978400797, validation loss: 0.5869569817314977.
epoch: 788, train loss: 0.5266235022369875, validation loss: 0.5800927138846853.
epoch: 789, train loss: 0.4665090526462695, validation loss: 0.6005237400531769.
epoch: 790, train loss: 0.48508224178344833, validation loss: 0.49654483795166016.
epoch: 791, train loss: 0.519184282340041, validation loss: 0.5779040611308554.
epoch: 792, train loss: 0.5185642827541457, validation loss: 0.5615451387737108.
epoch: 793, train loss: 0.528140450426198, validation loss: 0.5984840898410134.
epoch: 794, train loss: 0.5084953994379131, validation loss: 0.6050231910270193.
epoch: 795, train loss: 0.5173581906961738, validation loss: 0.5505924121193264.
epoch: 796, train loss: 0.4847733448131369, validation loss: 0.4824113340481468.
epoch: 797, train loss: 0.5237324531745473, validation loss: 0.523710670678512.
epoch: 798, train loss: 0.5004943963311134, validation loss: 0.6037445094274438.
epoch: 799, train loss: 0.49543824422796934, validation loss: 0.49512258560761163.
epoch: 800, train loss: 0.47137215829223666, validation loss: 0.5389015285865121.
epoch: 801, train loss: 0.4908553482195653, validation loss: 0.5054427514905515.
epoch: 802, train loss: 0.48617610704461367, validation loss: 0.5360892726027447.
epoch: 803, train loss: 0.5080969068435354, validation loss: 0.5763327207254327.
epoch: 804, train loss: 0.5875535683894376, validation loss: 0.6410465292308641.
epoch: 805, train loss: 0.5609959746719501, validation loss: 0.6064491401547971.
epoch: 806, train loss: 0.5130493791278349, validation loss: 0.5709343112033346.
epoch: 807, train loss: 0.5090429190922221, validation loss: 0.5963793098926544.
epoch: 808, train loss: 0.5333813189639958, validation loss: 0.5430871287117833.
epoch: 809, train loss: 0.4753760134955065, validation loss: 0.5305067728395048.
epoch: 810, train loss: 0.5199522129986265, validation loss: 0.5391950516597085.
epoch: 811, train loss: 0.48590563743486315, validation loss: 0.5423036165859388.
epoch: 812, train loss: 0.4907473493880088, validation loss: 0.6308616892151211.
epoch: 813, train loss: 0.4871555808760704, validation loss: 0.4796783535376839.
epoch: 814, train loss: 0.4637432217324546, validation loss: 0.7512335388556771.
epoch: 815, train loss: 0.5277434644895956, validation loss: 0.5605289320582929.
epoch: 816, train loss: 0.4763803940027132, validation loss: 0.5674762505552043.
epoch: 817, train loss: 0.4718959352018636, validation loss: 0.5803606276926787.
epoch: 818, train loss: 0.4758897183138296, validation loss: 0.5357139382673346.
epoch: 819, train loss: 0.4722347191167534, validation loss: 0.5952637338120005.
epoch: 820, train loss: 0.4419335228040678, validation loss: 0.5385201988012894.
epoch: 821, train loss: 0.5080399323220647, validation loss: 0.5233560359996298.
epoch: 822, train loss: 0.5140136804329146, validation loss: 0.5604617854823237.
epoch: 823, train loss: 0.5203647264920244, validation loss: 0.5029440081637838.
epoch: 824, train loss: 0.5288055785205386, validation loss: 0.6416748049466506.
epoch: 825, train loss: 0.5228050902075724, validation loss: 0.5649130059325177.
epoch: 826, train loss: 0.48253660204760523, validation loss: 0.547043414219566.
epoch: 827, train loss: 0.49445246351421424, validation loss: 0.48553647036137787.
epoch: 828, train loss: 0.49597420714317114, validation loss: 0.5594728861166083.
epoch: 829, train loss: 0.5145896654063409, validation loss: 0.5602746204189633.
epoch: 830, train loss: 0.48577617095151077, validation loss: 0.5979912229206251.
epoch: 831, train loss: 0.4953050249760304, validation loss: 0.5825276621009993.
epoch: 832, train loss: 0.48486083144441655, validation loss: 0.5299789387246837.
epoch: 833, train loss: 0.4417099460549311, validation loss: 0.5651132179343182.
epoch: 834, train loss: 0.463151769490417, validation loss: 0.530454687450243.
epoch: 835, train loss: 0.5337168365170103, validation loss: 0.5463123956452245.
epoch: 836, train loss: 0.48726321770510544, validation loss: 0.5881340542565221.
epoch: 837, train loss: 0.48421215710289983, validation loss: 0.578673652332762.
epoch: 838, train loss: 0.4727328760088037, validation loss: 0.655890941619873.
epoch: 839, train loss: 0.486932363668713, validation loss: 0.5534783200077389.
epoch: 840, train loss: 0.5033401026638276, validation loss: 0.577326291281244.
epoch: 841, train loss: 0.47811022182123375, validation loss: 0.5269838830699092.
epoch: 842, train loss: 0.5180665150694891, validation loss: 0.6869698244592418.
epoch: 843, train loss: 0.5326757627889651, validation loss: 0.5518601692241171.
epoch: 844, train loss: 0.4770071271362655, validation loss: 0.5975643124269403.
epoch: 845, train loss: 0.4726652526253954, validation loss: 0.5337542774884597.
epoch: 846, train loss: 0.4877880255290128, validation loss: 0.5693332073481187.
epoch: 847, train loss: 0.4947655347235706, validation loss: 0.5456687872824462.
epoch: 848, train loss: 0.4570899244842179, validation loss: 0.5267474638379138.
epoch: 849, train loss: 0.4647268461524893, validation loss: 0.5446820051773734.
epoch: 850, train loss: 0.5127473923317883, validation loss: 0.6239817310934481.
epoch: 851, train loss: 0.48527497668331915, validation loss: 0.515092015914295.
epoch: 852, train loss: 0.4717108864303029, validation loss: 0.5443693749282671.
epoch: 853, train loss: 0.5261725817525059, validation loss: 0.6098025169061578.
epoch: 854, train loss: 0.5091028169754448, validation loss: 0.5572338441143865.
epoch: 855, train loss: 0.49612859301610823, validation loss: 0.5679584948912911.
epoch: 856, train loss: 0.4656005773795854, validation loss: 0.5252677694610928.
epoch: 857, train loss: 0.5053769664480052, validation loss: 0.5889798959960109.
epoch: 858, train loss: 0.47827039248899583, validation loss: 0.5632302177988965.
epoch: 859, train loss: 0.49219060094531525, validation loss: 0.5120149682397428.
epoch: 860, train loss: 0.5044683691011657, validation loss: 0.5722754325555719.
epoch: 861, train loss: 0.5264365210992481, validation loss: 0.5438138408505399.
epoch: 862, train loss: 0.4951006094796942, validation loss: 0.5438384957935499.
epoch: 863, train loss: 0.5275449741870986, validation loss: 0.5172077754269475.
epoch: 864, train loss: 0.4922219065077808, validation loss: 0.5203928753085758.
epoch: 865, train loss: 0.46504688276610245, validation loss: 0.5481137186288834.
epoch: 866, train loss: 0.47873084329137017, validation loss: 0.6581807486388994.
epoch: 867, train loss: 0.5390764971118455, validation loss: 0.49533703534499457.
epoch: 868, train loss: 0.48482503830839735, validation loss: 0.588358021300772.
epoch: 869, train loss: 0.508525783452419, validation loss: 0.550498022981312.
epoch: 870, train loss: 0.49508768784890483, validation loss: 0.5519186945065208.
epoch: 871, train loss: 0.5002219827350126, validation loss: 0.53688859032548.
epoch: 872, train loss: 0.47184895129378784, validation loss: 0.5082230865955353.
epoch: 873, train loss: 0.5150591173303236, validation loss: 0.6326976664688276.
epoch: 874, train loss: 0.49840260276553827, validation loss: 0.5688572104858316.
epoch: 875, train loss: 0.5147366918828509, validation loss: 0.49233168363571167.
epoch: 876, train loss: 0.4972673799466649, validation loss: 0.6191444150779558.
epoch: 877, train loss: 0.4976409348325992, validation loss: 0.5568806256936945.
epoch: 878, train loss: 0.47761537941223986, validation loss: 0.5271579318720362.
epoch: 879, train loss: 0.45218241993987235, validation loss: 0.5829147592834805.
epoch: 880, train loss: 0.5646407582344265, validation loss: 0.5744641941526661.
epoch: 881, train loss: 0.5730890153198067, validation loss: 0.6385863332644753.
epoch: 882, train loss: 0.4960859122626278, validation loss: 0.5507152145323546.
epoch: 883, train loss: 0.4571561646570853, validation loss: 0.5618765548519467.
epoch: 884, train loss: 0.4979034293135372, validation loss: 0.6629808363707169.
epoch: 885, train loss: 0.44100233338294775, validation loss: 0.544325998943785.
epoch: 886, train loss: 0.459754235427314, validation loss: 0.5506456973760024.
epoch: 887, train loss: 0.4837083666149629, validation loss: 0.48101384808187897.
epoch: 888, train loss: 0.47932971631168225, validation loss: 0.4875714273556419.
epoch: 889, train loss: 0.47974895747429736, validation loss: 0.5103956201802129.
epoch: 890, train loss: 0.4735200000465463, validation loss: 0.5959301299375036.
epoch: 891, train loss: 0.47761589015295747, validation loss: 0.5476244778736777.
epoch: 892, train loss: 0.5014120159892861, validation loss: 0.6262954538283141.
epoch: 893, train loss: 0.5230995508235529, validation loss: 0.5977346482484237.
epoch: 894, train loss: 0.44412653653993517, validation loss: 0.5909853266633075.
epoch: 895, train loss: 0.4763934140631912, validation loss: 0.5690752267837524.
epoch: 896, train loss: 0.45623290962582336, validation loss: 0.5110715757245603.
epoch: 897, train loss: 0.4842579072221703, validation loss: 0.5629873534907466.
epoch: 898, train loss: 0.5350340626655369, validation loss: 0.5636665043623551.
epoch: 899, train loss: 0.5195567431526447, validation loss: 0.49454928027546924.
epoch: 900, train loss: 0.4631905446358777, validation loss: 0.5668559631575709.
epoch: 901, train loss: 0.5340593055300756, validation loss: 0.5567293827948363.
epoch: 902, train loss: 0.4852289013359525, validation loss: 0.45815239004466846.
epoch: 903, train loss: 0.46128007578193597, validation loss: 0.571550330390101.
epoch: 904, train loss: 0.5010694767083597, validation loss: 0.6717965512172036.
epoch: 905, train loss: 0.46112642375701063, validation loss: 0.8044447484223739.
epoch: 906, train loss: 0.4805008183925524, validation loss: 0.5697005300418191.
epoch: 907, train loss: 0.45461808828585737, validation loss: 0.5642241472783296.
epoch: 908, train loss: 0.5015985711452065, validation loss: 0.5989152452220088.
epoch: 909, train loss: 0.5053283281009132, validation loss: 0.5022717053475587.
epoch: 910, train loss: 0.4904145910105574, validation loss: 0.5616403481234675.
epoch: 911, train loss: 0.4847906685750419, validation loss: 0.5861488995344742.
epoch: 912, train loss: 0.4910097570594298, validation loss: 0.5297241172064906.
epoch: 913, train loss: 0.4855855226243308, validation loss: 0.5678080799786941.
epoch: 914, train loss: 0.4845393353372539, validation loss: 0.5358901036822278.
epoch: 915, train loss: 0.4811983116722982, validation loss: 0.5667443858540576.
epoch: 916, train loss: 0.48927027096442127, validation loss: 0.627118279752524.
epoch: 917, train loss: 0.4457153312930273, validation loss: 0.5804216343423595.
epoch: 918, train loss: 0.5033815940585705, validation loss: 0.6081010621526967.
epoch: 919, train loss: 0.4763811562859684, validation loss: 0.5369347372780675.
epoch: 920, train loss: 0.5409584257307403, validation loss: 0.5462395328542461.
epoch: 921, train loss: 0.5203562758931326, validation loss: 0.5319383338741634.
epoch: 922, train loss: 0.4992814906146548, validation loss: 0.5631404091482577.
epoch: 923, train loss: 0.48706281021100667, validation loss: 0.5638650681661523.
epoch: 924, train loss: 0.4686551744784784, validation loss: 0.675600106301515.
epoch: 925, train loss: 0.5033389756438928, validation loss: 0.578607079775437.
epoch: 926, train loss: 0.4987576907381005, validation loss: 0.5845463871955872.
epoch: 927, train loss: 0.5452831112736956, validation loss: 0.6002396863439808.
epoch: 928, train loss: 0.49024845099230424, validation loss: 0.5735163857107577.
epoch: 929, train loss: 0.506636229403522, validation loss: 0.5777889658575472.
epoch: 930, train loss: 0.47013884769120345, validation loss: 0.5497255351232446.
epoch: 931, train loss: 0.5302502682449621, validation loss: 0.5485316709331844.
epoch: 932, train loss: 0.5010393819677721, validation loss: 0.5567871643149335.
epoch: 933, train loss: 0.4882267734052938, validation loss: 0.5303602957207224.
epoch: 934, train loss: 0.4577992893413666, validation loss: 0.5936085361501445.
epoch: 935, train loss: 0.4943229964840303, validation loss: 0.5907734865727632.
epoch: 936, train loss: 0.46990708323246844, validation loss: 0.5187411308288574.
epoch: 937, train loss: 0.4773184359073639, validation loss: 0.542965195749117.
epoch: 938, train loss: 0.5314681613390598, validation loss: 0.5563456040361653.
epoch: 939, train loss: 0.48445069653178574, validation loss: 0.4884446716826895.
epoch: 940, train loss: 0.49875837496114434, validation loss: 0.5245269873867864.
epoch: 941, train loss: 0.5271723102265542, validation loss: 0.5527972617874974.
epoch: 942, train loss: 0.5147031289995263, validation loss: 0.5477925299302392.
epoch: 943, train loss: 0.4954057836204494, validation loss: 0.5002418406631636.
epoch: 944, train loss: 0.48699567829250195, validation loss: 0.48202073185340216.
epoch: 945, train loss: 0.5051840859542199, validation loss: 0.5556430000325908.
epoch: 946, train loss: 0.5002249875746736, validation loss: 0.506846797855004.
epoch: 947, train loss: 0.4857568816034072, validation loss: 0.5344239926856497.
epoch: 948, train loss: 0.5285655321604615, validation loss: 0.5999304885449617.
epoch: 949, train loss: 0.4877287117986504, validation loss: 0.5018847195998483.
epoch: 950, train loss: 0.48030254600244926, validation loss: 0.5209336954614391.
epoch: 951, train loss: 0.4676201295688612, validation loss: 0.469164929960085.
epoch: 952, train loss: 0.47764718518891464, validation loss: 0.5252227472222369.
epoch: 953, train loss: 0.49030718043309834, validation loss: 0.5407138129939204.
epoch: 954, train loss: 0.5230449912471509, validation loss: 0.5635716293169104.
epoch: 955, train loss: 0.5244047466768037, validation loss: 0.5445848755214525.
epoch: 956, train loss: 0.4839133926487844, validation loss: 0.47815266510714655.
epoch: 957, train loss: 0.49859467722954004, validation loss: 0.6183413850224536.
epoch: 958, train loss: 0.47586655521064725, validation loss: 0.4750025259411853.
epoch: 959, train loss: 0.45700646704490033, validation loss: 0.5331542271634807.
epoch: 960, train loss: 0.5281483759300425, validation loss: 0.698965460062027.
epoch: 961, train loss: 0.5153271375446145, validation loss: 0.5046615522840748.
epoch: 962, train loss: 0.4811437345972849, validation loss: 0.5398295826238134.
epoch: 963, train loss: 0.5093585944503819, validation loss: 0.5224524282890818.
epoch: 964, train loss: 0.5024536027820832, validation loss: 0.6152628737947216.
epoch: 965, train loss: 0.4937831573530075, validation loss: 0.4790784690691077.
epoch: 966, train loss: 0.48606831942676404, validation loss: 0.5457319384035857.
epoch: 967, train loss: 0.49535126820069936, validation loss: 0.5750373809233956.
epoch: 968, train loss: 0.4611333399464231, validation loss: 0.5077953040599823.
epoch: 969, train loss: 0.46578477063310253, validation loss: 0.5571802271449048.
epoch: 970, train loss: 0.4886996703683783, validation loss: 0.5351595088191654.
epoch: 971, train loss: 0.4775220449637929, validation loss: 0.5957029267497684.
epoch: 972, train loss: 0.4763520511738751, validation loss: 0.5602655281191287.
epoch: 973, train loss: 0.48533565790281386, validation loss: 0.6092552270578302.
epoch: 974, train loss: 0.47324217842259536, validation loss: 0.5419120775616687.
epoch: 975, train loss: 0.5032562387919207, validation loss: 0.5912693505701812.
epoch: 976, train loss: 0.5284955502923475, validation loss: 0.5468524914720784.
epoch: 977, train loss: 0.5278861984747265, validation loss: 0.535113957265149.
epoch: 978, train loss: 0.47123194779824773, validation loss: 0.5314699152241582.
epoch: 979, train loss: 0.5024082991508169, validation loss: 0.5661216520744822.
epoch: 980, train loss: 0.4518744465681391, validation loss: 0.5955813656682554.
epoch: 981, train loss: 0.514890377264504, validation loss: 0.5130625626315242.
epoch: 982, train loss: 0.47237202757542285, validation loss: 0.48585185214229254.
epoch: 983, train loss: 0.4466186435124196, validation loss: 0.5221325483011163.
epoch: 984, train loss: 0.47464577429885163, validation loss: 0.4945326641849849.
epoch: 985, train loss: 0.515225652844534, validation loss: 0.49713778236637945.
epoch: 986, train loss: 0.45332376289805143, validation loss: 0.5543740702712018.
epoch: 987, train loss: 0.5195722333881834, validation loss: 0.5308945930522421.
epoch: 988, train loss: 0.48677712555872193, validation loss: 0.5836702002131421.
epoch: 989, train loss: 0.4697171154372189, validation loss: 0.4798562617405601.
epoch: 990, train loss: 0.4728146348524531, validation loss: 0.5695251368958018.
epoch: 991, train loss: 0.5233945178055982, validation loss: 0.5485564560993857.
epoch: 992, train loss: 0.4895774473290925, validation loss: 0.6536804074826448.
epoch: 993, train loss: 0.47986111824118766, validation loss: 0.476699463699175.
epoch: 994, train loss: 0.5899349113396548, validation loss: 0.6723117245280225.
epoch: 995, train loss: 0.5473473137671795, validation loss: 0.5924115414204805.
epoch: 996, train loss: 0.5260865606299234, validation loss: 0.5740536179231561.
epoch: 997, train loss: 0.5249580411462609, validation loss: 0.5780865329763164.
epoch: 998, train loss: 0.5347548064288743, validation loss: 0.5774178738179414.
epoch: 999, train loss: 0.5213580075480523, validation loss: 0.5479421084341796.
epoch: 1000, train loss: 0.5408350067947982, validation loss: 0.5880466751430345.
epoch: 1001, train loss: 0.5176298667531495, validation loss: 0.5919468934121339.
epoch: 1002, train loss: 0.49183314683240487, validation loss: 0.4482658440652101.
epoch: 1003, train loss: 0.48278660224665193, validation loss: 0.5350516282993815.
epoch: 1004, train loss: 0.45317764170126085, validation loss: 0.6436328149360159.
epoch: 1005, train loss: 0.5241756981939351, validation loss: 0.6028257323348004.
epoch: 1006, train loss: 0.47998252442670525, validation loss: 0.5810384089532106.
epoch: 1007, train loss: 0.4819076139172283, validation loss: 0.5094607614952585.
epoch: 1008, train loss: 0.4957264105387784, validation loss: 0.5520163113656251.
epoch: 1009, train loss: 0.4976902907594628, validation loss: 0.5384372239527495.
epoch: 1010, train loss: 0.5175760140933028, validation loss: 0.5501360297203064.
epoch: 1011, train loss: 0.5065864321835544, validation loss: 0.6170459895030312.
epoch: 1012, train loss: 0.4758663439969404, validation loss: 0.6309312283992767.
epoch: 1013, train loss: 0.48580250567799316, validation loss: 0.6082303705422775.
epoch: 1014, train loss: 0.49033423670388143, validation loss: 0.5950799092002537.
epoch: 1015, train loss: 0.4939628556507443, validation loss: 0.48459823623947473.
epoch: 1016, train loss: 0.579772152211688, validation loss: 0.9206992050875789.
epoch: 1017, train loss: 0.5951365354137683, validation loss: 0.6150822172994199.
epoch: 1018, train loss: 0.5272079391763844, validation loss: 0.627970990927323.
epoch: 1019, train loss: 0.4964829886998605, validation loss: 0.5526861094910166.
epoch: 1020, train loss: 0.47749196033958996, validation loss: 0.5216901522615681.
epoch: 1021, train loss: 0.49559900027896286, validation loss: 0.5844741087892781.
epoch: 1022, train loss: 0.5071482583196885, validation loss: 0.6779842596987019.
epoch: 1023, train loss: 0.4884987124882707, validation loss: 0.5431664793387704.
epoch: 1024, train loss: 0.4852639469531698, validation loss: 0.6152459447798522.
epoch: 1025, train loss: 0.4785929346850159, validation loss: 0.5606415958508201.
epoch: 1026, train loss: 0.4893118333105647, validation loss: 0.5953139196271482.
epoch: 1027, train loss: 0.455897176757865, validation loss: 0.6595711332300435.
epoch: 1028, train loss: 0.45440972890328923, validation loss: 0.5845992526282435.
epoch: 1029, train loss: 0.47329296650142844, validation loss: 0.5394227880498638.
epoch: 1030, train loss: 0.5185279884469618, validation loss: 0.4983753698027652.
epoch: 1031, train loss: 0.5086578260594552, validation loss: 0.49125162155731866.
epoch: 1032, train loss: 0.46743840416637034, validation loss: 0.5408265655455382.
epoch: 1033, train loss: 0.48251359752558787, validation loss: 0.5458631580290587.
epoch: 1034, train loss: 0.4988758692500788, validation loss: 0.6233965184377588.
epoch: 1035, train loss: 0.49564116988160195, validation loss: 0.5573029608830161.
epoch: 1036, train loss: 0.5108407502054074, validation loss: 0.6453338680060013.
epoch: 1037, train loss: 0.46349614038379916, validation loss: 0.5669452781262605.
epoch: 1038, train loss: 0.47664106630404063, validation loss: 0.5149725921775984.
epoch: 1039, train loss: 0.491907914844128, validation loss: 0.5531586602978085.
epoch: 1040, train loss: 0.46219146114970566, validation loss: 0.5123063170391581.
epoch: 1041, train loss: 0.5670289863413627, validation loss: 0.5942645707856054.
epoch: 1042, train loss: 0.47518924944991364, validation loss: 0.5168863560842432.
epoch: 1043, train loss: 0.49984637203566523, validation loss: 0.496820581348046.
epoch: 1044, train loss: 0.439586887392429, validation loss: 0.5233666002750397.
epoch: 1045, train loss: 0.4678840562017686, validation loss: 0.5811144152413243.
epoch: 1046, train loss: 0.5021973364396927, validation loss: 0.6349170117274575.
epoch: 1047, train loss: 0.43789074809179396, validation loss: 0.6159376618654832.
epoch: 1048, train loss: 0.49443883578711695, validation loss: 0.5005554958530094.
epoch: 1049, train loss: 0.4704253125354784, validation loss: 0.5104082680266836.
epoch: 1050, train loss: 0.4975195773150943, validation loss: 0.6156931091909823.
epoch: 1051, train loss: 0.5099584437018141, validation loss: 0.5271311557811239.
epoch: 1052, train loss: 0.4712335196656918, validation loss: 0.4942622573479362.
epoch: 1053, train loss: 0.4871191579267519, validation loss: 0.5660331521345221.
epoch: 1054, train loss: 0.43331775055565963, validation loss: 0.4975213648184486.
epoch: 1055, train loss: 0.44392802217684757, validation loss: 0.5370650518199672.
epoch: 1056, train loss: 0.5233520557847592, validation loss: 0.5611980596314305.
epoch: 1057, train loss: 0.4813408559068627, validation loss: 0.6016713005045186.
epoch: 1058, train loss: 0.4677696748884446, validation loss: 0.5466515655102937.
epoch: 1059, train loss: 0.4471635289421869, validation loss: 0.5003517140512881.
epoch: 1060, train loss: 0.4746552975079335, validation loss: 0.4734375191771466.
epoch: 1061, train loss: 0.4501162444779632, validation loss: 0.5378041643163433.
epoch: 1062, train loss: 0.5141465693985651, validation loss: 0.5007895464482515.
epoch: 1063, train loss: 0.4899027929940355, validation loss: 0.5644938414511473.
epoch: 1064, train loss: 0.514405306189432, validation loss: 0.5974569942640222.
epoch: 1065, train loss: 0.49171470638808856, validation loss: 0.6146208605040675.
epoch: 1066, train loss: 0.4735530875964996, validation loss: 0.6074424839538076.
epoch: 1067, train loss: 0.46980900625023275, validation loss: 0.5055770252061926.
epoch: 1068, train loss: 0.4774392174744825, validation loss: 0.5364541968573695.
epoch: 1069, train loss: 0.49688176769729053, validation loss: 0.48943697887918225.
epoch: 1070, train loss: 0.4917474400012865, validation loss: 0.5350063650504403.
epoch: 1071, train loss: 0.4653785068781004, validation loss: 0.5557364329047825.
epoch: 1072, train loss: 0.49237579243992446, validation loss: 0.5090618165938751.
epoch: 1073, train loss: 0.48588829207310985, validation loss: 0.4868857484796773.
epoch: 1074, train loss: 0.471535802160928, validation loss: 0.5744592845439911.
epoch: 1075, train loss: 0.4899442541763323, validation loss: 0.5047231834867726.
epoch: 1076, train loss: 0.5309550469621606, validation loss: 0.555573020292365.
epoch: 1077, train loss: 0.47607000554920337, validation loss: 0.5245912373065948.
epoch: 1078, train loss: 0.4510384303167326, validation loss: 0.6501487752665644.
epoch: 1079, train loss: 0.4834684914131777, validation loss: 0.5360860487689143.
epoch: 1080, train loss: 0.5226625790563199, validation loss: 0.5093512807203375.
epoch: 1081, train loss: 0.4791332276862696, validation loss: 0.525476397379585.
epoch: 1082, train loss: 0.4785461666387156, validation loss: 0.5077836720839791.
epoch: 1083, train loss: 0.4649046924682932, validation loss: 0.6736869228922803.
epoch: 1084, train loss: 0.48981086978124916, validation loss: 0.5558265330998794.
epoch: 1085, train loss: 0.44509826942321357, validation loss: 0.5912884642248568.
epoch: 1086, train loss: 0.4971831775859955, validation loss: 0.5741015698598779.
epoch: 1087, train loss: 0.5234938698624252, validation loss: 0.596873595662739.
epoch: 1088, train loss: 0.4778410425973595, validation loss: 0.5481151407179625.
epoch: 1089, train loss: 0.5026988024831912, validation loss: 0.525933633679929.
epoch: 1090, train loss: 0.4819169671983894, validation loss: 0.557998398075933.
epoch: 1091, train loss: 0.4842390341496249, validation loss: 0.4845419862995977.
epoch: 1092, train loss: 0.4930713826089824, validation loss: 0.5035748533580614.
epoch: 1093, train loss: 0.4962735217098796, validation loss: 0.6470888075621232.
epoch: 1094, train loss: 0.5286045882406585, validation loss: 0.4950588099334551.
epoch: 1095, train loss: 0.4584076199509682, validation loss: 0.5611103384391122.
epoch: 1096, train loss: 0.45055165640804745, validation loss: 0.5115285165931868.
epoch: 1097, train loss: 0.5526484520336904, validation loss: 0.4931478085725204.
epoch: 1098, train loss: 0.49215883563417906, validation loss: 0.5970598472201306.
epoch: 1099, train loss: 0.4578044124699514, validation loss: 0.4911452933498051.
epoch: 1100, train loss: 0.5121701525165401, validation loss: 0.5694117740444515.
epoch: 1101, train loss: 0.4761527649579792, validation loss: 0.562779928031175.
epoch: 1102, train loss: 0.45810232810471035, validation loss: 0.5713303322377412.
epoch: 1103, train loss: 0.5136356808997076, validation loss: 0.5865845291510873.
epoch: 1104, train loss: 0.49939365780681644, validation loss: 0.5294390625279882.
epoch: 1105, train loss: 0.5017036579617666, validation loss: 0.5030461031457653.
epoch: 1106, train loss: 0.4902120381593704, validation loss: 0.5139174590940061.
epoch: 1107, train loss: 0.44346299576103143, validation loss: 0.5344873440006505.
epoch: 1108, train loss: 0.48367138466703785, validation loss: 0.5356040480344192.
epoch: 1109, train loss: 0.4944084108969487, validation loss: 0.4953188533368318.
epoch: 1110, train loss: 0.47983303283332684, validation loss: 0.5547039560649706.
epoch: 1111, train loss: 0.4638941743231695, validation loss: 0.5566722951505495.
epoch: 1112, train loss: 0.48643243599922287, validation loss: 0.5212990939617157.
epoch: 1113, train loss: 0.4730169835987441, validation loss: 0.5584602168072825.
epoch: 1114, train loss: 0.4698751972082558, validation loss: 0.5110630736402844.
epoch: 1115, train loss: 0.42905203246195384, validation loss: 0.48028486707936163.
epoch: 1116, train loss: 0.4588641729376732, validation loss: 0.44976819792519446.
epoch: 1117, train loss: 0.4905412238125407, validation loss: 0.5285219381684843.
epoch: 1118, train loss: 0.44973593909259235, validation loss: 0.5151469875936923.
epoch: 1119, train loss: 0.5017156669306099, validation loss: 0.5487474514090497.
epoch: 1120, train loss: 0.4649069109641084, validation loss: 0.628169922725014.
epoch: 1121, train loss: 0.5456108746178653, validation loss: 0.5199514491402585.
epoch: 1122, train loss: 0.49905521907937633, validation loss: 0.5363366590893787.
epoch: 1123, train loss: 0.45868933679313834, validation loss: 0.48185944427614624.
epoch: 1124, train loss: 0.4378614748289826, validation loss: 0.5209166278009829.
epoch: 1125, train loss: 0.43268297106847853, validation loss: 0.6233728178169416.
epoch: 1126, train loss: 0.49761840714774, validation loss: 0.5781644349512847.
epoch: 1127, train loss: 0.4641531447478391, validation loss: 0.6808880334315093.
epoch: 1128, train loss: 0.5295691015796924, validation loss: 0.5467296100181082.
epoch: 1129, train loss: 0.4660649506050512, validation loss: 0.5602738727693972.
epoch: 1130, train loss: 0.4913118116625952, validation loss: 0.6154914964800295.
epoch: 1131, train loss: 0.45045155505521584, validation loss: 0.5679061568301657.
epoch: 1132, train loss: 0.5204660984080866, validation loss: 0.5138717598241308.
epoch: 1133, train loss: 0.4416913905548393, validation loss: 0.512114044116891.
epoch: 1134, train loss: 0.4701096820175101, validation loss: 0.498772197443506.
epoch: 1135, train loss: 0.5064208811029381, validation loss: 0.5421453325644784.
epoch: 1136, train loss: 0.4301610799557572, validation loss: 0.6368443849294082.
epoch: 1137, train loss: 0.47638113345574895, validation loss: 0.5652951857318049.
epoch: 1138, train loss: 0.5535770699791952, validation loss: 0.6111588193022687.
epoch: 1139, train loss: 0.5021142553572261, validation loss: 0.5640404172565626.
epoch: 1140, train loss: 0.47158711342089765, validation loss: 0.6310210266838903.
epoch: 1141, train loss: 0.47631664724524964, validation loss: 0.5484206443247588.
epoch: 1142, train loss: 0.4869022254550129, validation loss: 0.524976442689481.
epoch: 1143, train loss: 0.4801296576720859, validation loss: 0.585041827481726.
epoch: 1144, train loss: 0.4489783393133671, validation loss: 0.45535394290219183.
epoch: 1145, train loss: 0.46515472383674134, validation loss: 0.5813165034936822.
epoch: 1146, train loss: 0.45199776119595275, validation loss: 0.5367642990920855.
epoch: 1147, train loss: 0.5244519695502903, validation loss: 0.464362862965335.
epoch: 1148, train loss: 0.49657546516952167, validation loss: 0.5843485347602678.
epoch: 1149, train loss: 0.46288778954142823, validation loss: 0.4552815724974093.
epoch: 1150, train loss: 0.48212964600379316, validation loss: 0.5720608817494434.
epoch: 1151, train loss: 0.43956251620152675, validation loss: 0.5847974328891091.
epoch: 1152, train loss: 0.4813783681447353, validation loss: 0.6681696059911147.
epoch: 1153, train loss: 0.4694426838957935, validation loss: 0.5998452668604644.
epoch: 1154, train loss: 0.4626443085320499, validation loss: 0.6264271515866985.
epoch: 1155, train loss: 0.4269235289971763, validation loss: 0.49397182982900867.
epoch: 1156, train loss: 0.5116734301004935, validation loss: 0.5829341903976772.
epoch: 1157, train loss: 0.499088823248487, validation loss: 0.530796301105748.
epoch: 1158, train loss: 0.47257680534769636, validation loss: 0.6113909003527268.
epoch: 1159, train loss: 0.4792821810606423, validation loss: 0.5226018273312113.
epoch: 1160, train loss: 0.5012883394956589, validation loss: 0.5337871079859526.
epoch: 1161, train loss: 0.45585498104401684, validation loss: 0.7366319765215334.
epoch: 1162, train loss: 0.5212848867298266, validation loss: 0.5388477146625519.
epoch: 1163, train loss: 0.49889089782303625, validation loss: 0.5591346958409185.
epoch: 1164, train loss: 0.48264599817061643, validation loss: 0.48475511566452356.
epoch: 1165, train loss: 0.49749002749219945, validation loss: 0.6115550146154736.
epoch: 1166, train loss: 0.4826775309416132, validation loss: 0.5841158174950144.
epoch: 1167, train loss: 0.4669783252094864, validation loss: 0.5265424510707026.
epoch: 1168, train loss: 0.44857411018205345, validation loss: 0.4914237442223922.
epoch: 1169, train loss: 0.4666997977626433, validation loss: 0.5023244101068248.
epoch: 1170, train loss: 0.41275314631265236, validation loss: 0.4774508929770926.
epoch: 1171, train loss: 0.4613250656685698, validation loss: 0.6405801500963129.
epoch: 1172, train loss: 0.5522199162376036, validation loss: 0.5470111545013345.
epoch: 1173, train loss: 0.47602813096221436, validation loss: 0.5305789190789928.
epoch: 1174, train loss: 0.46172709475963486, validation loss: 0.5590162795522938.
epoch: 1175, train loss: 0.48564050572180967, validation loss: 0.5702086596385293.
epoch: 1176, train loss: 0.49976850430899805, validation loss: 0.5678490957488185.
epoch: 1177, train loss: 0.49892501327969613, validation loss: 0.476642625487369.
epoch: 1178, train loss: 0.46278865854127693, validation loss: 0.48044323662052985.
epoch: 1179, train loss: 0.5212598795737695, validation loss: 0.4767728512701781.
epoch: 1180, train loss: 0.4927276247138277, validation loss: 0.6002022274162458.
epoch: 1181, train loss: 0.5099647684928474, validation loss: 0.4753369092941284.
epoch: 1182, train loss: 0.485463159620215, validation loss: 0.5364594239255657.
epoch: 1183, train loss: 0.460310460367334, validation loss: 0.5262583766294562.
epoch: 1184, train loss: 0.4750421812774938, validation loss: 0.5712444808172144.
epoch: 1185, train loss: 0.5164034892933085, validation loss: 0.5285322031249171.
epoch: 1186, train loss: 0.5018528989695628, validation loss: 0.5344974385655444.
epoch: 1187, train loss: 0.5154484372346773, validation loss: 0.6506305505400118.
epoch: 1188, train loss: 0.4733514644957464, validation loss: 0.4823620293451392.
epoch: 1189, train loss: 0.4169067281101822, validation loss: 0.6170480018076689.
epoch: 1190, train loss: 0.4363686730828854, validation loss: 0.539974147858827.
epoch: 1191, train loss: 0.49252298050517335, validation loss: 0.5778427072193312.
epoch: 1192, train loss: 0.49420479254438243, validation loss: 0.6901391874188962.
epoch: 1193, train loss: 0.5105491723489324, validation loss: 0.5530964349922927.
epoch: 1194, train loss: 0.48362494663361016, validation loss: 0.6213000559288523.
epoch: 1195, train loss: 0.4502221671266293, validation loss: 0.484156824324442.
epoch: 1196, train loss: 0.46585055283450205, validation loss: 0.5123862442762955.
epoch: 1197, train loss: 0.44240262475582437, validation loss: 0.4515190811260887.
epoch: 1198, train loss: 0.4742579153918345, validation loss: 0.5669534335965696.
epoch: 1199, train loss: 0.48782486379693407, validation loss: 0.6487645014472629.
epoch: 1200, train loss: 1.7606396609490071, validation loss: 1.5729793776636538.
epoch: 1201, train loss: 1.5018162628926268, validation loss: 1.4956655139508455.
epoch: 1202, train loss: 1.4422167211497596, validation loss: 1.4409451070039168.
epoch: 1203, train loss: 1.4035141457111464, validation loss: 1.4254645731138147.
epoch: 1204, train loss: 1.3808915702574844, validation loss: 1.3988492437030957.
epoch: 1205, train loss: 1.3603215086350746, validation loss: 1.3872384921364163.
epoch: 1206, train loss: 1.3446354406689285, validation loss: 1.3778172264928403.
epoch: 1207, train loss: 1.332679498086282, validation loss: 1.3620233846747356.
epoch: 1208, train loss: 1.3222357373718823, validation loss: 1.3538618606069814.
epoch: 1209, train loss: 1.317259885849209, validation loss: 1.350288836852364.
epoch: 1210, train loss: 1.313162273223247, validation loss: 1.344334223996038.
epoch: 1211, train loss: 1.3086483336369925, validation loss: 1.3441585146862527.
epoch: 1212, train loss: 1.3054121207753453, validation loss: 1.345966795216436.
epoch: 1213, train loss: 1.2992064854420653, validation loss: 1.3378695249557495.
epoch: 1214, train loss: 1.2955663488545548, validation loss: 1.351137917974721.
epoch: 1215, train loss: 1.2948389742352546, validation loss: 1.3240965241971223.
epoch: 1216, train loss: 1.2890152100029342, validation loss: 1.3240702255912449.
epoch: 1217, train loss: 1.2881034273620044, validation loss: 1.3213380056878794.
epoch: 1218, train loss: 1.2853450950132597, validation loss: 1.3085687678793203.
epoch: 1219, train loss: 1.2847361783368871, validation loss: 1.3209448586339536.
epoch: 1220, train loss: 1.2840947601773323, validation loss: 1.3444062004918638.
epoch: 1221, train loss: 1.2822559295444313, validation loss: 1.329287466795548.
epoch: 1222, train loss: 1.2763371380097275, validation loss: 1.3219946311867756.
epoch: 1223, train loss: 1.2749709612732634, validation loss: 1.3229715927787449.
epoch: 1224, train loss: 1.2803857512430314, validation loss: 1.3246708175410395.
epoch: 1225, train loss: 1.2813764952738351, validation loss: 1.3129568151805713.
epoch: 1226, train loss: 1.2767219138801644, validation loss: 1.314799075541289.
epoch: 1227, train loss: 1.2758668070539423, validation loss: 1.3061092780983967.
epoch: 1228, train loss: 1.2760595072300063, validation loss: 1.3060878981714663.
epoch: 1229, train loss: 1.275874962500476, validation loss: 1.3029321794924529.
epoch: 1230, train loss: 1.2794719322012105, validation loss: 1.3079136610031128.
epoch: 1231, train loss: 1.2739320457528491, validation loss: 1.3051600611728171.
epoch: 1232, train loss: 1.2748391278293154, validation loss: 1.3179283608560977.
epoch: 1233, train loss: 1.2722198361650519, validation loss: 1.3059222024420034.
epoch: 1234, train loss: 1.2732987163263723, validation loss: 1.3067456691161445.
epoch: 1235, train loss: 1.2745747784955785, validation loss: 1.3052353547967.
epoch: 1236, train loss: 1.2731689094403469, validation loss: 1.3141993906186975.
epoch: 1237, train loss: 1.2705854111855184, validation loss: 1.3006353378295898.
epoch: 1238, train loss: 1.2729919558271356, validation loss: 1.3154395248578943.
epoch: 1239, train loss: 1.269049153415435, validation loss: 1.313264732775481.
epoch: 1240, train loss: 1.2776698770873043, validation loss: 1.3145772218704224.
epoch: 1241, train loss: 1.2772617001052295, validation loss: 1.3154507616291875.
epoch: 1242, train loss: 1.2774099800564827, validation loss: 1.307636489038882.
epoch: 1243, train loss: 1.2779578101744347, validation loss: 1.3160425476405933.
epoch: 1244, train loss: 1.2743058073411293, validation loss: 1.2937945801278818.
epoch: 1245, train loss: 1.2733165146014012, validation loss: 1.2974994338077048.
epoch: 1246, train loss: 1.2747301945992566, validation loss: 1.3447185702945874.
epoch: 1247, train loss: 1.2751992109718673, validation loss: 1.2965786197911138.
epoch: 1248, train loss: 1.2724083858892459, validation loss: 1.2942492599072664.
epoch: 1249, train loss: 1.2738611206002193, validation loss: 1.3081954043844473.
epoch: 1250, train loss: 1.2735867073776526, validation loss: 1.3305566984674204.
epoch: 1251, train loss: 1.2726758598187649, validation loss: 1.2885165214538574.
epoch: 1252, train loss: 1.2677311591052134, validation loss: 1.2970878974251125.
epoch: 1253, train loss: 1.270754019054798, validation loss: 1.293530101361482.
epoch: 1254, train loss: 1.2730798732250108, validation loss: 1.29655136751092.
epoch: 1255, train loss: 1.274653858001079, validation loss: 1.2935840150584346.
epoch: 1256, train loss: 1.2733981499978162, validation loss: 1.3064938576325127.
epoch: 1257, train loss: 1.2753506045822705, validation loss: 1.3044545909632808.
epoch: 1258, train loss: 1.2856887950809723, validation loss: 1.3127009609471196.
epoch: 1259, train loss: 1.2895366806502735, validation loss: 1.3040772676467896.
epoch: 1260, train loss: 1.2838595810286495, validation loss: 1.29882478195688.
epoch: 1261, train loss: 1.276360510686122, validation loss: 1.3111518880595332.
epoch: 1262, train loss: 1.2785519645848404, validation loss: 1.2903396616811338.
epoch: 1263, train loss: 1.2723421438024678, validation loss: 1.3037394129711648.
epoch: 1264, train loss: 1.274167088193631, validation loss: 1.2903642239777937.
epoch: 1265, train loss: 1.2721540151386086, validation loss: 1.2931387009827986.
epoch: 1266, train loss: 1.2699270729624896, validation loss: 1.3102043607960576.
epoch: 1267, train loss: 1.2770116788531662, validation loss: 1.3131566047668457.
epoch: 1268, train loss: 1.2821206171578223, validation loss: 1.3050898209862087.
epoch: 1269, train loss: 1.276280989340686, validation loss: 1.2934593480566274.
epoch: 1270, train loss: 1.272571383266274, validation loss: 1.2904971267866052.
epoch: 1271, train loss: 1.2753375374942744, validation loss: 1.311745083850363.
epoch: 1272, train loss: 1.2779201761298222, validation loss: 1.2919764155926912.
epoch: 1273, train loss: 1.2752592005860914, validation loss: 1.3042488927426545.
epoch: 1274, train loss: 1.2739529729983128, validation loss: 1.2933538996655007.
epoch: 1275, train loss: 1.2728418778935704, validation loss: 1.304968388184257.
epoch: 1276, train loss: 1.2710868153003378, validation loss: 1.2893024682998657.
epoch: 1277, train loss: 1.276018425958966, validation loss: 1.3013949757036956.
epoch: 1278, train loss: 1.27605984954659, validation loss: 1.292533532432888.
epoch: 1279, train loss: 1.2798645638544626, validation loss: 1.2904661893844604.
epoch: 1280, train loss: 1.2792758711981118, validation loss: 1.2937974359678186.
epoch: 1281, train loss: 1.2775677989382264, validation loss: 1.2948810795079106.
epoch: 1282, train loss: 1.2750990729813183, validation loss: 1.288838241411292.
epoch: 1283, train loss: 1.2728793435140486, validation loss: 1.2968967168227485.
epoch: 1284, train loss: 1.270286930810421, validation loss: 1.2855314223662666.
epoch: 1285, train loss: 1.2710442564903048, validation loss: 1.2930279503697935.
epoch: 1286, train loss: 1.2747285726967208, validation loss: 1.2809140474899956.
epoch: 1287, train loss: 1.2806386521103186, validation loss: 1.3134110440378604.
epoch: 1288, train loss: 1.283224433933923, validation loss: 1.3074696271315864.
epoch: 1289, train loss: 1.283027086782893, validation loss: 1.3142141984856648.
epoch: 1290, train loss: 1.2797154724051099, validation loss: 1.29095691183339.
epoch: 1291, train loss: 1.275125714617038, validation loss: 1.283134584841521.
epoch: 1292, train loss: 1.2725562097829417, validation loss: 1.2830095342967822.
epoch: 1293, train loss: 1.2765723827782027, validation loss: 1.2934048953263655.
epoch: 1294, train loss: 1.2813397963112647, validation loss: 1.299296938854715.
epoch: 1295, train loss: 1.2769009377978264, validation loss: 1.2961818187133125.
epoch: 1296, train loss: 1.2735379824944593, validation loss: 1.314550078433493.
epoch: 1297, train loss: 1.278513694028242, validation loss: 1.2938514325929724.
epoch: 1298, train loss: 1.2719567204834124, validation loss: 1.280079748319543.
epoch: 1299, train loss: 1.2710557005821017, validation loss: 1.2859491835469785.
epoch: 1300, train loss: 1.2692010555792292, validation loss: 1.2829877967419832.
epoch: 1301, train loss: 1.2682935874396508, validation loss: 1.2853011618489805.
epoch: 1302, train loss: 1.2658668701801825, validation loss: 1.2834992875223574.
epoch: 1303, train loss: 1.2691367164664311, validation loss: 1.2833017888276472.
epoch: 1304, train loss: 1.2727033042032785, validation loss: 1.3039332576419995.
epoch: 1305, train loss: 1.2679486777804314, validation loss: 1.2809746317241504.
epoch: 1306, train loss: 1.2678179215947423, validation loss: 1.2857863954875781.
epoch: 1307, train loss: 1.2691140295168675, validation loss: 1.283807054809902.
epoch: 1308, train loss: 1.263288388558484, validation loss: 1.2823592009751692.
epoch: 1309, train loss: 1.2703646366749335, validation loss: 1.3274013892464016.
epoch: 1310, train loss: 1.2843294351472767, validation loss: 1.2943955970847087.
epoch: 1311, train loss: 1.2770958974820759, validation loss: 1.2930369584456733.
epoch: 1312, train loss: 1.2737568157528518, validation loss: 1.2866245715514473.
epoch: 1313, train loss: 1.2689492899343509, validation loss: 1.3077999923540198.
epoch: 1314, train loss: 1.2706160523475858, validation loss: 1.2828503017840178.
epoch: 1315, train loss: 1.2723550041881175, validation loss: 1.3019182319226472.
epoch: 1316, train loss: 1.2699556656933706, validation loss: 1.2936047056446904.
epoch: 1317, train loss: 1.2687777247997598, validation loss: 1.28309486741605.
epoch: 1318, train loss: 1.2709298330709475, validation loss: 1.286989740703417.
epoch: 1319, train loss: 1.2693221175342524, validation loss: 1.2888113519419795.
epoch: 1320, train loss: 1.2662753960408202, validation loss: 1.2861797705940579.
epoch: 1321, train loss: 1.2683858237135301, validation loss: 1.276135449824126.
epoch: 1322, train loss: 1.2727556841089092, validation loss: 1.2750424094822095.
epoch: 1323, train loss: 1.263663575189923, validation loss: 1.2824521842210188.
epoch: 1324, train loss: 1.2703340184797935, validation loss: 1.279346455698428.
epoch: 1325, train loss: 1.2750264001548837, validation loss: 1.2801514034685881.
epoch: 1326, train loss: 1.2752408926640082, validation loss: 1.2962296112723972.
epoch: 1327, train loss: 1.2662764481448252, validation loss: 1.2802827254585598.
epoch: 1328, train loss: 1.2708412824420754, validation loss: 1.2952978662822558.
epoch: 1329, train loss: 1.2738173718846173, validation loss: 1.2760537240816199.
epoch: 1330, train loss: 1.270038540210199, validation loss: 1.2898870862048606.
epoch: 1331, train loss: 1.2671878523782854, validation loss: 1.2863435019617495.
epoch: 1332, train loss: 1.26395692628458, validation loss: 1.2846322474272356.
epoch: 1333, train loss: 1.267081692678119, validation loss: 1.2818020323048467.
epoch: 1334, train loss: 1.268550231916095, validation loss: 1.2880220983339392.
epoch: 1335, train loss: 1.276700982260048, validation loss: 1.2992475447447405.
epoch: 1336, train loss: 1.2727322720606393, validation loss: 1.2920490606971409.
epoch: 1337, train loss: 1.2697880596195885, validation loss: 1.3078081193177595.
epoch: 1338, train loss: 1.2779608702440874, validation loss: 1.2914790122405342.
epoch: 1339, train loss: 1.2814282047639198, validation loss: 1.3068795618803606.
epoch: 1340, train loss: 1.2787950760727629, validation loss: 1.3164712397948555.
epoch: 1341, train loss: 1.2811500413702168, validation loss: 1.295161661894425.
epoch: 1342, train loss: 1.2731947198920293, validation loss: 1.307550575422204.
epoch: 1343, train loss: 1.2699871172598742, validation loss: 1.2856950708057568.
epoch: 1344, train loss: 1.2733372438938246, validation loss: 1.2976893497549968.
epoch: 1345, train loss: 1.2803627197895575, validation loss: 1.3242684188096419.
epoch: 1346, train loss: 1.2904067039489746, validation loss: 1.3045931432558142.
epoch: 1347, train loss: 1.2867062485546148, validation loss: 1.305920958518982.
epoch: 1348, train loss: 1.282418839428403, validation loss: 1.2896478798078455.
epoch: 1349, train loss: 1.2785178794773346, validation loss: 1.2983062163643215.
epoch: 1350, train loss: 1.27990962059126, validation loss: 1.2832797869392063.
epoch: 1351, train loss: 1.2739029947770846, validation loss: 1.2931310456732046.
epoch: 1352, train loss: 1.269131540158473, validation loss: 1.277983318204465.
epoch: 1353, train loss: 1.2718214715292695, validation loss: 1.2828874173371687.
epoch: 1354, train loss: 1.268041302304749, validation loss: 1.2856020823768948.
epoch: 1355, train loss: 1.2840177630065779, validation loss: 1.3126091438791025.
epoch: 1356, train loss: 1.2739403729045062, validation loss: 1.2894591870515242.
epoch: 1357, train loss: 1.272616633581459, validation loss: 1.2847815441048664.
epoch: 1358, train loss: 1.2745482582564747, validation loss: 1.2976954864419026.
epoch: 1359, train loss: 1.2761361828637778, validation loss: 1.2863202768823374.
epoch: 1360, train loss: 1.3202292656679766, validation loss: 1.3543178724206013.
epoch: 1361, train loss: 1.3160309474402612, validation loss: 1.3279450665349546.
epoch: 1362, train loss: 1.3082502675712655, validation loss: 1.3111054430837217.
epoch: 1363, train loss: 1.297183828616361, validation loss: 1.3068266329558.
epoch: 1364, train loss: 1.2883924595806577, validation loss: 1.3042374849319458.
epoch: 1365, train loss: 1.2877026971327055, validation loss: 1.2972142955531245.
epoch: 1366, train loss: 1.2840570430143163, validation loss: 1.2994694761607959.
epoch: 1367, train loss: 1.2819338851018782, validation loss: 1.3089980768120808.
epoch: 1368, train loss: 1.2834387186470382, validation loss: 1.290961706120035.
epoch: 1369, train loss: 1.2848796811672525, validation loss: 1.3050164969071099.
epoch: 1370, train loss: 1.2809826748086772, validation loss: 1.2959423376166301.
epoch: 1371, train loss: 1.2783171769675858, validation loss: 1.3103040508601977.
epoch: 1372, train loss: 1.2826163298493132, validation loss: 1.3003159605938455.
epoch: 1373, train loss: 1.2773591717448802, validation loss: 1.2985759196074114.
epoch: 1374, train loss: 1.2808109193766883, validation loss: 1.3071313837300176.
epoch: 1375, train loss: 1.276500740182509, validation loss: 1.297223837479301.
epoch: 1376, train loss: 1.2754268165028424, validation loss: 1.280027933742689.
epoch: 1377, train loss: 1.2761250646836166, validation loss: 1.2967363958773406.
epoch: 1378, train loss: 1.2743118399873785, validation loss: 1.2900555859441343.
epoch: 1379, train loss: 1.2736387974625334, validation loss: 1.2835661898488584.
epoch: 1380, train loss: 1.2779727660187887, validation loss: 1.3289111075193987.
epoch: 1381, train loss: 1.2874779023161722, validation loss: 1.2996624760005786.
epoch: 1382, train loss: 1.2844030703973333, validation loss: 1.3129814863204956.
epoch: 1383, train loss: 1.2745336294174194, validation loss: 1.2870975007181582.
epoch: 1384, train loss: 1.2746892565980963, validation loss: 1.284641094829725.
epoch: 1385, train loss: 1.2726049795063263, validation loss: 1.2855877513470857.
epoch: 1386, train loss: 1.2769536643946937, validation loss: 1.277502899584563.
epoch: 1387, train loss: 1.2717366601349016, validation loss: 1.2883055365603904.
epoch: 1388, train loss: 1.2756944861980752, validation loss: 1.2982330581416255.
epoch: 1389, train loss: 1.2766040946365496, validation loss: 1.2964187808658765.
epoch: 1390, train loss: 1.2730041250176387, validation loss: 1.3107580983120461.
epoch: 1391, train loss: 1.2732706102756186, validation loss: 1.2848244128019914.
epoch: 1392, train loss: 1.2710488159722144, validation loss: 1.2792844461358113.
epoch: 1393, train loss: 1.267947735042747, validation loss: 1.2911752877028093.
epoch: 1394, train loss: 1.2730291185029057, validation loss: 1.27729782850846.
epoch: 1395, train loss: 1.2690237115282532, validation loss: 1.2735958617666494.
epoch: 1396, train loss: 1.2694583114134061, validation loss: 1.279430073240529.
epoch: 1397, train loss: 1.2668744730293204, validation loss: 1.2875101877295452.
epoch: 1398, train loss: 1.2761718461272913, validation loss: 1.2925838283870532.
epoch: 1399, train loss: 1.2706908851588539, validation loss: 1.3139194250106812.
epoch: 1400, train loss: 1.272347679925621, validation loss: 1.2864979868349822.
epoch: 1401, train loss: 1.278941823801863, validation loss: 1.3291893212691597.
epoch: 1402, train loss: 1.2996553488827627, validation loss: 1.3106290983117146.
epoch: 1403, train loss: 1.2902711389261647, validation loss: 1.3074292566465295.
epoch: 1404, train loss: 1.2889572961614766, validation loss: 1.2965901416280996.
epoch: 1405, train loss: 1.281352621699692, validation loss: 1.2918949593668398.
epoch: 1406, train loss: 1.277254797996731, validation loss: 1.2972468293231467.
epoch: 1407, train loss: 1.2821482474650812, validation loss: 1.2919150953707488.
epoch: 1408, train loss: 1.2797770806408804, validation loss: 1.3144014089003853.
epoch: 1409, train loss: 1.282944330381691, validation loss: 1.2998970384183137.
epoch: 1410, train loss: 1.27900605682933, validation loss: 1.3002356083496758.
epoch: 1411, train loss: 1.2805994814689006, validation loss: 1.306125697882279.
epoch: 1412, train loss: 1.278810194872935, validation loss: 1.3055130450621895.
epoch: 1413, train loss: 1.277902957496293, validation loss: 1.2905580220015154.
epoch: 1414, train loss: 1.2701168289972007, validation loss: 1.2782375242399133.
epoch: 1415, train loss: 1.2808473175818766, validation loss: 1.296745989633643.
epoch: 1416, train loss: 1.2794395072744527, validation loss: 1.2931526329206384.
epoch: 1417, train loss: 1.2748640666314222, validation loss: 1.2830690663793813.
epoch: 1418, train loss: 1.2729941584648343, validation loss: 1.2984370511511099.
epoch: 1419, train loss: 1.2735584777429563, validation loss: 1.3270473272904106.
epoch: 1420, train loss: 1.2778877457347484, validation loss: 1.2988770578218543.
epoch: 1421, train loss: 1.284276838696331, validation loss: 1.317059708678204.
epoch: 1422, train loss: 1.2769010723184009, validation loss: 1.2976288536320562.
epoch: 1423, train loss: 1.2708856982922336, validation loss: 1.2861097636430159.
epoch: 1424, train loss: 1.268247661240604, validation loss: 1.301589328309764.
epoch: 1425, train loss: 1.277453867667312, validation loss: 1.3406443699546482.
epoch: 1426, train loss: 1.2795167013045845, validation loss: 1.3120790979136592.
epoch: 1427, train loss: 1.2719620881824318, validation loss: 1.270217195801113.
epoch: 1428, train loss: 1.2702800068286582, validation loss: 1.2900713630344556.
epoch: 1429, train loss: 1.2672758211783313, validation loss: 1.2832062607226165.
epoch: 1430, train loss: 1.2653604516195596, validation loss: 1.303992597953133.
epoch: 1431, train loss: 1.2698362945416652, validation loss: 1.2973564241243445.
epoch: 1432, train loss: 1.2772630792145336, validation loss: 1.285177899443585.
epoch: 1433, train loss: 1.2748699822557081, validation loss: 1.2801911001620085.
epoch: 1434, train loss: 1.2679389463652164, validation loss: 1.2826116240542869.
epoch: 1435, train loss: 1.266996900969689, validation loss: 1.278141306794208.
epoch: 1436, train loss: 1.2653010941426688, validation loss: 1.2862985237785007.
epoch: 1437, train loss: 1.267157038417431, validation loss: 1.280105481977048.
epoch: 1438, train loss: 1.2766867919799385, validation loss: 1.305769293204598.
epoch: 1439, train loss: 1.2874714070503865, validation loss: 1.2894565955452297.
epoch: 1440, train loss: 1.276584506034851, validation loss: 1.282138694887576.
epoch: 1441, train loss: 1.2713582931308571, validation loss: 1.3054074308146602.
epoch: 1442, train loss: 1.2682421765196215, validation loss: 1.2824324576751045.
epoch: 1443, train loss: 1.2678771314271, validation loss: 1.2803639536318572.
epoch: 1444, train loss: 1.2696377170195274, validation loss: 1.301565787066584.
epoch: 1445, train loss: 1.2686801208268612, validation loss: 1.2998119333515996.
epoch: 1446, train loss: 1.271333568686739, validation loss: 1.2957338716672815.
epoch: 1447, train loss: 1.2697051183893047, validation loss: 1.286454827889152.
epoch: 1448, train loss: 1.2712302853208068, validation loss: 1.2890539687612783.
epoch: 1449, train loss: 1.2689925924353642, validation loss: 1.3183345535527105.
epoch: 1450, train loss: 1.2716418198489268, validation loss: 1.2863528728485107.
epoch: 1451, train loss: 1.2746849016312065, validation loss: 1.2932495811711187.
epoch: 1452, train loss: 1.2716221360985291, validation loss: 1.2827438012413357.
epoch: 1453, train loss: 1.2675816050363242, validation loss: 1.2900591311247454.
epoch: 1454, train loss: 1.2642729162076198, validation loss: 1.2878626947817595.
epoch: 1455, train loss: 1.267247004246493, validation loss: 1.29644659291143.
epoch: 1456, train loss: 1.269042873601301, validation loss: 1.2757692544356636.
epoch: 1457, train loss: 1.2802862771060488, validation loss: 1.2996603043183037.
epoch: 1458, train loss: 1.2901286608582243, validation loss: 1.2992611138716987.
epoch: 1459, train loss: 1.2808882271477935, validation loss: 1.304020601770152.
epoch: 1460, train loss: 1.2862573052765032, validation loss: 1.3008166447929714.
epoch: 1461, train loss: 1.2831384774741776, validation loss: 1.2956004816552866.
epoch: 1462, train loss: 1.2824900204982232, validation loss: 1.2948873768682065.
epoch: 1463, train loss: 1.276542226108936, validation loss: 1.2916222240613855.
epoch: 1464, train loss: 1.2822063166067141, validation loss: 1.3047869049984475.
epoch: 1465, train loss: 1.2840143234357921, validation loss: 1.299792097962421.
epoch: 1466, train loss: 1.2861198886818843, validation loss: 1.3208211090253748.
epoch: 1467, train loss: 1.2782167633739085, validation loss: 1.2936022488967232.
epoch: 1468, train loss: 1.2749306685333952, validation loss: 1.2830440842587014.
epoch: 1469, train loss: 1.2786735536855296, validation loss: 1.2999314017917798.
epoch: 1470, train loss: 1.270200564226973, validation loss: 1.2834811832593835.
epoch: 1471, train loss: 1.2732095116869024, validation loss: 1.2881699541340703.
epoch: 1472, train loss: 1.27767654624554, validation loss: 1.297670550968336.
epoch: 1473, train loss: 1.2767166850763723, validation loss: 1.297107053839642.
epoch: 1474, train loss: 1.2703586204336323, validation loss: 1.2773461704668791.
epoch: 1475, train loss: 1.2638691434072793, validation loss: 1.2847736607427183.
epoch: 1476, train loss: 1.2793206173345584, validation loss: 1.2858104446659917.
epoch: 1477, train loss: 1.2693906213165422, validation loss: 1.3102238748384558.
epoch: 1478, train loss: 1.270249282548187, validation loss: 1.2854708744132.
epoch: 1479, train loss: 1.26791371774236, validation loss: 1.2775789758433467.
epoch: 1480, train loss: 1.2682787540855758, validation loss: 1.2917602062225342.
epoch: 1481, train loss: 1.2680669115224015, validation loss: 1.281751477200052.
epoch: 1482, train loss: 1.265143331037749, validation loss: 1.2747735199720964.
epoch: 1483, train loss: 1.2635092713417264, validation loss: 1.2793780668922092.
epoch: 1484, train loss: 1.2685404490987096, validation loss: 1.2922346591949463.
epoch: 1485, train loss: 1.2641499665899014, validation loss: 1.2808200846547666.
epoch: 1486, train loss: 1.2686037339201761, validation loss: 1.2908699564311816.
epoch: 1487, train loss: 1.2700051342675445, validation loss: 1.2979199108870134.
epoch: 1488, train loss: 1.2726482546657598, validation loss: 1.2910054662953252.
epoch: 1489, train loss: 1.2750003972184767, validation loss: 1.308129932569421.
epoch: 1490, train loss: 1.2663935936919046, validation loss: 1.2762823882310286.
epoch: 1491, train loss: 1.2671801825182154, validation loss: 1.2814388897107996.
epoch: 1492, train loss: 1.2622017783856174, validation loss: 1.284142229868018.
epoch: 1493, train loss: 1.2635844180343347, validation loss: 1.286156555880671.
epoch: 1494, train loss: 1.2723548991964497, validation loss: 1.290895850762077.
epoch: 1495, train loss: 1.2777647720564396, validation loss: 1.3118875648664392.
epoch: 1496, train loss: 1.2675266823637377, validation loss: 1.2844289955885515.
epoch: 1497, train loss: 1.2622392724413392, validation loss: 1.278553667275802.
epoch: 1498, train loss: 1.258955004018381, validation loss: 1.280103299928748.
epoch: 1499, train loss: 1.2709354982463592, validation loss: 1.2975579966669497.
epoch: 1500, train loss: 1.268384079320715, validation loss: 1.2809097300405088.
epoch: 1501, train loss: 1.2799023586675662, validation loss: 1.338740763456925.
epoch: 1502, train loss: 1.284901917527575, validation loss: 1.2927557126335476.
epoch: 1503, train loss: 1.2854806086338988, validation loss: 1.291510239891384.
epoch: 1504, train loss: 1.2779788194446389, validation loss: 1.2893297983252483.
epoch: 1505, train loss: 1.2739939569333278, validation loss: 1.2946914278942605.
epoch: 1506, train loss: 1.2703338434936804, validation loss: 1.2934639039246931.
epoch: 1507, train loss: 1.2710026196383555, validation loss: 1.2772883228633716.
epoch: 1508, train loss: 1.2688904475728306, validation loss: 1.2933334112167358.
epoch: 1509, train loss: 1.2680993966006358, validation loss: 1.2799328824748164.
epoch: 1510, train loss: 1.2652437063532138, validation loss: 1.2867499797240547.
epoch: 1511, train loss: 1.2625433359671077, validation loss: 1.2832710017328677.
epoch: 1512, train loss: 1.2662713363629963, validation loss: 1.2887931492017664.
epoch: 1513, train loss: 1.26340040373146, validation loss: 1.2879522572393003.
epoch: 1514, train loss: 1.262498103150534, validation loss: 1.2697305834811667.
epoch: 1515, train loss: 1.264312871005557, validation loss: 1.3015339219051858.
epoch: 1516, train loss: 1.266255423563336, validation loss: 1.2972638399704643.
epoch: 1517, train loss: 1.262244991206248, validation loss: 1.286000510920649.
epoch: 1518, train loss: 1.26439928024187, validation loss: 1.2885573687760725.
epoch: 1519, train loss: 1.264609721822476, validation loss: 1.2705630737802256.
epoch: 1520, train loss: 1.2607729708382842, validation loss: 1.2793158914731897.
epoch: 1521, train loss: 1.2624761412996766, validation loss: 1.2858544795409492.
epoch: 1522, train loss: 1.2633665439185746, validation loss: 1.28433198514192.
epoch: 1523, train loss: 1.261814282574785, validation loss: 1.2903682563615881.
epoch: 1524, train loss: 1.2637235987077065, validation loss: 1.277198895164158.
epoch: 1525, train loss: 1.2616164793661975, validation loss: 1.2778505501539812.
epoch: 1526, train loss: 1.2606513653326472, validation loss: 1.288140514622564.
epoch: 1527, train loss: 1.2665219427248753, validation loss: 1.2788537274236265.
epoch: 1528, train loss: 1.2610412606405557, validation loss: 1.2967394072076548.
epoch: 1529, train loss: 1.2638713690119052, validation loss: 1.279794858849567.
epoch: 1530, train loss: 1.2657517336924142, validation loss: 1.3009338534396628.
epoch: 1531, train loss: 1.2633873617977178, validation loss: 1.279366690179576.
epoch: 1532, train loss: 1.2627390360613482, validation loss: 1.273264651713164.
epoch: 1533, train loss: 1.261808716922725, validation loss: 1.2907558161279429.
epoch: 1534, train loss: 1.2675137476089897, validation loss: 1.2833381580269856.
epoch: 1535, train loss: 1.26411714138241, validation loss: 1.271189580792966.
epoch: 1536, train loss: 1.2859535829736553, validation loss: 1.2931280136108398.
epoch: 1537, train loss: 1.2725594962408784, validation loss: 1.3024480446525242.
epoch: 1538, train loss: 1.2697555909463025, validation loss: 1.297785064448481.
epoch: 1539, train loss: 1.266616664895224, validation loss: 1.292564075926076.
epoch: 1540, train loss: 1.2670112870155124, validation loss: 1.2852908113728398.
epoch: 1541, train loss: 1.26491728616417, validation loss: 1.2790870718334033.
epoch: 1542, train loss: 1.2627310960664662, validation loss: 1.2975724831871365.
epoch: 1543, train loss: 1.2590773685262837, validation loss: 1.2892676799193672.
epoch: 1544, train loss: 1.2628980907825156, validation loss: 1.2921529230864153.
epoch: 1545, train loss: 1.266280426891572, validation loss: 1.2814370082772297.
epoch: 1546, train loss: 1.2626274988191937, validation loss: 1.2734013484871907.
epoch: 1547, train loss: 1.2715292009738608, validation loss: 1.2831730946250584.
epoch: 1548, train loss: 1.2602401424985412, validation loss: 1.2962483582289324.
epoch: 1549, train loss: 1.2674026434574652, validation loss: 1.285668741101804.
epoch: 1550, train loss: 1.2624411145481496, validation loss: 1.2994935097901716.
epoch: 1551, train loss: 1.257352912097896, validation loss: 1.2845158680625584.
epoch: 1552, train loss: 1.2552975099021142, validation loss: 1.26559142962746.
epoch: 1553, train loss: 1.2556183228798963, validation loss: 1.2706689212633215.
epoch: 1554, train loss: 1.2556686171697915, validation loss: 1.2979411042254905.
epoch: 1555, train loss: 1.260882791029204, validation loss: 1.2969270737274834.
epoch: 1556, train loss: 1.2632839198506207, validation loss: 1.273738576018292.
epoch: 1557, train loss: 1.2593819132638633, validation loss: 1.2822193321974382.
epoch: 1558, train loss: 1.2603997309273536, validation loss: 1.2728254691414211.
epoch: 1559, train loss: 1.2645970703264988, validation loss: 1.275216237358425.
epoch: 1560, train loss: 1.260893395187658, validation loss: 1.2726590529732082.
epoch: 1561, train loss: 1.2600512898296392, validation loss: 1.284778937049534.
epoch: 1562, train loss: 1.2588915496791175, validation loss: 1.2941237895385078.
epoch: 1563, train loss: 1.2734006424562647, validation loss: 1.2786950235781462.
epoch: 1564, train loss: 1.2610714588690242, validation loss: 1.275216263273488.
epoch: 1565, train loss: 1.2580915055143724, validation loss: 1.2725517594295999.
epoch: 1566, train loss: 1.2583249457385561, validation loss: 1.2809310788693635.
epoch: 1567, train loss: 1.257512059780436, validation loss: 1.2857980728149414.
epoch: 1568, train loss: 1.2560771320937971, validation loss: 1.271416804064875.
epoch: 1569, train loss: 1.2571728010790064, validation loss: 1.2837376750033835.
epoch: 1570, train loss: 1.2547604611160559, validation loss: 1.2733238676319951.
epoch: 1571, train loss: 1.2547255185765958, validation loss: 1.3001672962437505.
epoch: 1572, train loss: 1.2599627785726424, validation loss: 1.2858625909556514.
epoch: 1573, train loss: 1.2584346740617665, validation loss: 1.2748705615168032.
epoch: 1574, train loss: 1.2652478032155867, validation loss: 1.285577374955882.
epoch: 1575, train loss: 1.2613893670773288, validation loss: 1.2678867733996848.
epoch: 1576, train loss: 1.2628108952023567, validation loss: 1.2850121933480967.
epoch: 1577, train loss: 1.2585910668066882, validation loss: 1.2788773515950078.
epoch: 1578, train loss: 1.2606825248910747, validation loss: 1.30280646033909.
epoch: 1579, train loss: 1.263179882950739, validation loss: 1.2813169489736143.
epoch: 1580, train loss: 1.2599982176351985, validation loss: 1.288584776546644.
epoch: 1581, train loss: 1.2678955191865973, validation loss: 1.2910792412965193.
epoch: 1582, train loss: 1.2609184247638108, validation loss: 1.2761422654856807.
epoch: 1583, train loss: 1.2553589879919629, validation loss: 1.2710158824920654.
epoch: 1584, train loss: 1.256779384175572, validation loss: 1.2806523934654568.
epoch: 1585, train loss: 1.2575743253077936, validation loss: 1.269064996553504.
epoch: 1586, train loss: 1.2599159205725434, validation loss: 1.2782459414523581.
epoch: 1587, train loss: 1.2541178967974602, validation loss: 1.2710089890853218.
epoch: 1588, train loss: 1.2568963503618853, validation loss: 1.2786710573279338.
epoch: 1589, train loss: 1.2554443013777428, validation loss: 1.2794022300969.
epoch: 1590, train loss: 1.2571253525007755, validation loss: 1.284361367640288.
epoch: 1591, train loss: 1.2560050990603386, validation loss: 1.2732021290323008.
epoch: 1592, train loss: 1.2553327116397544, validation loss: 1.2696067146632983.
epoch: 1593, train loss: 1.2519747226610096, validation loss: 1.2825217920800913.
epoch: 1594, train loss: 1.2533998959655062, validation loss: 1.2786147387131401.
epoch: 1595, train loss: 1.2559662160523442, validation loss: 1.2685687127320662.
epoch: 1596, train loss: 1.253767570224377, validation loss: 1.2859101347301318.
epoch: 1597, train loss: 1.2561632263551064, validation loss: 1.2657379948574563.
epoch: 1598, train loss: 1.254317510018655, validation loss: 1.2703885980274365.
epoch: 1599, train loss: 1.254007460874155, validation loss: 1.2766097421231477.
epoch: 1600, train loss: 1.254924484349172, validation loss: 1.2740925135819807.
epoch: 1601, train loss: 1.2621053697866038, validation loss: 1.278177085130111.
epoch: 1602, train loss: 1.2556063516424336, validation loss: 1.283121829447539.
epoch: 1603, train loss: 1.2556334701153116, validation loss: 1.2744240397992341.
epoch: 1604, train loss: 1.2563114024083548, validation loss: 1.2932460308074951.
epoch: 1605, train loss: 1.258983490663931, validation loss: 1.2901086599930474.
epoch: 1606, train loss: 1.2535805188187765, validation loss: 1.2756093999613887.
epoch: 1607, train loss: 1.2553777825941734, validation loss: 1.2824256109154744.
epoch: 1608, train loss: 1.2553971787111475, validation loss: 1.316206947616909.
epoch: 1609, train loss: 1.2560006303524753, validation loss: 1.2705115546350894.
epoch: 1610, train loss: 1.2558616487258072, validation loss: 1.2745152971018916.
epoch: 1611, train loss: 1.2534289360046387, validation loss: 1.2871054825575456.
epoch: 1612, train loss: 1.256349881854626, validation loss: 1.2866223584050718.
epoch: 1613, train loss: 1.2635618841976202, validation loss: 1.2816557158594546.
epoch: 1614, train loss: 1.2573172586773513, validation loss: 1.2792682803195456.
epoch: 1615, train loss: 1.2558652873432965, validation loss: 1.2819539671358855.
epoch: 1616, train loss: 1.2528102037009843, validation loss: 1.3167128718417624.
epoch: 1617, train loss: 1.257606643055557, validation loss: 1.2716584464778071.
epoch: 1618, train loss: 1.254989165778554, validation loss: 1.2732596501060154.
epoch: 1619, train loss: 1.2493297310050475, validation loss: 1.2782842698304548.
epoch: 1620, train loss: 1.2508937186057414, validation loss: 1.2768422572509102.
epoch: 1621, train loss: 1.2643471146942278, validation loss: 1.2964960025704426.
epoch: 1622, train loss: 1.2740753725034382, validation loss: 1.2896268834238467.
epoch: 1623, train loss: 1.2609887199664334, validation loss: 1.2777618428935176.
epoch: 1624, train loss: 1.256578771346206, validation loss: 1.2809711331906526.
epoch: 1625, train loss: 1.2558483082220095, validation loss: 1.2735675106877866.
epoch: 1626, train loss: 1.2559757265475913, validation loss: 1.3028746843338013.
epoch: 1627, train loss: 1.263722596912209, validation loss: 1.3125972488652105.
epoch: 1628, train loss: 1.2581943546960113, validation loss: 1.2682702593181445.
epoch: 1629, train loss: 1.255540688103492, validation loss: 1.2777776407158894.
epoch: 1630, train loss: 1.25666459437904, validation loss: 1.2882058827773384.
epoch: 1631, train loss: 1.2558682063303956, validation loss: 1.2625616374223128.
epoch: 1632, train loss: 1.2534300657587314, validation loss: 1.2962133469788923.
epoch: 1633, train loss: 1.2552390426670739, validation loss: 1.2720444461573726.
epoch: 1634, train loss: 1.2557352245400806, validation loss: 1.2645179344260173.
epoch: 1635, train loss: 1.2520867181480477, validation loss: 1.269202558890633.
epoch: 1636, train loss: 1.2546617131714428, validation loss: 1.299566160077634.
epoch: 1637, train loss: 1.2526654704995113, validation loss: 1.3103798731513645.
epoch: 1638, train loss: 1.2524914697769585, validation loss: 1.2697281474652498.
epoch: 1639, train loss: 1.252929635004166, validation loss: 1.2739588022232056.
epoch: 1640, train loss: 1.249524183229569, validation loss: 1.2681674801785012.
epoch: 1641, train loss: 1.26072099558804, validation loss: 1.383455312770346.
epoch: 1642, train loss: 1.3100265844152608, validation loss: 1.3098755038302878.
epoch: 1643, train loss: 1.2815319529367148, validation loss: 1.2849749067555303.
epoch: 1644, train loss: 1.2754757469947184, validation loss: 1.2857986118482507.
epoch: 1645, train loss: 1.2717158433494218, validation loss: 1.27897047996521.
epoch: 1646, train loss: 1.270366304511324, validation loss: 1.2827295842378035.
epoch: 1647, train loss: 1.2675377732023188, validation loss: 1.2896463508191316.
epoch: 1648, train loss: 1.2615655660629272, validation loss: 1.2757045289744502.
epoch: 1649, train loss: 1.2601009312025997, validation loss: 1.2682199685469917.
epoch: 1650, train loss: 1.2539971290378396, validation loss: 1.2739679450574128.
epoch: 1651, train loss: 1.2555800031084534, validation loss: 1.2746212171471638.
epoch: 1652, train loss: 1.2568265013738509, validation loss: 1.2783868727476702.
epoch: 1653, train loss: 1.2551897151754536, validation loss: 1.2762605677480283.
epoch: 1654, train loss: 1.2521588102393193, validation loss: 1.2739781296771506.
epoch: 1655, train loss: 1.255068074672594, validation loss: 1.2716338893641597.
epoch: 1656, train loss: 1.2539874916776605, validation loss: 1.2850632771201755.
epoch: 1657, train loss: 1.2554333516217153, validation loss: 1.269429642221202.
epoch: 1658, train loss: 1.2530783119551632, validation loss: 1.300548071446626.
epoch: 1659, train loss: 1.2542442761429953, validation loss: 1.2863140054371045.
epoch: 1660, train loss: 1.2532751964866569, validation loss: 1.2789170431054158.
epoch: 1661, train loss: 1.2553189752298757, validation loss: 1.2788609421771506.
epoch: 1662, train loss: 1.2521436531609351, validation loss: 1.2924345317094221.
epoch: 1663, train loss: 1.2511428255553638, validation loss: 1.2701214603755786.
epoch: 1664, train loss: 1.2500916872549495, validation loss: 1.2658561623614768.
epoch: 1665, train loss: 1.2515697260515406, validation loss: 1.2682569493418154.
epoch: 1666, train loss: 1.251945893698876, validation loss: 1.280021864434947.
epoch: 1667, train loss: 1.2566759137932313, validation loss: 1.2726329357727715.
epoch: 1668, train loss: 1.2589837454874582, validation loss: 1.2940297334090523.
epoch: 1669, train loss: 1.2672941761279324, validation loss: 1.27607566377391.
epoch: 1670, train loss: 1.2592607047579705, validation loss: 1.2857399608777917.
epoch: 1671, train loss: 1.2567304405597373, validation loss: 1.2669997889062632.
epoch: 1672, train loss: 1.2490845295267368, validation loss: 1.2673021451286648.
epoch: 1673, train loss: 1.2483049171780227, validation loss: 1.3707541382831077.
epoch: 1674, train loss: 1.249693725087227, validation loss: 1.2653481182844744.
epoch: 1675, train loss: 1.2504986076179994, validation loss: 1.2769484364468118.
epoch: 1676, train loss: 1.254426149053311, validation loss: 1.2656788411347761.
epoch: 1677, train loss: 1.2495015728364296, validation loss: 1.2787091835685398.
epoch: 1678, train loss: 1.2563397971861954, validation loss: 1.2792380685391633.
epoch: 1679, train loss: 1.2568132549250892, validation loss: 1.2797092043835183.
epoch: 1680, train loss: 1.2541387737344165, validation loss: 1.2726348638534546.
epoch: 1681, train loss: 1.2528522408336675, validation loss: 1.265936685645062.
epoch: 1682, train loss: 1.2510954196299982, validation loss: 1.2673479370448901.
epoch: 1683, train loss: 1.2455874331500552, validation loss: 1.2716353043265964.
epoch: 1684, train loss: 1.2508532935326253, validation loss: 1.284323583478513.
epoch: 1685, train loss: 1.252972210219147, validation loss: 1.2882324094357698.
epoch: 1686, train loss: 1.2532685863862343, validation loss: 1.2686077304508374.
epoch: 1687, train loss: 1.2540565499471963, validation loss: 1.2691986405331155.
epoch: 1688, train loss: 1.2604998098600895, validation loss: 1.2773658192676047.
epoch: 1689, train loss: 1.256963363481224, validation loss: 1.2692898149075715.
epoch: 1690, train loss: 1.2525513915840638, validation loss: 1.2747721827548484.
epoch: 1691, train loss: 1.2517914804843588, validation loss: 1.29686585198278.
epoch: 1692, train loss: 1.2514775707087387, validation loss: 1.2693869549295176.
epoch: 1693, train loss: 1.249486439818636, validation loss: 1.272450706233149.
epoch: 1694, train loss: 1.250333637272546, validation loss: 1.2733865872673367.
epoch: 1695, train loss: 1.2556891485091743, validation loss: 1.284898421038752.
epoch: 1696, train loss: 1.2519872166694852, validation loss: 1.28689734313799.
epoch: 1697, train loss: 1.2501796134021304, validation loss: 1.2644641865854678.
epoch: 1698, train loss: 1.2550288766895958, validation loss: 1.2721844652424688.
epoch: 1699, train loss: 1.2474918868563591, validation loss: 1.2803559095963188.
epoch: 1700, train loss: 1.2492801968110812, validation loss: 1.288814409919407.
epoch: 1701, train loss: 1.2574923683743957, validation loss: 1.2800391445989194.
epoch: 1702, train loss: 1.257347605644016, validation loss: 1.2689906877020132.
epoch: 1703, train loss: 1.2524992982181935, validation loss: 1.2706375640371572.
epoch: 1704, train loss: 1.2485450178111366, validation loss: 1.2783242204914922.
epoch: 1705, train loss: 1.2465603778121668, validation loss: 1.2654697065768035.
epoch: 1706, train loss: 1.2681622658300837, validation loss: 1.2837174975353738.
epoch: 1707, train loss: 1.2575959710899842, validation loss: 1.3441872182099714.
epoch: 1708, train loss: 1.2609351020340527, validation loss: 1.2786290697429492.
epoch: 1709, train loss: 1.2537691166641516, validation loss: 1.269895491392716.
epoch: 1710, train loss: 1.2514219294994249, validation loss: 1.2738854677780815.
epoch: 1711, train loss: 1.250439463405434, validation loss: 1.291705566903819.
epoch: 1712, train loss: 1.2565790316380492, validation loss: 1.2988470896430637.
epoch: 1713, train loss: 1.2525794768552168, validation loss: 1.266866227854853.
epoch: 1714, train loss: 1.2498740351528204, validation loss: 1.2697649053905322.
epoch: 1715, train loss: 1.2512811378601494, validation loss: 1.2790660858154297.
epoch: 1716, train loss: 1.2509325239636482, validation loss: 1.2732206583023071.
epoch: 1717, train loss: 1.2547054706363503, validation loss: 1.2640610259512197.
epoch: 1718, train loss: 1.2528129805118666, validation loss: 1.2667311740958171.
epoch: 1719, train loss: 1.2555912164373135, validation loss: 1.2820868543956592.
epoch: 1720, train loss: 1.2615340127857453, validation loss: 1.3498941193456235.
epoch: 1721, train loss: 1.2548951971421547, validation loss: 1.2699414491653442.
epoch: 1722, train loss: 1.251047181426932, validation loss: 1.2713522081789763.
epoch: 1723, train loss: 1.246564042677573, validation loss: 1.257988048636395.
epoch: 1724, train loss: 1.2463914123150186, validation loss: 1.3030588937842327.
epoch: 1725, train loss: 1.2483366870005197, validation loss: 1.2889023345449697.
epoch: 1726, train loss: 1.257124328832014, validation loss: 1.2690620526023533.
epoch: 1727, train loss: 1.2502360551729115, validation loss: 1.2735238230746726.
epoch: 1728, train loss: 1.2484553647697518, validation loss: 1.2794618191926375.
epoch: 1729, train loss: 1.254737889001129, validation loss: 1.2760614467703777.
epoch: 1730, train loss: 1.2542410214012916, validation loss: 1.3193272870519888.
epoch: 1731, train loss: 1.2546256824370918, validation loss: 1.2734357170436694.
epoch: 1732, train loss: 1.2521785913257424, validation loss: 1.2692901569864024.
epoch: 1733, train loss: 1.2491030561814613, validation loss: 1.2983756324519282.
epoch: 1734, train loss: 1.248251405330973, validation loss: 1.2682993982149207.
epoch: 1735, train loss: 1.2473322699923035, validation loss: 1.2601992513822473.
epoch: 1736, train loss: 1.2511576217248899, validation loss: 1.2673777808313784.
epoch: 1737, train loss: 1.2560576780126729, validation loss: 1.2958073460537454.
epoch: 1738, train loss: 1.2579005705107242, validation loss: 1.2724904495736826.
epoch: 1739, train loss: 1.2504183600801941, validation loss: 1.2831652630930361.
epoch: 1740, train loss: 1.2525689820630834, validation loss: 1.2724436003228892.
epoch: 1741, train loss: 1.2485262975780242, validation loss: 1.2840105554331904.
epoch: 1742, train loss: 1.248774629120433, validation loss: 1.2754337269326914.
epoch: 1743, train loss: 1.2496708598705606, validation loss: 1.3003745597341787.
epoch: 1744, train loss: 1.2566676358564184, validation loss: 1.316063176030698.
epoch: 1745, train loss: 1.2534420435581732, validation loss: 1.266100753908572.
epoch: 1746, train loss: 1.2445919776181562, validation loss: 1.2778660214465598.
epoch: 1747, train loss: 1.254618060698203, validation loss: 1.3061267603998599.
epoch: 1748, train loss: 1.2570958564040857, validation loss: 1.2684309689894966.
epoch: 1749, train loss: 1.2481370300327965, validation loss: 1.2762567945148633.
epoch: 1750, train loss: 1.2477062404702564, validation loss: 1.290898172751717.
epoch: 1751, train loss: 1.2546467813876792, validation loss: 1.281029234761777.
epoch: 1752, train loss: 1.2527253780889949, validation loss: 1.2698222502418186.
epoch: 1753, train loss: 1.2502497992384325, validation loss: 1.2852384111155635.
epoch: 1754, train loss: 1.248372169809604, validation loss: 1.2638059128885684.
epoch: 1755, train loss: 1.251431493584169, validation loss: 1.2682961121849392.
epoch: 1756, train loss: 1.2503573391415657, validation loss: 1.2637345687202786.
epoch: 1757, train loss: 1.2484241538091536, validation loss: 1.2741521182267561.
epoch: 1758, train loss: 1.246595478932792, validation loss: 1.2711898969567341.
epoch: 1759, train loss: 1.250215938331884, validation loss: 1.270403265953064.
epoch: 1760, train loss: 1.2511988418911575, validation loss: 1.2860634119614311.
epoch: 1761, train loss: 1.2501031040051662, validation loss: 1.279248419015304.
epoch: 1762, train loss: 1.2483264885911154, validation loss: 1.2638506371042002.
epoch: 1763, train loss: 1.2509123622824292, validation loss: 1.2785521642021511.
epoch: 1764, train loss: 1.2581093387866238, validation loss: 1.3220804515092268.
epoch: 1765, train loss: 1.2598529266654899, validation loss: 1.2936063331106435.
epoch: 1766, train loss: 1.2547617166414173, validation loss: 1.278059088665506.
epoch: 1767, train loss: 1.2509149006747324, validation loss: 1.2736496303392493.
epoch: 1768, train loss: 1.2488196388297124, validation loss: 1.2665488201638926.
epoch: 1769, train loss: 1.2525771353222908, validation loss: 1.2967267347418743.
epoch: 1770, train loss: 1.255190431524854, validation loss: 1.297330581623575.
epoch: 1771, train loss: 1.25134340776216, validation loss: 1.2833382824192876.
epoch: 1772, train loss: 1.251117927218796, validation loss: 1.3247232126153035.
epoch: 1773, train loss: 1.2515665697395255, validation loss: 1.2614658967308376.
epoch: 1774, train loss: 1.2567914571237127, validation loss: 1.2674865308015242.
epoch: 1775, train loss: 1.252474334261833, validation loss: 1.3021483628646187.
epoch: 1776, train loss: 1.249523893408819, validation loss: 1.2781591000764265.
epoch: 1777, train loss: 1.250599848021061, validation loss: 1.2648247895033464.
epoch: 1778, train loss: 1.248659927910621, validation loss: 1.2819770056268442.
epoch: 1779, train loss: 1.2464920610462853, validation loss: 1.2743357782778533.
epoch: 1780, train loss: 1.2506786792650135, validation loss: 1.2750006188517031.
epoch: 1781, train loss: 1.2500421115017812, validation loss: 1.272332813428796.
epoch: 1782, train loss: 1.2489593389931075, validation loss: 1.2641545015832651.
epoch: 1783, train loss: 1.2499959698510825, validation loss: 1.271234102871107.
epoch: 1784, train loss: 1.2490433268590804, validation loss: 1.291476327440013.
epoch: 1785, train loss: 1.2475142763295304, validation loss: 1.263978854469631.
epoch: 1786, train loss: 1.2485188016104043, validation loss: 1.2849454465119734.
epoch: 1787, train loss: 1.2511507808615308, validation loss: 1.2760476599568906.
epoch: 1788, train loss: 1.2485913738198238, validation loss: 1.2706882590832917.
epoch: 1789, train loss: 1.250435164215368, validation loss: 1.2718400177748308.
epoch: 1790, train loss: 1.2527140674241093, validation loss: 1.257361686748007.
epoch: 1791, train loss: 1.246732224018202, validation loss: 1.3179282260977703.
epoch: 1792, train loss: 1.2478139455165338, validation loss: 1.2666392533675483.
epoch: 1793, train loss: 1.2499741053362505, validation loss: 1.2644661820453147.
epoch: 1794, train loss: 1.2494439531903747, validation loss: 1.2731449915015178.
epoch: 1795, train loss: 1.2503667916726628, validation loss: 1.2873422270235808.
epoch: 1796, train loss: 1.2557538168145976, validation loss: 1.2654932685520337.
epoch: 1797, train loss: 1.2512661131150131, validation loss: 1.2725393150163733.
epoch: 1798, train loss: 1.249351105558763, validation loss: 1.2949050975882488.
epoch: 1799, train loss: 1.255113102974148, validation loss: 1.2932956892511118.
epoch: 1800, train loss: 1.2551492102649233, validation loss: 1.2785437832707944.
epoch: 1801, train loss: 1.2540840074556683, validation loss: 1.2678007716717927.
epoch: 1802, train loss: 1.2484161974093235, validation loss: 1.262520686439846.
epoch: 1803, train loss: 1.2483825322684892, validation loss: 1.2895319876463518.
epoch: 1804, train loss: 1.249001953579964, validation loss: 1.2594738421232805.
epoch: 1805, train loss: 1.2495740575527927, validation loss: 1.2651807328929072.
epoch: 1806, train loss: 1.2608852802066628, validation loss: 1.277101096899613.
epoch: 1807, train loss: 1.2474804613568367, validation loss: 1.271219745926235.
epoch: 1808, train loss: 1.2470663118799892, validation loss: 1.2733306936595752.
epoch: 1809, train loss: 1.246976682899195, validation loss: 1.2708299004513284.
epoch: 1810, train loss: 1.2416652309785194, validation loss: 1.2567586121351824.
epoch: 1811, train loss: 1.244028957611924, validation loss: 1.2772562296494194.
epoch: 1812, train loss: 1.2479093227911433, validation loss: 1.2812896863273953.
epoch: 1813, train loss: 1.249969789741236, validation loss: 1.2655034583547842.
epoch: 1814, train loss: 1.2640130213641245, validation loss: 1.316646529280621.
epoch: 1815, train loss: 1.297407437901978, validation loss: 1.2859555638354758.
epoch: 1816, train loss: 1.2686459471326355, validation loss: 1.2779295807299407.
epoch: 1817, train loss: 1.2638998173792428, validation loss: 1.2861182015875112.
epoch: 1818, train loss: 1.2658799689844114, validation loss: 1.2723683999932331.
epoch: 1819, train loss: 1.2599094657722962, validation loss: 1.2806564051172007.
epoch: 1820, train loss: 1.2618682734463194, validation loss: 1.2780038118362427.
epoch: 1821, train loss: 1.258193855985589, validation loss: 1.2943031736042188.
epoch: 1822, train loss: 1.2629230427085807, validation loss: 1.2745295866675999.
epoch: 1823, train loss: 1.2588128420191074, validation loss: 1.2684053752733313.
epoch: 1824, train loss: 1.2559321768786929, validation loss: 1.3474365680114082.
epoch: 1825, train loss: 1.2578310321230408, validation loss: 1.276896015457485.
epoch: 1826, train loss: 1.2517981758905112, validation loss: 1.2774365984875222.
epoch: 1827, train loss: 1.258364428073988, validation loss: 1.2662991026173467.
epoch: 1828, train loss: 1.2531004498857972, validation loss: 1.3051442685334578.
epoch: 1829, train loss: 1.2538824486076285, validation loss: 1.2845829103303992.
epoch: 1830, train loss: 1.257213144127382, validation loss: 1.2625188050062761.
epoch: 1831, train loss: 1.2513690640073303, validation loss: 1.26491307693979.
epoch: 1832, train loss: 1.2565270356082041, validation loss: 1.2761839420899102.
epoch: 1833, train loss: 1.2520732474983285, validation loss: 1.2671905963317207.
epoch: 1834, train loss: 1.2512554083395442, validation loss: 1.2624661559643953.
epoch: 1835, train loss: 1.2484390768436118, validation loss: 1.2570262369902239.
epoch: 1836, train loss: 1.254359773539622, validation loss: 1.2643655486728833.
epoch: 1837, train loss: 1.2543114708104264, validation loss: 1.277227266975071.
epoch: 1838, train loss: 1.2496828836038572, validation loss: 1.2676696570023247.
epoch: 1839, train loss: 1.2587971577950574, validation loss: 1.2806420274402783.
epoch: 1840, train loss: 1.2567776069728607, validation loss: 1.3068860458291096.
epoch: 1841, train loss: 1.2566540361544407, validation loss: 1.2963890096415644.
epoch: 1842, train loss: 1.2594910860061646, validation loss: 1.2735778559809146.
epoch: 1843, train loss: 1.2532374891666098, validation loss: 1.273860646330792.
epoch: 1844, train loss: 1.2596852024760814, validation loss: 1.2716364342233408.
epoch: 1845, train loss: 1.2532876598725624, validation loss: 1.2585343692613684.
epoch: 1846, train loss: 1.2486105533914829, validation loss: 1.3485542432121609.
epoch: 1847, train loss: 1.2502508447804581, validation loss: 1.269474340521771.
epoch: 1848, train loss: 1.255844250731512, validation loss: 1.2716883731924968.
epoch: 1849, train loss: 1.247438601397593, validation loss: 1.2571869051974753.
epoch: 1850, train loss: 1.2501373203522568, validation loss: 1.2710551386294158.
epoch: 1851, train loss: 1.2645478959477277, validation loss: 1.2664547847664875.
epoch: 1852, train loss: 1.2534786659643191, validation loss: 1.2858048573784207.
epoch: 1853, train loss: 1.25794601549796, validation loss: 1.2619728886562844.
epoch: 1854, train loss: 1.2477376264169675, validation loss: 1.2663209438323975.
epoch: 1855, train loss: 1.246410809525656, validation loss: 1.2875166405802188.
epoch: 1856, train loss: 1.2573845102152694, validation loss: 1.2687082705290422.
epoch: 1857, train loss: 1.2506021753363652, validation loss: 1.263287419858186.
epoch: 1858, train loss: 1.2518874866153122, validation loss: 1.2632871607075566.
epoch: 1859, train loss: 1.254762629850195, validation loss: 1.267075398693914.
epoch: 1860, train loss: 1.2486873033943526, validation loss: 1.2861329368923022.
epoch: 1861, train loss: 1.2524183485486091, validation loss: 1.2617049009903618.
epoch: 1862, train loss: 1.2531373774239776, validation loss: 1.2767646623694378.
epoch: 1863, train loss: 1.2498814676879744, validation loss: 1.2885704196017722.
epoch: 1864, train loss: 1.2535495145605244, validation loss: 1.2671486294787864.
epoch: 1865, train loss: 1.2447847226344118, validation loss: 1.269449047420336.
epoch: 1866, train loss: 1.244471529208192, validation loss: 1.2655781714812568.
epoch: 1867, train loss: 1.2463489322487367, validation loss: 1.2755929646284685.
epoch: 1868, train loss: 1.263326317892162, validation loss: 1.3019360096558281.
epoch: 1869, train loss: 1.251396683377957, validation loss: 1.2775411813155464.
epoch: 1870, train loss: 1.254921454902089, validation loss: 1.2617958680443142.
epoch: 1871, train loss: 1.2502190093381689, validation loss: 1.269445258638133.
epoch: 1872, train loss: 1.2480174663963668, validation loss: 1.2724530489548393.
epoch: 1873, train loss: 1.2520602099392393, validation loss: 1.2573423126469487.
epoch: 1874, train loss: 1.2501475636018526, validation loss: 1.2624466004578963.
epoch: 1875, train loss: 1.2497902408652348, validation loss: 1.2585944870243901.
epoch: 1876, train loss: 1.253613295905087, validation loss: 1.2860462095426477.
epoch: 1877, train loss: 1.2523309003322496, validation loss: 1.2668222966401472.
epoch: 1878, train loss: 1.2492752228308162, validation loss: 1.2838142332823381.
epoch: 1879, train loss: 1.2486278923279648, validation loss: 1.2786117792129517.
epoch: 1880, train loss: 1.2570672757035002, validation loss: 1.273234927135965.
epoch: 1881, train loss: 1.264541718937935, validation loss: 1.3143806820330413.
epoch: 1882, train loss: 1.2696120596806937, validation loss: 1.2681327591771665.
epoch: 1883, train loss: 1.2499923870104168, validation loss: 1.2754366294197415.
epoch: 1884, train loss: 1.2488732523874406, validation loss: 1.2912913198056428.
epoch: 1885, train loss: 1.2499552932354288, validation loss: 1.2535936262296594.
epoch: 1886, train loss: 1.244693980304473, validation loss: 1.2693827722383582.
epoch: 1887, train loss: 1.247887748097061, validation loss: 1.3042406828507134.
epoch: 1888, train loss: 1.2609637264811664, validation loss: 1.2700542470683223.
epoch: 1889, train loss: 1.2445545262152995, validation loss: 1.2681585705798606.
epoch: 1890, train loss: 1.2612488783827616, validation loss: 1.326876427816308.
epoch: 1891, train loss: 1.2628775003853194, validation loss: 1.264662794444872.
epoch: 1892, train loss: 1.249962653588811, validation loss: 1.2662996727487315.
epoch: 1893, train loss: 1.2509848426241394, validation loss: 1.26070933756621.
epoch: 1894, train loss: 1.2473001731645077, validation loss: 1.2583648899327153.
epoch: 1895, train loss: 1.2503477050623764, validation loss: 1.2613862079122793.
epoch: 1896, train loss: 1.2524065129253843, validation loss: 1.2564207833746206.
epoch: 1897, train loss: 1.2459878746522677, validation loss: 1.2700663856838061.
epoch: 1898, train loss: 1.2436784669893597, validation loss: 1.2592179878898289.
epoch: 1899, train loss: 1.2495014295665496, validation loss: 1.268543445545694.
epoch: 1900, train loss: 1.2483758532672846, validation loss: 1.2635215728179268.
epoch: 1901, train loss: 1.2445078705428938, validation loss: 1.2610787619715151.
epoch: 1902, train loss: 1.247658166316671, validation loss: 1.277894756068354.
epoch: 1903, train loss: 1.24969246081256, validation loss: 1.296507425930189.
epoch: 1904, train loss: 1.263288759310311, validation loss: 1.264992117881775.
epoch: 1905, train loss: 1.2580080371384228, validation loss: 1.2679442219112231.
epoch: 1906, train loss: 1.2513728382390574, validation loss: 1.2733183788216633.
epoch: 1907, train loss: 1.2560495619380145, validation loss: 1.2840494332106218.
epoch: 1908, train loss: 1.251488393599834, validation loss: 1.2658679537151172.
epoch: 1909, train loss: 1.249751820476777, validation loss: 1.2899603377217832.
epoch: 1910, train loss: 1.2592454634675192, validation loss: 1.2614718623783276.
epoch: 1911, train loss: 1.2553265827511428, validation loss: 1.2960311537203582.
epoch: 1912, train loss: 1.2482874120047334, validation loss: 1.2646186921907507.
epoch: 1913, train loss: 1.259866322946111, validation loss: 1.2674432681954426.
epoch: 1914, train loss: 1.2521944778774856, validation loss: 1.2662172421165134.
epoch: 1915, train loss: 1.2471300188554537, validation loss: 1.378378837004952.
epoch: 1916, train loss: 1.2479912873801835, validation loss: 1.2684993018274722.
epoch: 1917, train loss: 1.2562981668962252, validation loss: 1.2970499992370605.
epoch: 1918, train loss: 1.254825741872875, validation loss: 1.2648222912912783.
epoch: 1919, train loss: 1.2470892142812047, validation loss: 1.2607688540997712.
epoch: 1920, train loss: 1.24101828981977, validation loss: 1.273535184238268.
epoch: 1921, train loss: 1.247736962563401, validation loss: 1.2698973883753237.
epoch: 1922, train loss: 1.2521346752796698, validation loss: 1.2822259923686152.
epoch: 1923, train loss: 1.2528941970352734, validation loss: 1.2719577913698943.
epoch: 1924, train loss: 1.2437691721347495, validation loss: 1.3023350549780803.
epoch: 1925, train loss: 1.2498072068625634, validation loss: 1.2623584633288176.
epoch: 1926, train loss: 1.2419642231879977, validation loss: 1.272000375001327.
epoch: 1927, train loss: 1.242386489833167, validation loss: 1.2750018368596616.
epoch: 1928, train loss: 1.2485204574164994, validation loss: 1.2661525840344636.
epoch: 1929, train loss: 1.2496655260751006, validation loss: 1.2660778501759404.
epoch: 1930, train loss: 1.250492336553171, validation loss: 1.2880123698193093.
epoch: 1931, train loss: 1.2530198315961645, validation loss: 1.284341371577719.
epoch: 1932, train loss: 1.2488697089186502, validation loss: 1.2869072789731233.
epoch: 1933, train loss: 1.2471941151750197, validation loss: 1.276384358820708.
epoch: 1934, train loss: 1.2389644187524778, validation loss: 1.3167450790819915.
epoch: 1935, train loss: 1.2457199709131084, validation loss: 1.2743929469067117.
epoch: 1936, train loss: 1.2488926222564978, validation loss: 1.29347780994747.
epoch: 1937, train loss: 1.252328830027799, validation loss: 1.253922348437102.
epoch: 1938, train loss: 1.2467177122011097, validation loss: 1.2500405933545984.
epoch: 1939, train loss: 1.2440323184389588, validation loss: 1.2626061905985293.
epoch: 1940, train loss: 1.2411303902984758, validation loss: 1.25142851083175.
epoch: 1941, train loss: 1.2494581970599814, validation loss: 1.271636522334555.
epoch: 1942, train loss: 1.250321874924756, validation loss: 1.318835947824561.
epoch: 1943, train loss: 1.247548291442591, validation loss: 1.3023590989734815.
epoch: 1944, train loss: 1.2599383439492742, validation loss: 1.2645903462949006.
epoch: 1945, train loss: 1.2509089916124256, validation loss: 1.2698541205862295.
epoch: 1946, train loss: 1.2448202087244857, validation loss: 1.2818708523460056.
epoch: 1947, train loss: 1.2557861958075007, validation loss: 1.2671697606211123.
epoch: 1948, train loss: 1.2445917785714526, validation loss: 1.2652916493623152.
epoch: 1949, train loss: 1.2425012916599938, validation loss: 1.26633780417235.
epoch: 1950, train loss: 1.2413473140209093, validation loss: 1.2737283240193906.
epoch: 1951, train loss: 1.2435117358461432, validation loss: 1.307751847350079.
epoch: 1952, train loss: 1.2461160235448714, validation loss: 1.2960401669792507.
epoch: 1953, train loss: 1.2472365493074469, validation loss: 1.2612907005392986.
epoch: 1954, train loss: 1.2567557216784275, validation loss: 1.2699300672696985.
epoch: 1955, train loss: 1.2511004821969829, validation loss: 1.2876367206158845.
epoch: 1956, train loss: 1.2495913177455238, validation loss: 1.2957685771195784.
epoch: 1957, train loss: 1.2489096790278724, validation loss: 1.2896134386891904.
epoch: 1958, train loss: 1.2422074943507484, validation loss: 1.2803666487984036.
epoch: 1959, train loss: 1.2408123092913845, validation loss: 1.264713131863138.
epoch: 1960, train loss: 1.244317154271887, validation loss: 1.2737262404483298.
epoch: 1961, train loss: 1.2463070679148402, validation loss: 1.2731299555819968.
epoch: 1962, train loss: 1.2498869841251898, validation loss: 1.2682558298110962.
epoch: 1963, train loss: 1.241708136479789, validation loss: 1.267748412878617.
epoch: 1964, train loss: 1.2480186497399566, validation loss: 1.255605682082798.
epoch: 1965, train loss: 1.2467398490380803, validation loss: 1.2590790572373762.
epoch: 1966, train loss: 1.2455535864611285, validation loss: 1.290043312570323.
epoch: 1967, train loss: 1.24580970816656, validation loss: 1.2538450749024102.
epoch: 1968, train loss: 1.2436714467652348, validation loss: 1.2563939716504968.
epoch: 1969, train loss: 1.243440284641511, validation loss: 1.2584782683331033.
epoch: 1970, train loss: 1.2397740412195888, validation loss: 1.2526629852211995.
epoch: 1971, train loss: 1.240066351146873, validation loss: 1.2650241799976514.
epoch: 1972, train loss: 1.2572339423205874, validation loss: 1.3135143207467121.
epoch: 1973, train loss: 1.2629875513391757, validation loss: 1.2799386822659036.
epoch: 1974, train loss: 1.2616035030522477, validation loss: 1.2656258240990017.
epoch: 1975, train loss: 1.25545810559474, validation loss: 1.278568552887958.
epoch: 1976, train loss: 1.2479823652757418, validation loss: 1.2657007600950159.
epoch: 1977, train loss: 1.2520470652011557, validation loss: 1.2907682087110437.
epoch: 1978, train loss: 1.2604181777446641, validation loss: 1.2795096583988355.
epoch: 1979, train loss: 1.2550363376599933, validation loss: 1.2695160067599753.
epoch: 1980, train loss: 1.2531040841286336, validation loss: 1.2673418366390725.
epoch: 1981, train loss: 1.2462967557644626, validation loss: 1.318720853847006.
epoch: 1982, train loss: 1.2426002758358596, validation loss: 1.2570237076800803.
epoch: 1983, train loss: 1.246140375049836, validation loss: 1.2672588151434194.
epoch: 1984, train loss: 1.2417221331815107, validation loss: 1.2960263438846753.
epoch: 1985, train loss: 1.2535418162652112, validation loss: 1.2973965458247974.
epoch: 1986, train loss: 1.252794316055578, validation loss: 1.3889966736669126.
epoch: 1987, train loss: 1.286586326196653, validation loss: 1.2840643706529036.
epoch: 1988, train loss: 1.2625310661595897, validation loss: 1.2701443952062856.
epoch: 1989, train loss: 1.258507025351218, validation loss: 1.27579737227896.
epoch: 1990, train loss: 1.2536010982793406, validation loss: 1.2787053688712742.
epoch: 1991, train loss: 1.252524643863013, validation loss: 1.2634806529335354.
epoch: 1992, train loss: 1.249229040714579, validation loss: 1.259584463160971.
epoch: 1993, train loss: 1.251143406290527, validation loss: 1.2616036404734072.
epoch: 1994, train loss: 1.2511512959769013, validation loss: 1.2639747806217358.
epoch: 1995, train loss: 1.2446251057703561, validation loss: 1.2624618281488833.
epoch: 1996, train loss: 1.2420427733605062, validation loss: 1.2674815965735393.
epoch: 1997, train loss: 1.2433681138064883, validation loss: 1.4944480864898018.
epoch: 1998, train loss: 1.2524873849448808, validation loss: 1.2655781662982444.
epoch: 1999, train loss: 1.2506687684890327, validation loss: 1.271096390226613.
epoch: 2000, train loss: 1.253788582775571, validation loss: 1.2539808646492336.
epoch: 2001, train loss: 1.2453295867377465, validation loss: 1.277784886567489.
epoch: 2002, train loss: 1.2486993249403227, validation loss: 1.2687802884889685.
epoch: 2003, train loss: 1.255652328149988, validation loss: 1.2617454943449602.
epoch: 2004, train loss: 1.2497165049981633, validation loss: 1.2694340529649153.
epoch: 2005, train loss: 1.250533135659104, validation loss: 1.2747575355612712.
epoch: 2006, train loss: 1.24345963810562, validation loss: 1.2578832792199177.
epoch: 2007, train loss: 1.249868129371503, validation loss: 1.2533017085946125.
epoch: 2008, train loss: 1.2449212336758955, validation loss: 1.2668223951173865.
epoch: 2009, train loss: 1.2536920068460866, validation loss: 1.28067772284798.
epoch: 2010, train loss: 1.252154869770785, validation loss: 1.262755528740261.
epoch: 2011, train loss: 1.243311109892819, validation loss: 1.2631306389103765.
epoch: 2012, train loss: 1.2471675315034498, validation loss: 1.2800097776495891.
epoch: 2013, train loss: 1.2457955353850618, validation loss: 1.295462535775226.
epoch: 2014, train loss: 1.2530066956073866, validation loss: 1.264079415279886.
epoch: 2015, train loss: 1.245559498804425, validation loss: 1.2510253501975017.
epoch: 2016, train loss: 1.2579025916003306, validation loss: 1.2828311661015386.
epoch: 2017, train loss: 1.253205577167896, validation loss: 1.285347995550736.
epoch: 2018, train loss: 1.248098621674634, validation loss: 1.260028953137605.
epoch: 2019, train loss: 1.2467502683674523, validation loss: 1.3161587455998296.
epoch: 2020, train loss: 1.2671078870055872, validation loss: 1.2811220210531484.
epoch: 2021, train loss: 1.2617930841008458, validation loss: 1.2789642810821533.
epoch: 2022, train loss: 1.261018484010609, validation loss: 1.2704014829967334.
epoch: 2023, train loss: 1.253197225955648, validation loss: 1.265538267467333.
epoch: 2024, train loss: 1.2526918245018075, validation loss: 1.2760110264239104.
epoch: 2025, train loss: 1.247902010558942, validation loss: 1.2811096440190854.
epoch: 2026, train loss: 1.2574737575076043, validation loss: 1.264167054839756.
epoch: 2027, train loss: 1.2482431470800976, validation loss: 1.3076999653940615.
epoch: 2028, train loss: 1.2474043063067515, validation loss: 1.2649156217989714.
epoch: 2029, train loss: 1.2698083623833614, validation loss: 1.3104653462119724.
epoch: 2030, train loss: 1.2552805898386403, validation loss: 1.2791813093682993.
epoch: 2031, train loss: 1.250709510724479, validation loss: 1.2743324922478718.
epoch: 2032, train loss: 1.246354567895242, validation loss: 1.2592228288235872.
epoch: 2033, train loss: 1.256309775037503, validation loss: 1.2814457053723542.
epoch: 2034, train loss: 1.253930942727885, validation loss: 1.2607083735258684.
epoch: 2035, train loss: 1.2501133713153525, validation loss: 1.2727424891098686.
epoch: 2036, train loss: 1.2437684295374318, validation loss: 1.2499191035395083.
epoch: 2037, train loss: 1.2440298784763442, validation loss: 1.2635857903439065.
epoch: 2038, train loss: 1.2450738839053233, validation loss: 1.2647976719814797.
epoch: 2039, train loss: 1.249557290602168, validation loss: 1.2790475306303606.
epoch: 2040, train loss: 1.2501831568709207, validation loss: 1.2668588368789009.
epoch: 2041, train loss: 1.2529517827777688, validation loss: 1.2913500640703284.
epoch: 2042, train loss: 1.2496982451972611, validation loss: 1.2959632614384526.
epoch: 2043, train loss: 1.25189932661319, validation loss: 1.2788947146871816.
epoch: 2044, train loss: 1.244809981879838, validation loss: 1.2658132936643518.
epoch: 2045, train loss: 1.2468319168878257, validation loss: 1.262907976689546.
epoch: 2046, train loss: 1.2484436527304692, validation loss: 1.2701128151105798.
epoch: 2047, train loss: 1.2457864240768852, validation loss: 1.2686321061590444.
epoch: 2048, train loss: 1.2510006821483648, validation loss: 1.295673624328945.
epoch: 2049, train loss: 1.2594713530409227, validation loss: 1.2882526490999304.
epoch: 2050, train loss: 1.2495777410104734, validation loss: 1.2722719544949739.
epoch: 2051, train loss: 1.2465938690605514, validation loss: 1.283512841100278.
epoch: 2052, train loss: 1.248035240610805, validation loss: 1.2625557754350745.
epoch: 2053, train loss: 1.2474097768101124, validation loss: 1.264389825903851.
epoch: 2054, train loss: 1.2419545814531658, validation loss: 1.3002239258392998.
epoch: 2055, train loss: 1.254101745579221, validation loss: 1.2640392262002695.
epoch: 2056, train loss: 1.2438060078052207, validation loss: 1.269246827001157.
epoch: 2057, train loss: 1.2534841397486696, validation loss: 1.2614835189736409.
epoch: 2058, train loss: 1.250724757483246, validation loss: 1.2718106300934502.
epoch: 2059, train loss: 1.2585289806400963, validation loss: 1.268538817115452.
epoch: 2060, train loss: 1.2499197218396247, validation loss: 1.275298792382945.
epoch: 2061, train loss: 1.2481144130776782, validation loss: 1.2721289707266765.
epoch: 2062, train loss: 1.2476387887919715, validation loss: 1.2747144128965295.
epoch: 2063, train loss: 1.244913175565387, validation loss: 1.2525718730428945.
epoch: 2064, train loss: 1.2446021771212237, validation loss: 1.2773348144862964.
epoch: 2065, train loss: 1.2418708571600259, validation loss: 1.3104149414145427.
epoch: 2066, train loss: 1.2514942862571927, validation loss: 1.297751784324646.
epoch: 2067, train loss: 1.250862611543148, validation loss: 1.2623282152673472.
epoch: 2068, train loss: 1.2487241806240257, validation loss: 1.2623771584552268.
epoch: 2069, train loss: 1.2564638524974159, validation loss: 1.2719452381134033.
epoch: 2070, train loss: 1.2503015677863305, validation loss: 1.277532178422679.
epoch: 2071, train loss: 1.2528579781908509, validation loss: 1.2656130324239316.
epoch: 2072, train loss: 1.2467308733441413, validation loss: 1.2601748497589775.
epoch: 2073, train loss: 1.2471224660173468, validation loss: 1.2578053889067278.
epoch: 2074, train loss: 1.2480377910334035, validation loss: 1.264482653659323.
epoch: 2075, train loss: 1.24780140776153, validation loss: 1.2607442244239475.
epoch: 2076, train loss: 1.2479359469282518, validation loss: 1.2631876727809077.
epoch: 2077, train loss: 1.2500762480114578, validation loss: 1.2766988588416057.
epoch: 2078, train loss: 1.2496670998564554, validation loss: 1.297889232635498.
epoch: 2079, train loss: 1.2575732032093434, validation loss: 1.288590078768523.
epoch: 2080, train loss: 1.2502075269681598, validation loss: 1.259904788888019.
epoch: 2081, train loss: 1.2572135815926648, validation loss: 1.2567007697146872.
epoch: 2082, train loss: 1.2490602184873107, validation loss: 1.267945610958597.
epoch: 2083, train loss: 1.2426065862725635, validation loss: 1.267152998758399.
epoch: 2084, train loss: 1.247710943222046, validation loss: 1.2752029584801716.
epoch: 2085, train loss: 1.245154037388093, validation loss: 1.2667263124300085.
epoch: 2086, train loss: 1.2449842352385914, validation loss: 1.2636079218076623.
epoch: 2087, train loss: 1.2426280658179467, validation loss: 1.2643122413884038.
epoch: 2088, train loss: 1.2752332676441298, validation loss: 1.2799142650935962.
epoch: 2089, train loss: 1.2610436426390201, validation loss: 1.303416143292966.
epoch: 2090, train loss: 1.255868668949932, validation loss: 1.26560480179994.
epoch: 2091, train loss: 1.2542355071514024, validation loss: 1.260428506395091.
epoch: 2092, train loss: 1.2511263156155927, validation loss: 1.2777751891509346.
epoch: 2093, train loss: 1.2530287438576375, validation loss: 1.3088698179825493.
epoch: 2094, train loss: 1.252184594443085, validation loss: 1.2752828649852588.
epoch: 2095, train loss: 1.2517195240073247, validation loss: 1.2822422981262207.
epoch: 2096, train loss: 1.2467226708700898, validation loss: 1.2576045989990234.
epoch: 2097, train loss: 1.244139705229243, validation loss: 1.2596604305764902.
epoch: 2098, train loss: 1.2450568074480108, validation loss: 1.2706885234169338.
epoch: 2099, train loss: 1.3506142207241933, validation loss: 1.5510475687358691.
epoch: 2100, train loss: 1.3824132276237557, validation loss: 1.3800488969554072.
epoch: 2101, train loss: 1.346836837059861, validation loss: 1.3897124166074006.
epoch: 2102, train loss: 1.3441298325127418, validation loss: 1.3636855457140051.
epoch: 2103, train loss: 1.330641561691914, validation loss: 1.3408593716828718.
epoch: 2104, train loss: 1.321089992829419, validation loss: 1.3387288891750833.
epoch: 2105, train loss: 1.3152961162252164, validation loss: 1.3252679057743237.
epoch: 2106, train loss: 1.3107201921830482, validation loss: 1.3249942530756411.
epoch: 2107, train loss: 1.3072317248090692, validation loss: 1.3135594388713008.
epoch: 2108, train loss: 1.3032229548200556, validation loss: 1.3160170886827551.
epoch: 2109, train loss: 1.3037740779579232, validation loss: 1.3263817921928738.
epoch: 2110, train loss: 1.3057421850501945, validation loss: 1.319880874260612.
epoch: 2111, train loss: 1.3021742728872037, validation loss: 1.318180016849352.
epoch: 2112, train loss: 1.3041966420794846, validation loss: 1.3192276229029116.
epoch: 2113, train loss: 1.302033036127003, validation loss: 1.3142850139866704.
epoch: 2114, train loss: 1.2995383323879417, validation loss: 1.3074029113935388.
epoch: 2115, train loss: 1.2970732953570305, validation loss: 1.3126045620959739.
epoch: 2116, train loss: 1.297539456175008, validation loss: 1.2995841036672178.
epoch: 2117, train loss: 1.2950551302061168, validation loss: 1.3025784233342046.
epoch: 2118, train loss: 1.2937841677884443, validation loss: 1.3130172646563987.
epoch: 2119, train loss: 1.2920825897006813, validation loss: 1.3149190156356148.
epoch: 2120, train loss: 1.2937201469316395, validation loss: 1.3106264860733696.
epoch: 2121, train loss: 1.2920854026024495, validation loss: 1.310779949893122.
epoch: 2122, train loss: 1.289535726975957, validation loss: 1.2922102161075757.
epoch: 2123, train loss: 1.2906326678914761, validation loss: 1.307037970294123.
epoch: 2124, train loss: 1.2917144921941495, validation loss: 1.3200063446293706.
epoch: 2125, train loss: 1.2869550722454666, validation loss: 1.299128744913184.
epoch: 2126, train loss: 1.2859269457125881, validation loss: 1.2964353872382122.
epoch: 2127, train loss: 1.2877179712330529, validation loss: 1.3120477199554443.
epoch: 2128, train loss: 1.2920406980252048, validation loss: 1.3028070512025252.
epoch: 2129, train loss: 1.2907232144557008, validation loss: 1.3122105080148447.
epoch: 2130, train loss: 1.286415188684376, validation loss: 1.2988803386688232.
epoch: 2131, train loss: 1.2920461466553015, validation loss: 1.292363368946573.
epoch: 2132, train loss: 1.2844727837711298, validation loss: 1.302502585494.
epoch: 2133, train loss: 1.2844561808699861, validation loss: 1.2996310358462126.
epoch: 2134, train loss: 1.283987510094949, validation loss: 1.294485822967861.
epoch: 2135, train loss: 1.2826043859534306, validation loss: 1.2947410293247388.
epoch: 2136, train loss: 1.2796154295632598, validation loss: 1.3016119262446528.
epoch: 2137, train loss: 1.2810423210126545, validation loss: 1.2938683343970256.
epoch: 2138, train loss: 1.2833560005240483, validation loss: 1.3049639048783674.
epoch: 2139, train loss: 1.2845526135295904, validation loss: 1.306779752606931.
epoch: 2140, train loss: 1.2815733305904844, validation loss: 1.2935178331706836.
epoch: 2141, train loss: 1.2796282462023814, validation loss: 1.3112895903380022.
epoch: 2142, train loss: 1.2810963107905258, validation loss: 1.3024944326151973.
epoch: 2143, train loss: 1.278685667099209, validation loss: 1.291183844856594.
epoch: 2144, train loss: 1.2811529953545386, validation loss: 1.3014050048330557.
epoch: 2145, train loss: 1.281900113875713, validation loss: 1.3046142173850017.
epoch: 2146, train loss: 1.2811190994507675, validation loss: 1.2981979069502458.
epoch: 2147, train loss: 1.2771109287891913, validation loss: 1.28634672579558.
epoch: 2148, train loss: 1.2739424093053975, validation loss: 1.2931593190068784.
epoch: 2149, train loss: 1.276575740324248, validation loss: 1.2897196904472683.
epoch: 2150, train loss: 1.2724316349816978, validation loss: 1.2946941282438196.
epoch: 2151, train loss: 1.2723799156486442, validation loss: 1.2915992270345273.
epoch: 2152, train loss: 1.2754909357893358, validation loss: 1.2938326182572737.
epoch: 2153, train loss: 1.274159265220712, validation loss: 1.3022067287693853.
epoch: 2154, train loss: 1.2732827641548368, validation loss: 1.2947598695755005.
epoch: 2155, train loss: 1.27348498576278, validation loss: 1.2856888978377632.
epoch: 2156, train loss: 1.2754114308488478, validation loss: 1.2878683494484944.
epoch: 2157, train loss: 1.2748194889191093, validation loss: 1.2919697761535645.
epoch: 2158, train loss: 1.2783643499426884, validation loss: 1.2954271202502043.
epoch: 2159, train loss: 1.2773788642445836, validation loss: 1.2885870985362842.
epoch: 2160, train loss: 1.2717147792151215, validation loss: 1.30168981137483.
epoch: 2161, train loss: 1.2716101703293827, validation loss: 1.2903853499371072.
epoch: 2162, train loss: 1.2716326997914444, validation loss: 1.2837958180386086.
epoch: 2163, train loss: 1.2726408133813, validation loss: 1.2828529554864634.
epoch: 2164, train loss: 1.269414756276192, validation loss: 1.3069124273631885.
epoch: 2165, train loss: 1.2708298908461124, validation loss: 1.2894921924756921.
epoch: 2166, train loss: 1.2711386997765357, validation loss: 1.2992902942325757.
epoch: 2167, train loss: 1.2758183446499185, validation loss: 1.3027810687604158.
epoch: 2168, train loss: 1.272179729347929, validation loss: 1.2861981029095857.
epoch: 2169, train loss: 1.270486255304529, validation loss: 1.2819335978964101.
epoch: 2170, train loss: 1.2706707311332772, validation loss: 1.3022480943928594.
epoch: 2171, train loss: 1.2754647775527534, validation loss: 1.3036988196165666.
epoch: 2172, train loss: 1.2767618675844385, validation loss: 1.3062355673831443.
epoch: 2173, train loss: 1.273661188029368, validation loss: 1.2785750990328582.
epoch: 2174, train loss: 1.26860453666897, validation loss: 1.2962948083877563.
epoch: 2175, train loss: 1.2687569747277356, validation loss: 1.280385540879291.
epoch: 2176, train loss: 1.270064304728027, validation loss: 1.2909562276757283.
epoch: 2177, train loss: 1.2678072791580761, validation loss: 1.2857134290363477.
epoch: 2178, train loss: 1.2679857365581968, validation loss: 1.2851646931275078.
epoch: 2179, train loss: 1.2692846158228883, validation loss: 1.2761544922123784.
epoch: 2180, train loss: 1.2697320050055827, validation loss: 1.2884759902954102.
epoch: 2181, train loss: 1.2735081834530613, validation loss: 1.3024828589480857.
epoch: 2182, train loss: 1.2670324461175761, validation loss: 1.2749149177385413.
epoch: 2183, train loss: 1.2718253715322652, validation loss: 1.2848152855168218.
epoch: 2184, train loss: 1.2681331940747183, validation loss: 1.2778924703598022.
epoch: 2185, train loss: 1.266829812198604, validation loss: 1.2870812364246533.
epoch: 2186, train loss: 1.2684545341981661, validation loss: 1.279328465461731.
epoch: 2187, train loss: 1.2653839577228652, validation loss: 1.2758536649786907.
epoch: 2188, train loss: 1.264204513042345, validation loss: 1.283083869063336.
epoch: 2189, train loss: 1.2711886255019302, validation loss: 1.303448858468429.
epoch: 2190, train loss: 1.268488402760357, validation loss: 1.3052698892095815.
epoch: 2191, train loss: 1.268642619115497, validation loss: 1.2951824302258699.
epoch: 2192, train loss: 1.264765390562355, validation loss: 1.275612421657728.
epoch: 2193, train loss: 1.26588373009218, validation loss: 1.2846265461133874.
epoch: 2194, train loss: 1.2671925376314637, validation loss: 1.306660532951355.
epoch: 2195, train loss: 1.2738912761758228, validation loss: 1.28560427479122.
epoch: 2196, train loss: 1.2676753964992837, validation loss: 1.2815289238224858.
epoch: 2197, train loss: 1.264298962890555, validation loss: 1.2766351803489353.
epoch: 2198, train loss: 1.2664555518999012, validation loss: 1.2809304880059285.
epoch: 2199, train loss: 1.2642024985147178, validation loss: 1.300380836362424.
epoch: 2200, train loss: 1.2673124840500158, validation loss: 1.3000643616137297.
epoch: 2201, train loss: 1.2675623543765566, validation loss: 1.2884820181390513.
epoch: 2202, train loss: 1.2703919749741162, validation loss: 1.2950191394142483.
epoch: 2203, train loss: 1.2643952402499838, validation loss: 1.2870384662047676.
epoch: 2204, train loss: 1.2621840085458318, validation loss: 1.2774507481118906.
epoch: 2205, train loss: 1.2638080634108377, validation loss: 1.287430395250735.
epoch: 2206, train loss: 1.261404533998682, validation loss: 1.283085304757823.
epoch: 2207, train loss: 1.2723069672190814, validation loss: 1.2811987089074177.
epoch: 2208, train loss: 1.2609069784846874, validation loss: 1.310853678247203.
epoch: 2209, train loss: 1.265741703707144, validation loss: 1.3011385720709097.
epoch: 2210, train loss: 1.2608242231771487, validation loss: 1.3226499402004739.
epoch: 2211, train loss: 1.2661251190605514, validation loss: 1.2845644328905188.
epoch: 2212, train loss: 1.2630076484942654, validation loss: 1.2739826803622039.
epoch: 2213, train loss: 1.2670177943115934, validation loss: 1.3095009482425193.
epoch: 2214, train loss: 1.2657827795098682, validation loss: 1.2924726890481038.
epoch: 2215, train loss: 1.2618455963397244, validation loss: 1.2811491593070652.
epoch: 2216, train loss: 1.261578869382176, validation loss: 1.270452266154082.
epoch: 2217, train loss: 1.271848270652491, validation loss: 1.2845239380131597.
epoch: 2218, train loss: 1.2632403483084582, validation loss: 1.2853766005972158.
epoch: 2219, train loss: 1.2652388636125338, validation loss: 1.283208147339199.
epoch: 2220, train loss: 1.2601032672672097, validation loss: 1.2749320061310478.
epoch: 2221, train loss: 1.2699814083379344, validation loss: 1.3396149303602136.
epoch: 2222, train loss: 1.2657163558749978, validation loss: 1.288457523221555.
epoch: 2223, train loss: 1.2608177322860157, validation loss: 1.2765255337176116.
epoch: 2224, train loss: 1.2605433999945264, validation loss: 1.3175849137098894.
epoch: 2225, train loss: 1.2638466161325437, validation loss: 1.2820017337799072.
epoch: 2226, train loss: 1.259747529248579, validation loss: 1.3606648911600527.
epoch: 2227, train loss: 1.2627666794925654, validation loss: 1.29174354283706.
epoch: 2228, train loss: 1.2694283647274753, validation loss: 1.2760470276293547.
epoch: 2229, train loss: 1.2695940076758008, validation loss: 1.3002678052238796.
epoch: 2230, train loss: 1.2648669535960626, validation loss: 1.281625042790952.
epoch: 2231, train loss: 1.2636418933168463, validation loss: 1.281947135925293.
epoch: 2232, train loss: 1.2639076698810683, validation loss: 1.2844043659127278.
epoch: 2233, train loss: 1.2593104073760706, validation loss: 1.2780721705892812.
epoch: 2234, train loss: 1.257762782070615, validation loss: 1.2824109378068342.
epoch: 2235, train loss: 1.2602204674974493, validation loss: 1.2833895268647566.
epoch: 2236, train loss: 1.262565962765195, validation loss: 1.281836131344671.
epoch: 2237, train loss: 1.2624581625702185, validation loss: 1.2828385156133901.
epoch: 2238, train loss: 1.2625614546854562, validation loss: 1.2983564760373987.
epoch: 2239, train loss: 1.2625401020050049, validation loss: 1.2876048399054485.
epoch: 2240, train loss: 1.2614774288387474, validation loss: 1.2800796861233918.
epoch: 2241, train loss: 1.2592722757146992, validation loss: 1.275858718415965.
epoch: 2242, train loss: 1.266309190233913, validation loss: 1.2902480519336204.
epoch: 2243, train loss: 1.2591823951913677, validation loss: 1.2851712185403574.
epoch: 2244, train loss: 1.2638215526528316, validation loss: 1.2880949507588926.
epoch: 2245, train loss: 1.2600973614858926, validation loss: 1.2991911380187324.
epoch: 2246, train loss: 1.267746376335074, validation loss: 1.2782903391381968.
epoch: 2247, train loss: 1.2636429246412504, validation loss: 1.2724174831224524.
epoch: 2248, train loss: 1.2586064612099883, validation loss: 1.2754705366880998.
epoch: 2249, train loss: 1.27227445917392, validation loss: 1.2759120567985203.
epoch: 2250, train loss: 1.2647700080084145, validation loss: 1.2827337150988372.
epoch: 2251, train loss: 1.2639050647753094, validation loss: 1.2881030258925066.
epoch: 2252, train loss: 1.2642805434148245, validation loss: 1.2889234138571697.
epoch: 2253, train loss: 1.2616615306346788, validation loss: 1.2874061024707297.
epoch: 2254, train loss: 1.2578337006612654, validation loss: 1.268838027249212.
epoch: 2255, train loss: 1.2574232422977412, validation loss: 1.2898083510606184.
epoch: 2256, train loss: 1.2568302581069666, validation loss: 1.271386955095374.
epoch: 2257, train loss: 1.2582398663967027, validation loss: 1.3256848324900088.
epoch: 2258, train loss: 1.2590822582944818, validation loss: 1.2982334209525066.
epoch: 2259, train loss: 1.2611652798608903, validation loss: 1.2923858062080715.
epoch: 2260, train loss: 1.2559009396701777, validation loss: 1.2723377165587053.
epoch: 2261, train loss: 1.2573239934553795, validation loss: 1.3014630856721296.
epoch: 2262, train loss: 1.2624891613601545, validation loss: 1.2792920444322669.
epoch: 2263, train loss: 1.264088268673748, validation loss: 1.2841302933900252.
epoch: 2264, train loss: 1.2589149934436203, validation loss: 1.2804182716037915.
epoch: 2265, train loss: 1.2621869833097545, validation loss: 1.3270446165748264.
epoch: 2266, train loss: 1.2674732230125216, validation loss: 1.2851602512857188.
epoch: 2267, train loss: 1.2560501995436641, validation loss: 1.277779688005862.
epoch: 2268, train loss: 1.2573505694713067, validation loss: 1.270649510881175.
epoch: 2269, train loss: 1.2581318879346235, validation loss: 1.273400322250698.
epoch: 2270, train loss: 1.2550995634236466, validation loss: 1.3491111838299295.
epoch: 2271, train loss: 1.258222312008569, validation loss: 1.2736717929010806.
epoch: 2272, train loss: 1.2595653326139538, validation loss: 1.281671026478643.
epoch: 2273, train loss: 1.2612595492546712, validation loss: 1.2901786721271018.
epoch: 2274, train loss: 1.2604235990331807, validation loss: 1.2744397754254548.
epoch: 2275, train loss: 1.25886128364353, validation loss: 1.2830674078153528.
epoch: 2276, train loss: 1.2606872232682114, validation loss: 1.2781747320423955.
epoch: 2277, train loss: 1.2528467397077367, validation loss: 1.2722271473511406.
epoch: 2278, train loss: 1.254933571596758, validation loss: 1.2934055691180022.
epoch: 2279, train loss: 1.2639721467954304, validation loss: 1.2757384103277456.
epoch: 2280, train loss: 1.2611514515833024, validation loss: 1.2759983695071677.
epoch: 2281, train loss: 1.2564621704434036, validation loss: 1.2778082049411277.
epoch: 2282, train loss: 1.254886148172781, validation loss: 1.288905371790347.
epoch: 2283, train loss: 1.2546277144633302, validation loss: 1.2737202851668648.
epoch: 2284, train loss: 1.2534976661752124, validation loss: 1.287562572437784.
epoch: 2285, train loss: 1.2577379176376062, validation loss: 1.2954850352328757.
epoch: 2286, train loss: 1.2573253878759683, validation loss: 1.270776349565257.
epoch: 2287, train loss: 1.255394664379435, validation loss: 1.2762698194255.
epoch: 2288, train loss: 1.2599616433502336, validation loss: 1.2949191591014033.
epoch: 2289, train loss: 1.2663440048147778, validation loss: 1.4574697795121565.
epoch: 2290, train loss: 1.2928257688469844, validation loss: 1.3122440472893093.
epoch: 2291, train loss: 1.277459989993944, validation loss: 1.2944106381872427.
epoch: 2292, train loss: 1.265151292905895, validation loss: 1.2769960424174434.
epoch: 2293, train loss: 1.263273211794162, validation loss: 1.276682480521824.
epoch: 2294, train loss: 1.25912952860561, validation loss: 1.3182789657426917.
epoch: 2295, train loss: 1.2560878215579812, validation loss: 1.2745819299117378.
epoch: 2296, train loss: 1.2560733852036503, validation loss: 1.2858763103899749.
epoch: 2297, train loss: 1.2596571543894777, validation loss: 1.270932912826538.
epoch: 2298, train loss: 1.2570019927593545, validation loss: 1.2774709203968877.
epoch: 2299, train loss: 1.255043307575611, validation loss: 1.2700933425322822.
epoch: 2300, train loss: 1.2543437338750296, validation loss: 1.2798510427060334.
epoch: 2301, train loss: 1.2555593394358224, validation loss: 1.4485264809235283.
epoch: 2302, train loss: 1.2606824516156399, validation loss: 1.271840883337933.
epoch: 2303, train loss: 1.256230326967502, validation loss: 1.2729580039563386.
epoch: 2304, train loss: 1.2560695606634158, validation loss: 1.2897922007933906.
epoch: 2305, train loss: 1.2562620880406932, validation loss: 1.278649081354556.
epoch: 2306, train loss: 1.2550859855949332, validation loss: 1.2743034570113472.
epoch: 2307, train loss: 1.2601841578789807, validation loss: 1.2960495534150496.
epoch: 2308, train loss: 1.2667145816557999, validation loss: 1.2793633575024812.
epoch: 2309, train loss: 1.2553070368023094, validation loss: 1.2850383986597476.
epoch: 2310, train loss: 1.259546588320251, validation loss: 1.2899227349654487.
epoch: 2311, train loss: 1.256796358922206, validation loss: 1.4853845679241677.
epoch: 2312, train loss: 1.2592453125419967, validation loss: 1.3396761780199797.
epoch: 2313, train loss: 1.26144390259314, validation loss: 1.2759324986001719.
epoch: 2314, train loss: 1.25855630909631, validation loss: 1.3115571478138799.
epoch: 2315, train loss: 1.2616142854778045, validation loss: 1.277873650841091.
epoch: 2316, train loss: 1.2563733387430873, validation loss: 1.2756239642267642.
epoch: 2317, train loss: 1.2550066928251074, validation loss: 1.275300171064294.
epoch: 2318, train loss: 1.2601024590500998, validation loss: 1.2712098515552024.
epoch: 2319, train loss: 1.2552315959142983, validation loss: 1.2738142169040183.
epoch: 2320, train loss: 1.2621538037553839, validation loss: 1.3234644558118738.
epoch: 2321, train loss: 1.2726344012339181, validation loss: 1.2784524948700615.
epoch: 2322, train loss: 1.2594344014421515, validation loss: 1.3692628197048022.
epoch: 2323, train loss: 1.25486421585083, validation loss: 1.2792265518851902.
epoch: 2324, train loss: 1.2565392080796969, validation loss: 1.275440003560937.
epoch: 2325, train loss: 1.2558922942625272, validation loss: 1.2906094271203745.
epoch: 2326, train loss: 1.2578695629714827, validation loss: 1.31698667484781.
epoch: 2327, train loss: 1.2526209660626333, validation loss: 1.3494088546089504.
epoch: 2328, train loss: 1.259983201639368, validation loss: 1.3043403314507527.
epoch: 2329, train loss: 1.2586694179324929, validation loss: 1.287215372790461.
epoch: 2330, train loss: 1.2599626538950368, validation loss: 1.331888805265012.
epoch: 2331, train loss: 1.2571205447573182, validation loss: 1.2778336898140286.
epoch: 2332, train loss: 1.2516511438089772, validation loss: 1.2762579036795574.
epoch: 2333, train loss: 1.2604702328323225, validation loss: 1.2753122993137525.
epoch: 2334, train loss: 1.2543185107204893, validation loss: 1.274896782377492.
epoch: 2335, train loss: 1.2566042449496209, validation loss: 1.285629847775335.
epoch: 2336, train loss: 1.2604900368856728, validation loss: 1.2722807759824006.
epoch: 2337, train loss: 1.2538261807292974, validation loss: 1.276029804478521.
epoch: 2338, train loss: 1.252497874268698, validation loss: 1.2806448314500891.
epoch: 2339, train loss: 1.2545673803451958, validation loss: 1.2717374459556912.
epoch: 2340, train loss: 1.2526448713530094, validation loss: 1.2812328494113425.
epoch: 2341, train loss: 1.2542764014060344, validation loss: 1.2739139691643093.
epoch: 2342, train loss: 1.252085206705496, validation loss: 1.2691055225289387.
epoch: 2343, train loss: 1.2616802410248222, validation loss: 1.2708208923754485.
epoch: 2344, train loss: 1.261671469845903, validation loss: 1.2905508901761926.
epoch: 2345, train loss: 1.2579611911686188, validation loss: 1.2803455021070398.
epoch: 2346, train loss: 1.2574592128806157, validation loss: 1.269813667172971.
epoch: 2347, train loss: 1.2583627427389863, validation loss: 1.3059523779412974.
epoch: 2348, train loss: 1.2609640283322117, validation loss: 1.278807546781457.
epoch: 2349, train loss: 1.2578303617074948, validation loss: 1.2831184812214063.
epoch: 2350, train loss: 1.2590728779451563, validation loss: 1.2661562898884648.
epoch: 2351, train loss: 1.257519201401177, validation loss: 1.275462684424027.
epoch: 2352, train loss: 1.2548235228302282, validation loss: 1.2816567628279976.
epoch: 2353, train loss: 1.254890704373701, validation loss: 1.2960169056187505.
epoch: 2354, train loss: 1.2572379002877332, validation loss: 1.288128225699715.
epoch: 2355, train loss: 1.2578937143360802, validation loss: 1.2862940612046614.
epoch: 2356, train loss: 1.270395468134399, validation loss: 1.287743822388027.
epoch: 2357, train loss: 1.266156829825235, validation loss: 1.2814108703447424.
epoch: 2358, train loss: 1.2647794660078275, validation loss: 1.2643342743749204.
epoch: 2359, train loss: 1.253764605303423, validation loss: 1.3138298003569893.
epoch: 2360, train loss: 1.2634670526609508, validation loss: 1.3046557695969292.
epoch: 2361, train loss: 1.2622915014214473, validation loss: 1.2710235118865967.
epoch: 2362, train loss: 1.2545360687675826, validation loss: 1.2789653746978096.
epoch: 2363, train loss: 1.2622555308385726, validation loss: 1.3020676374435425.
epoch: 2364, train loss: 1.2531403029730561, validation loss: 1.268600064775218.
epoch: 2365, train loss: 1.2661677095868171, validation loss: 1.277906008388685.
epoch: 2366, train loss: 1.2540377378463745, validation loss: 1.277418613433838.
epoch: 2367, train loss: 1.2557546261253707, validation loss: 1.2688762467840444.
epoch: 2368, train loss: 1.2533082852669812, validation loss: 1.2686371544133062.
epoch: 2369, train loss: 1.2528088934924624, validation loss: 1.3039582138476165.
epoch: 2370, train loss: 1.2629639457125184, validation loss: 1.2881640195846558.
epoch: 2371, train loss: 1.2538154617362065, validation loss: 1.2895859065263167.
epoch: 2372, train loss: 1.2510077417443652, validation loss: 1.328797433687293.
epoch: 2373, train loss: 1.2635425449511326, validation loss: 1.2667732290599658.
epoch: 2374, train loss: 1.2495756838299812, validation loss: 1.2971436510915342.
epoch: 2375, train loss: 1.2571138766927457, validation loss: 1.2880989468615989.
epoch: 2376, train loss: 1.2585761503342094, validation loss: 1.2672499418258667.
epoch: 2377, train loss: 1.2618105684945342, validation loss: 1.2702754891437034.
epoch: 2378, train loss: 1.2557105908700086, validation loss: 1.2834173596423606.
epoch: 2379, train loss: 1.255246137260297, validation loss: 1.2742659993793652.
epoch: 2380, train loss: 1.2536349023154023, validation loss: 1.2799783737763115.
epoch: 2381, train loss: 1.2572928349906152, validation loss: 1.2817243182140847.
epoch: 2382, train loss: 1.2532640050310608, validation loss: 1.2800245129543801.
epoch: 2383, train loss: 1.2544619162148292, validation loss: 1.2952355250068333.
epoch: 2384, train loss: 1.2544631706465275, validation loss: 1.2739958555802056.
epoch: 2385, train loss: 1.251215654775637, validation loss: 1.26725565350574.
epoch: 2386, train loss: 1.2524372218945705, validation loss: 1.3411661852961.
epoch: 2387, train loss: 1.2573967953340723, validation loss: 1.3434477578038755.
epoch: 2388, train loss: 1.2541650457119724, validation loss: 1.2944690144580344.
epoch: 2389, train loss: 1.2826846356785626, validation loss: 1.2904661375543345.
epoch: 2390, train loss: 1.274272284376512, validation loss: 1.3054541556731514.
epoch: 2391, train loss: 1.2619332064182387, validation loss: 1.3001752418020498.
epoch: 2392, train loss: 1.262701778236879, validation loss: 1.2710634677306465.
epoch: 2393, train loss: 1.2595937842622809, validation loss: 1.3169976317364236.
epoch: 2394, train loss: 1.2549979599244003, validation loss: 1.281455117723216.
epoch: 2395, train loss: 1.2563964314417009, validation loss: 1.2702503100685452.
epoch: 2396, train loss: 1.3027553766145619, validation loss: 1.3392472318981006.
epoch: 2397, train loss: 1.3092529719028998, validation loss: 1.29976893507916.
epoch: 2398, train loss: 1.2852493852650353, validation loss: 1.2950659264688906.
epoch: 2399, train loss: 1.2784080111652338, validation loss: 1.2887407489444898.
epoch: 2400, train loss: 1.2609863565602433, validation loss: 1.2587315777073735.
epoch: 2401, train loss: 1.2536870208355264, validation loss: 1.2728794864986255.
epoch: 2402, train loss: 1.254836577887929, validation loss: 1.263482840164848.
epoch: 2403, train loss: 1.2500720702180075, validation loss: 1.2628316205480825.
epoch: 2404, train loss: 1.2452997669167476, validation loss: 1.2571236620778623.
epoch: 2405, train loss: 1.2451939364092066, validation loss: 1.2599949162939321.
epoch: 2406, train loss: 1.2468869718936606, validation loss: 1.257690201634946.
epoch: 2407, train loss: 1.2424981637832222, validation loss: 1.2661656089451.
epoch: 2408, train loss: 1.244768436895598, validation loss: 1.271718372469363.
epoch: 2409, train loss: 1.2484042983536328, validation loss: 1.2624662803566975.
epoch: 2410, train loss: 1.2404724753231084, validation loss: 1.2528533520905867.
epoch: 2411, train loss: 1.2395073733198534, validation loss: 1.2574641756389453.
epoch: 2412, train loss: 1.2416531733416636, validation loss: 1.2556631565093994.
epoch: 2413, train loss: 1.2467740052336946, validation loss: 1.2577325002006863.
epoch: 2414, train loss: 1.2379971578580524, validation loss: 1.272665780523549.
epoch: 2415, train loss: 1.2401411150573591, validation loss: 1.2629101535548335.
epoch: 2416, train loss: 1.2352203819729866, validation loss: 1.2620249364687048.
epoch: 2417, train loss: 1.2391729704830625, validation loss: 1.2752422923627107.
epoch: 2418, train loss: 1.2411855546706314, validation loss: 1.2541163175002388.
epoch: 2419, train loss: 1.2383389068306039, validation loss: 1.2733181870501975.
epoch: 2420, train loss: 1.241427911530941, validation loss: 1.2592447840649148.
epoch: 2421, train loss: 1.234471601083738, validation loss: 1.2706519676291423.
epoch: 2422, train loss: 1.2403517010015086, validation loss: 1.2561109066009521.
epoch: 2423, train loss: 1.236864734133449, validation loss: 1.2544560380603955.
epoch: 2424, train loss: 1.236151748840962, validation loss: 1.2678345597308616.
epoch: 2425, train loss: 1.2375080104267926, validation loss: 1.2687818693078083.
epoch: 2426, train loss: 1.2333078909357753, validation loss: 1.2608399753985198.
epoch: 2427, train loss: 1.236442568105295, validation loss: 1.2548863680466362.
epoch: 2428, train loss: 1.233210622717481, validation loss: 1.2564989639365154.
epoch: 2429, train loss: 1.2321007153309813, validation loss: 1.2549037311388098.
epoch: 2430, train loss: 1.2357501535240663, validation loss: 1.2536749476971834.
epoch: 2431, train loss: 1.2312089182914945, validation loss: 1.2560888269673223.
epoch: 2432, train loss: 1.2363827939427228, validation loss: 1.262572158937869.
epoch: 2433, train loss: 1.2508456827303684, validation loss: 1.260717080987018.
epoch: 2434, train loss: 1.2443880564575895, validation loss: 1.2700549830561099.
epoch: 2435, train loss: 1.2406212266432035, validation loss: 1.2756266542102979.
epoch: 2436, train loss: 1.2336505848333377, validation loss: 1.252212607342264.
epoch: 2437, train loss: 1.23674902784715, validation loss: 1.264955380688543.
epoch: 2438, train loss: 1.235682487487793, validation loss: 1.2533317441525667.
epoch: 2439, train loss: 1.235901947415203, validation loss: 1.2500276202740876.
epoch: 2440, train loss: 1.229277836073429, validation loss: 1.4002079393552698.
epoch: 2441, train loss: 1.2368316180115446, validation loss: 1.264716765154963.
epoch: 2442, train loss: 1.2330473902028636, validation loss: 1.2607826668283213.
epoch: 2443, train loss: 1.2334594999978301, validation loss: 1.2552510759104853.
epoch: 2444, train loss: 1.2310357629706006, validation loss: 1.258823467337567.
epoch: 2445, train loss: 1.23431733770108, validation loss: 1.2569350004196167.
epoch: 2446, train loss: 1.2342945916937031, validation loss: 1.2875199266102002.
epoch: 2447, train loss: 1.2373239173801667, validation loss: 1.259610652923584.
epoch: 2448, train loss: 1.2307923047914417, validation loss: 1.2582984955414482.
epoch: 2449, train loss: 1.2298654230362778, validation loss: 1.2707742919092593.
epoch: 2450, train loss: 1.2370412852786004, validation loss: 1.2563612201939458.
epoch: 2451, train loss: 1.2326515245875087, validation loss: 1.2531780470972476.
epoch: 2452, train loss: 1.228913770903141, validation loss: 1.2580660529758618.
epoch: 2453, train loss: 1.240480042378837, validation loss: 1.2535957668138586.
epoch: 2454, train loss: 1.2329262276308253, validation loss: 1.2549893804218457.
epoch: 2455, train loss: 1.2337926615268813, validation loss: 1.2589302684949792.
epoch: 2456, train loss: 1.2326056968181505, validation loss: 1.379079590673032.
epoch: 2457, train loss: 1.2389801532850353, validation loss: 1.2636230562044226.
epoch: 2458, train loss: 1.2328505526988878, validation loss: 1.2852165439854497.
epoch: 2459, train loss: 1.2422681926587307, validation loss: 1.2636618355046147.
epoch: 2460, train loss: 1.2328399037002424, validation loss: 1.2516629955042964.
epoch: 2461, train loss: 1.2334044559286275, validation loss: 1.2553569596746694.
epoch: 2462, train loss: 1.2301459006213267, validation loss: 1.2437523447948953.
epoch: 2463, train loss: 1.2417733286498884, validation loss: 1.2509165691292805.
epoch: 2464, train loss: 1.2316008532812837, validation loss: 1.2511101028193599.
epoch: 2465, train loss: 1.2261865696775804, validation loss: 1.260381817817688.
epoch: 2466, train loss: 1.234477786842836, validation loss: 1.2684542355330095.
epoch: 2467, train loss: 1.2360537456809928, validation loss: 1.2528573119122048.
epoch: 2468, train loss: 1.2336788385286244, validation loss: 1.2609549501667852.
epoch: 2469, train loss: 1.2299303800687877, validation loss: 1.2689407338266787.
epoch: 2470, train loss: 1.2317702792106417, validation loss: 1.2580522195152615.
epoch: 2471, train loss: 1.2300901751999462, validation loss: 1.251825467399929.
epoch: 2472, train loss: 1.2378125978172372, validation loss: 1.2657601263212122.
epoch: 2473, train loss: 1.2339963858280707, validation loss: 1.2770958931549736.
epoch: 2474, train loss: 1.2262262455914, validation loss: 1.2572538697201272.
epoch: 2475, train loss: 1.2323000398250894, validation loss: 1.2783807982569155.
epoch: 2476, train loss: 1.235125781199254, validation loss: 1.2543319930200991.
epoch: 2477, train loss: 1.2317258513301885, validation loss: 1.2575942329738452.
epoch: 2478, train loss: 1.2303518472461525, validation loss: 1.2512625818667205.
epoch: 2479, train loss: 1.2312070798436436, validation loss: 1.2597563422244529.
epoch: 2480, train loss: 1.2329672356264307, validation loss: 1.2656993347665537.
epoch: 2481, train loss: 1.235514120224419, validation loss: 1.2610522197640461.
epoch: 2482, train loss: 1.2288549383845897, validation loss: 1.2551130989323491.
epoch: 2483, train loss: 1.2283464254589256, validation loss: 1.2588685491810674.
epoch: 2484, train loss: 1.2290100023287152, validation loss: 1.2544942990593289.
epoch: 2485, train loss: 1.2278445849724866, validation loss: 1.2552061184592869.
epoch: 2486, train loss: 1.2266159615385424, validation loss: 1.262369067772575.
epoch: 2487, train loss: 1.232063445476217, validation loss: 1.2613180409307065.
epoch: 2488, train loss: 1.2264888713119226, validation loss: 1.2560934191164763.
epoch: 2489, train loss: 1.2428735997698723, validation loss: 1.2743385667386262.
epoch: 2490, train loss: 1.230099610232432, validation loss: 1.2634428946868232.
epoch: 2491, train loss: 1.2317691352389275, validation loss: 1.2694162026695583.
epoch: 2492, train loss: 1.2308591101147712, validation loss: 1.258098612660947.
epoch: 2493, train loss: 1.2251490102995426, validation loss: 1.2886229235193003.
epoch: 2494, train loss: 1.238894714127987, validation loss: 1.266409713289012.
epoch: 2495, train loss: 1.2307283178381963, validation loss: 1.2533255919166233.
epoch: 2496, train loss: 1.2257878955351103, validation loss: 1.2758580860884294.
epoch: 2497, train loss: 1.2324614721700686, validation loss: 1.2783339334570842.
epoch: 2498, train loss: 1.2359370146322688, validation loss: 1.2576085484546164.
epoch: 2499, train loss: 1.227834226888254, validation loss: 1.308854087539341.
epoch: 2500, train loss: 1.232184051373683, validation loss: 1.2742817246395608.
epoch: 2501, train loss: 1.2244466488514472, validation loss: 1.2599713646847268.
epoch: 2502, train loss: 1.23686201638038, validation loss: 1.2633396076119465.
epoch: 2503, train loss: 1.231067359994311, validation loss: 1.2522062063217163.
epoch: 2504, train loss: 1.2252362791551363, validation loss: 1.2508901513141135.
epoch: 2505, train loss: 1.2334434526775955, validation loss: 1.2497715379880823.
epoch: 2506, train loss: 1.226971936882089, validation loss: 1.257937799329343.
epoch: 2507, train loss: 1.2274146419052685, validation loss: 1.253480719483417.
epoch: 2508, train loss: 1.224099659044808, validation loss: 1.342989164849986.
epoch: 2509, train loss: 1.246815837851358, validation loss: 1.2488732182461282.
epoch: 2510, train loss: 1.2314971040148255, validation loss: 1.2481647107912146.
epoch: 2511, train loss: 1.2244972603036723, validation loss: 1.2480917080588962.
epoch: 2512, train loss: 1.2288098204026527, validation loss: 1.2802462370499321.
epoch: 2513, train loss: 1.222412827911727, validation loss: 1.3384852046551912.
epoch: 2514, train loss: 1.2319086593225461, validation loss: 1.2659507108771282.
epoch: 2515, train loss: 1.2311409766520929, validation loss: 1.2579147712044094.
epoch: 2516, train loss: 1.224638232397377, validation loss: 1.268017255741617.
epoch: 2517, train loss: 1.2426942904061133, validation loss: 1.2591150066126948.
epoch: 2518, train loss: 1.2420131252446305, validation loss: 1.3130377531051636.
epoch: 2519, train loss: 1.232802844922477, validation loss: 1.2549328804016113.
epoch: 2520, train loss: 1.2300389589519676, validation loss: 1.2826446035633916.
epoch: 2521, train loss: 1.2261561702150818, validation loss: 1.2901756245156992.
epoch: 2522, train loss: 1.2377859321209268, validation loss: 1.2778714843418286.
epoch: 2523, train loss: 1.230798522266773, validation loss: 1.2527399892392366.
epoch: 2524, train loss: 1.2258261540614137, validation loss: 1.2583827920581983.
epoch: 2525, train loss: 1.234636108809655, validation loss: 1.2654185657915862.
epoch: 2526, train loss: 1.2339876398034053, validation loss: 1.2548798840978872.
epoch: 2527, train loss: 1.2371357405951264, validation loss: 1.2606031065401824.
epoch: 2528, train loss: 1.2284464026809832, validation loss: 1.2447191528652026.
epoch: 2529, train loss: 1.2235089857643897, validation loss: 1.251036286354065.
epoch: 2530, train loss: 1.2255797069007104, validation loss: 1.2584415155908335.
epoch: 2531, train loss: 1.2310135955110602, validation loss: 1.2547487383303435.
epoch: 2532, train loss: 1.2252018462627305, validation loss: 1.2633947548658953.
epoch: 2533, train loss: 1.2371540539855257, validation loss: 1.2667364555856455.
epoch: 2534, train loss: 1.231314714895476, validation loss: 1.3027795605037524.
epoch: 2535, train loss: 1.228116560419765, validation loss: 1.2590450825898543.
epoch: 2536, train loss: 1.2302457192622194, validation loss: 1.2705544129661892.
epoch: 2537, train loss: 1.2346057388760627, validation loss: 1.2651594929073169.
epoch: 2538, train loss: 1.2258256936292036, validation loss: 1.25387384062228.
epoch: 2539, train loss: 1.2234392297377281, validation loss: 1.2758121542308642.
epoch: 2540, train loss: 1.2372183745060492, validation loss: 1.2621373871098394.
epoch: 2541, train loss: 1.2327471369997076, validation loss: 1.2527664329694665.
epoch: 2542, train loss: 1.2277259400131506, validation loss: 1.2954571091610452.
epoch: 2543, train loss: 1.2279493535330537, validation loss: 1.2586120315220044.
epoch: 2544, train loss: 1.2290942439245522, validation loss: 1.25722641011943.
epoch: 2545, train loss: 1.2440649752223163, validation loss: 1.2619889248972354.
epoch: 2546, train loss: 1.2363473548801667, validation loss: 1.2555749105370564.
epoch: 2547, train loss: 1.2395599249306075, validation loss: 1.2680729731269504.
epoch: 2548, train loss: 1.2326852772213996, validation loss: 1.2485450195229573.
epoch: 2549, train loss: 1.2241445484511349, validation loss: 1.251235904900924.
epoch: 2550, train loss: 1.2243889767095584, validation loss: 1.2499795530153357.
epoch: 2551, train loss: 1.2259503329565766, validation loss: 1.2735891083012456.
epoch: 2552, train loss: 1.2275566387613979, validation loss: 1.2722237939419954.
epoch: 2553, train loss: 1.2334272019360044, validation loss: 1.2592987547750059.
epoch: 2554, train loss: 1.2399142882145873, validation loss: 1.2505677834801052.
epoch: 2555, train loss: 1.2264366948276484, validation loss: 1.283665304598601.
epoch: 2556, train loss: 1.223480289135504, validation loss: 1.262411584024844.
epoch: 2557, train loss: 1.231031345664908, validation loss: 1.2639168500900269.
epoch: 2558, train loss: 1.2255780106290766, validation loss: 1.2482347540233447.
epoch: 2559, train loss: 1.224984498198973, validation loss: 1.264101251311924.
epoch: 2560, train loss: 1.2320489402211041, validation loss: 1.275715040123981.
epoch: 2561, train loss: 1.23157320766274, validation loss: 1.2508541552916816.
epoch: 2562, train loss: 1.2265188967416045, validation loss: 1.2993911712065986.
epoch: 2563, train loss: 1.2249626424334465, validation loss: 1.2771826360536658.
epoch: 2564, train loss: 1.22566718245865, validation loss: 1.2458394610363503.
epoch: 2565, train loss: 1.2247732134040343, validation loss: 1.2650674944338591.
epoch: 2566, train loss: 1.2360497417799923, validation loss: 1.2683947811955991.
epoch: 2567, train loss: 1.2228370904922485, validation loss: 1.2715385893116826.
epoch: 2568, train loss: 1.224054909627372, validation loss: 1.2489233898079914.
epoch: 2569, train loss: 1.2239606741371505, validation loss: 1.2732735613118047.
epoch: 2570, train loss: 1.2193978795217812, validation loss: 1.2506236719048542.
epoch: 2571, train loss: 1.2339227483906876, validation loss: 1.2787234316701475.
epoch: 2572, train loss: 1.2227960628107053, validation loss: 1.2672545236089956.
epoch: 2573, train loss: 1.2208117345057496, validation loss: 1.261956997539686.
epoch: 2574, train loss: 1.2261056221953226, validation loss: 1.3448393811350283.
epoch: 2575, train loss: 1.2302430725972586, validation loss: 1.2578382388405178.
epoch: 2576, train loss: 1.237246764909237, validation loss: 1.2676938564881035.
epoch: 2577, train loss: 1.2244688545891997, validation loss: 1.257719081381093.
epoch: 2578, train loss: 1.2273842883766244, validation loss: 1.2515219242676445.
epoch: 2579, train loss: 1.221907858454853, validation loss: 1.2742582300434941.
epoch: 2580, train loss: 1.229213807560982, validation loss: 1.2615157780439958.
epoch: 2581, train loss: 1.2227660166014225, validation loss: 1.2908458191415537.
epoch: 2582, train loss: 1.2260104724026601, validation loss: 1.258343561835911.
epoch: 2583, train loss: 1.2237843264133559, validation loss: 1.258766531944275.
epoch: 2584, train loss: 1.2280652523040771, validation loss: 1.3062781458315642.
epoch: 2585, train loss: 1.2231941737166239, validation loss: 1.3900521527165952.
epoch: 2586, train loss: 1.2253531316004762, validation loss: 1.2511412060779075.
epoch: 2587, train loss: 1.2236666504396212, validation loss: 1.2577199158461199.
epoch: 2588, train loss: 1.225868202130729, validation loss: 1.3867392436317776.
epoch: 2589, train loss: 1.224315437701864, validation loss: 1.3337788996489153.
epoch: 2590, train loss: 1.228180428163721, validation loss: 1.2589782424595044.
epoch: 2591, train loss: 1.2421243671977191, validation loss: 1.2662696423737898.
epoch: 2592, train loss: 1.231088987184227, validation loss: 1.2520850896835327.
epoch: 2593, train loss: 1.223841773260624, validation loss: 1.2593663516251936.
epoch: 2594, train loss: 1.2311876640407318, validation loss: 1.2581459231998608.
epoch: 2595, train loss: 1.2224185827675216, validation loss: 1.2569258368533591.
epoch: 2596, train loss: 1.2235158867792253, validation loss: 1.2877345033313916.
epoch: 2597, train loss: 1.235541915674822, validation loss: 1.2635245426841404.
epoch: 2598, train loss: 1.230020760396205, validation loss: 1.2676324688869973.
epoch: 2599, train loss: 1.2211482656111412, validation loss: 1.2653348394062207.
epoch: 2600, train loss: 1.2193998120246676, validation loss: 1.2513056423353113.
epoch: 2601, train loss: 1.234759236694476, validation loss: 1.2753758948782217.
epoch: 2602, train loss: 1.2248240359332583, validation loss: 1.2704426723977793.
epoch: 2603, train loss: 1.2220737496647267, validation loss: 1.2816699069479238.
epoch: 2604, train loss: 1.2457625001942345, validation loss: 1.2692944796189018.
epoch: 2605, train loss: 1.2403900087426563, validation loss: 1.2775347647459612.
epoch: 2606, train loss: 1.228248610409028, validation loss: 1.2559365241423897.
epoch: 2607, train loss: 1.2206761585463077, validation loss: 1.2520962901737378.
epoch: 2608, train loss: 1.238256658982793, validation loss: 1.271921800530475.
epoch: 2609, train loss: 1.233201503753662, validation loss: 1.258986675220987.
epoch: 2610, train loss: 1.224464388068663, validation loss: 1.2752572920011438.
epoch: 2611, train loss: 1.2283993521961598, validation loss: 1.2712982478349104.
epoch: 2612, train loss: 1.2248675582605764, validation loss: 1.27709220285001.
epoch: 2613, train loss: 1.235323185220771, validation loss: 1.271051769671233.
epoch: 2614, train loss: 1.2208220586864227, validation loss: 1.2556552731472512.
epoch: 2615, train loss: 1.2283264311081772, validation loss: 1.2577415704727173.
epoch: 2616, train loss: 1.22821863747518, validation loss: 1.267635651256727.
epoch: 2617, train loss: 1.229250108430145, validation loss: 1.2694414335748423.
epoch: 2618, train loss: 1.2300428283323936, validation loss: 1.2612011432647705.
epoch: 2619, train loss: 1.2215991742020353, validation loss: 1.2820666250975237.
epoch: 2620, train loss: 1.2364778343690646, validation loss: 1.288003532782845.
epoch: 2621, train loss: 1.2264512274243415, validation loss: 1.2563314386036084.
epoch: 2622, train loss: 1.2272579724635553, validation loss: 1.3308813882910686.
epoch: 2623, train loss: 1.232628922943675, validation loss: 1.2713803726693857.
epoch: 2624, train loss: 1.24491712915788, validation loss: 1.2717532541440881.
epoch: 2625, train loss: 1.2294960656297316, validation loss: 1.2711453178654546.
epoch: 2626, train loss: 1.227147176725055, validation loss: 1.336573828821597.
epoch: 2627, train loss: 1.2297118092895647, validation loss: 1.263877739077029.
epoch: 2628, train loss: 1.247750410246193, validation loss: 1.2579032856485117.
epoch: 2629, train loss: 1.2271557204220274, validation loss: 1.2811478583709053.
epoch: 2630, train loss: 1.239865177268282, validation loss: 1.2539432411608489.
epoch: 2631, train loss: 1.2295948420095881, validation loss: 1.2671263321586277.
epoch: 2632, train loss: 1.2345883397881043, validation loss: 1.2457463689472363.
epoch: 2633, train loss: 1.2243148580603642, validation loss: 1.2613376689993816.
epoch: 2634, train loss: 1.2278824913392372, validation loss: 1.2568191652712615.
epoch: 2635, train loss: 1.228170887045904, validation loss: 1.2691534394803254.
epoch: 2636, train loss: 1.2237818000513478, validation loss: 1.249361540960229.
epoch: 2637, train loss: 1.2255803532556657, validation loss: 1.2451294142266978.
epoch: 2638, train loss: 1.2181043504574978, validation loss: 1.2706887825675632.
epoch: 2639, train loss: 1.2260869599263602, validation loss: 1.3415010804715364.
epoch: 2640, train loss: 1.2204896156940985, validation loss: 1.336679308310799.
epoch: 2641, train loss: 1.2272395814230683, validation loss: 1.26560261975164.
epoch: 2642, train loss: 1.2206347918291705, validation loss: 1.2842597494954648.
epoch: 2643, train loss: 1.2278158588146946, validation loss: 1.251600928928541.
epoch: 2644, train loss: 1.2298957842205642, validation loss: 1.2587259748707647.
epoch: 2645, train loss: 1.2283694328518089, validation loss: 1.275310806606127.
epoch: 2646, train loss: 1.2194870010428471, validation loss: 1.3010806467222131.
epoch: 2647, train loss: 1.223791289766994, validation loss: 1.2607187654661096.
epoch: 2648, train loss: 1.225592846170478, validation loss: 1.2800821895184724.
epoch: 2649, train loss: 1.2189342122559155, validation loss: 1.2602778154870737.
epoch: 2650, train loss: 1.2343406830358943, validation loss: 1.2678713228391565.
epoch: 2651, train loss: 1.2256575844703463, validation loss: 1.2548012940779976.
epoch: 2652, train loss: 1.2208499624094833, validation loss: 1.2534067941748577.
epoch: 2653, train loss: 1.2154479715802253, validation loss: 1.2822577797848245.
epoch: 2654, train loss: 1.2264652722472444, validation loss: 1.2503295255743938.
epoch: 2655, train loss: 1.2218707307763057, validation loss: 1.256597814352616.
epoch: 2656, train loss: 1.2325574761136957, validation loss: 1.2524967971055403.
epoch: 2657, train loss: 1.2266365595913808, validation loss: 1.2690249992453533.
epoch: 2658, train loss: 1.235231807472509, validation loss: 1.2491856968921164.
epoch: 2659, train loss: 1.2256361027376368, validation loss: 1.258737942446833.
epoch: 2660, train loss: 1.22887330317716, validation loss: 1.2802950662115347.
epoch: 2661, train loss: 1.229772168561953, validation loss: 1.2527288250301196.
epoch: 2662, train loss: 1.224345380013142, validation loss: 1.2964465151662412.
epoch: 2663, train loss: 1.223388047393309, validation loss: 1.2529669015303901.
epoch: 2664, train loss: 1.217711540537143, validation loss: 1.2607542380042698.
epoch: 2665, train loss: 1.233498939680397, validation loss: 1.2641167848006538.
epoch: 2666, train loss: 1.219609196032953, validation loss: 1.274308417154395.
epoch: 2667, train loss: 1.222499671332333, validation loss: 1.3388151293215544.
epoch: 2668, train loss: 1.231077954309796, validation loss: 1.2741471529006958.
epoch: 2669, train loss: 1.2346663059444603, validation loss: 1.25502392001774.
epoch: 2670, train loss: 1.2398544943660772, validation loss: 1.27902280766031.
epoch: 2671, train loss: 1.2302335916309182, validation loss: 1.266942200453385.
epoch: 2672, train loss: 1.2460637464435822, validation loss: 1.267455121745234.
epoch: 2673, train loss: 1.236518646598956, validation loss: 1.24651212795921.
epoch: 2674, train loss: 1.221109649456969, validation loss: 1.2786554927411287.
epoch: 2675, train loss: 1.2240452635178871, validation loss: 1.2565309534902158.
epoch: 2676, train loss: 1.2154882227608916, validation loss: 1.3219771851664004.
epoch: 2677, train loss: 1.22718403754978, validation loss: 1.2774045260056206.
epoch: 2678, train loss: 1.2184940510933553, validation loss: 1.2793358668037083.
epoch: 2679, train loss: 1.2183422703261768, validation loss: 1.264448010403177.
epoch: 2680, train loss: 1.2222987074370777, validation loss: 1.2503528283989949.
epoch: 2681, train loss: 1.2266885676515211, validation loss: 1.277233642080556.
epoch: 2682, train loss: 1.2279650497873988, validation loss: 1.256541423175646.
epoch: 2683, train loss: 1.2247922836093728, validation loss: 1.3439595647480176.
epoch: 2684, train loss: 1.2235157774129044, validation loss: 1.2605952335440593.
epoch: 2685, train loss: 1.2291421430920242, validation loss: 1.2833931342415188.
epoch: 2686, train loss: 1.2362845797057544, validation loss: 1.2568464071854302.
epoch: 2687, train loss: 1.2242080377876212, validation loss: 1.266541449919991.
epoch: 2688, train loss: 1.217304767818626, validation loss: 1.2560995350713315.
epoch: 2689, train loss: 1.2245314110309706, validation loss: 1.266203507133152.
epoch: 2690, train loss: 1.2256388762675294, validation loss: 1.2658293402713279.
epoch: 2691, train loss: 1.2231250235793787, validation loss: 1.2610363182814226.
epoch: 2692, train loss: 1.2363625218015197, validation loss: 1.2635711638823799.
epoch: 2693, train loss: 1.226413352773824, validation loss: 1.2647253274917603.
epoch: 2694, train loss: 1.2211095029060994, validation loss: 1.2583515229432478.
epoch: 2695, train loss: 1.2290783169072703, validation loss: 1.2947561948195747.
epoch: 2696, train loss: 1.2266897531824374, validation loss: 1.2659698465596074.
epoch: 2697, train loss: 1.221098590334621, validation loss: 1.2784116423648337.
epoch: 2698, train loss: 1.2183638822048082, validation loss: 1.2683182695637578.
epoch: 2699, train loss: 1.2165101886889256, validation loss: 1.2796603855879412.
epoch: 2700, train loss: 1.22161170539506, validation loss: 1.2962417913519817.
epoch: 2701, train loss: 1.2233174940861693, validation loss: 1.244647451069044.
epoch: 2702, train loss: 1.224770447529784, validation loss: 1.2602735654167507.
epoch: 2703, train loss: 1.2256985869976358, validation loss: 1.250020866808684.
epoch: 2704, train loss: 1.2175486000306015, validation loss: 1.2639942117359326.
epoch: 2705, train loss: 1.2197296980324142, validation loss: 1.2775010596150937.
epoch: 2706, train loss: 1.221638042992408, validation loss: 1.286879451378532.
epoch: 2707, train loss: 1.2207788393038128, validation loss: 1.2755447418793389.
epoch: 2708, train loss: 1.2351265128599394, validation loss: 1.2604728677998418.
epoch: 2709, train loss: 1.2337168805096128, validation loss: 1.2592528851135918.
epoch: 2710, train loss: 1.2186079298684356, validation loss: 1.2642033981240315.
epoch: 2711, train loss: 1.228164913457468, validation loss: 1.2501677119213601.
epoch: 2712, train loss: 1.216527873222981, validation loss: 1.2693505494490913.
epoch: 2713, train loss: 1.2271622025638544, validation loss: 1.2527945300807124.
epoch: 2714, train loss: 1.2296658229390416, validation loss: 1.2771390780158665.
epoch: 2715, train loss: 1.232724444581828, validation loss: 1.2526344371878582.
epoch: 2716, train loss: 1.219825896648092, validation loss: 1.2487230974694956.
epoch: 2717, train loss: 1.2211700360709374, validation loss: 1.2451922997184421.
epoch: 2718, train loss: 1.2175765376572216, validation loss: 1.25777718813523.
epoch: 2719, train loss: 1.2206327029324453, validation loss: 1.2566704957381538.
epoch: 2720, train loss: 1.2229958838279094, validation loss: 1.2689117970673933.
epoch: 2721, train loss: 1.224528739211756, validation loss: 1.2506109838900359.
epoch: 2722, train loss: 1.2255480956593785, validation loss: 1.281482484029687.
epoch: 2723, train loss: 1.2235416327047786, validation loss: 1.266449430714483.
epoch: 2724, train loss: 1.22171065348004, validation loss: 1.2801143760266511.
epoch: 2725, train loss: 1.2330140072271365, validation loss: 1.2641541284063589.
epoch: 2726, train loss: 1.23461386479369, validation loss: 1.3114480091177898.
epoch: 2727, train loss: 1.2219728668895335, validation loss: 1.2929743683856467.
epoch: 2728, train loss: 1.2210423968253878, validation loss: 1.2995071618453315.
epoch: 2729, train loss: 1.2209720403776256, validation loss: 1.2477702887161919.
epoch: 2730, train loss: 1.2290862437781938, validation loss: 1.2567509568255881.
epoch: 2731, train loss: 1.2205350409953966, validation loss: 1.2544934853263523.
epoch: 2732, train loss: 1.2218128705243452, validation loss: 1.2687866428624028.
epoch: 2733, train loss: 1.2136622426706716, validation loss: 1.261677710906319.
epoch: 2734, train loss: 1.2231808572734169, validation loss: 1.2759147156839785.
epoch: 2735, train loss: 1.218700070993616, validation loss: 1.2627717101055642.
epoch: 2736, train loss: 1.2281857324302743, validation loss: 1.2496142076409382.
epoch: 2737, train loss: 1.2198873638013088, validation loss: 1.2923376249230427.
epoch: 2738, train loss: 1.2187987434754677, validation loss: 1.2941389187522556.
epoch: 2739, train loss: 1.2188918317129853, validation loss: 1.2760438037955242.
epoch: 2740, train loss: 1.2272962255215427, validation loss: 1.2553151223970496.
epoch: 2741, train loss: 1.2312070700006748, validation loss: 1.24901951395947.
epoch: 2742, train loss: 1.227990170137598, validation loss: 1.256047653115314.
epoch: 2743, train loss: 1.2239837230892356, validation loss: 1.2568792052890942.
epoch: 2744, train loss: 1.2348463677485055, validation loss: 1.2754035773484602.
epoch: 2745, train loss: 1.2240845807101748, validation loss: 1.2434215597484424.
epoch: 2746, train loss: 1.2211413514723473, validation loss: 1.275069200474283.
epoch: 2747, train loss: 1.2160867441684828, validation loss: 1.30208566914434.
epoch: 2748, train loss: 1.24270100768553, validation loss: 1.2525615018347036.
epoch: 2749, train loss: 1.2194670143477413, validation loss: 1.2620794617611428.
epoch: 2750, train loss: 1.213540808870158, validation loss: 1.2589880539023357.
epoch: 2751, train loss: 1.2268311386808344, validation loss: 1.2423268971235857.
epoch: 2752, train loss: 1.2187205192145951, validation loss: 1.248977780342102.
epoch: 2753, train loss: 1.2259221186331652, validation loss: 1.2489602876746135.
epoch: 2754, train loss: 1.2200574656145289, validation loss: 1.3446108154628589.
epoch: 2755, train loss: 1.217365793131907, validation loss: 1.282102398250414.
epoch: 2756, train loss: 1.2216962029080871, validation loss: 1.244629336440045.
epoch: 2757, train loss: 1.2258215322407013, validation loss: 1.2657644593197366.
epoch: 2758, train loss: 1.2309773263581303, validation loss: 1.276292692060056.
epoch: 2759, train loss: 1.2356746765451694, validation loss: 1.2584278428036233.
epoch: 2760, train loss: 1.2234284757474148, validation loss: 1.25451486007027.
epoch: 2761, train loss: 1.22108349231405, validation loss: 1.2990895146908967.
epoch: 2762, train loss: 1.2200554434312594, validation loss: 1.3000360416329426.
epoch: 2763, train loss: 1.2175715210240916, validation loss: 1.2520626368729963.
epoch: 2764, train loss: 1.2288715084758373, validation loss: 1.2510673533315244.
epoch: 2765, train loss: 1.2235419531480982, validation loss: 1.2480527888173643.
epoch: 2766, train loss: 1.222637314315236, validation loss: 1.2518113540566487.
epoch: 2767, train loss: 1.2201216986419958, validation loss: 1.2496038416157598.
epoch: 2768, train loss: 1.2151807360692854, validation loss: 1.2602282918017844.
epoch: 2769, train loss: 1.2214850274794693, validation loss: 1.251224714776744.
epoch: 2770, train loss: 1.241267748928945, validation loss: 1.2628211145815642.
epoch: 2771, train loss: 1.2312414143063606, validation loss: 1.2803721738898235.
epoch: 2772, train loss: 1.2287662291745527, validation loss: 1.267921603244284.
epoch: 2773, train loss: 1.2225043795524386, validation loss: 1.2861764845640764.
epoch: 2774, train loss: 1.2227039359031466, validation loss: 1.2534281222716621.
epoch: 2775, train loss: 1.2232923288957789, validation loss: 1.2939411090767903.
epoch: 2776, train loss: 1.2239058280209882, validation loss: 1.2602351800255154.
epoch: 2777, train loss: 1.2202686541671053, validation loss: 1.2594727640566619.
epoch: 2778, train loss: 1.2180299813594293, validation loss: 1.2561878484228384.
epoch: 2779, train loss: 1.216767097831866, validation loss: 1.2575425894364067.
epoch: 2780, train loss: 1.2295680002335014, validation loss: 1.263182899226313.
epoch: 2781, train loss: 1.2201836426323707, validation loss: 1.2584812330163044.
epoch: 2782, train loss: 1.2191942777108709, validation loss: 1.2537702995797861.
epoch: 2783, train loss: 1.2262498894962697, validation loss: 1.2670161257619443.
epoch: 2784, train loss: 1.222537615977296, validation loss: 1.2806056686069653.
epoch: 2785, train loss: 1.2170968700986389, validation loss: 1.2562100628147954.
epoch: 2786, train loss: 1.2184827601144073, validation loss: 1.2463620590127034.
epoch: 2787, train loss: 1.2182887136389355, validation loss: 1.2623428935589998.
epoch: 2788, train loss: 1.2206852457938937, validation loss: 1.30554155163143.
epoch: 2789, train loss: 1.217509235810796, validation loss: 1.2600702047348022.
epoch: 2790, train loss: 1.2292564429274393, validation loss: 1.268754798433055.
epoch: 2791, train loss: 1.234519119656414, validation loss: 1.2460488910260408.
epoch: 2792, train loss: 1.2282827250454404, validation loss: 1.261766537376072.
epoch: 2793, train loss: 1.2145570111930917, validation loss: 1.2738611542660256.
epoch: 2794, train loss: 1.2228183440112192, validation loss: 1.3063259954037874.
epoch: 2795, train loss: 1.2242597505586956, validation loss: 1.269948264826899.
epoch: 2796, train loss: 1.2262600222858815, validation loss: 1.252112487088079.
epoch: 2797, train loss: 1.2161926326401737, validation loss: 1.2850966816363127.
epoch: 2798, train loss: 1.215759493889065, validation loss: 1.261673004730888.
epoch: 2799, train loss: 1.2231655044293186, validation loss: 1.294535289640012.
epoch: 2800, train loss: 1.2175371646881104, validation loss: 1.260619018388831.
epoch: 2801, train loss: 1.2284105436517558, validation loss: 1.2657587839209514.
epoch: 2802, train loss: 1.222050629624533, validation loss: 1.2559812379919963.
epoch: 2803, train loss: 1.2205964622147587, validation loss: 1.2530650263247283.
epoch: 2804, train loss: 1.2216696684513617, validation loss: 1.268987837045089.
epoch: 2805, train loss: 1.2148088807359747, validation loss: 1.2942109937253206.
epoch: 2806, train loss: 1.215057546939325, validation loss: 1.2502336139264314.
epoch: 2807, train loss: 1.2129344983932075, validation loss: 1.2516036396441252.
epoch: 2808, train loss: 1.22532916834595, validation loss: 1.278495798940244.
epoch: 2809, train loss: 1.2283353499316294, validation loss: 1.2688457551209822.
epoch: 2810, train loss: 1.2327278163454949, validation loss: 1.3102383769076804.
epoch: 2811, train loss: 1.2363418460985935, validation loss: 1.25398980534595.
epoch: 2812, train loss: 1.2160399375705544, validation loss: 1.2480917547060095.
epoch: 2813, train loss: 1.2153551808191, validation loss: 1.2460884114970332.
epoch: 2814, train loss: 1.219331531349672, validation loss: 1.260455001955447.
epoch: 2815, train loss: 1.2197063231686933, validation loss: 1.2793505502783733.
epoch: 2816, train loss: 1.2179226142550827, validation loss: 1.2939825524454531.
epoch: 2817, train loss: 1.2218852775906204, validation loss: 1.2618511345075525.
epoch: 2818, train loss: 1.2217318169567564, validation loss: 1.2612626034280527.
epoch: 2819, train loss: 1.2205484722732405, validation loss: 1.2622469145318735.
epoch: 2820, train loss: 1.2194331873447524, validation loss: 1.2506325452224067.
epoch: 2821, train loss: 1.222809942490464, validation loss: 1.247677637183148.
epoch: 2822, train loss: 1.220005254133032, validation loss: 1.2540617922078008.
epoch: 2823, train loss: 1.2274550232318564, validation loss: 1.2623350412949272.
epoch: 2824, train loss: 1.2205403966641208, validation loss: 1.2498001585835996.
epoch: 2825, train loss: 1.220870583429249, validation loss: 1.2666588814362236.
epoch: 2826, train loss: 1.2249600941981744, validation loss: 1.2801948993102363.
epoch: 2827, train loss: 1.2174792071001246, validation loss: 1.2615333588226982.
epoch: 2828, train loss: 1.2148826701925435, validation loss: 1.2686148933742358.
epoch: 2829, train loss: 1.226674695627405, validation loss: 1.2624784241551938.
epoch: 2830, train loss: 1.2297786047699255, validation loss: 1.2605089622995127.
epoch: 2831, train loss: 1.2156121107416415, validation loss: 1.2587090989817744.
epoch: 2832, train loss: 1.2220165871698923, validation loss: 1.254158362098362.
epoch: 2833, train loss: 1.2182990892217793, validation loss: 1.304853361585866.
epoch: 2834, train loss: 1.2251320935170584, validation loss: 1.2495744280193164.
epoch: 2835, train loss: 1.218515855456711, validation loss: 1.2896899866021199.
epoch: 2836, train loss: 1.2218571245123486, validation loss: 1.2430184457613074.
epoch: 2837, train loss: 1.2152805131509763, validation loss: 1.2527192001757415.
epoch: 2838, train loss: 1.2261418224474705, validation loss: 1.245703707570615.
epoch: 2839, train loss: 1.2177356448742227, validation loss: 1.251489924347919.
epoch: 2840, train loss: 1.2371027622747859, validation loss: 1.2497785972512288.
epoch: 2841, train loss: 1.2217223622383329, validation loss: 1.2885300076526145.
epoch: 2842, train loss: 1.2144325774744016, validation loss: 1.2498037763263867.
epoch: 2843, train loss: 1.233668147970777, validation loss: 1.2916524151097173.
epoch: 2844, train loss: 1.2426645197999586, validation loss: 1.2469787286675496.
epoch: 2845, train loss: 1.2192358369127325, validation loss: 1.2516932124676912.
epoch: 2846, train loss: 1.2249176228811982, validation loss: 1.2495289108027583.
epoch: 2847, train loss: 1.220281740941039, validation loss: 1.275252622106801.
epoch: 2848, train loss: 1.2248957999255679, validation loss: 1.2844084293945977.
epoch: 2849, train loss: 1.2143069636931114, validation loss: 1.2893218268518862.
epoch: 2850, train loss: 1.220185843082743, validation loss: 1.2681084145670352.
epoch: 2851, train loss: 1.2210927709526973, validation loss: 1.2572126233059426.
epoch: 2852, train loss: 1.2197119959997476, validation loss: 1.261022977207018.
epoch: 2853, train loss: 1.2235794745454, validation loss: 1.2506408276765242.
epoch: 2854, train loss: 1.225752316483664, validation loss: 1.2540077644845713.
epoch: 2855, train loss: 1.217816187701094, validation loss: 1.2543238349582837.
epoch: 2856, train loss: 1.2146571841808633, validation loss: 1.2545474404874055.
epoch: 2857, train loss: 1.2229931966974101, validation loss: 1.248370657796445.
epoch: 2858, train loss: 1.2182163284459244, validation loss: 1.3590962523999421.
epoch: 2859, train loss: 1.2195333187733222, validation loss: 1.2499862546506135.
epoch: 2860, train loss: 1.212182403704442, validation loss: 1.3124909504600193.
epoch: 2861, train loss: 1.2389778762782386, validation loss: 1.2519703377848086.
epoch: 2862, train loss: 1.2172919041519865, validation loss: 1.2901830932368403.
epoch: 2863, train loss: 1.2310526699101159, validation loss: 1.244857668876648.
epoch: 2864, train loss: 1.2257707512706792, validation loss: 1.2737745513086733.
epoch: 2865, train loss: 1.2317820984289187, validation loss: 1.2652276495228643.
epoch: 2866, train loss: 1.2248323576165996, validation loss: 1.2514495797779248.
epoch: 2867, train loss: 1.2356721436211822, validation loss: 1.257504499476889.
epoch: 2868, train loss: 1.2283375033544839, validation loss: 1.262079612068508.
epoch: 2869, train loss: 1.219212299093194, validation loss: 1.2531436059785925.
epoch: 2870, train loss: 1.2202803126168906, validation loss: 1.2664610147476196.
epoch: 2871, train loss: 1.2278774025243357, validation loss: 1.2603844507880833.
epoch: 2872, train loss: 1.2182467388450553, validation loss: 1.2580634459205295.
epoch: 2873, train loss: 1.2185704697162734, validation loss: 1.254181524981623.
epoch: 2874, train loss: 1.2155156999553016, validation loss: 1.2411918588306592.
epoch: 2875, train loss: 1.2138879660072677, validation loss: 1.2520350839780725.
epoch: 2876, train loss: 1.2125565797910778, validation loss: 1.2662455361822378.
epoch: 2877, train loss: 1.2264305823439852, validation loss: 1.2522582904152249.
epoch: 2878, train loss: 1.2150022688261959, validation loss: 1.2659695303958396.
epoch: 2879, train loss: 1.2121354418063381, validation loss: 1.2511257969814797.
epoch: 2880, train loss: 1.216773356866399, validation loss: 1.2844637736030247.
epoch: 2881, train loss: 1.2259066629847255, validation loss: 1.2465902877890545.
epoch: 2882, train loss: 1.2129201790608397, validation loss: 1.2618470554766448.
epoch: 2883, train loss: 1.2220074485201355, validation loss: 1.2422981003056401.
epoch: 2884, train loss: 1.2204500425846205, validation loss: 1.2540160884027896.
epoch: 2885, train loss: 1.2145322583137301, validation loss: 1.254384439924489.
epoch: 2886, train loss: 1.2309195962520914, validation loss: 1.2997289118559465.
epoch: 2887, train loss: 1.2371347398932921, validation loss: 1.2815178321755452.
epoch: 2888, train loss: 1.2246138327712313, validation loss: 1.2715779905733855.
epoch: 2889, train loss: 1.2293286815695805, validation loss: 1.259932367698006.
epoch: 2890, train loss: 1.2176030852379056, validation loss: 1.275373355202053.
epoch: 2891, train loss: 1.2249010845061836, validation loss: 1.2687830924987793.
epoch: 2892, train loss: 1.238724730430393, validation loss: 1.3340214750041133.
epoch: 2893, train loss: 1.2395964959345827, validation loss: 1.2452087039532869.
epoch: 2894, train loss: 1.220788524785173, validation loss: 1.256499979806983.
epoch: 2895, train loss: 1.2169695589520515, validation loss: 1.243071436882019.
epoch: 2896, train loss: 1.2109672695124916, validation loss: 1.255849319955577.
epoch: 2897, train loss: 1.2309178267050227, validation loss: 1.2624735573063726.
epoch: 2898, train loss: 1.2322817909608192, validation loss: 1.2645182246747224.
epoch: 2899, train loss: 1.2183021033575776, validation loss: 1.2591490330903425.
epoch: 2900, train loss: 1.2185609592210263, validation loss: 1.245576060336569.
epoch: 2901, train loss: 1.2124451398849487, validation loss: 1.2566691170568052.
epoch: 2902, train loss: 1.2159670175762352, validation loss: 1.2516003795292066.
epoch: 2903, train loss: 1.212268559210891, validation loss: 1.253289590711179.
epoch: 2904, train loss: 1.2143471886258606, validation loss: 1.2661438662072886.
epoch: 2905, train loss: 1.2211006070495745, validation loss: 1.2797108784965847.
epoch: 2906, train loss: 1.2177136906790078, validation loss: 1.2730302603348442.
epoch: 2907, train loss: 1.2152098253232624, validation loss: 1.2580678722132808.
epoch: 2908, train loss: 1.2187754736034149, validation loss: 1.3097369981848674.
epoch: 2909, train loss: 1.2277344683988378, validation loss: 1.2660336960916934.
epoch: 2910, train loss: 1.2267972755869594, validation loss: 1.259578632271808.
epoch: 2911, train loss: 1.219383119443141, validation loss: 1.2587000909058943.
epoch: 2912, train loss: 1.2176613610818845, validation loss: 1.2505531207374905.
epoch: 2913, train loss: 1.2251804082765492, validation loss: 1.2524629934974338.
epoch: 2914, train loss: 1.2129410363118582, validation loss: 1.2641000955001167.
epoch: 2915, train loss: 1.228335352118956, validation loss: 1.2590615231057871.
epoch: 2916, train loss: 1.2243430778520916, validation loss: 1.2659387122029844.
epoch: 2917, train loss: 1.2208490929472338, validation loss: 1.2561968202176301.
epoch: 2918, train loss: 1.2223144168153814, validation loss: 1.2738518922225288.
epoch: 2919, train loss: 1.2210718108973373, validation loss: 1.2432404963866523.
epoch: 2920, train loss: 1.2169888216421145, validation loss: 1.2965054874834807.
epoch: 2921, train loss: 1.2122269814167548, validation loss: 1.250008691912112.
epoch: 2922, train loss: 1.2158876723105754, validation loss: 1.2615486176117607.
epoch: 2923, train loss: 1.217788028060843, validation loss: 1.3478619223055632.
epoch: 2924, train loss: 1.2193371735581564, validation loss: 1.2426187421964563.
epoch: 2925, train loss: 1.2174867172853663, validation loss: 1.267392142959263.
epoch: 2926, train loss: 1.2168549561719282, validation loss: 1.378971006559289.
epoch: 2927, train loss: 1.225075538005304, validation loss: 1.2397549307864646.
epoch: 2928, train loss: 1.2150899642104402, validation loss: 1.25670441855555.
epoch: 2929, train loss: 1.2108124308629866, validation loss: 1.261713198993517.
epoch: 2930, train loss: 1.2290636541646556, validation loss: 1.2595229511675627.
epoch: 2931, train loss: 1.223924201562864, validation loss: 1.2422104659287825.
epoch: 2932, train loss: 1.220041872164525, validation loss: 1.2533172731814177.
epoch: 2933, train loss: 1.2261651218484302, validation loss: 1.2684132949165676.
epoch: 2934, train loss: 1.2212390418446393, validation loss: 1.2838552153628806.
epoch: 2935, train loss: 1.2149279008217908, validation loss: 1.2965237420538198.
epoch: 2936, train loss: 1.2216271085476658, validation loss: 1.312331754228343.
epoch: 2937, train loss: 1.231143297405418, validation loss: 1.2470414068387903.
epoch: 2938, train loss: 1.216518813316975, validation loss: 1.2539772728215093.
epoch: 2939, train loss: 1.2123157573402474, validation loss: 1.2408711910247803.
epoch: 2940, train loss: 1.221189376411088, validation loss: 1.264808670334194.
epoch: 2941, train loss: 1.2123053347298858, validation loss: 1.2591025207353674.
epoch: 2942, train loss: 1.2226540134587418, validation loss: 1.2745412950930388.
epoch: 2943, train loss: 1.224975692022831, validation loss: 1.2699750039888464.
epoch: 2944, train loss: 1.2208281525778115, validation loss: 1.3091381788253784.
epoch: 2945, train loss: 1.2217186700313463, validation loss: 1.3368886190911997.
epoch: 2946, train loss: 1.2255509938668767, validation loss: 1.2484966050023618.
epoch: 2947, train loss: 1.2241441853549502, validation loss: 1.2502507852471394.
epoch: 2948, train loss: 1.228677003755482, validation loss: 1.2521677587343298.
epoch: 2949, train loss: 1.2200968812365052, validation loss: 1.2613152991170469.
epoch: 2950, train loss: 1.2179228461116827, validation loss: 1.243976328683936.
epoch: 2951, train loss: 1.2159323254856496, validation loss: 1.295912566392318.
epoch: 2952, train loss: 1.2117612908739563, validation loss: 1.3364175350769707.
epoch: 2953, train loss: 1.21712277898001, validation loss: 1.265415274578592.
epoch: 2954, train loss: 1.2255073873274918, validation loss: 1.36192496444868.
epoch: 2955, train loss: 1.2422605545148937, validation loss: 1.2714956687844319.
epoch: 2956, train loss: 1.2245876176641621, validation loss: 1.3202518743017446.
epoch: 2957, train loss: 1.2107966088373727, validation loss: 1.2552446386088496.
epoch: 2958, train loss: 1.2168286787260563, validation loss: 1.2705232682435408.
epoch: 2959, train loss: 1.2108971744502357, validation loss: 1.2825414823449177.
epoch: 2960, train loss: 1.2166182371454501, validation loss: 1.2471572108890698.
epoch: 2961, train loss: 1.2076257018867982, validation loss: 1.252540831980498.
epoch: 2962, train loss: 1.2153398192256963, validation loss: 1.2798887646716575.
epoch: 2963, train loss: 1.2129620029291976, validation loss: 1.298826699671538.
epoch: 2964, train loss: 1.2317643854596199, validation loss: 1.3961956086366072.
epoch: 2965, train loss: 1.221874708429389, validation loss: 1.2467385996942935.
epoch: 2966, train loss: 1.2155822646727257, validation loss: 1.2572178115015444.
epoch: 2967, train loss: 1.2207198416421172, validation loss: 1.2420023472412773.
epoch: 2968, train loss: 1.2211013026193742, validation loss: 1.292058395302814.
epoch: 2969, train loss: 1.2176401407346813, validation loss: 1.2866521088973335.
epoch: 2970, train loss: 1.2135508279187963, validation loss: 1.2621832619542661.
epoch: 2971, train loss: 1.2281559487001612, validation loss: 1.2684772999390312.
epoch: 2972, train loss: 1.2229390144348145, validation loss: 1.281766829283341.
epoch: 2973, train loss: 1.2224814060631148, validation loss: 1.2584307090095852.
epoch: 2974, train loss: 1.219002699633257, validation loss: 1.2447252584540325.
epoch: 2975, train loss: 1.218094999637079, validation loss: 1.2470181558443152.
epoch: 2976, train loss: 1.2111029132790523, validation loss: 1.2350234207899675.
epoch: 2977, train loss: 1.2078566551208496, validation loss: 1.2614007047984912.
epoch: 2978, train loss: 1.2102992173728593, validation loss: 1.3317420482635498.
epoch: 2979, train loss: 1.2273767617864346, validation loss: 1.2372211114219998.
epoch: 2980, train loss: 1.2237364622431064, validation loss: 1.2866692957670793.
epoch: 2981, train loss: 1.2132587465671225, validation loss: 1.2540284809858904.
epoch: 2982, train loss: 1.2094310336156722, validation loss: 1.3042059203852778.
epoch: 2983, train loss: 1.2151439999221663, validation loss: 1.2855846467225447.
epoch: 2984, train loss: 1.2143603858597782, validation loss: 1.2599438221558281.
epoch: 2985, train loss: 1.2099430615748834, validation loss: 1.3224016065182893.
epoch: 2986, train loss: 1.2237991433624829, validation loss: 1.2505753869595735.
epoch: 2987, train loss: 1.2252170973961507, validation loss: 1.2668197465979534.
epoch: 2988, train loss: 1.2227600386383337, validation loss: 1.251808498216712.
epoch: 2989, train loss: 1.211783755809889, validation loss: 1.2541092789691428.
epoch: 2990, train loss: 1.2232609943512383, validation loss: 1.2808566300765327.
epoch: 2991, train loss: 1.2195310581714736, validation loss: 1.27698248365651.
epoch: 2992, train loss: 1.2247790196619996, validation loss: 1.2709786736446878.
epoch: 2993, train loss: 1.2200337418722451, validation loss: 1.3291312456130981.
epoch: 2994, train loss: 1.2172854493517395, validation loss: 1.2705907769825147.
epoch: 2995, train loss: 1.2288225320501065, validation loss: 1.2517255751982979.
epoch: 2996, train loss: 1.223231003918779, validation loss: 1.2708201252895852.
epoch: 2997, train loss: 1.220141771736495, validation loss: 1.2618526583132537.
epoch: 2998, train loss: 1.2150752544403076, validation loss: 1.2569021504858267.
epoch: 2999, train loss: 1.2164159739783051, validation loss: 1.2463239586871604.
epoch: 3000, train loss: 1.2096246601244725, validation loss: 1.2633951746899148.
epoch: 3001, train loss: 1.2249973618656123, validation loss: 1.2812705143638279.
epoch: 3002, train loss: 1.2352555388704352, validation loss: 1.2396124756854514.
epoch: 3003, train loss: 1.2242205482010449, validation loss: 1.2659560390140698.
epoch: 3004, train loss: 1.2260729107288046, validation loss: 1.2639579721119092.
epoch: 3005, train loss: 1.2187358567474085, validation loss: 1.2834635454675425.
epoch: 3006, train loss: 1.2126922651168404, validation loss: 1.2468404821727588.
epoch: 3007, train loss: 1.217225738621633, validation loss: 1.2636189512584521.
epoch: 3008, train loss: 1.225190345300447, validation loss: 1.2643248983051465.
epoch: 3009, train loss: 1.2156576290043122, validation loss: 1.2549371926680855.
epoch: 3010, train loss: 1.2166635793283445, validation loss: 1.2584265677825264.
epoch: 3011, train loss: 1.221803824835961, validation loss: 1.3029681806978972.
epoch: 3012, train loss: 1.213201208945808, validation loss: 1.2817220014074575.
epoch: 3013, train loss: 1.219094981840991, validation loss: 1.2623369952906733.
epoch: 3014, train loss: 1.2193817009619616, validation loss: 1.243681964666947.
epoch: 3015, train loss: 1.2118852083836127, validation loss: 1.35907548925151.
epoch: 3016, train loss: 1.2200244096441006, validation loss: 1.252748686334361.
epoch: 3017, train loss: 1.2198413479218788, validation loss: 1.2648504868797634.
epoch: 3018, train loss: 1.2245789678818588, validation loss: 1.2508334284243376.
epoch: 3019, train loss: 1.2144572592656546, validation loss: 1.241986279902251.
epoch: 3020, train loss: 1.209425740285751, validation loss: 1.2637766962466033.
epoch: 3021, train loss: 1.2601430875445725, validation loss: 1.3529803908389548.
epoch: 3022, train loss: 1.2272440971584495, validation loss: 1.2608634596285613.
epoch: 3023, train loss: 1.220169614214416, validation loss: 1.2570725109266199.
epoch: 3024, train loss: 1.2114002562444144, validation loss: 1.279829097830731.
epoch: 3025, train loss: 1.2313477205573966, validation loss: 1.2580457822136257.
epoch: 3026, train loss: 1.2237280060391906, validation loss: 1.4297814576522163.
epoch: 3027, train loss: 1.235213887800864, validation loss: 1.2460832129354062.
epoch: 3028, train loss: 1.2241459166238067, validation loss: 1.2440610813057942.
epoch: 3029, train loss: 1.2127232081299528, validation loss: 1.2918857180553933.
epoch: 3030, train loss: 1.2214120035871454, validation loss: 1.246906192406364.
epoch: 3031, train loss: 1.2322235643316846, validation loss: 1.2530288281648054.
epoch: 3032, train loss: 1.2149806656968702, validation loss: 1.2716887204543403.
epoch: 3033, train loss: 1.2200200601455269, validation loss: 1.2941170723541924.
epoch: 3034, train loss: 1.213295261794274, validation loss: 1.2565382459889287.
epoch: 3035, train loss: 1.2414331654889867, validation loss: 1.3514392583266548.
epoch: 3036, train loss: 1.2272608980126338, validation loss: 1.2609664098076199.
epoch: 3037, train loss: 1.213796621068902, validation loss: 1.253822305928106.
epoch: 3038, train loss: 1.2117522069073599, validation loss: 1.249799132347107.
epoch: 3039, train loss: 1.2104075064352893, validation loss: 1.3746972498686418.
epoch: 3040, train loss: 1.2223381154034116, validation loss: 1.2768544373304949.
epoch: 3041, train loss: 1.2239238920561764, validation loss: 1.248726098433785.
epoch: 3042, train loss: 1.223531077761169, validation loss: 1.255867574525916.
epoch: 3043, train loss: 1.23046494405204, validation loss: 1.2509672589924024.
epoch: 3044, train loss: 1.2190256698415913, validation loss: 1.2507950274840645.
epoch: 3045, train loss: 1.2119428684952063, validation loss: 1.267609435579051.
epoch: 3046, train loss: 1.2247126933631547, validation loss: 1.2584025859832764.
epoch: 3047, train loss: 1.2165930730487229, validation loss: 1.2538632465445476.
epoch: 3048, train loss: 1.2229739690045698, validation loss: 1.257371099098869.
epoch: 3049, train loss: 1.2170029955172756, validation loss: 1.2730404501375945.
epoch: 3050, train loss: 1.2202894775145645, validation loss: 1.3075808856798254.
epoch: 3051, train loss: 1.2258318662643433, validation loss: 1.2647916596868765.
epoch: 3052, train loss: 1.2195028022888603, validation loss: 1.266439059506292.
epoch: 3053, train loss: 1.2153313083386204, validation loss: 1.2709590196609497.
epoch: 3054, train loss: 1.225067867051571, validation loss: 1.2700982041980908.
epoch: 3055, train loss: 1.220802875833774, validation loss: 1.2532052319982778.
epoch: 3056, train loss: 1.2127891778945923, validation loss: 1.2633888565975686.
epoch: 3057, train loss: 1.22056168044379, validation loss: 1.283671031827512.
epoch: 3058, train loss: 1.2112439805214559, validation loss: 1.2597830036412114.
epoch: 3059, train loss: 1.210955266558796, validation loss: 1.2672057721925818.
epoch: 3060, train loss: 1.2153390066339336, validation loss: 1.2888594710308572.
epoch: 3061, train loss: 1.2214759949150436, validation loss: 1.3391919602518496.
epoch: 3062, train loss: 1.2193518483310664, validation loss: 1.261353637861169.
epoch: 3063, train loss: 1.2233779638185414, validation loss: 1.2508277893066406.
epoch: 3064, train loss: 1.221607751802567, validation loss: 1.2615716975668203.
epoch: 3065, train loss: 1.2195029608700254, validation loss: 1.256505416787189.
epoch: 3066, train loss: 1.2153860844603372, validation loss: 1.2602354184440945.
epoch: 3067, train loss: 1.2173829144294108, validation loss: 1.3169560743414837.
epoch: 3068, train loss: 1.2097411855645137, validation loss: 1.2554784339407217.
epoch: 3069, train loss: 1.213925193209167, validation loss: 1.2969495628191077.
epoch: 3070, train loss: 1.2124123857655655, validation loss: 1.3220551480417666.
epoch: 3071, train loss: 1.2138738358786347, validation loss: 1.2653920961462932.
epoch: 3072, train loss: 1.223660121270276, validation loss: 1.4537715860035108.
epoch: 3073, train loss: 1.2199840939373052, validation loss: 1.2456002390902976.
epoch: 3074, train loss: 1.2120262012569183, validation loss: 1.2661640799563865.
epoch: 3075, train loss: 1.220690849724166, validation loss: 1.269025496814562.
epoch: 3076, train loss: 1.2185449600219727, validation loss: 1.2721154897109321.
epoch: 3077, train loss: 1.224411743496536, validation loss: 1.2694108382515286.
epoch: 3078, train loss: 1.2164345465668844, validation loss: 1.2507520292116248.
epoch: 3079, train loss: 1.2277584710252394, validation loss: 1.2748106303422346.
epoch: 3080, train loss: 1.234964386038824, validation loss: 1.2619850635528564.
epoch: 3081, train loss: 1.2284305456581466, validation loss: 1.2605437765950742.
epoch: 3082, train loss: 1.2147304639903778, validation loss: 1.2521556149358335.
epoch: 3083, train loss: 1.216213630973746, validation loss: 1.2528271053148352.
epoch: 3084, train loss: 1.210861425880992, validation loss: 1.2667583175327466.
epoch: 3085, train loss: 1.209940436783187, validation loss: 1.254587313403254.
epoch: 3086, train loss: 1.2148741450878457, validation loss: 1.2688620556955752.
epoch: 3087, train loss: 1.2211101908202564, validation loss: 1.2576249630554863.
epoch: 3088, train loss: 1.222481380908861, validation loss: 1.260905146598816.
epoch: 3089, train loss: 1.222017046508439, validation loss: 1.2571422950081204.
epoch: 3090, train loss: 1.2235513739629622, validation loss: 1.3764206222865893.
epoch: 3091, train loss: 1.2116730792806782, validation loss: 1.274736762046814.
epoch: 3092, train loss: 1.2263335547315966, validation loss: 1.2989295565563699.
epoch: 3093, train loss: 1.2145346435931845, validation loss: 1.256965818612472.
epoch: 3094, train loss: 1.2181867295448934, validation loss: 1.2584570698116138.
epoch: 3095, train loss: 1.2255313166784585, validation loss: 1.2619067637816719.
epoch: 3096, train loss: 1.2204877925575326, validation loss: 1.29253816086313.
epoch: 3097, train loss: 1.2200106098017562, validation loss: 1.2558344395264336.
epoch: 3098, train loss: 1.221950440231813, validation loss: 1.2526187067446501.
epoch: 3099, train loss: 1.2177975757406392, validation loss: 1.2513258457183838.
epoch: 3100, train loss: 1.2255016762182254, validation loss: 1.259507821953815.
epoch: 3101, train loss: 1.2217655674033208, validation loss: 1.245633576227271.
epoch: 3102, train loss: 1.209071217326943, validation loss: 1.2616074810857358.
epoch: 3103, train loss: 1.2113518222756343, validation loss: 1.2800548646761023.
epoch: 3104, train loss: 1.2192998479265686, validation loss: 1.3778672477473384.
epoch: 3105, train loss: 1.2177723580544149, validation loss: 1.3459331781967827.
epoch: 3106, train loss: 1.2137562244310292, validation loss: 1.2579405722410784.
epoch: 3107, train loss: 1.2127203974155112, validation loss: 1.2722254836040994.
epoch: 3108, train loss: 1.2187980019718134, validation loss: 1.2574571163757988.
epoch: 3109, train loss: 1.2223549665661033, validation loss: 1.2517451877179353.
epoch: 3110, train loss: 1.2207610771196697, validation loss: 1.2494839533515598.
epoch: 3111, train loss: 1.2086156234828704, validation loss: 1.3652976854987766.
epoch: 3112, train loss: 1.229016603679832, validation loss: 1.3089928730674412.
epoch: 3113, train loss: 1.2179803017082564, validation loss: 1.278276598971823.
epoch: 3114, train loss: 1.2127103050914378, validation loss: 1.2717001852781877.
epoch: 3115, train loss: 1.2170234842037937, validation loss: 1.321321373400481.
epoch: 3116, train loss: 1.211353830241282, validation loss: 1.3579981327056885.
epoch: 3117, train loss: 1.215129583253773, validation loss: 1.2622366055198337.
epoch: 3118, train loss: 1.2126335736808427, validation loss: 1.3179703588071077.
epoch: 3119, train loss: 1.2460728140052306, validation loss: 1.2476922169975613.
epoch: 3120, train loss: 1.223159390851992, validation loss: 1.2922405263651973.
epoch: 3121, train loss: 1.222225615737635, validation loss: 1.2637776343718818.
epoch: 3122, train loss: 1.2124734712303231, validation loss: 1.3012690336807915.
epoch: 3123, train loss: 1.2265973966056054, validation loss: 1.2512500441592673.
epoch: 3124, train loss: 1.2213814072652693, validation loss: 1.26814299562703.
epoch: 3125, train loss: 1.2161937164604117, validation loss: 1.2977873397910076.
epoch: 3126, train loss: 1.2098322669300465, validation loss: 1.3095312066700147.
epoch: 3127, train loss: 1.2131865527651726, validation loss: 1.2550401376641316.
epoch: 3128, train loss: 1.2167193080307146, validation loss: 1.2596260620200115.
epoch: 3129, train loss: 1.2215447163363116, validation loss: 1.267798257910687.
epoch: 3130, train loss: 1.2124506169502889, validation loss: 1.2483909907548323.
epoch: 3131, train loss: 1.2102017971353793, validation loss: 1.2608352951381518.
epoch: 3132, train loss: 1.223375673687786, validation loss: 1.275836275971454.
epoch: 3133, train loss: 1.229212301586746, validation loss: 1.249002482580102.
epoch: 3134, train loss: 1.218181600264453, validation loss: 1.2662849115288777.
epoch: 3135, train loss: 1.204703106792695, validation loss: 1.296804640604102.
epoch: 3136, train loss: 1.2076942789445229, validation loss: 1.3435423166855522.
epoch: 3137, train loss: 1.2266887481059503, validation loss: 1.2595014416653176.
epoch: 3138, train loss: 1.216966643245942, validation loss: 1.2609507156454998.
epoch: 3139, train loss: 1.2132057246811894, validation loss: 1.2762581213660862.
epoch: 3140, train loss: 1.2240684666764845, validation loss: 1.2744226092877595.
epoch: 3141, train loss: 1.228547204525099, validation loss: 1.258599535278652.
epoch: 3142, train loss: 1.2292870294063463, validation loss: 1.2941122366034465.
epoch: 3143, train loss: 1.2277649137951911, validation loss: 1.2754778965659763.
epoch: 3144, train loss: 1.21750706817032, validation loss: 1.2593832689782847.
epoch: 3145, train loss: 1.2209488470619971, validation loss: 1.257060346396073.
epoch: 3146, train loss: 1.2127560038085377, validation loss: 1.2531802654266357.
epoch: 3147, train loss: 1.2121913301835365, validation loss: 1.246283857718758.
epoch: 3148, train loss: 1.2197772089494479, validation loss: 1.2964842785959658.
epoch: 3149, train loss: 1.2155853761445492, validation loss: 1.2597869219987288.
epoch: 3150, train loss: 1.2086044189033158, validation loss: 1.3314914288728132.
epoch: 3151, train loss: 1.2174932038018462, validation loss: 1.260039676790652.
epoch: 3152, train loss: 1.2289198429212658, validation loss: 1.2553583694540935.
epoch: 3153, train loss: 1.2160566684302934, validation loss: 1.2791085139564846.
epoch: 3154, train loss: 1.2085048036837795, validation loss: 1.2623298168182373.
epoch: 3155, train loss: 1.220936228375916, validation loss: 1.248571287030759.
epoch: 3156, train loss: 1.2158807056759475, validation loss: 1.2674319277638975.
epoch: 3157, train loss: 1.2247759847466004, validation loss: 1.2503500762193098.
epoch: 3158, train loss: 1.2158624415003925, validation loss: 1.2516328044559644.
epoch: 3159, train loss: 1.2210248446245806, validation loss: 1.2552385122879692.
epoch: 3160, train loss: 1.2140041720976524, validation loss: 1.2501841679863308.
epoch: 3161, train loss: 1.2157344347840056, validation loss: 1.2450820363086204.
epoch: 3162, train loss: 1.2177011233950974, validation loss: 1.26025114370429.
epoch: 3163, train loss: 1.2246071286157731, validation loss: 1.2729406719622405.
epoch: 3164, train loss: 1.2134859791589439, validation loss: 1.2487464365751848.
epoch: 3165, train loss: 1.2083290432571272, validation loss: 1.2563262918721074.
epoch: 3166, train loss: 1.221825413747665, validation loss: 1.291779823925184.
epoch: 3167, train loss: 1.2323047961663762, validation loss: 1.2470323365667593.
epoch: 3168, train loss: 1.2210445633722007, validation loss: 1.2518686159797336.
epoch: 3169, train loss: 1.2201517382892995, validation loss: 1.2784507689268694.
epoch: 3170, train loss: 1.2128857308571492, validation loss: 1.3104938216831372.
epoch: 3171, train loss: 1.2210437726537022, validation loss: 1.295721665672634.
epoch: 3172, train loss: 1.2196184702969473, validation loss: 1.2534841143566628.
epoch: 3173, train loss: 1.2171024215330772, validation loss: 1.2569195913231892.
epoch: 3174, train loss: 1.220042268070606, validation loss: 1.2491065937539805.
epoch: 3175, train loss: 1.2278356103722108, validation loss: 1.2433752184328826.
epoch: 3176, train loss: 1.2184763009395074, validation loss: 1.258064866065979.
epoch: 3177, train loss: 1.220412312297646, validation loss: 1.4114643128021904.
epoch: 3178, train loss: 1.2179663345354412, validation loss: 1.2641998270283574.
epoch: 3179, train loss: 1.2479897103178392, validation loss: 1.2775591249051301.
epoch: 3180, train loss: 1.2360074224822017, validation loss: 1.249373664026675.
epoch: 3181, train loss: 1.2252336642064086, validation loss: 1.254086390785549.
epoch: 3182, train loss: 1.2213213771855065, validation loss: 1.2676119286081065.
epoch: 3183, train loss: 1.2220009784086034, validation loss: 1.253659030665522.
epoch: 3184, train loss: 1.2131611305639285, validation loss: 1.271246303682742.
epoch: 3185, train loss: 1.2107462019001671, validation loss: 1.269882839658986.
epoch: 3186, train loss: 1.2189817111426537, validation loss: 1.2360826056936514.
epoch: 3187, train loss: 1.224968856627788, validation loss: 1.2708686538364575.
epoch: 3188, train loss: 1.225728772102146, validation loss: 1.2458185320315154.
epoch: 3189, train loss: 1.2180237923193415, validation loss: 1.2589862139328667.
epoch: 3190, train loss: 1.2218582061452603, validation loss: 1.2715353965759277.
epoch: 3191, train loss: 1.2184547612426477, validation loss: 1.3079439297966335.
epoch: 3192, train loss: 1.2217948611723173, validation loss: 1.2543580480243848.
epoch: 3193, train loss: 1.2102256882081337, validation loss: 1.2484173930209617.
epoch: 3194, train loss: 1.2153550091139766, validation loss: 1.2673041198564612.
epoch: 3195, train loss: 1.2164197886755708, validation loss: 1.2835285352623982.
epoch: 3196, train loss: 1.2276183158979503, validation loss: 1.2450719398000967.
epoch: 3197, train loss: 1.2152068833692358, validation loss: 1.2664978141370027.
epoch: 3198, train loss: 1.218638000138309, validation loss: 1.3296966760054878.
epoch: 3199, train loss: 1.211881219793897, validation loss: 1.2976650362429412.
epoch: 3200, train loss: 1.2248906717387908, validation loss: 1.2569457188896511.
best validation loss 0.4377209064753159 at epoch 580.
