seed:  666
number of classes: 10
how to merge clusters:  [[0, 9], [1, 5], 2, [3, 8], 4, 6, 7]
whether to further subcluster data according to chemical reaction: False
number of epochs to train: 3000
learning rate decay to half at epoch 2000.
begin to select hard pairs at epoch 400
batch size: 96
number of hardest positive pairs for each mini-batch:  128
number of hardest negative pairs for each mini-batch:  128
number of workers to load data:  36
similar margin of contrastive loss: 0.0
dissimilar margin of contrastive loss: 2.0
device:  cuda
number of classes after merging:  7
number of pockets in training set:  10527
number of pockets in validation set:  2254
number of pockets in test set:  2263
model architecture:
SelectiveSiameseNet(
  (embedding_net): EmbeddingNet(
    (set2set): Set2Set(32, 64)
    (conv1): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=11, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=11, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=32, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=32, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=32, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=32, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv4): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=32, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=32, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (bn4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.003
    weight_decay: 0.0005
)
loss function:
SelectiveContrastiveLoss(similar_margin=0.0, dissimilar_margin=2.0, num_pos_pair=128, num_neg_pair=128)
epoch: 1, train loss: 0.893420799609718, validation loss: 0.9100973943005437.
epoch: 2, train loss: 0.8757193454908668, validation loss: 0.8121664809144061.
epoch: 3, train loss: 0.8133545137873484, validation loss: 0.7862623709699382.
epoch: 4, train loss: 0.7925874984592473, validation loss: 0.7728462491346442.
epoch: 5, train loss: 0.8091452654895432, validation loss: 0.9014916860538981.
epoch: 6, train loss: 0.7889583028784586, validation loss: 0.788617879152298.
epoch: 7, train loss: 0.8005202073569692, validation loss: 0.7332952087340148.
epoch: 8, train loss: 0.7443019906315235, validation loss: 0.7978889294292616.
epoch: 9, train loss: 0.747865740038933, validation loss: 0.7423652280931887.
epoch: 10, train loss: 0.7688251214289884, validation loss: 0.9556084249330603.
epoch: 11, train loss: 0.7419190177130043, validation loss: 0.7844738960266113.
epoch: 12, train loss: 0.7276975471492207, validation loss: 0.8232289604518724.
epoch: 13, train loss: 0.7321021037364225, validation loss: 0.7510282708250958.
epoch: 14, train loss: 0.7266477187839123, validation loss: 0.7819645534390989.
epoch: 15, train loss: 0.7330605343941154, validation loss: 0.8175281363984813.
epoch: 16, train loss: 0.7193353515152537, validation loss: 0.7583609404771224.
epoch: 17, train loss: 0.7433560463266635, validation loss: 0.7280090580815854.
epoch: 18, train loss: 0.7121806773570699, validation loss: 0.850203363791756.
epoch: 19, train loss: 0.7246815381793801, validation loss: 0.8767484996629797.
epoch: 20, train loss: 0.7680283243503045, validation loss: 0.7425279746884885.
epoch: 21, train loss: 0.7031259580489693, validation loss: 0.7287860409073208.
epoch: 22, train loss: 0.7123759536568178, validation loss: 0.9460620335910631.
epoch: 23, train loss: 0.76336317461565, validation loss: 0.6896418734737064.
epoch: 24, train loss: 0.7448778078643554, validation loss: 0.6837686455768087.
epoch: 25, train loss: 0.7187927247734245, validation loss: 0.7622176460597826.
epoch: 26, train loss: 0.703857165410978, validation loss: 0.7433443471141483.
epoch: 27, train loss: 0.6875248316231124, validation loss: 0.6894816082456837.
epoch: 28, train loss: 0.6771042363359294, validation loss: 0.8408115558002306.
epoch: 29, train loss: 0.6945324520999139, validation loss: 0.7262282708416814.
epoch: 30, train loss: 0.7087509153632943, validation loss: 0.7200745240501736.
epoch: 31, train loss: 0.6901176511694532, validation loss: 0.7417869593786157.
epoch: 32, train loss: 0.7365473473290785, validation loss: 0.7740461722664211.
epoch: 33, train loss: 0.7333480412260108, validation loss: 0.7082716278407885.
epoch: 34, train loss: 0.6735769168499413, validation loss: 0.6889247933159703.
epoch: 35, train loss: 0.7114259502209654, validation loss: 0.6617932241895924.
epoch: 36, train loss: 0.6703460850846876, validation loss: 0.7447333076725835.
epoch: 37, train loss: 0.6945822094011744, validation loss: 0.6916959544886714.
epoch: 38, train loss: 0.6415913602627745, validation loss: 0.7483448852663455.
epoch: 39, train loss: 0.6756673261113123, validation loss: 0.7433425874813743.
epoch: 40, train loss: 0.670697076058169, validation loss: 0.7862084106258724.
epoch: 41, train loss: 0.6542425385308922, validation loss: 0.7338982846425928.
epoch: 42, train loss: 0.6867623758425406, validation loss: 0.6167167645433674.
epoch: 43, train loss: 0.6658962978682387, validation loss: 0.6191545815571494.
epoch: 44, train loss: 0.6620743408662464, validation loss: 0.6671733247197192.
epoch: 45, train loss: 0.6616304090263647, validation loss: 0.6159012823001199.
epoch: 46, train loss: 0.6778932916461875, validation loss: 0.7118726761444755.
epoch: 47, train loss: 0.6677892549869118, validation loss: 0.743512696546057.
epoch: 48, train loss: 0.6633653766518339, validation loss: 0.7276552151078763.
epoch: 49, train loss: 0.6588667948311622, validation loss: 0.7101838744204977.
epoch: 50, train loss: 0.6677293397417856, validation loss: 0.7467080276945363.
epoch: 51, train loss: 0.6641160624289731, validation loss: 0.7740974257821622.
epoch: 52, train loss: 0.6715196458571547, validation loss: 0.6564830710058627.
epoch: 53, train loss: 0.6877319172981682, validation loss: 0.6448490930640179.
epoch: 54, train loss: 0.637877880159868, validation loss: 0.9153647643068562.
epoch: 55, train loss: 0.6997191525927378, validation loss: 0.6815733326518018.
epoch: 56, train loss: 0.643384569008416, validation loss: 0.8898869364157967.
epoch: 57, train loss: 0.6984497475514718, validation loss: 0.6503242487492769.
epoch: 58, train loss: 0.6898106038570404, validation loss: 0.7467874521794526.
epoch: 59, train loss: 0.6474558749330153, validation loss: 0.693964008403861.
epoch: 60, train loss: 0.66233902841533, validation loss: 0.915523578291354.
epoch: 61, train loss: 0.6667485868712084, validation loss: 0.7216055289558743.
epoch: 62, train loss: 0.6802819617297671, validation loss: 0.6328061235987622.
epoch: 63, train loss: 0.6548664381197833, validation loss: 0.6759921778803286.
epoch: 64, train loss: 0.6513203065329736, validation loss: 0.8975061541018279.
epoch: 65, train loss: 0.6692662810513733, validation loss: 0.639812531678573.
epoch: 66, train loss: 0.6459833145688433, validation loss: 0.7123503179653831.
epoch: 67, train loss: 0.6303117565058787, validation loss: 0.7188289955906246.
epoch: 68, train loss: 0.6316361142954695, validation loss: 0.6526136126207269.
epoch: 69, train loss: 0.6552988597012441, validation loss: 0.6796859982221023.
epoch: 70, train loss: 0.6556832804045546, validation loss: 0.704828652350799.
epoch: 71, train loss: 0.6418070074068297, validation loss: 0.6780466618745223.
epoch: 72, train loss: 0.6260341102376991, validation loss: 0.6732972290204919.
epoch: 73, train loss: 0.6381373883934196, validation loss: 0.6652498867200769.
epoch: 74, train loss: 0.6674597104755017, validation loss: 0.6325137861396956.
epoch: 75, train loss: 0.6513344128744318, validation loss: 0.6980586259261422.
epoch: 76, train loss: 0.6535085229151839, validation loss: 0.7099799578604491.
epoch: 77, train loss: 0.6258497087780489, validation loss: 0.6629774609337682.
epoch: 78, train loss: 0.6443056147032922, validation loss: 0.7017452794572582.
epoch: 79, train loss: 0.6117379050189202, validation loss: 0.6389451324939728.
epoch: 80, train loss: 0.6894464552949328, validation loss: 0.7297301201716714.
epoch: 81, train loss: 0.6803575910012657, validation loss: 0.6873251173807227.
epoch: 82, train loss: 0.5944151328791172, validation loss: 0.680063053317692.
epoch: 83, train loss: 0.6865787156131289, validation loss: 0.6789578510367352.
epoch: 84, train loss: 0.6368368642592649, validation loss: 0.710328529710355.
epoch: 85, train loss: 0.590950099426672, validation loss: 0.6682410706644473.
epoch: 86, train loss: 0.6178420336421476, validation loss: 0.643573162348374.
epoch: 87, train loss: 0.6030159056733507, validation loss: 0.5942115122857301.
epoch: 88, train loss: 0.6269129209835594, validation loss: 0.706196270559145.
epoch: 89, train loss: 0.6425768634594908, validation loss: 0.7039488916811736.
epoch: 90, train loss: 0.6229080371900436, validation loss: 0.625900615816531.
epoch: 91, train loss: 0.6388697479296168, validation loss: 0.613711927248084.
epoch: 92, train loss: 0.5995153689056362, validation loss: 0.6159491811109625.
epoch: 93, train loss: 0.6429371877547798, validation loss: 0.6575417129889779.
epoch: 94, train loss: 0.6187140952556505, validation loss: 0.686666145272877.
epoch: 95, train loss: 0.5969228681621201, validation loss: 0.667033129412195.
epoch: 96, train loss: 0.5952574763822993, validation loss: 0.6799505910147792.
epoch: 97, train loss: 0.6513494767180277, validation loss: 0.6145734268686046.
epoch: 98, train loss: 0.6146642202084217, validation loss: 0.6163463825764863.
epoch: 99, train loss: 0.5865987684201757, validation loss: 0.6191210085931032.
epoch: 100, train loss: 0.6179942278140181, validation loss: 0.6454136267952297.
epoch: 101, train loss: 0.6068350943403507, validation loss: 0.749666769867358.
epoch: 102, train loss: 0.5808530679536522, validation loss: 0.704808393250341.
epoch: 103, train loss: 0.6129316992442543, validation loss: 0.5822321448637091.
epoch: 104, train loss: 0.63052475589131, validation loss: 0.5668875600980676.
epoch: 105, train loss: 0.6008083727381645, validation loss: 0.7232459939044454.
epoch: 106, train loss: 0.6117137397101166, validation loss: 0.5934304400630619.
epoch: 107, train loss: 0.6088637518226554, validation loss: 0.6556055727212325.
epoch: 108, train loss: 0.5816912698909777, validation loss: 0.6984591833923174.
epoch: 109, train loss: 0.5889556339574517, validation loss: 0.6725203226441923.
epoch: 110, train loss: 0.6040128198785519, validation loss: 0.6400609366271807.
epoch: 111, train loss: 0.6657452473946668, validation loss: 0.606170847364094.
epoch: 112, train loss: 0.6294731579789328, validation loss: 0.6835132396739462.
epoch: 113, train loss: 0.5835731658366842, validation loss: 0.668835971666419.
epoch: 114, train loss: 0.6418896243659729, validation loss: 0.6458054094210915.
epoch: 115, train loss: 0.6011353508321517, validation loss: 0.6829374290030935.
epoch: 116, train loss: 0.5839803503193987, validation loss: 0.5318484850551771.
epoch: 117, train loss: 0.5913441159309597, validation loss: 0.6927832028140193.
epoch: 118, train loss: 0.5811391308766987, validation loss: 0.5346697296785272.
epoch: 119, train loss: 0.5942309398990159, validation loss: 0.6053717084552931.
epoch: 120, train loss: 0.5808512204830799, validation loss: 0.6061236676962479.
epoch: 121, train loss: 0.6388471588629101, validation loss: 0.5869112377581389.
epoch: 122, train loss: 0.579985500749098, validation loss: 0.5500686155713123.
epoch: 123, train loss: 0.5921743774632795, validation loss: 0.6159374299256698.
epoch: 124, train loss: 0.5589887480670159, validation loss: 0.6286760218765425.
epoch: 125, train loss: 0.6510358064546498, validation loss: 0.6415564080943232.
epoch: 126, train loss: 0.5944784420345901, validation loss: 0.7227935609610184.
epoch: 127, train loss: 0.592600234194633, validation loss: 0.6187213076197583.
epoch: 128, train loss: 0.5780302707208406, validation loss: 0.5767280692639558.
epoch: 129, train loss: 0.5740078365037201, validation loss: 0.6376529569211213.
epoch: 130, train loss: 0.5796277149828202, validation loss: 0.6939998333868773.
epoch: 131, train loss: 0.5839920202526477, validation loss: 0.5933599964432095.
epoch: 132, train loss: 0.5734068118377563, validation loss: 0.5658941579901654.
epoch: 133, train loss: 0.5965363856302489, validation loss: 0.6524649780729542.
epoch: 134, train loss: 0.5931744168110944, validation loss: 0.6957941612471705.
epoch: 135, train loss: 0.6372980100846072, validation loss: 0.6119285407273666.
epoch: 136, train loss: 0.5614197948657045, validation loss: 0.6722143253554469.
epoch: 137, train loss: 0.6243978287648717, validation loss: 0.6357598473196444.
epoch: 138, train loss: 0.5733685971946891, validation loss: 0.613197191901829.
epoch: 139, train loss: 0.5818975939663178, validation loss: 0.6297596187695212.
epoch: 140, train loss: 0.6011778859917177, validation loss: 0.643341733061749.
epoch: 141, train loss: 0.5925916036881438, validation loss: 0.6873501500357753.
epoch: 142, train loss: 0.5879480959078588, validation loss: 0.6947329523770706.
epoch: 143, train loss: 0.6121106716470981, validation loss: 0.6726494431495667.
epoch: 144, train loss: 0.5507940721074376, validation loss: 0.7040322254533353.
epoch: 145, train loss: 0.586120282838104, validation loss: 0.731803158055181.
epoch: 146, train loss: 0.549801262146836, validation loss: 0.5804625943950985.
epoch: 147, train loss: 0.5613665062626567, validation loss: 0.6458677442177482.
epoch: 148, train loss: 0.5819897189599659, validation loss: 0.5938031958497089.
epoch: 149, train loss: 0.6060957017294858, validation loss: 0.7257522111353667.
epoch: 150, train loss: 0.5954728859280227, validation loss: 0.7232479388299196.
epoch: 151, train loss: 0.5720311725905182, validation loss: 0.5662031536516936.
epoch: 152, train loss: 0.6041558245453266, validation loss: 0.671335369348526.
epoch: 153, train loss: 0.5706846861664309, validation loss: 0.646440995776135.
epoch: 154, train loss: 0.6076725888142892, validation loss: 0.6402056230151135.
epoch: 155, train loss: 0.5651037328013586, validation loss: 0.7457981433557428.
epoch: 156, train loss: 0.5913684050971215, validation loss: 0.6423276960849762.
epoch: 157, train loss: 0.5865702202560705, validation loss: 0.6347552019616832.
epoch: 158, train loss: 0.5895979852851377, validation loss: 0.5142851355283157.
epoch: 159, train loss: 0.5824682504758922, validation loss: 0.6391072869300842.
epoch: 160, train loss: 0.6241168336037102, validation loss: 0.6721423022125078.
epoch: 161, train loss: 0.5684688351023088, validation loss: 0.5671199715655783.
epoch: 162, train loss: 0.5646304026109363, validation loss: 0.7016955730707749.
epoch: 163, train loss: 0.5948965352609616, validation loss: 0.5969166950039242.
epoch: 164, train loss: 0.6020639842256493, validation loss: 0.5935977930608003.
epoch: 165, train loss: 0.6048949390923212, validation loss: 0.6427693690942682.
epoch: 166, train loss: 0.5663037089579696, validation loss: 0.6337124821932419.
epoch: 167, train loss: 0.5861889897683344, validation loss: 0.5549046163973601.
epoch: 168, train loss: 0.5494169405567537, validation loss: 0.610213155331819.
epoch: 169, train loss: 0.5654340626996591, validation loss: 0.6349883986556012.
epoch: 170, train loss: 0.6093268892086974, validation loss: 0.6189639335093291.
epoch: 171, train loss: 0.5537410597188757, validation loss: 0.6021966454775437.
epoch: 172, train loss: 0.5380208771163171, validation loss: 0.5966803846151932.
epoch: 173, train loss: 0.5595775025153379, validation loss: 0.6141743556312893.
epoch: 174, train loss: 0.5912641040775755, validation loss: 0.680994926587395.
epoch: 175, train loss: 0.610595959589022, validation loss: 0.5770977787349535.
epoch: 176, train loss: 0.6038202867595428, validation loss: 0.620427166638167.
epoch: 177, train loss: 0.6231111862243862, validation loss: 0.6170505997927292.
epoch: 178, train loss: 0.5719767685877074, validation loss: 0.563847822987515.
epoch: 179, train loss: 0.5630975122298669, validation loss: 0.6409804108350173.
epoch: 180, train loss: 0.5903316938549007, validation loss: 0.6413498585638793.
epoch: 181, train loss: 0.5541096961279528, validation loss: 0.5877244576163914.
epoch: 182, train loss: 0.5456885921025495, validation loss: 0.570223788852277.
epoch: 183, train loss: 0.6043291589535704, validation loss: 0.5873895067235698.
epoch: 184, train loss: 0.5847968716140187, validation loss: 0.5700146892796392.
epoch: 185, train loss: 0.5911189038819129, validation loss: 0.6451709438925204.
epoch: 186, train loss: 0.5736302472309235, validation loss: 0.5940039106037306.
epoch: 187, train loss: 0.525591193536006, validation loss: 0.5981748959292537.
epoch: 188, train loss: 0.591375562439271, validation loss: 0.6317160777423693.
epoch: 189, train loss: 0.5811873469330849, validation loss: 0.6403960611509241.
epoch: 190, train loss: 0.5523508986748686, validation loss: 0.5933290655198304.
epoch: 191, train loss: 0.5790233617528863, validation loss: 0.5998274606207142.
epoch: 192, train loss: 0.5657346866546421, validation loss: 0.6667149339033209.
epoch: 193, train loss: 0.5746195614337921, validation loss: 0.5970056018103724.
epoch: 194, train loss: 0.5554760002761806, validation loss: 0.5301607108634451.
epoch: 195, train loss: 0.5359410471325621, validation loss: 0.6051175283349078.
epoch: 196, train loss: 0.5787456224270917, validation loss: 0.6595862857673479.
epoch: 197, train loss: 0.5235433797223852, validation loss: 0.706040752970654.
epoch: 198, train loss: 0.5864055840247268, validation loss: 0.595527650869411.
epoch: 199, train loss: 0.5667179552240109, validation loss: 0.546137212411217.
epoch: 200, train loss: 0.6118162323575501, validation loss: 0.6685965216678121.
epoch: 201, train loss: 0.5687928948927363, validation loss: 0.6005601377590842.
epoch: 202, train loss: 0.5260609970727098, validation loss: 0.6892972070237865.
epoch: 203, train loss: 0.5786073702737826, validation loss: 0.6325230689152427.
epoch: 204, train loss: 0.5567208348064248, validation loss: 0.6045705727908922.
epoch: 205, train loss: 0.5365937576381439, validation loss: 0.5851613892161328.
epoch: 206, train loss: 0.5765963111995557, validation loss: 0.531902050194533.
epoch: 207, train loss: 0.5621685962611382, validation loss: 0.5977283184942992.
epoch: 208, train loss: 0.5277526870780035, validation loss: 0.5529673902884774.
epoch: 209, train loss: 0.5875554590597065, validation loss: 0.6499315007873203.
epoch: 210, train loss: 0.5395946273016273, validation loss: 0.633151905692142.
epoch: 211, train loss: 0.5335545515248535, validation loss: 0.5459873987280804.
epoch: 212, train loss: 0.5519655724184229, validation loss: 0.6471685767173767.
epoch: 213, train loss: 0.5823229034559443, validation loss: 0.6758644554926001.
epoch: 214, train loss: 0.535526560534031, validation loss: 0.6346535423527593.
epoch: 215, train loss: 0.5773423896470201, validation loss: 0.515571433564891.
epoch: 216, train loss: 0.5578062758533233, validation loss: 0.5958574932554493.
epoch: 217, train loss: 0.5115438814556926, validation loss: 0.6606701146001401.
epoch: 218, train loss: 0.5385708859480849, validation loss: 0.6240378307259601.
epoch: 219, train loss: 0.5600733344161183, validation loss: 0.6259802463261978.
epoch: 220, train loss: 0.5719715616571794, validation loss: 0.6015556040017501.
epoch: 221, train loss: 0.6028849384106627, validation loss: 0.6905629116555919.
epoch: 222, train loss: 0.5618279226329348, validation loss: 0.6031556414521259.
epoch: 223, train loss: 0.5271728384658831, validation loss: 0.5958088610483252.
epoch: 224, train loss: 0.531865394443547, validation loss: 0.5332421802956125.
epoch: 225, train loss: 0.5751907452257401, validation loss: 0.61537439149359.
epoch: 226, train loss: 0.5593254646850289, validation loss: 0.6323538837225541.
epoch: 227, train loss: 0.5622077865884938, validation loss: 0.5742346631444019.
epoch: 228, train loss: 0.5649386912310889, validation loss: 0.620616958193157.
epoch: 229, train loss: 0.5509035278350936, validation loss: 0.5779930936253589.
epoch: 230, train loss: 0.5448414486482602, validation loss: 0.6093307681705641.
epoch: 231, train loss: 0.5345529699270878, validation loss: 0.6509528574736222.
epoch: 232, train loss: 0.5505584598681249, validation loss: 0.5958100311134172.
epoch: 233, train loss: 0.543413940372817, validation loss: 0.6108369917973228.
epoch: 234, train loss: 0.5487775731524196, validation loss: 0.6029124493184297.
epoch: 235, train loss: 0.5667373499739061, validation loss: 0.605571413817613.
epoch: 236, train loss: 0.558763551329254, validation loss: 0.7421412960342739.
epoch: 237, train loss: 0.5511394934643299, validation loss: 0.7031933328379756.
epoch: 238, train loss: 0.5501443257025622, validation loss: 0.5063037677951481.
epoch: 239, train loss: 0.5556737047816636, validation loss: 0.6077825906484023.
epoch: 240, train loss: 0.5715602721096179, validation loss: 0.6658646127452021.
epoch: 241, train loss: 0.5461471530549024, validation loss: 0.5811180770397186.
epoch: 242, train loss: 0.5243600572741359, validation loss: 0.5416401987490447.
epoch: 243, train loss: 0.5110661398380174, validation loss: 0.6208604483500771.
epoch: 244, train loss: 0.5406758075733797, validation loss: 0.6278398931026459.
epoch: 245, train loss: 0.5779485377149844, validation loss: 0.5658437337564386.
epoch: 246, train loss: 0.553285648243143, validation loss: 0.5961942556111709.
epoch: 247, train loss: 0.5987011330937027, validation loss: 0.5824474355448848.
epoch: 248, train loss: 0.5491245640527218, validation loss: 0.6100710759992185.
epoch: 249, train loss: 0.5644318950832437, validation loss: 0.5682777995648591.
epoch: 250, train loss: 0.5216937138946778, validation loss: 0.5164054036140442.
epoch: 251, train loss: 0.5389750798087601, validation loss: 0.6182987055052882.
epoch: 252, train loss: 0.5620430377098399, validation loss: 0.5679141684718754.
epoch: 253, train loss: 0.5481417745078375, validation loss: 0.6049405427082725.
epoch: 254, train loss: 0.5758827980778632, validation loss: 0.5299489873906841.
epoch: 255, train loss: 0.5466048439981741, validation loss: 0.5387338568334994.
epoch: 256, train loss: 0.5206974012042405, validation loss: 0.5245954990386963.
epoch: 257, train loss: 0.5649061228977431, validation loss: 0.5575368086928907.
epoch: 258, train loss: 0.5446447668545836, validation loss: 0.5738537538310756.
epoch: 259, train loss: 0.5452391718505719, validation loss: 0.5574551185835963.
epoch: 260, train loss: 0.5450990534977082, validation loss: 0.5907293363757755.
epoch: 261, train loss: 0.5598383502129021, validation loss: 0.5268157707608264.
epoch: 262, train loss: 0.5238258034811107, validation loss: 0.6176125433133997.
epoch: 263, train loss: 0.5087745624397872, validation loss: 0.6755952200163966.
epoch: 264, train loss: 0.5579824196089298, validation loss: 0.6088175527427507.
epoch: 265, train loss: 0.580044074479593, validation loss: 0.5300309230451998.
epoch: 266, train loss: 0.5596976881727166, validation loss: 0.5776175960250522.
epoch: 267, train loss: 0.5216067091587486, validation loss: 0.6174394566079845.
epoch: 268, train loss: 0.5382609938809632, validation loss: 0.5923098040663678.
epoch: 269, train loss: 0.5403732725786506, validation loss: 0.5763111360695051.
epoch: 270, train loss: 0.532376260248893, validation loss: 0.5726503937140756.
epoch: 271, train loss: 0.5639000535011292, validation loss: 0.6290657805359882.
epoch: 272, train loss: 0.5263857562607581, validation loss: 0.598822146654129.
epoch: 273, train loss: 0.5836469146910064, validation loss: 0.545160570870275.
epoch: 274, train loss: 0.538805532346078, validation loss: 0.6757925528547039.
epoch: 275, train loss: 0.5248315025360213, validation loss: 0.6779116230166476.
epoch: 276, train loss: 0.5474733249583376, validation loss: 0.6452567940172942.
epoch: 277, train loss: 0.5631145304496136, validation loss: 0.6280519405136937.
epoch: 278, train loss: 0.5693332771642492, validation loss: 0.579712643571522.
epoch: 279, train loss: 0.5227830575420223, validation loss: 0.5329938245856244.
epoch: 280, train loss: 0.5728625451479483, validation loss: 0.5794065918611444.
epoch: 281, train loss: 0.5667868460263681, validation loss: 0.5449402124985404.
epoch: 282, train loss: 0.5246174480390111, validation loss: 0.5698394101598988.
epoch: 283, train loss: 0.5191253245970525, validation loss: 0.6591729405133621.
epoch: 284, train loss: 0.5306961353218883, validation loss: 0.5877859838630842.
epoch: 285, train loss: 0.5433210077088907, validation loss: 0.571053797784059.
epoch: 286, train loss: 0.5598512976814848, validation loss: 0.5781385704227116.
epoch: 287, train loss: 0.5818518359179891, validation loss: 0.5954160379326862.
epoch: 288, train loss: 0.5301473001274494, validation loss: 0.5864269882440567.
epoch: 289, train loss: 0.5099633717482243, validation loss: 0.612243115901947.
epoch: 290, train loss: 0.5099940066217282, validation loss: 0.5300655993430511.
epoch: 291, train loss: 0.6008652257263114, validation loss: 0.7184792575628861.
epoch: 292, train loss: 0.5291122523469662, validation loss: 0.5593612077443496.
epoch: 293, train loss: 0.5687624708228155, validation loss: 0.5718001438223798.
epoch: 294, train loss: 0.5589038264860801, validation loss: 0.5778889254383419.
epoch: 295, train loss: 0.5515466582611066, validation loss: 0.5288477669591489.
epoch: 296, train loss: 0.5196534768430465, validation loss: 0.6564210471899613.
epoch: 297, train loss: 0.5133888344152258, validation loss: 0.6154976513074792.
epoch: 298, train loss: 0.5343129003266676, validation loss: 0.5461874766194302.
epoch: 299, train loss: 0.5526724888370671, validation loss: 0.629049451454826.
epoch: 300, train loss: 0.5632903220456674, validation loss: 0.5949629985767863.
epoch: 301, train loss: 0.5661984630134127, validation loss: 0.5712564730125925.
epoch: 302, train loss: 0.5184696354997267, validation loss: 0.5420018680717634.
epoch: 303, train loss: 0.5626581390516474, validation loss: 0.5680751761664515.
epoch: 304, train loss: 0.5148496783654625, validation loss: 0.5767171667969745.
epoch: 305, train loss: 0.5050377676246363, validation loss: 0.611782097298166.
epoch: 306, train loss: 0.5190256708258882, validation loss: 0.48860461038091907.
epoch: 307, train loss: 0.51172455270356, validation loss: 0.5637376878572546.
epoch: 308, train loss: 0.5567432209986065, validation loss: 0.6013614392798879.
epoch: 309, train loss: 0.5650156253795011, validation loss: 0.572970273702041.
epoch: 310, train loss: 0.5522810686892325, validation loss: 0.6304588758427164.
epoch: 311, train loss: 0.5549564697873701, validation loss: 0.5215522646903992.
epoch: 312, train loss: 0.5166170018801995, validation loss: 0.5334893128146296.
epoch: 313, train loss: 0.5296225791130591, validation loss: 0.5495511137920878.
epoch: 314, train loss: 0.5380996963299742, validation loss: 0.6596769690513611.
epoch: 315, train loss: 0.5154424494286196, validation loss: 0.5548291685788528.
epoch: 316, train loss: 0.5534921556437781, validation loss: 0.5037511094756748.
epoch: 317, train loss: 0.5192239056213186, validation loss: 0.5928622536037279.
epoch: 318, train loss: 0.5564379082360399, validation loss: 0.562780508528585.
epoch: 319, train loss: 0.5434638256326728, validation loss: 0.6192772453245909.
epoch: 320, train loss: 0.528404478086244, validation loss: 0.5350832952105481.
epoch: 321, train loss: 0.5108054159978114, validation loss: 0.5376799495323844.
epoch: 322, train loss: 0.5311900574132937, validation loss: 0.5692444949046426.
epoch: 323, train loss: 0.5062232367489317, validation loss: 0.5841177663077479.
epoch: 324, train loss: 0.5487183187532862, validation loss: 0.6335863820884539.
epoch: 325, train loss: 0.5461721308187607, validation loss: 0.5745284764663033.
epoch: 326, train loss: 0.5071304290119661, validation loss: 0.5322935866272968.
epoch: 327, train loss: 0.506776019384008, validation loss: 0.5779970223489015.
epoch: 328, train loss: 0.5501081491008811, validation loss: 0.6324517312257186.
epoch: 329, train loss: 0.541897558291024, validation loss: 0.5582682101622872.
epoch: 330, train loss: 0.4824448959269655, validation loss: 0.5179287519143976.
epoch: 331, train loss: 0.5568158216432694, validation loss: 0.6707311544729315.
epoch: 332, train loss: 0.515383628256824, validation loss: 0.6198706613934558.
epoch: 333, train loss: 0.5246136060001654, validation loss: 0.5948016475076261.
epoch: 334, train loss: 0.5305355682012138, validation loss: 0.5877139050027599.
epoch: 335, train loss: 0.5186162796042381, validation loss: 0.502959373852481.
epoch: 336, train loss: 0.49879051430509724, validation loss: 0.6948662665875062.
epoch: 337, train loss: 0.5472400199382677, validation loss: 0.5625497595123623.
epoch: 338, train loss: 0.534256599911856, validation loss: 0.5800649070221445.
epoch: 339, train loss: 0.5412146919364229, validation loss: 0.7528267787850421.
epoch: 340, train loss: 0.5327123953114956, validation loss: 0.6008879684883616.
epoch: 341, train loss: 0.5052745820732292, validation loss: 0.5344009334626405.
epoch: 342, train loss: 0.5337538773860406, validation loss: 0.5728008060351663.
epoch: 343, train loss: 0.5154209920299162, validation loss: 0.5647146922090779.
epoch: 344, train loss: 0.5537285311233013, validation loss: 0.5158766546975011.
epoch: 345, train loss: 0.5095589432967912, validation loss: 0.6256536232388538.
epoch: 346, train loss: 0.5004539147976341, validation loss: 0.5851174476354019.
epoch: 347, train loss: 0.5447380462097465, validation loss: 0.5806560827338177.
epoch: 348, train loss: 0.4875816203858874, validation loss: 0.5710406238618104.
epoch: 349, train loss: 0.5077922691445832, validation loss: 0.5556253751982814.
epoch: 350, train loss: 0.5102479865244769, validation loss: 0.6273454544336899.
epoch: 351, train loss: 0.48818394405032517, validation loss: 0.592744159957637.
epoch: 352, train loss: 0.5261120811241482, validation loss: 0.7891265231630077.
epoch: 353, train loss: 0.5429141968488693, validation loss: 0.63064636743587.
epoch: 354, train loss: 0.4809923639538091, validation loss: 0.5807293964468915.
epoch: 355, train loss: 0.5185682762653456, validation loss: 0.5966931801775227.
epoch: 356, train loss: 0.5212830127379217, validation loss: 0.5220432385154392.
epoch: 357, train loss: 0.5260043268630265, validation loss: 0.5979151414788287.
epoch: 358, train loss: 0.5096620228312431, validation loss: 0.5398029438827349.
epoch: 359, train loss: 0.5481831874322454, validation loss: 0.6608104602150295.
epoch: 360, train loss: 0.5226857737390274, validation loss: 0.5101558371730472.
epoch: 361, train loss: 0.5208533039880455, validation loss: 0.5598450419695481.
epoch: 362, train loss: 0.5366262736123636, validation loss: 0.5757602116335994.
epoch: 363, train loss: 0.504914303575087, validation loss: 0.5852067379847817.
epoch: 364, train loss: 0.5059026429139146, validation loss: 0.6629702474759973.
epoch: 365, train loss: 0.5265511743245869, validation loss: 0.555398966955102.
epoch: 366, train loss: 0.4914433898728922, validation loss: 0.6216971511426179.
epoch: 367, train loss: 0.5133876704841579, validation loss: 0.5564833840598231.
epoch: 368, train loss: 0.5121005944429188, validation loss: 0.6297075554080631.
epoch: 369, train loss: 0.5281494646717649, validation loss: 0.564612891363061.
epoch: 370, train loss: 0.5190089600622108, validation loss: 0.555680909882421.
epoch: 371, train loss: 0.5501274496590326, validation loss: 0.55722023870634.
epoch: 372, train loss: 0.5327577474740667, validation loss: 0.5997200601774714.
epoch: 373, train loss: 0.48613948477517577, validation loss: 0.5626774171124334.
epoch: 374, train loss: 0.5047857213184375, validation loss: 0.5425048820350481.
epoch: 375, train loss: 0.539244261083253, validation loss: 0.5203256231287251.
epoch: 376, train loss: 0.5284926874921956, validation loss: 0.5626142504422561.
epoch: 377, train loss: 0.5044195154391298, validation loss: 0.6843084291271542.
epoch: 378, train loss: 0.5124801899041604, validation loss: 0.5703632922276206.
epoch: 379, train loss: 0.5154617035060848, validation loss: 0.6060111820697784.
epoch: 380, train loss: 0.5627131864018396, validation loss: 0.5666252478309299.
epoch: 381, train loss: 0.5255643211373495, validation loss: 0.6184587621170542.
epoch: 382, train loss: 0.5000053135626906, validation loss: 0.5273641879143922.
epoch: 383, train loss: 0.5346101940771856, validation loss: 0.49659130301164545.
epoch: 384, train loss: 0.510319431303838, validation loss: 0.5732370524302773.
epoch: 385, train loss: 0.55483059940535, validation loss: 0.7085219077442003.
epoch: 386, train loss: 0.5262002538923823, validation loss: 0.5427043528660483.
epoch: 387, train loss: 0.5095920793780493, validation loss: 0.5908542469791744.
epoch: 388, train loss: 0.49678344901548616, validation loss: 0.7477761377458987.
epoch: 389, train loss: 0.5531241379746603, validation loss: 0.6014926485393358.
epoch: 390, train loss: 0.5136383460202348, validation loss: 0.5705543639867202.
epoch: 391, train loss: 0.5684901050744801, validation loss: 0.5699574817781863.
epoch: 392, train loss: 0.5158344684937678, validation loss: 0.5718932022219119.
epoch: 393, train loss: 0.4835956277103599, validation loss: 0.5926544562630032.
epoch: 394, train loss: 0.5600466692666395, validation loss: 0.6515084712401681.
epoch: 395, train loss: 0.5236995321348172, validation loss: 0.5662850737571716.
epoch: 396, train loss: 0.5087102160814705, validation loss: 0.6856253859789475.
epoch: 397, train loss: 0.4689583360055171, validation loss: 0.5089262743359027.
epoch: 398, train loss: 0.5123256386146633, validation loss: 0.5380940100421077.
epoch: 399, train loss: 0.5044546723365784, validation loss: 0.534637565198152.
epoch: 400, train loss: 1.7628189751861292, validation loss: 1.5943778027658877.
epoch: 401, train loss: 1.5093843499454884, validation loss: 1.4966839448265408.
epoch: 402, train loss: 1.437145952784687, validation loss: 1.4369046636249707.
epoch: 403, train loss: 1.4048654322230487, validation loss: 1.41795015335083.
epoch: 404, train loss: 1.3867396914630854, validation loss: 1.3972572865693464.
epoch: 405, train loss: 1.3696213807534734, validation loss: 1.3837014436721802.
epoch: 406, train loss: 1.3503860880475524, validation loss: 1.3669152985448423.
epoch: 407, train loss: 1.339796602179151, validation loss: 1.350284369095512.
epoch: 408, train loss: 1.3311121452839003, validation loss: 1.3629740010137144.
epoch: 409, train loss: 1.3250711817260181, validation loss: 1.3487244066984758.
epoch: 410, train loss: 1.3194309287114974, validation loss: 1.34251636525859.
epoch: 411, train loss: 1.3128376160192927, validation loss: 1.3247847660728123.
epoch: 412, train loss: 1.3115549820278762, validation loss: 1.3259388519370037.
epoch: 413, train loss: 1.307538083933909, validation loss: 1.3267197712608005.
epoch: 414, train loss: 1.3042522362612803, validation loss: 1.329172149948452.
epoch: 415, train loss: 1.3017865977156053, validation loss: 1.3212685688682224.
epoch: 416, train loss: 1.2979746400763135, validation loss: 1.3176697233448857.
epoch: 417, train loss: 1.295850523021243, validation loss: 1.3166507171547932.
epoch: 418, train loss: 1.2991059843553316, validation loss: 1.3173094469568003.
epoch: 419, train loss: 1.2993229080777648, validation loss: 1.311503177103789.
epoch: 420, train loss: 1.3104105498812615, validation loss: 1.3590954283009404.
epoch: 421, train loss: 1.3208635739230234, validation loss: 1.3338060741839202.
epoch: 422, train loss: 1.3061747430661403, validation loss: 1.3232626655827397.
epoch: 423, train loss: 1.2997815368372365, validation loss: 1.3176427664964094.
epoch: 424, train loss: 1.2904728465124007, validation loss: 1.304029791251473.
epoch: 425, train loss: 1.2887783706735034, validation loss: 1.3299215202746184.
epoch: 426, train loss: 1.3005823290676153, validation loss: 1.2953513653382012.
epoch: 427, train loss: 1.286868739565578, validation loss: 1.3044640033141426.
epoch: 428, train loss: 1.288909024054851, validation loss: 1.3096659183502197.
epoch: 429, train loss: 1.2890374146470236, validation loss: 1.3042775185211846.
epoch: 430, train loss: 1.289914005393282, validation loss: 1.3010312681612761.
epoch: 431, train loss: 1.283715241545931, validation loss: 1.3006619111351345.
epoch: 432, train loss: 1.2804902256081958, validation loss: 1.297018517618594.
epoch: 433, train loss: 1.2810501396109204, validation loss: 1.3039648273716802.
epoch: 434, train loss: 1.2904861782668928, validation loss: 1.3126409623933875.
epoch: 435, train loss: 1.2899864824540024, validation loss: 1.3120806839155115.
epoch: 436, train loss: 1.2902937985341483, validation loss: 1.3063377349273018.
epoch: 437, train loss: 1.284249281664507, validation loss: 1.3105818914330525.
epoch: 438, train loss: 1.2795829597963106, validation loss: 1.2950668697771819.
epoch: 439, train loss: 1.2837589257354036, validation loss: 1.2978313124698142.
epoch: 440, train loss: 1.2846727404025717, validation loss: 1.289165584937386.
epoch: 441, train loss: 1.2822779635770605, validation loss: 1.324305886807649.
epoch: 442, train loss: 1.2797502574570683, validation loss: 1.2994419543639473.
epoch: 443, train loss: 1.276067620023675, validation loss: 1.2835332621698794.
epoch: 444, train loss: 1.2789018285383873, validation loss: 1.382881558459738.
epoch: 445, train loss: 1.2992144057510095, validation loss: 1.318914999132571.
epoch: 446, train loss: 1.2828968850844498, validation loss: 1.3103855537331623.
epoch: 447, train loss: 1.2995842257770924, validation loss: 1.3146575067354285.
epoch: 448, train loss: 1.296073476108936, validation loss: 1.3136423670727273.
epoch: 449, train loss: 1.2916946072097217, validation loss: 1.3225937978081082.
epoch: 450, train loss: 1.3001314193830578, validation loss: 1.3407714833383975.
epoch: 451, train loss: 1.294189802003563, validation loss: 1.315844328507133.
epoch: 452, train loss: 1.2897183052990415, validation loss: 1.3188595979110054.
epoch: 453, train loss: 1.2944035223864634, validation loss: 1.3493156847746477.
epoch: 454, train loss: 1.2982267185088692, validation loss: 1.3195909209873364.
epoch: 455, train loss: 1.303390991797141, validation loss: 1.3253967761993408.
epoch: 456, train loss: 1.3070505496558793, validation loss: 1.3457743240439373.
epoch: 457, train loss: 1.3125440068201188, validation loss: 1.3455043046370796.
epoch: 458, train loss: 1.3201735599325337, validation loss: 1.332042377928029.
epoch: 459, train loss: 1.3073712565483304, validation loss: 1.337643618169038.
epoch: 460, train loss: 1.30596863457916, validation loss: 1.322362578433493.
epoch: 461, train loss: 1.3044591245301274, validation loss: 1.3118428095527317.
epoch: 462, train loss: 1.300411926497013, validation loss: 1.3111908902292666.
epoch: 463, train loss: 1.293874154397107, validation loss: 1.3128835532976233.
epoch: 464, train loss: 1.2908722840317892, validation loss: 1.2954256275425786.
epoch: 465, train loss: 1.2898699996668264, validation loss: 1.3241941203241763.
epoch: 466, train loss: 1.2985260005390973, validation loss: 1.3070120396821394.
epoch: 467, train loss: 1.2883455075255228, validation loss: 1.3117581605911255.
epoch: 468, train loss: 1.288642988292449, validation loss: 1.3057791616605676.
epoch: 469, train loss: 1.2888437345487262, validation loss: 1.3026846284451692.
epoch: 470, train loss: 1.2916015780300176, validation loss: 1.3357803251432336.
epoch: 471, train loss: 1.301859366784402, validation loss: 1.327218050542085.
epoch: 472, train loss: 1.2980700873453683, validation loss: 1.3006124807440715.
epoch: 473, train loss: 1.2945155922425997, validation loss: 1.2993667644003164.
epoch: 474, train loss: 1.2900950985217312, validation loss: 1.2940838129624077.
epoch: 475, train loss: 1.2899074412267142, validation loss: 1.2968307370724885.
epoch: 476, train loss: 1.2849890890471432, validation loss: 1.300276922143024.
epoch: 477, train loss: 1.2940124065504162, validation loss: 1.3363289470257966.
epoch: 478, train loss: 1.3017348586966138, validation loss: 1.3076596830202185.
epoch: 479, train loss: 1.2933948269677817, validation loss: 1.2962482182875923.
epoch: 480, train loss: 1.2898353786643493, validation loss: 1.3101160578105762.
epoch: 481, train loss: 1.2928015606118999, validation loss: 1.3084609871325286.
epoch: 482, train loss: 1.2947119124438784, validation loss: 1.2910345896430637.
epoch: 483, train loss: 1.288152835784702, validation loss: 1.2970358910767927.
epoch: 484, train loss: 1.2848053405044275, validation loss: 1.3097464260847673.
epoch: 485, train loss: 1.3015533882543582, validation loss: 1.331550603327544.
epoch: 486, train loss: 1.2965339258176471, validation loss: 1.3079502219739167.
epoch: 487, train loss: 1.2959806525379145, validation loss: 1.3139265775680542.
epoch: 488, train loss: 1.2908061053774773, validation loss: 1.3140179540800012.
epoch: 489, train loss: 1.2970876387499888, validation loss: 1.2942973530810813.
epoch: 490, train loss: 1.2862021059071251, validation loss: 1.3055357414743174.
epoch: 491, train loss: 1.2881222766473752, validation loss: 1.303759129151054.
epoch: 492, train loss: 1.2917696379740304, validation loss: 1.3168201342872952.
epoch: 493, train loss: 1.2904606215450742, validation loss: 1.3014962310376375.
epoch: 494, train loss: 1.286462606640037, validation loss: 1.2893017063970151.
epoch: 495, train loss: 1.2832830728740867, validation loss: 1.3159082609674204.
epoch: 496, train loss: 1.288101821864417, validation loss: 1.2949584307877913.
epoch: 497, train loss: 1.2861313448039764, validation loss: 1.30541643889054.
epoch: 498, train loss: 1.2944998106825243, validation loss: 1.3360301308009936.
epoch: 499, train loss: 1.2964060919000469, validation loss: 1.3033697708793308.
epoch: 500, train loss: 1.2926792562554736, validation loss: 1.3140790151513142.
epoch: 501, train loss: 1.296966886301653, validation loss: 1.3267143601956575.
epoch: 502, train loss: 1.2963327486580665, validation loss: 1.3064045024954754.
epoch: 503, train loss: 1.2935826745601968, validation loss: 1.31540672675423.
epoch: 504, train loss: 1.2912338797105563, validation loss: 1.3014615359513655.
epoch: 505, train loss: 1.2849463290030803, validation loss: 1.3114660408185876.
epoch: 506, train loss: 1.289189375868631, validation loss: 1.315081440884134.
epoch: 507, train loss: 1.3116332839388367, validation loss: 1.3106412472932234.
epoch: 508, train loss: 1.2980361039485406, validation loss: 1.3254943256792815.
epoch: 509, train loss: 1.3002864275503596, validation loss: 1.3297741827757463.
epoch: 510, train loss: 1.2982768432809673, validation loss: 1.3055894685828167.
epoch: 511, train loss: 1.289140434440123, validation loss: 1.3012447823648867.
epoch: 512, train loss: 1.284428531970453, validation loss: 1.300170203913813.
epoch: 513, train loss: 1.2832323115900022, validation loss: 1.2968617003896963.
epoch: 514, train loss: 1.2859045376471423, validation loss: 1.297801085140394.
epoch: 515, train loss: 1.2886112939327135, validation loss: 1.2971726655960083.
epoch: 516, train loss: 1.2845518206237654, validation loss: 1.3028096686238828.
epoch: 517, train loss: 1.2859872590511217, validation loss: 1.3228507663892664.
epoch: 518, train loss: 1.287705622681784, validation loss: 1.2952344158421392.
epoch: 519, train loss: 1.2859276215964501, validation loss: 1.3002934455871582.
epoch: 520, train loss: 1.2841476508236807, validation loss: 1.291334375091221.
epoch: 521, train loss: 1.285586980504727, validation loss: 1.2973762180494226.
epoch: 522, train loss: 1.285720668801474, validation loss: 1.281741790149523.
epoch: 523, train loss: 1.281031793410625, validation loss: 1.3057168929473213.
epoch: 524, train loss: 1.2879663377726844, validation loss: 1.3125701624414194.
epoch: 525, train loss: 1.2855112213607227, validation loss: 1.3013912283855935.
epoch: 526, train loss: 1.2832586437190345, validation loss: 1.2909758816594663.
epoch: 527, train loss: 1.2882924364247452, validation loss: 1.2912798601648081.
epoch: 528, train loss: 1.2911204471500641, validation loss: 1.3054658381835273.
epoch: 529, train loss: 1.2917187432630346, validation loss: 1.3267583380574766.
epoch: 530, train loss: 1.29155332232834, validation loss: 1.3145099152689395.
epoch: 531, train loss: 1.2870632333493015, validation loss: 1.295041612956835.
epoch: 532, train loss: 1.2855027006306778, validation loss: 1.3031471812206765.
epoch: 533, train loss: 1.2829706964142826, validation loss: 1.298201032306837.
epoch: 534, train loss: 1.2814768979308802, validation loss: 1.2932608334914497.
epoch: 535, train loss: 1.2844000048593645, validation loss: 1.30255867605624.
epoch: 536, train loss: 1.2835781705488853, validation loss: 1.3196685469668845.
epoch: 537, train loss: 1.297192052963677, validation loss: 1.3244533331497856.
epoch: 538, train loss: 1.2924388789255685, validation loss: 1.308069337969241.
epoch: 539, train loss: 1.2836374274087607, validation loss: 1.286475471828295.
epoch: 540, train loss: 1.2776014914206408, validation loss: 1.2913341366726419.
epoch: 541, train loss: 1.278088266696405, validation loss: 1.2908295911291372.
epoch: 542, train loss: 1.2775479970722023, validation loss: 1.2955871250318445.
epoch: 543, train loss: 1.2802440398329988, validation loss: 1.2966372448465098.
epoch: 544, train loss: 1.2865504704484152, validation loss: 1.300537135290063.
epoch: 545, train loss: 1.2815939647342087, validation loss: 1.2928334992864858.
epoch: 546, train loss: 1.2851073227891134, validation loss: 1.3095049547112507.
epoch: 547, train loss: 1.2832890913027142, validation loss: 1.2990474338116853.
epoch: 548, train loss: 1.2790466328279688, validation loss: 1.2873394541118457.
epoch: 549, train loss: 1.2792462832337126, validation loss: 1.2940653044244517.
epoch: 550, train loss: 1.2766627084224595, validation loss: 1.2932715260464211.
epoch: 551, train loss: 1.278290856868849, validation loss: 1.2890188953150874.
epoch: 552, train loss: 1.2779368544937273, validation loss: 1.2908239882925283.
epoch: 553, train loss: 1.2797092319628514, validation loss: 1.30282055295032.
epoch: 554, train loss: 1.27723237462, validation loss: 1.2957172704779583.
epoch: 555, train loss: 1.2805068864734894, validation loss: 1.3193081721015598.
epoch: 556, train loss: 1.2842471260543262, validation loss: 1.3412652896798176.
epoch: 557, train loss: 1.2918720726573139, validation loss: 1.3075778173363728.
epoch: 558, train loss: 1.2847244816088894, validation loss: 1.306976935137873.
epoch: 559, train loss: 1.2806952688672126, validation loss: 1.2987048107644785.
epoch: 560, train loss: 1.276893312777948, validation loss: 1.3040570590807044.
epoch: 561, train loss: 1.2789842218434044, validation loss: 1.2933694849843564.
epoch: 562, train loss: 1.2722702638818584, validation loss: 1.2740044956621916.
epoch: 563, train loss: 1.2722448788651632, validation loss: 1.3092703560124272.
epoch: 564, train loss: 1.2806698083877563, validation loss: 1.3049221764440122.
epoch: 565, train loss: 1.277767380443188, validation loss: 1.2958098805469016.
epoch: 566, train loss: 1.2733829612031988, validation loss: 1.3030636569728022.
epoch: 567, train loss: 1.2759920796123119, validation loss: 1.2912904438765154.
epoch: 568, train loss: 1.278705903149526, validation loss: 1.3144507615462593.
epoch: 569, train loss: 1.2750521515487532, validation loss: 1.2922879975775015.
epoch: 570, train loss: 1.2719823132961168, validation loss: 1.2869348111359968.
epoch: 571, train loss: 1.2718788768173357, validation loss: 1.302633902300959.
epoch: 572, train loss: 1.2782357963946982, validation loss: 1.3016345967417178.
epoch: 573, train loss: 1.274981986492052, validation loss: 1.294608473777771.
epoch: 574, train loss: 1.2776329014279426, validation loss: 1.2991938331852788.
epoch: 575, train loss: 1.2800774246180824, validation loss: 1.2987143164095671.
epoch: 576, train loss: 1.2760294030565735, validation loss: 1.2883691839549853.
epoch: 577, train loss: 1.2738685017332025, validation loss: 1.2828171356864597.
epoch: 578, train loss: 1.2779827555385204, validation loss: 1.2911012276359226.
epoch: 579, train loss: 1.2751567265309325, validation loss: 1.3044923958571062.
epoch: 580, train loss: 1.2748177762425275, validation loss: 1.284870323927506.
epoch: 581, train loss: 1.2750553406706644, validation loss: 1.2971691204153972.
epoch: 582, train loss: 1.2791367867671022, validation loss: 1.3087441765743753.
epoch: 583, train loss: 1.2799209421927775, validation loss: 1.3062663959420246.
epoch: 584, train loss: 1.2769703001057335, validation loss: 1.3313769672227942.
epoch: 585, train loss: 1.2786801014471492, validation loss: 1.30544564516648.
epoch: 586, train loss: 1.2749258520406321, validation loss: 1.2859705168267954.
epoch: 587, train loss: 1.280964474065588, validation loss: 1.3191730976104736.
epoch: 588, train loss: 1.2834735922857161, validation loss: 1.3110072664592578.
epoch: 589, train loss: 1.275196550089285, validation loss: 1.2861110593961633.
epoch: 590, train loss: 1.2734619882128655, validation loss: 1.2910812471223914.
epoch: 591, train loss: 1.2723453788582337, validation loss: 1.3064362277155337.
epoch: 592, train loss: 1.2699805148150942, validation loss: 1.291828409485195.
epoch: 593, train loss: 1.2715805834586467, validation loss: 1.2828878371611885.
epoch: 594, train loss: 1.2729221877701786, validation loss: 1.3400672829669455.
epoch: 595, train loss: 1.2838763961004556, validation loss: 1.2957719979078874.
epoch: 596, train loss: 1.2760180705184236, validation loss: 1.2988725693329521.
epoch: 597, train loss: 1.2739882370747557, validation loss: 1.2864453015120134.
epoch: 598, train loss: 1.2741674589454581, validation loss: 1.3154122466626375.
epoch: 599, train loss: 1.2743346723941489, validation loss: 1.2840384244918823.
epoch: 600, train loss: 1.2718095549749673, validation loss: 1.2993928867837656.
epoch: 601, train loss: 1.2742767169934894, validation loss: 1.2841126400491465.
epoch: 602, train loss: 1.2753470315845734, validation loss: 1.284870728202488.
epoch: 603, train loss: 1.2706390433355208, validation loss: 1.2855279290157815.
epoch: 604, train loss: 1.2715529236224814, validation loss: 1.274864056836004.
epoch: 605, train loss: 1.269772789893894, validation loss: 1.29583071625751.
epoch: 606, train loss: 1.2707377212856887, validation loss: 1.3022937204526819.
epoch: 607, train loss: 1.2751104394230275, validation loss: 1.287911513577337.
epoch: 608, train loss: 1.2751578300371083, validation loss: 1.288251669510551.
epoch: 609, train loss: 1.2774908684809274, validation loss: 1.2842754592066226.
epoch: 610, train loss: 1.276345121751138, validation loss: 1.2941658082215681.
epoch: 611, train loss: 1.270581285887902, validation loss: 1.2920563739279043.
epoch: 612, train loss: 1.2716471109915217, validation loss: 1.2858014625051748.
epoch: 613, train loss: 1.267613204247361, validation loss: 1.300843912622203.
epoch: 614, train loss: 1.2672388958274772, validation loss: 1.3084965944290161.
epoch: 615, train loss: 1.2749977286802519, validation loss: 1.291843243267225.
epoch: 616, train loss: 1.2677043118608107, validation loss: 1.2854006601416545.
epoch: 617, train loss: 1.2741691267818487, validation loss: 1.2960412035817686.
epoch: 618, train loss: 1.273261208053029, validation loss: 1.2809306590453438.
epoch: 619, train loss: 1.2813689949315623, validation loss: 1.286863669105198.
epoch: 620, train loss: 1.2714202414958848, validation loss: 1.2771294998086018.
epoch: 621, train loss: 1.2692508227234587, validation loss: 1.29932541432588.
epoch: 622, train loss: 1.2680045902182202, validation loss: 1.2705552837123042.
epoch: 623, train loss: 1.2683302207824287, validation loss: 1.2871985539146091.
epoch: 624, train loss: 1.2710570523498255, validation loss: 1.3033677235893582.
epoch: 625, train loss: 1.2689261436462402, validation loss: 1.2757695032202678.
epoch: 626, train loss: 1.2674560623431423, validation loss: 1.3932637183562568.
epoch: 627, train loss: 1.2740200812663507, validation loss: 1.2838721378989841.
epoch: 628, train loss: 1.2922477328449213, validation loss: 1.381818185681882.
epoch: 629, train loss: 1.2949500958853906, validation loss: 1.340536319691202.
epoch: 630, train loss: 1.3077992561760299, validation loss: 1.3288149730018948.
epoch: 631, train loss: 1.3011180578021828, validation loss: 1.3060018705285115.
epoch: 632, train loss: 1.2867467611207875, validation loss: 1.2964989154235176.
epoch: 633, train loss: 1.2843553057504355, validation loss: 1.2888323535089907.
epoch: 634, train loss: 1.277211593925406, validation loss: 1.2904111717058264.
epoch: 635, train loss: 1.2729644523848087, validation loss: 1.2821056687313577.
epoch: 636, train loss: 1.274826491644623, validation loss: 1.3416689737983372.
epoch: 637, train loss: 1.2766063311778078, validation loss: 1.3070751273113748.
epoch: 638, train loss: 1.2836072302739554, validation loss: 1.2870905865793643.
epoch: 639, train loss: 1.2776023991611025, validation loss: 1.275729625121407.
epoch: 640, train loss: 1.2697817109046725, validation loss: 1.2815942453301472.
epoch: 641, train loss: 1.2674898160706967, validation loss: 1.2750381490458613.
epoch: 642, train loss: 1.267256138521597, validation loss: 1.2750756792400195.
epoch: 643, train loss: 1.2655684040227067, validation loss: 1.2821394516074138.
epoch: 644, train loss: 1.269280020250093, validation loss: 1.42072870420373.
epoch: 645, train loss: 1.2693553845816796, validation loss: 1.273708296858746.
epoch: 646, train loss: 1.2663756937061974, validation loss: 1.2731213310490483.
epoch: 647, train loss: 1.2658048496333831, validation loss: 1.27955308686132.
epoch: 648, train loss: 1.2619965393608863, validation loss: 1.2875738973202913.
epoch: 649, train loss: 1.2674437312904847, validation loss: 1.3154620813286824.
epoch: 650, train loss: 1.2708711350729707, validation loss: 1.318486680155215.
epoch: 651, train loss: 1.267883496546964, validation loss: 1.2883577035821003.
epoch: 652, train loss: 1.2684377125643809, validation loss: 1.279048318448274.
epoch: 653, train loss: 1.2649979427320148, validation loss: 1.2800741662149844.
epoch: 654, train loss: 1.2681108341304534, validation loss: 1.2973971159561821.
epoch: 655, train loss: 1.2660498422220212, validation loss: 1.2837829745334128.
epoch: 656, train loss: 1.2685546000069434, validation loss: 1.2752991085467131.
epoch: 657, train loss: 1.26412936416241, validation loss: 1.2862738889196645.
epoch: 658, train loss: 1.2646565907592073, validation loss: 1.2759515669034875.
epoch: 659, train loss: 1.2597175661576998, validation loss: 1.2801914163257764.
epoch: 660, train loss: 1.2618964768330985, validation loss: 1.266713577768077.
epoch: 661, train loss: 1.2625275806549492, validation loss: 1.2835628416227258.
epoch: 662, train loss: 1.2640088566946328, validation loss: 1.2844913524130117.
epoch: 663, train loss: 1.264715541393385, validation loss: 1.2970282927803372.
epoch: 664, train loss: 1.2753322988475135, validation loss: 1.3108293647351472.
epoch: 665, train loss: 1.2686413635901355, validation loss: 1.2722035594608472.
epoch: 666, train loss: 1.2653833583954277, validation loss: 1.2810497646746428.
epoch: 667, train loss: 1.264473102508335, validation loss: 1.2965156047240547.
epoch: 668, train loss: 1.2694885763553305, validation loss: 1.336517738259357.
epoch: 669, train loss: 1.2757984060759937, validation loss: 1.294560406519019.
epoch: 670, train loss: 1.269317680542622, validation loss: 1.301098512566608.
epoch: 671, train loss: 1.2729030792866278, validation loss: 1.2893386820088262.
epoch: 672, train loss: 1.2753467373891707, validation loss: 1.2819818465606025.
epoch: 673, train loss: 1.2721158845709004, validation loss: 1.2853353282679683.
epoch: 674, train loss: 1.2657532101377436, validation loss: 1.2810240051020747.
epoch: 675, train loss: 1.2658487525554971, validation loss: 1.2777495021405427.
epoch: 676, train loss: 1.2623247039427452, validation loss: 1.3049998594366985.
epoch: 677, train loss: 1.2639063968570954, validation loss: 1.2951421737670898.
epoch: 678, train loss: 1.2680101941484925, validation loss: 1.2762451016384622.
epoch: 679, train loss: 1.269382695539282, validation loss: 1.2855104933614316.
epoch: 680, train loss: 1.2680257165103876, validation loss: 1.2751229897789333.
epoch: 681, train loss: 1.2749135625471764, validation loss: 1.3022349088088325.
epoch: 682, train loss: 1.2716080562784038, validation loss: 1.2939038691313371.
epoch: 683, train loss: 1.2711703689820175, validation loss: 1.2819982507954473.
epoch: 684, train loss: 1.2655692341130809, validation loss: 1.2745318412780762.
epoch: 685, train loss: 1.2650548055631305, validation loss: 1.2747119976126629.
epoch: 686, train loss: 1.2637356618128786, validation loss: 1.2751110636669656.
epoch: 687, train loss: 1.2633234492135703, validation loss: 1.2719195718350618.
epoch: 688, train loss: 1.264444673826935, validation loss: 1.2760843712350596.
epoch: 689, train loss: 1.2643289434800453, validation loss: 1.272526554439379.
epoch: 690, train loss: 1.2705636440067116, validation loss: 1.280357257179592.
epoch: 691, train loss: 1.2654715382724726, validation loss: 1.312579403752866.
epoch: 692, train loss: 1.2652881189223824, validation loss: 1.2676345109939575.
epoch: 693, train loss: 1.2703323320511284, validation loss: 1.3213245609532231.
epoch: 694, train loss: 1.2687784477111397, validation loss: 1.280192546222521.
epoch: 695, train loss: 1.2646149834361644, validation loss: 1.2745001730711565.
epoch: 696, train loss: 1.2624715533825235, validation loss: 1.2789439533067786.
epoch: 697, train loss: 1.269511410949427, validation loss: 1.2891775006833284.
epoch: 698, train loss: 1.2678692154928084, validation loss: 1.2824727193168972.
epoch: 699, train loss: 1.264452364466606, validation loss: 1.2698223746341208.
epoch: 700, train loss: 1.2637834198977969, validation loss: 1.2742429608884065.
epoch: 701, train loss: 1.2666660317587197, validation loss: 1.286016583442688.
epoch: 702, train loss: 1.2651296886829062, validation loss: 1.2874641470287158.
epoch: 703, train loss: 1.2639014228768306, validation loss: 1.2992652447327324.
epoch: 704, train loss: 1.2657373848311397, validation loss: 1.305786511172419.
epoch: 705, train loss: 1.2660314982090521, validation loss: 1.3061783987542857.
epoch: 706, train loss: 1.2698124045625738, validation loss: 1.2836948736854221.
epoch: 707, train loss: 1.2675263903556613, validation loss: 1.2747902092726335.
epoch: 708, train loss: 1.265529255254553, validation loss: 1.2984856211620828.
epoch: 709, train loss: 1.269843673487322, validation loss: 1.2860868339953215.
epoch: 710, train loss: 1.2670647452730652, validation loss: 1.2805835423262224.
epoch: 711, train loss: 1.2717135280644127, validation loss: 1.2776942097622415.
epoch: 712, train loss: 1.2675800629712026, validation loss: 1.2863957467286482.
epoch: 713, train loss: 1.2670483162643713, validation loss: 1.2872798339180325.
epoch: 714, train loss: 1.2667027165036682, validation loss: 1.28198009988536.
epoch: 715, train loss: 1.263922454020299, validation loss: 1.2762367207071055.
epoch: 716, train loss: 1.2605769940472524, validation loss: 1.2864170696424402.
epoch: 717, train loss: 1.262314928781002, validation loss: 1.2892736352008323.
epoch: 718, train loss: 1.2658531272083247, validation loss: 1.2716069739797842.
epoch: 719, train loss: 1.2693701227870555, validation loss: 1.303573437359022.
epoch: 720, train loss: 1.2705710120157365, validation loss: 1.2936451797899993.
epoch: 721, train loss: 1.2637936139325483, validation loss: 1.281648858733799.
epoch: 722, train loss: 1.2691055230044443, validation loss: 1.2801500351532646.
epoch: 723, train loss: 1.2666542169150956, validation loss: 1.2929923949034319.
epoch: 724, train loss: 1.265983433898436, validation loss: 1.2777322582576587.
epoch: 725, train loss: 1.2666602954951995, validation loss: 1.278972915981127.
epoch: 726, train loss: 1.2631171001206845, validation loss: 1.2862243807834128.
epoch: 727, train loss: 1.2668387321157193, validation loss: 1.3069618836693142.
epoch: 728, train loss: 1.2619136637503947, validation loss: 1.2913298917853313.
epoch: 729, train loss: 1.2651912455165057, validation loss: 1.2845754778903464.
epoch: 730, train loss: 1.2629222826126518, validation loss: 1.287524016007133.
epoch: 731, train loss: 1.2606924586339827, validation loss: 1.2941386544186135.
epoch: 732, train loss: 1.2609789130884572, validation loss: 1.2920991907949033.
epoch: 733, train loss: 1.264450176046529, validation loss: 1.284035034801649.
epoch: 734, train loss: 1.262010377481443, validation loss: 1.2771558139635169.
epoch: 735, train loss: 1.2595476447989087, validation loss: 1.2853807003601738.
epoch: 736, train loss: 1.2589203338010595, validation loss: 1.2703784341397493.
epoch: 737, train loss: 1.2590700453574504, validation loss: 1.2711800906969153.
epoch: 738, train loss: 1.2601205176169719, validation loss: 1.2839045058126035.
epoch: 739, train loss: 1.2622871486418838, validation loss: 1.278239851412566.
epoch: 740, train loss: 1.2605144157322175, validation loss: 1.2931419455486795.
epoch: 741, train loss: 1.2625854409069097, validation loss: 1.2799437046051025.
epoch: 742, train loss: 1.2633388818950828, validation loss: 1.2959186460660852.
epoch: 743, train loss: 1.2644583632092956, validation loss: 1.3025903805442478.
epoch: 744, train loss: 1.2643831563652108, validation loss: 1.2900712801062542.
epoch: 745, train loss: 1.2595513326312424, validation loss: 1.2764318403990373.
epoch: 746, train loss: 1.260159461870106, validation loss: 1.320655900499095.
epoch: 747, train loss: 1.264219298275239, validation loss: 1.2851125157397727.
epoch: 748, train loss: 1.259094730429693, validation loss: 1.2875983922377876.
epoch: 749, train loss: 1.2614600866212757, validation loss: 1.28969711324443.
epoch: 750, train loss: 1.26956166696111, validation loss: 1.2797554109407507.
epoch: 751, train loss: 1.2649075317820277, validation loss: 1.2812856280285378.
epoch: 752, train loss: 1.257325317881523, validation loss: 1.2746361805045086.
epoch: 753, train loss: 1.2619820778523017, validation loss: 1.3378884429517.
epoch: 754, train loss: 1.2668370117834948, validation loss: 1.318799376487732.
epoch: 755, train loss: 1.2678790256517742, validation loss: 1.305369283842004.
epoch: 756, train loss: 1.2636672083390963, validation loss: 1.2634575159653374.
epoch: 757, train loss: 1.2568334855070902, validation loss: 1.278316601462986.
epoch: 758, train loss: 1.2609248905006898, validation loss: 1.2874590573103533.
epoch: 759, train loss: 1.2663399418559642, validation loss: 1.287081495575283.
epoch: 760, train loss: 1.2644422557375847, validation loss: 1.279785410217617.
epoch: 761, train loss: 1.2616519599879554, validation loss: 1.2853074851243391.
epoch: 762, train loss: 1.2586246652340671, validation loss: 1.2868126734443333.
epoch: 763, train loss: 1.261287533908809, validation loss: 1.2942518980606743.
epoch: 764, train loss: 1.2630779076060024, validation loss: 1.2836767435073853.
epoch: 765, train loss: 1.257486828970253, validation loss: 1.284058436103489.
epoch: 766, train loss: 1.2639331052062708, validation loss: 1.2941337564717168.
epoch: 767, train loss: 1.2622598081553749, validation loss: 1.2900121056515237.
epoch: 768, train loss: 1.257574502481233, validation loss: 1.2857995758885923.
epoch: 769, train loss: 1.2573656237453497, validation loss: 1.279425216757733.
epoch: 770, train loss: 1.2666641080051386, validation loss: 1.2867017414258874.
epoch: 771, train loss: 1.26346331123912, validation loss: 1.2861837718797766.
epoch: 772, train loss: 1.2617676345580215, validation loss: 1.284784866415936.
epoch: 773, train loss: 1.2619490262565263, validation loss: 1.2746529009031213.
epoch: 774, train loss: 1.2604111050247053, validation loss: 1.2906374620354695.
epoch: 775, train loss: 1.2616576962514754, validation loss: 1.2742108521254167.
epoch: 776, train loss: 1.2622950973860714, validation loss: 1.2800776647484822.
epoch: 777, train loss: 1.2606997686788577, validation loss: 1.272753560024759.
epoch: 778, train loss: 1.261100797478212, validation loss: 1.2853298601896868.
epoch: 779, train loss: 1.2602932879684168, validation loss: 1.2688389550084653.
epoch: 780, train loss: 1.2602660415369435, validation loss: 1.2742617596750674.
epoch: 781, train loss: 1.2571460369530074, validation loss: 1.287968355676402.
epoch: 782, train loss: 1.2626799749671866, validation loss: 1.2930175687955774.
epoch: 783, train loss: 1.2654077777075112, validation loss: 1.2854169088861216.
epoch: 784, train loss: 1.2564966766112442, validation loss: 1.2755829562311587.
epoch: 785, train loss: 1.2593525571560642, validation loss: 1.2791377098663994.
epoch: 786, train loss: 1.2603631632043681, validation loss: 1.2932389663613362.
epoch: 787, train loss: 1.2588130082559148, validation loss: 1.2684450875157895.
epoch: 788, train loss: 1.2540619799850183, validation loss: 1.2906752099161563.
epoch: 789, train loss: 1.2560497730150135, validation loss: 1.270551790361819.
epoch: 790, train loss: 1.2582052355512567, validation loss: 1.2777393382528555.
epoch: 791, train loss: 1.2587968592250018, validation loss: 1.2739945079969324.
epoch: 792, train loss: 1.2601311469296796, validation loss: 1.3078685791596123.
epoch: 793, train loss: 1.264485288103786, validation loss: 1.2808328659638115.
epoch: 794, train loss: 1.269420026639186, validation loss: 1.292582014332647.
epoch: 795, train loss: 1.2639043560815513, validation loss: 1.2769322706305462.
epoch: 796, train loss: 1.2589166219081354, validation loss: 1.2804590567298557.
epoch: 797, train loss: 1.2609169023846267, validation loss: 1.285117558811022.
epoch: 798, train loss: 1.2615085129344135, validation loss: 1.2721377611160278.
epoch: 799, train loss: 1.2578313306930962, validation loss: 1.2653945425282354.
epoch: 800, train loss: 1.2599134532683487, validation loss: 1.2748379759166553.
epoch: 801, train loss: 1.2619056132955289, validation loss: 1.273517090341319.
epoch: 802, train loss: 1.256748164465668, validation loss: 1.2792684202608855.
epoch: 803, train loss: 1.257206715575052, validation loss: 1.2729053445484326.
epoch: 804, train loss: 1.2617409098038979, validation loss: 1.2818663275760154.
epoch: 805, train loss: 1.2560833769107083, validation loss: 1.2640321410220603.
epoch: 806, train loss: 1.2578811448648435, validation loss: 1.2793189701826677.
epoch: 807, train loss: 1.2597580710682301, validation loss: 1.2773193587427554.
epoch: 808, train loss: 1.2559293191367333, validation loss: 1.2732181289921636.
epoch: 809, train loss: 1.2555964889876339, validation loss: 1.2650050702302351.
epoch: 810, train loss: 1.2565588087116906, validation loss: 1.2809075168941333.
epoch: 811, train loss: 1.2523195284222244, validation loss: 1.2945897527362988.
epoch: 812, train loss: 1.256001950403966, validation loss: 1.2721814539121545.
epoch: 813, train loss: 1.2648560825837862, validation loss: 1.2797472943430361.
epoch: 814, train loss: 1.2602411650736398, validation loss: 1.2716884302056355.
epoch: 815, train loss: 1.2603932608158217, validation loss: 1.280388179032699.
epoch: 816, train loss: 1.2557029581944876, validation loss: 1.2705974941668303.
epoch: 817, train loss: 1.2589304633096818, validation loss: 1.2858471559441609.
epoch: 818, train loss: 1.2612516705049288, validation loss: 1.2784974937853606.
epoch: 819, train loss: 1.2629088950813363, validation loss: 1.2773827158886453.
epoch: 820, train loss: 1.260741626450775, validation loss: 1.2868453471556953.
epoch: 821, train loss: 1.257326873070603, validation loss: 1.2722504657247793.
epoch: 822, train loss: 1.254630192704157, validation loss: 1.2703272052433179.
epoch: 823, train loss: 1.2628541233342723, validation loss: 1.2766687196234.
epoch: 824, train loss: 1.2614477566622813, validation loss: 1.291278953137605.
epoch: 825, train loss: 1.2627572477410693, validation loss: 1.270447912423507.
epoch: 826, train loss: 1.2572936650809892, validation loss: 1.2716900058414624.
epoch: 827, train loss: 1.2577740468016458, validation loss: 1.2738595008850098.
epoch: 828, train loss: 1.2612745914984187, validation loss: 1.3105021611503933.
epoch: 829, train loss: 1.2648360532358152, validation loss: 1.3037602590477986.
epoch: 830, train loss: 1.2607348894854205, validation loss: 1.2680336755254995.
epoch: 831, train loss: 1.2553933519835865, validation loss: 1.2862557950227156.
epoch: 832, train loss: 1.2558087307378787, validation loss: 1.267974298933278.
epoch: 833, train loss: 1.2579159802253093, validation loss: 1.2698648286902385.
epoch: 834, train loss: 1.2590621042689052, validation loss: 1.2900204865828804.
epoch: 835, train loss: 1.2544978102412792, validation loss: 1.2697339317072993.
epoch: 836, train loss: 1.2549215511444511, validation loss: 1.3050970564717832.
epoch: 837, train loss: 1.2566259793185313, validation loss: 1.2835161841433982.
epoch: 838, train loss: 1.2572104340299555, validation loss: 1.2703213588051174.
epoch: 839, train loss: 1.256896724394702, validation loss: 1.2815406633460003.
epoch: 840, train loss: 1.2582589431640205, validation loss: 1.2762171081874683.
epoch: 841, train loss: 1.2556070439312437, validation loss: 1.268405743267225.
epoch: 842, train loss: 1.2563158481492909, validation loss: 1.2777363372885662.
epoch: 843, train loss: 1.2562272439309217, validation loss: 1.2657432711642722.
epoch: 844, train loss: 1.2567039279762757, validation loss: 1.2644815963247549.
epoch: 845, train loss: 1.257081309589771, validation loss: 1.2780629707419353.
epoch: 846, train loss: 1.2594630849470787, validation loss: 1.2803434392680293.
epoch: 847, train loss: 1.2748490200130218, validation loss: 1.2960041294927183.
epoch: 848, train loss: 1.2607983788219066, validation loss: 1.2811807497687961.
epoch: 849, train loss: 1.2580083892979752, validation loss: 1.2744030175001726.
epoch: 850, train loss: 1.2543400919765508, validation loss: 1.2793479795041292.
epoch: 851, train loss: 1.254636859675066, validation loss: 1.2702312676802925.
epoch: 852, train loss: 1.2558305416632136, validation loss: 1.2944705175316853.
epoch: 853, train loss: 1.2557491271867665, validation loss: 1.278262910635575.
epoch: 854, train loss: 1.2579090354639455, validation loss: 1.291267534960871.
epoch: 855, train loss: 1.2593004692585097, validation loss: 1.3005159367685732.
epoch: 856, train loss: 1.2626417022232617, validation loss: 1.2883011931958406.
epoch: 857, train loss: 1.2609203539857077, validation loss: 1.2706485779389092.
epoch: 858, train loss: 1.2575432740220236, validation loss: 1.2808814152427341.
epoch: 859, train loss: 1.2579356246038313, validation loss: 1.265749216079712.
epoch: 860, train loss: 1.254460678188079, validation loss: 1.2803546760393225.
epoch: 861, train loss: 1.2538271420592562, validation loss: 1.2738855662553206.
epoch: 862, train loss: 1.2518841509425311, validation loss: 1.2687616192776223.
epoch: 863, train loss: 1.2562787839032095, validation loss: 1.2681439026542332.
epoch: 864, train loss: 1.2546248512530545, validation loss: 1.2763640569603962.
epoch: 865, train loss: 1.2562499275994956, validation loss: 1.28170935485674.
epoch: 866, train loss: 1.257581616760394, validation loss: 1.2771907785664434.
epoch: 867, train loss: 1.2595567790740128, validation loss: 1.3062948247660762.
epoch: 868, train loss: 1.2583700746571251, validation loss: 1.2714165604632834.
epoch: 869, train loss: 1.2525177406608512, validation loss: 1.2860685327778691.
epoch: 870, train loss: 1.2540959404149186, validation loss: 1.3035455164702043.
epoch: 871, train loss: 1.2534489861322105, validation loss: 1.2952054479847783.
epoch: 872, train loss: 1.2557883043901636, validation loss: 1.2904489455015764.
epoch: 873, train loss: 1.25705401613078, validation loss: 1.274140337239141.
epoch: 874, train loss: 1.2517298952155156, validation loss: 1.2772408620170925.
epoch: 875, train loss: 1.2520353651921683, validation loss: 1.2674731534460317.
epoch: 876, train loss: 1.2532071465745978, validation loss: 1.267907800881759.
epoch: 877, train loss: 1.2548691603021884, validation loss: 1.2701771829439246.
epoch: 878, train loss: 1.2531386034204326, validation loss: 1.2703224835188494.
epoch: 879, train loss: 1.252393185545545, validation loss: 1.2899336400239363.
epoch: 880, train loss: 1.257141980556173, validation loss: 1.2719713915949282.
epoch: 881, train loss: 1.2548937994405764, validation loss: 1.2762028341707976.
epoch: 882, train loss: 1.2623561216056893, validation loss: 1.276592757390893.
epoch: 883, train loss: 1.2634220615439458, validation loss: 1.281778273375138.
epoch: 884, train loss: 1.2641350905829614, validation loss: 1.2771800393643586.
epoch: 885, train loss: 1.2639611368879267, validation loss: 1.277744604193646.
epoch: 886, train loss: 1.263948499609571, validation loss: 1.3814394785010295.
epoch: 887, train loss: 1.264793820337418, validation loss: 1.2755323855773262.
epoch: 888, train loss: 1.2611344779303315, validation loss: 1.2664473212283591.
epoch: 889, train loss: 1.2588606690048079, validation loss: 1.2921482117279717.
epoch: 890, train loss: 1.2699714756886893, validation loss: 1.3002556251442952.
epoch: 891, train loss: 1.2659352700644677, validation loss: 1.309450222098309.
epoch: 892, train loss: 1.265089395943038, validation loss: 1.2769006387047146.
epoch: 893, train loss: 1.2606674443691148, validation loss: 1.2771283284477566.
epoch: 894, train loss: 1.2590718236538248, validation loss: 1.2767259141673213.
epoch: 895, train loss: 1.2595370395467915, validation loss: 1.283797113791756.
epoch: 896, train loss: 1.2589384295524808, validation loss: 1.26572731266851.
epoch: 897, train loss: 1.2536882796418776, validation loss: 1.2777752306150354.
epoch: 898, train loss: 1.2555118186758198, validation loss: 1.2698760758275571.
epoch: 899, train loss: 1.2571046680485436, validation loss: 1.268293375554292.
epoch: 900, train loss: 1.25653837361467, validation loss: 1.2700491625329722.
epoch: 901, train loss: 1.2584605206043349, validation loss: 1.269457371338554.
epoch: 902, train loss: 1.2550413542931234, validation loss: 1.2742184607878975.
epoch: 903, train loss: 1.2565732111624621, validation loss: 1.28438473266104.
epoch: 904, train loss: 1.2527838486050247, validation loss: 1.30668364400449.
epoch: 905, train loss: 1.2586432072000766, validation loss: 1.277161048806232.
epoch: 906, train loss: 1.25831591645512, validation loss: 1.2866937544034875.
epoch: 907, train loss: 1.2610452317316598, validation loss: 1.283061146736145.
epoch: 908, train loss: 1.2595524645726615, validation loss: 1.2837101739385854.
epoch: 909, train loss: 1.256959070853137, validation loss: 1.3012622853984004.
epoch: 910, train loss: 1.259888842565204, validation loss: 1.2741912447887918.
epoch: 911, train loss: 1.2578991673408297, validation loss: 1.2724067491033804.
epoch: 912, train loss: 1.2580831094619331, validation loss: 1.297848685928013.
epoch: 913, train loss: 1.2618941188952244, validation loss: 1.287167129309281.
epoch: 914, train loss: 1.2582918503962526, validation loss: 1.2737096807231074.
epoch: 915, train loss: 1.2552373343651448, validation loss: 1.27188125382299.
epoch: 916, train loss: 1.258562160194467, validation loss: 1.3028215221736743.
epoch: 917, train loss: 1.2567074637894238, validation loss: 1.2740360653918723.
epoch: 918, train loss: 1.2541904405716362, validation loss: 1.2820764313573423.
epoch: 919, train loss: 1.2576057298467793, validation loss: 1.2749282017998074.
epoch: 920, train loss: 1.2581128264785906, validation loss: 1.2771602506222932.
epoch: 921, train loss: 1.2523568726460867, validation loss: 1.2700736470844434.
epoch: 922, train loss: 1.2592216894167279, validation loss: 1.276569480481355.
epoch: 923, train loss: 1.2555997262307264, validation loss: 1.3034721923911052.
epoch: 924, train loss: 1.2612232997876789, validation loss: 1.2731229947960896.
epoch: 925, train loss: 1.2528901592307133, validation loss: 1.2758902259494946.
epoch: 926, train loss: 1.2529742247467741, validation loss: 1.2703695349071338.
epoch: 927, train loss: 1.2612198175640281, validation loss: 1.2998705895050713.
epoch: 928, train loss: 1.2576335712310371, validation loss: 1.2870358073193093.
epoch: 929, train loss: 1.2567862020720035, validation loss: 1.265449840089549.
epoch: 930, train loss: 1.2562564950470532, validation loss: 1.3045085616733716.
epoch: 931, train loss: 1.2557849938716363, validation loss: 1.2756639097047888.
epoch: 932, train loss: 1.2550321620538694, validation loss: 1.2925757999005525.
epoch: 933, train loss: 1.2550349694873215, validation loss: 1.2676174018694006.
epoch: 934, train loss: 1.2628379491491055, validation loss: 1.2785556160885354.
epoch: 935, train loss: 1.2557276192061397, validation loss: 1.2739967107772827.
epoch: 936, train loss: 1.2492402573244288, validation loss: 1.2679321817729785.
epoch: 937, train loss: 1.2529749914046822, validation loss: 1.2727663361507913.
epoch: 938, train loss: 1.2603009720461085, validation loss: 1.2775578498840332.
epoch: 939, train loss: 1.261295225642143, validation loss: 1.2758390126021013.
epoch: 940, train loss: 1.25303745816607, validation loss: 1.2636924930240796.
epoch: 941, train loss: 1.2505178560904406, validation loss: 1.303977950759556.
epoch: 942, train loss: 1.2614217635688432, validation loss: 1.2753638495569644.
epoch: 943, train loss: 1.2586050044505968, validation loss: 1.2765586894491445.
epoch: 944, train loss: 1.2562670379603675, validation loss: 1.2833733714145164.
epoch: 945, train loss: 1.2574447579340104, validation loss: 1.2989605457886406.
epoch: 946, train loss: 1.258438070979687, validation loss: 1.271591922511225.
epoch: 947, train loss: 1.256902728605708, validation loss: 1.271268606185913.
epoch: 948, train loss: 1.2715831295065922, validation loss: 1.3118688386419546.
epoch: 949, train loss: 1.2661242572539444, validation loss: 1.2956083442853845.
epoch: 950, train loss: 1.2575247112764132, validation loss: 1.2942311297292295.
epoch: 951, train loss: 1.2584778726647754, validation loss: 1.3173324750817341.
epoch: 952, train loss: 1.2560353005697968, validation loss: 1.2636894454126772.
epoch: 953, train loss: 1.2519457285557318, validation loss: 1.291464442792146.
epoch: 954, train loss: 1.2547753939934827, validation loss: 1.2690895173860632.
epoch: 955, train loss: 1.2525724763170294, validation loss: 1.2808499958204187.
epoch: 956, train loss: 1.2589019733831424, validation loss: 1.2870405083117278.
epoch: 957, train loss: 1.2572286172744331, validation loss: 1.2755461361097253.
epoch: 958, train loss: 1.2541028534600493, validation loss: 1.2708442833112634.
epoch: 959, train loss: 1.257985603918723, validation loss: 1.2740563724351965.
epoch: 960, train loss: 1.258896537877004, validation loss: 1.2736815369647483.
epoch: 961, train loss: 1.2533750435627928, validation loss: 1.2585758851922078.
epoch: 962, train loss: 1.2500432860960655, validation loss: 1.269221103709677.
epoch: 963, train loss: 1.2512831666053983, validation loss: 1.2756742653639421.
epoch: 964, train loss: 1.2518743724997985, validation loss: 1.2720497846603394.
epoch: 965, train loss: 1.252832769253932, validation loss: 1.2590787566226462.
epoch: 966, train loss: 1.2553683683412884, validation loss: 1.2815060978350432.
epoch: 967, train loss: 1.2561057029514138, validation loss: 1.267483633497487.
epoch: 968, train loss: 1.2533196637389856, validation loss: 1.2626715743023416.
epoch: 969, train loss: 1.256852235269109, validation loss: 1.269185615622479.
epoch: 970, train loss: 1.2544176578521729, validation loss: 1.3048946339151133.
epoch: 971, train loss: 1.2564111969886569, validation loss: 1.2745993811151255.
epoch: 972, train loss: 1.256556553578158, validation loss: 1.2799164471418962.
epoch: 973, train loss: 1.2529040082879024, validation loss: 1.2795157795367034.
epoch: 974, train loss: 1.2549521912128554, validation loss: 1.2712575871011484.
epoch: 975, train loss: 1.2608593199231208, validation loss: 1.2764047850733218.
epoch: 976, train loss: 1.2564241601786483, validation loss: 1.2858096361160278.
epoch: 977, train loss: 1.2549718104371237, validation loss: 1.267195515010668.
epoch: 978, train loss: 1.2576229648852566, validation loss: 1.2860602814218272.
epoch: 979, train loss: 1.2533191453426256, validation loss: 1.282528747682986.
epoch: 980, train loss: 1.251857337601688, validation loss: 1.2863277300544407.
epoch: 981, train loss: 1.2544024559335971, validation loss: 1.2964432913324107.
epoch: 982, train loss: 1.2565335232183474, validation loss: 1.2698467918064282.
epoch: 983, train loss: 1.256727982004848, validation loss: 1.2771139974179475.
epoch: 984, train loss: 1.2552566626750001, validation loss: 1.2709731122721797.
epoch: 985, train loss: 1.2530758238713675, validation loss: 1.280728816986084.
epoch: 986, train loss: 1.2545395608342023, validation loss: 1.2755098394725635.
epoch: 987, train loss: 1.2511343649767954, validation loss: 1.266123688739279.
epoch: 988, train loss: 1.256575006957448, validation loss: 1.2957628239756045.
epoch: 989, train loss: 1.2536107531381309, validation loss: 1.2703158544457478.
epoch: 990, train loss: 1.2544338167260547, validation loss: 1.2788539191950923.
epoch: 991, train loss: 1.252761673489842, validation loss: 1.2869779286177263.
epoch: 992, train loss: 1.2524087724335697, validation loss: 1.2714035044545713.
epoch: 993, train loss: 1.251789488923659, validation loss: 1.3092121974281643.
epoch: 994, train loss: 1.2524623838039712, validation loss: 1.2725183756455132.
epoch: 995, train loss: 1.2531487832375623, validation loss: 1.2860433018725852.
epoch: 996, train loss: 1.2629494743609646, validation loss: 1.275568355684695.
epoch: 997, train loss: 1.2534601174363302, validation loss: 1.2722544255463972.
epoch: 998, train loss: 1.2574148462453019, validation loss: 1.2855908663376518.
epoch: 999, train loss: 1.2546137746320951, validation loss: 1.2779741701872454.
epoch: 1000, train loss: 1.2512874570461587, validation loss: 1.2663943508396978.
epoch: 1001, train loss: 1.2516678604510947, validation loss: 1.2764800579651543.
epoch: 1002, train loss: 1.2499030981588801, validation loss: 1.2688073127166084.
epoch: 1003, train loss: 1.2492611900382085, validation loss: 1.2712277433146602.
epoch: 1004, train loss: 1.2558300199858639, validation loss: 1.2669065205947212.
epoch: 1005, train loss: 1.2553311969162126, validation loss: 1.2884154164272805.
epoch: 1006, train loss: 1.2545692789445229, validation loss: 1.2865751826244851.
epoch: 1007, train loss: 1.2548963356455531, validation loss: 1.2712413020755933.
epoch: 1008, train loss: 1.2539566000667186, validation loss: 1.2978634626969048.
epoch: 1009, train loss: 1.254337408127041, validation loss: 1.2696155413337376.
epoch: 1010, train loss: 1.2560333691605734, validation loss: 1.2831142881642217.
epoch: 1011, train loss: 1.2560721263972991, validation loss: 1.2650812138681826.
epoch: 1012, train loss: 1.251009971723644, validation loss: 1.2621056567067686.
epoch: 1013, train loss: 1.2507849789540701, validation loss: 1.2671340652134107.
epoch: 1014, train loss: 1.2523389628174109, validation loss: 1.2711819565814475.
epoch: 1015, train loss: 1.25008150415683, validation loss: 1.2779234233109846.
epoch: 1016, train loss: 1.2542998900107287, validation loss: 1.324691134950389.
epoch: 1017, train loss: 1.2518199452566445, validation loss: 1.2761017032291577.
epoch: 1018, train loss: 1.2529237696883875, validation loss: 1.2709024004314258.
epoch: 1019, train loss: 1.2506680477649794, validation loss: 1.2797069290409917.
epoch: 1020, train loss: 1.2513916601828479, validation loss: 1.2824005044024924.
epoch: 1021, train loss: 1.2525522730766085, validation loss: 1.2770504381345666.
epoch: 1022, train loss: 1.2477616454483171, validation loss: 1.2627641791882722.
epoch: 1023, train loss: 1.2524914949312123, validation loss: 1.2681881344836692.
epoch: 1024, train loss: 1.248928729547273, validation loss: 1.2892225255136904.
epoch: 1025, train loss: 1.2522979132626035, validation loss: 1.280584252398947.
epoch: 1026, train loss: 1.250068309110239, validation loss: 1.2736322102339372.
epoch: 1027, train loss: 1.249252274495746, validation loss: 1.2811480605083962.
epoch: 1028, train loss: 1.2615007512066343, validation loss: 1.2736588768337085.
epoch: 1029, train loss: 1.2540603307409024, validation loss: 1.268540646718896.
epoch: 1030, train loss: 1.2550080992759916, validation loss: 1.271509533343108.
epoch: 1031, train loss: 1.2593594461406044, validation loss: 1.2742300707360972.
epoch: 1032, train loss: 1.2529159259358678, validation loss: 1.2680374124775762.
epoch: 1033, train loss: 1.2539255028470941, validation loss: 1.2861581988956616.
epoch: 1034, train loss: 1.2558843827028887, validation loss: 1.2653993005337922.
epoch: 1035, train loss: 1.2648530750099671, validation loss: 1.2771626451741094.
epoch: 1036, train loss: 1.2636844422839104, validation loss: 1.2745590987412825.
epoch: 1037, train loss: 1.2598291788626155, validation loss: 1.3139145581618599.
epoch: 1038, train loss: 1.2689562095414608, validation loss: 1.2804138090299524.
epoch: 1039, train loss: 1.2619760419250627, validation loss: 1.2891177975613137.
epoch: 1040, train loss: 1.25725735874351, validation loss: 1.2856932515683381.
epoch: 1041, train loss: 1.2583393995914984, validation loss: 1.2881164965422258.
epoch: 1042, train loss: 1.2512556194165432, validation loss: 1.2654368203619253.
epoch: 1043, train loss: 1.255330526500667, validation loss: 1.2638079912766167.
epoch: 1044, train loss: 1.2521115639887819, validation loss: 1.2858571591584578.
epoch: 1045, train loss: 1.2510296292261247, validation loss: 1.2577037085657534.
epoch: 1046, train loss: 1.2495536880755642, validation loss: 1.2688569089640742.
epoch: 1047, train loss: 1.2504915097437868, validation loss: 1.2908265176026716.
epoch: 1048, train loss: 1.2515764280196724, validation loss: 1.2640417399613753.
epoch: 1049, train loss: 1.252976175841935, validation loss: 1.26798589333244.
epoch: 1050, train loss: 1.256014384260965, validation loss: 1.2685697700666345.
epoch: 1051, train loss: 1.2506499837297913, validation loss: 1.2682881355285645.
epoch: 1052, train loss: 1.2541195777578091, validation loss: 1.2794157940408457.
epoch: 1053, train loss: 1.2528066722624893, validation loss: 1.2669907704643582.
epoch: 1054, train loss: 1.2493417372397326, validation loss: 1.2609753297722859.
epoch: 1055, train loss: 1.2572111799082626, validation loss: 1.2733423191568125.
epoch: 1056, train loss: 1.25170993586199, validation loss: 1.276301902273427.
epoch: 1057, train loss: 1.2549478264029967, validation loss: 1.2768699967342874.
epoch: 1058, train loss: 1.2514543303655923, validation loss: 1.275659820307856.
epoch: 1059, train loss: 1.2524213845576715, validation loss: 1.2791600071865579.
epoch: 1060, train loss: 1.2494378308637426, validation loss: 1.2861738671427188.
epoch: 1061, train loss: 1.2523327420610901, validation loss: 1.3032721643862517.
epoch: 1062, train loss: 1.2582106885560063, validation loss: 1.2718842236892036.
epoch: 1063, train loss: 1.2573713228243206, validation loss: 1.267389468524767.
epoch: 1064, train loss: 1.2497342453090423, validation loss: 1.2690226046935371.
epoch: 1065, train loss: 1.2493788266400678, validation loss: 1.2772642063057942.
epoch: 1066, train loss: 1.2490069374031978, validation loss: 1.2730611044427622.
epoch: 1067, train loss: 1.248498527281875, validation loss: 1.2780776179355124.
epoch: 1068, train loss: 1.2491854888583542, validation loss: 1.274280713952106.
epoch: 1069, train loss: 1.252393650352408, validation loss: 1.2794898644737576.
epoch: 1070, train loss: 1.251127152267946, validation loss: 1.2607410472372305.
epoch: 1071, train loss: 1.2492954173219313, validation loss: 1.286154021387515.
epoch: 1072, train loss: 1.2601647322331, validation loss: 1.2790583579436592.
epoch: 1073, train loss: 1.2607945542816723, validation loss: 1.2717836317808733.
epoch: 1074, train loss: 1.2517431843171425, validation loss: 1.2787747123967046.
epoch: 1075, train loss: 1.2507540031310616, validation loss: 1.2877357006072998.
epoch: 1076, train loss: 1.2486346577285627, validation loss: 1.2664972906527312.
epoch: 1077, train loss: 1.2515523761784264, validation loss: 1.2679484305174455.
epoch: 1078, train loss: 1.2486986381198288, validation loss: 1.2624287760776023.
epoch: 1079, train loss: 1.2494224222428207, validation loss: 1.261364599932795.
epoch: 1080, train loss: 1.2505547223834816, validation loss: 1.2651786441388337.
epoch: 1081, train loss: 1.2489605245240238, validation loss: 1.2617721972258196.
epoch: 1082, train loss: 1.2506736604445572, validation loss: 1.2881729188172713.
epoch: 1083, train loss: 1.2621826316238542, validation loss: 1.2667345171389373.
epoch: 1084, train loss: 1.2506738682405665, validation loss: 1.2648312112559443.
epoch: 1085, train loss: 1.2487006012452853, validation loss: 1.2710620320361594.
epoch: 1086, train loss: 1.2449428958630344, validation loss: 1.265135127565135.
epoch: 1087, train loss: 1.2535993527928624, validation loss: 1.2817599203275598.
epoch: 1088, train loss: 1.2535095400766496, validation loss: 1.2659870645274287.
epoch: 1089, train loss: 1.247492811001769, validation loss: 1.2746185530786929.
epoch: 1090, train loss: 1.2457259466888708, validation loss: 1.3104228973388672.
epoch: 1091, train loss: 1.2498648046353542, validation loss: 1.274922868479853.
epoch: 1092, train loss: 1.2504623515890279, validation loss: 1.2663161599117776.
epoch: 1093, train loss: 1.248794097419179, validation loss: 1.2823190637256787.
epoch: 1094, train loss: 1.2562402443054619, validation loss: 1.2814266111539758.
epoch: 1095, train loss: 1.256517825870339, validation loss: 1.2778476839480193.
epoch: 1096, train loss: 1.2558538749677326, validation loss: 1.2924026354499485.
epoch: 1097, train loss: 1.2507213725956208, validation loss: 1.2704516856566719.
epoch: 1098, train loss: 1.249638456817067, validation loss: 1.2849481105804443.
epoch: 1099, train loss: 1.2505861630133532, validation loss: 1.283663552740346.
epoch: 1100, train loss: 1.254722379763192, validation loss: 1.2770829356235007.
epoch: 1101, train loss: 1.2482756944971347, validation loss: 1.2666858020036116.
epoch: 1102, train loss: 1.2514344956896721, validation loss: 1.2638863843420278.
epoch: 1103, train loss: 1.2502322875031637, validation loss: 1.285117050875788.
epoch: 1104, train loss: 1.2498430101149673, validation loss: 1.2707064514574797.
epoch: 1105, train loss: 1.2516630275533833, validation loss: 1.2795668477597444.
epoch: 1106, train loss: 1.2539957138376499, validation loss: 1.2721558342809263.
epoch: 1107, train loss: 1.2562826642202676, validation loss: 1.2694361728170644.
epoch: 1108, train loss: 1.2505798110174478, validation loss: 1.2660967163417651.
epoch: 1109, train loss: 1.2492196920814864, validation loss: 1.2564510003380154.
epoch: 1110, train loss: 1.2476238132616795, validation loss: 1.2843654829522837.
epoch: 1111, train loss: 1.2547741461237636, validation loss: 1.2774152341096296.
epoch: 1112, train loss: 1.2537707243490657, validation loss: 1.2672671494276628.
epoch: 1113, train loss: 1.2507916535806218, validation loss: 1.268429388170657.
epoch: 1114, train loss: 1.2490098662332658, validation loss: 1.267791105353314.
epoch: 1115, train loss: 1.2477688701874619, validation loss: 1.2631455919016963.
epoch: 1116, train loss: 1.249372324812303, validation loss: 1.2743397484654966.
epoch: 1117, train loss: 1.2499041130783362, validation loss: 1.2793677319651064.
epoch: 1118, train loss: 1.247496161985835, validation loss: 1.2701129187708315.
epoch: 1119, train loss: 1.254839090032315, validation loss: 1.2861180616461712.
epoch: 1120, train loss: 1.2553458509095219, validation loss: 1.2718410284622856.
epoch: 1121, train loss: 1.2556499155289536, validation loss: 1.2870656200077222.
epoch: 1122, train loss: 1.2537056349833078, validation loss: 1.276505936747012.
epoch: 1123, train loss: 1.252409388165955, validation loss: 1.2795765451762988.
epoch: 1124, train loss: 1.2493443434391547, validation loss: 1.2818665348965188.
epoch: 1125, train loss: 1.2480733241509954, validation loss: 1.2654058829597805.
epoch: 1126, train loss: 1.253161849231895, validation loss: 1.299069238745648.
epoch: 1127, train loss: 1.2481874391573284, validation loss: 1.274728940880817.
epoch: 1128, train loss: 1.250268229650795, validation loss: 1.2679652442102847.
epoch: 1129, train loss: 1.2485626071964928, validation loss: 1.2606208272602246.
epoch: 1130, train loss: 1.2510932137113098, validation loss: 1.2833166329757026.
epoch: 1131, train loss: 1.2487283299822327, validation loss: 1.2827627969824749.
epoch: 1132, train loss: 1.2646111545212773, validation loss: 1.2876611066901165.
epoch: 1133, train loss: 1.254691248640008, validation loss: 1.2696746743243674.
epoch: 1134, train loss: 1.2522532885227728, validation loss: 1.3047303013179614.
epoch: 1135, train loss: 1.2556717702008169, validation loss: 1.2683829794759336.
epoch: 1136, train loss: 1.249948861402109, validation loss: 1.2780925294627314.
epoch: 1137, train loss: 1.2488565794918516, validation loss: 1.3033717559731526.
epoch: 1138, train loss: 1.2488375453773988, validation loss: 1.2725827123807825.
epoch: 1139, train loss: 1.248806303794231, validation loss: 1.2795899847279424.
epoch: 1140, train loss: 1.2590057893630562, validation loss: 1.3103906641835752.
epoch: 1141, train loss: 1.2559754815670328, validation loss: 1.285875123480092.
epoch: 1142, train loss: 1.2571966998074033, validation loss: 1.2935576127923054.
epoch: 1143, train loss: 1.2537754478804561, validation loss: 1.2699727960254834.
epoch: 1144, train loss: 1.2500050877212385, validation loss: 1.2913234700327334.
epoch: 1145, train loss: 1.2547657774129044, validation loss: 1.2671022726141887.
epoch: 1146, train loss: 1.2518759419065002, validation loss: 1.2664507938467937.
epoch: 1147, train loss: 1.2470423344078414, validation loss: 1.2739259160083274.
epoch: 1148, train loss: 1.2454484329311126, validation loss: 1.264413683310799.
epoch: 1149, train loss: 1.2510774901153845, validation loss: 1.283888288166212.
epoch: 1150, train loss: 1.253347683390346, validation loss: 1.2908259163732114.
epoch: 1151, train loss: 1.2487592270614905, validation loss: 1.2617546630942302.
epoch: 1152, train loss: 1.2498488043426375, validation loss: 1.3018355421397998.
epoch: 1153, train loss: 1.2501278623528438, validation loss: 1.2652867669644563.
epoch: 1154, train loss: 1.2504260693121394, validation loss: 1.2717593182688174.
epoch: 1155, train loss: 1.2517807647722576, validation loss: 1.3016020629716956.
epoch: 1156, train loss: 1.2495257602919132, validation loss: 1.2773094643717227.
epoch: 1157, train loss: 1.2538056647011993, validation loss: 1.270653688389322.
epoch: 1158, train loss: 1.2487481799694375, validation loss: 1.2653758992319522.
epoch: 1159, train loss: 1.2486733143482733, validation loss: 1.2717901520107104.
epoch: 1160, train loss: 1.2474684890257108, validation loss: 1.2678389756575874.
epoch: 1161, train loss: 1.2566726787374654, validation loss: 1.2736502574837727.
epoch: 1162, train loss: 1.2587476006341636, validation loss: 1.265958029290904.
epoch: 1163, train loss: 1.2491399530970722, validation loss: 1.2808178248612776.
epoch: 1164, train loss: 1.2534654895100026, validation loss: 1.2763346070828645.
epoch: 1165, train loss: 1.2511374086415001, validation loss: 1.2579956780309263.
epoch: 1166, train loss: 1.2511176013071603, validation loss: 1.272995985072592.
epoch: 1167, train loss: 1.2531282781460964, validation loss: 1.2835232278575068.
epoch: 1168, train loss: 1.2477161173426776, validation loss: 1.2629333941832832.
epoch: 1169, train loss: 1.2505194265908057, validation loss: 1.2746338533318562.
epoch: 1170, train loss: 1.2486528770639262, validation loss: 1.2686004016710364.
epoch: 1171, train loss: 1.2498591711761755, validation loss: 1.2768247801324595.
epoch: 1172, train loss: 1.2497457747065692, validation loss: 1.278775541678719.
epoch: 1173, train loss: 1.251784244808582, validation loss: 1.2862755889477937.
epoch: 1174, train loss: 1.2547466568990584, validation loss: 1.285482292589934.
epoch: 1175, train loss: 1.2522528259032364, validation loss: 1.278086527534153.
epoch: 1176, train loss: 1.2524544886492808, validation loss: 1.2819164524907651.
epoch: 1177, train loss: 1.2490659142852922, validation loss: 1.2683633358582207.
epoch: 1178, train loss: 1.2475502873779436, validation loss: 1.286061421684597.
epoch: 1179, train loss: 1.2522754505139972, validation loss: 1.2727478276128354.
epoch: 1180, train loss: 1.2516912670310485, validation loss: 1.265463808308477.
epoch: 1181, train loss: 1.2533686817239185, validation loss: 1.2831059175988901.
epoch: 1182, train loss: 1.2502087135927393, validation loss: 1.2710850808931433.
epoch: 1183, train loss: 1.2473891470410408, validation loss: 1.2618841088336448.
epoch: 1184, train loss: 1.2521672194157172, validation loss: 1.2760177280591882.
epoch: 1185, train loss: 1.24943868938936, validation loss: 1.2696120687153027.
epoch: 1186, train loss: 1.2460046219169547, validation loss: 1.2634813681892727.
epoch: 1187, train loss: 1.2465546787331958, validation loss: 1.2699067748111228.
epoch: 1188, train loss: 1.248927375592223, validation loss: 1.2557118664617124.
epoch: 1189, train loss: 1.2565977321852237, validation loss: 1.2829870348391326.
epoch: 1190, train loss: 1.253350236000271, validation loss: 1.2765116847079734.
epoch: 1191, train loss: 1.2538805084490994, validation loss: 1.2888618500336357.
epoch: 1192, train loss: 1.248565853188891, validation loss: 1.2634689807891846.
epoch: 1193, train loss: 1.2541265170508569, validation loss: 1.275594659473585.
epoch: 1194, train loss: 1.2505632365515473, validation loss: 1.2605475083641384.
epoch: 1195, train loss: 1.247532939692156, validation loss: 1.2650949177534685.
epoch: 1196, train loss: 1.2464550263291105, validation loss: 1.2937625128289927.
epoch: 1197, train loss: 1.2490709320120854, validation loss: 1.269723037014837.
epoch: 1198, train loss: 1.2519559061855352, validation loss: 1.2555453725483106.
epoch: 1199, train loss: 1.2520499021635143, validation loss: 1.2723243547522503.
epoch: 1200, train loss: 1.2518968757139433, validation loss: 1.2692815531855044.
epoch: 1201, train loss: 1.2521072112092184, validation loss: 1.2814727347830068.
epoch: 1202, train loss: 1.2518785612298808, validation loss: 1.2769199661586597.
epoch: 1203, train loss: 1.249690120373297, validation loss: 1.2668061100918313.
epoch: 1204, train loss: 1.2494280808562532, validation loss: 1.257325669993525.
epoch: 1205, train loss: 1.2475072178271933, validation loss: 1.2989788677381433.
epoch: 1206, train loss: 1.2529343344749662, validation loss: 1.2751509521318518.
epoch: 1207, train loss: 1.2511792412591636, validation loss: 1.2688947916030884.
epoch: 1208, train loss: 1.2512240672330244, validation loss: 1.2604072508604631.
epoch: 1209, train loss: 1.2516394580176118, validation loss: 1.2665340330289758.
epoch: 1210, train loss: 1.2460310732552764, validation loss: 1.2613112822822903.
epoch: 1211, train loss: 1.246639947278784, validation loss: 1.2587823142176089.
epoch: 1212, train loss: 1.2471754211898243, validation loss: 1.2734830275825832.
epoch: 1213, train loss: 1.2498940535641592, validation loss: 1.2670379099638567.
epoch: 1214, train loss: 1.249687639945144, validation loss: 1.2664678407751995.
epoch: 1215, train loss: 1.2496808625142508, validation loss: 1.2838176333385964.
epoch: 1216, train loss: 1.2489953478541942, validation loss: 1.2719273048898447.
epoch: 1217, train loss: 1.24758595501611, validation loss: 1.2664539036543474.
epoch: 1218, train loss: 1.2503241278709623, validation loss: 1.2556884340617969.
epoch: 1219, train loss: 1.2500075353394955, validation loss: 1.2866522747537363.
epoch: 1220, train loss: 1.2507126364139243, validation loss: 1.2804463065188865.
epoch: 1221, train loss: 1.2457636255736744, validation loss: 1.2739991727082625.
epoch: 1222, train loss: 1.2479979488827766, validation loss: 1.2650726411653601.
epoch: 1223, train loss: 1.2498774878475645, validation loss: 1.2711531804955525.
epoch: 1224, train loss: 1.2426640746790334, validation loss: 1.2798274548157402.
epoch: 1225, train loss: 1.2474543578034147, validation loss: 1.3035919303479402.
epoch: 1226, train loss: 1.248865383480667, validation loss: 1.3044082185496455.
epoch: 1227, train loss: 1.2467743070847397, validation loss: 1.2673574893370918.
epoch: 1228, train loss: 1.2458653548441896, validation loss: 1.2712650817373525.
epoch: 1229, train loss: 1.2480661081611564, validation loss: 1.2760168987771738.
epoch: 1230, train loss: 1.2505011077320904, validation loss: 1.2675484729849773.
epoch: 1231, train loss: 1.2511313475600077, validation loss: 1.2750390560730644.
epoch: 1232, train loss: 1.2498365181301712, validation loss: 1.266981021217678.
epoch: 1233, train loss: 1.2477521699502927, validation loss: 1.278037781300752.
epoch: 1234, train loss: 1.2520209780526816, validation loss: 1.2722403225691423.
epoch: 1235, train loss: 1.2496146608930114, validation loss: 1.2608002735220867.
epoch: 1236, train loss: 1.2478857565363612, validation loss: 1.2745097098143205.
epoch: 1237, train loss: 1.2468527271113266, validation loss: 1.2617428406425144.
epoch: 1238, train loss: 1.2417364754808058, validation loss: 1.2602419490399568.
epoch: 1239, train loss: 1.2479189284350893, validation loss: 1.2674368205277815.
epoch: 1240, train loss: 1.2473641907403228, validation loss: 1.2623756346495256.
epoch: 1241, train loss: 1.247257991668281, validation loss: 1.2825724197470623.
epoch: 1242, train loss: 1.24888992200204, validation loss: 1.259281039237976.
epoch: 1243, train loss: 1.2845826739564947, validation loss: 1.3053151628245478.
epoch: 1244, train loss: 1.2850948244059852, validation loss: 1.2928753002830173.
epoch: 1245, train loss: 1.2703811422400517, validation loss: 1.2851716124493142.
epoch: 1246, train loss: 1.263796038583878, validation loss: 1.2710830128711204.
epoch: 1247, train loss: 1.2594282102147374, validation loss: 1.2662201083224753.
epoch: 1248, train loss: 1.2564319120634586, validation loss: 1.273756452228712.
epoch: 1249, train loss: 1.2523813925751852, validation loss: 1.2625728586445684.
epoch: 1250, train loss: 1.253863742592138, validation loss: 1.2814640169558318.
epoch: 1251, train loss: 1.250053354359548, validation loss: 1.2724877284920735.
epoch: 1252, train loss: 1.2536092898167601, validation loss: 1.2655286685280178.
epoch: 1253, train loss: 1.2519560144581925, validation loss: 1.2764985716861228.
epoch: 1254, train loss: 1.2571520433513397, validation loss: 1.270778775215149.
epoch: 1255, train loss: 1.2548121913857417, validation loss: 1.2960188129673833.
epoch: 1256, train loss: 1.2526153468210763, validation loss: 1.256952368694803.
epoch: 1257, train loss: 1.2609037324922894, validation loss: 1.304154028063235.
epoch: 1258, train loss: 1.25572703956464, validation loss: 1.2839774307997331.
epoch: 1259, train loss: 1.2582199759439592, validation loss: 1.2750822253849194.
epoch: 1260, train loss: 1.254206852081719, validation loss: 1.2736879587173462.
epoch: 1261, train loss: 1.2488831751937166, validation loss: 1.2825785097868547.
epoch: 1262, train loss: 1.2499545626684065, validation loss: 1.2948339711064878.
epoch: 1263, train loss: 1.2570689971293878, validation loss: 1.268698381341022.
epoch: 1264, train loss: 1.2522202522382824, validation loss: 1.2687297592992368.
epoch: 1265, train loss: 1.2510876491529133, validation loss: 1.2641183293384055.
epoch: 1266, train loss: 1.249372636506317, validation loss: 1.2718060327612835.
epoch: 1267, train loss: 1.2525396434538956, validation loss: 1.2710002142450083.
epoch: 1268, train loss: 1.249882270436768, validation loss: 1.2847434023152227.
epoch: 1269, train loss: 1.2498130820213107, validation loss: 1.2859571861184163.
epoch: 1270, train loss: 1.2499951452290246, validation loss: 1.270001717235731.
epoch: 1271, train loss: 1.251305002684987, validation loss: 1.2803279316943625.
epoch: 1272, train loss: 1.2481819238137761, validation loss: 1.2712372904238494.
epoch: 1273, train loss: 1.2521557020484855, validation loss: 1.274445704791857.
epoch: 1274, train loss: 1.2534804901945482, validation loss: 1.2793805288231892.
epoch: 1275, train loss: 1.2552421158606852, validation loss: 1.2797370319781096.
epoch: 1276, train loss: 1.2520352317652572, validation loss: 1.2791644697603972.
epoch: 1277, train loss: 1.2494742093829934, validation loss: 1.2712480244429216.
epoch: 1278, train loss: 1.2472024860732052, validation loss: 1.264447922291963.
epoch: 1279, train loss: 1.252615509776894, validation loss: 1.2908434764198635.
epoch: 1280, train loss: 1.25268280834233, validation loss: 1.2618342741675999.
epoch: 1281, train loss: 1.2473013477587918, validation loss: 1.2650628556375918.
epoch: 1282, train loss: 1.248124312917027, validation loss: 1.2619118120359338.
epoch: 1283, train loss: 1.2509900298687295, validation loss: 1.2737376949061519.
epoch: 1284, train loss: 1.256313449745878, validation loss: 1.2627112191656362.
epoch: 1285, train loss: 1.253542153113479, validation loss: 1.279033925222314.
epoch: 1286, train loss: 1.2485935316173309, validation loss: 1.264109492301941.
epoch: 1287, train loss: 1.2491706019147821, validation loss: 1.2667441005292146.
epoch: 1288, train loss: 1.2481310575380238, validation loss: 1.2665668518646904.
epoch: 1289, train loss: 1.2512573944319278, validation loss: 1.2677015947258992.
epoch: 1290, train loss: 1.2478799962122507, validation loss: 1.2690883149271426.
epoch: 1291, train loss: 1.2509592629353934, validation loss: 1.2613307548605877.
epoch: 1292, train loss: 1.2483123847103994, validation loss: 1.2694332184998884.
epoch: 1293, train loss: 1.248161269984114, validation loss: 1.2644280972688093.
epoch: 1294, train loss: 1.2531571267941677, validation loss: 1.2769157316373743.
epoch: 1295, train loss: 1.249277331413479, validation loss: 1.2823247702225395.
epoch: 1296, train loss: 1.2556009041060001, validation loss: 1.264849947846454.
epoch: 1297, train loss: 1.2543437535609674, validation loss: 1.2793717643489009.
epoch: 1298, train loss: 1.254799279597921, validation loss: 1.282138466835022.
epoch: 1299, train loss: 1.2542639467694343, validation loss: 1.2757268470266592.
epoch: 1300, train loss: 1.2521586155672686, validation loss: 1.2934361177942026.
epoch: 1301, train loss: 1.2532106342665645, validation loss: 1.2742084575736004.
epoch: 1302, train loss: 1.250963568687439, validation loss: 1.2730418651000313.
epoch: 1303, train loss: 1.2567363211868006, validation loss: 1.2706008112948874.
epoch: 1304, train loss: 1.2532850755464047, validation loss: 1.2632600276366523.
epoch: 1305, train loss: 1.2524452996910165, validation loss: 1.2725541280663533.
epoch: 1306, train loss: 1.2523686798340683, validation loss: 1.2630238325699517.
epoch: 1307, train loss: 1.250112618875066, validation loss: 1.3031559042308642.
epoch: 1308, train loss: 1.250599419305084, validation loss: 1.2794051014858743.
epoch: 1309, train loss: 1.2544564818023543, validation loss: 1.2832958853763083.
epoch: 1310, train loss: 1.2495211581571386, validation loss: 1.2635531269985696.
epoch: 1311, train loss: 1.2564121506629733, validation loss: 1.2740676714026409.
epoch: 1312, train loss: 1.2534665361456914, validation loss: 1.3316903788110483.
epoch: 1313, train loss: 1.2578920300947416, validation loss: 1.2757138583971106.
epoch: 1314, train loss: 1.249436029600441, validation loss: 1.2762775939443838.
epoch: 1315, train loss: 1.2529850356075742, validation loss: 1.3025050577910051.
epoch: 1316, train loss: 1.2586378395010571, validation loss: 1.2822896190311597.
epoch: 1317, train loss: 1.256763779788936, validation loss: 1.2628967295522275.
epoch: 1318, train loss: 1.2551772769438017, validation loss: 1.2700024065764055.
epoch: 1319, train loss: 1.2506081850156872, validation loss: 1.307515076968981.
epoch: 1320, train loss: 1.250440429110046, validation loss: 1.270539226739303.
epoch: 1321, train loss: 1.2656759559561352, validation loss: 1.2738641811453777.
epoch: 1322, train loss: 1.2499499463160104, validation loss: 1.2673991918563843.
epoch: 1323, train loss: 1.2535121517443875, validation loss: 1.281898477803106.
epoch: 1324, train loss: 1.257122600844147, validation loss: 1.2700568644896797.
epoch: 1325, train loss: 1.2557098613966495, validation loss: 1.2656749746073848.
epoch: 1326, train loss: 1.2579923518207095, validation loss: 1.3329479953517085.
epoch: 1327, train loss: 1.2812612614500414, validation loss: 1.2959184750266697.
epoch: 1328, train loss: 1.2679720340518776, validation loss: 1.2825377402098284.
epoch: 1329, train loss: 1.2599112265700594, validation loss: 1.2786232906839121.
epoch: 1330, train loss: 1.2564246490461017, validation loss: 1.2818282013354094.
epoch: 1331, train loss: 1.251268538860006, validation loss: 1.2719617460084998.
epoch: 1332, train loss: 1.2479256336842108, validation loss: 1.2622293337531711.
epoch: 1333, train loss: 1.2528325122430783, validation loss: 1.2676872118659641.
epoch: 1334, train loss: 1.2504094281327833, validation loss: 1.2764106159624846.
epoch: 1335, train loss: 1.2512102925449335, validation loss: 1.2668409192043801.
epoch: 1336, train loss: 1.2510765758129434, validation loss: 1.2720931561096855.
epoch: 1337, train loss: 1.2558581588465139, validation loss: 1.3015593342159106.
epoch: 1338, train loss: 1.251792337916313, validation loss: 1.2609914230263752.
epoch: 1339, train loss: 1.2641556711371886, validation loss: 1.3262465518453848.
epoch: 1340, train loss: 1.2710551176596125, validation loss: 1.2807986269826475.
epoch: 1341, train loss: 1.2570406832826246, validation loss: 1.2636529103569363.
epoch: 1342, train loss: 1.2479787791540864, validation loss: 1.2714467463286028.
epoch: 1343, train loss: 1.2493368463778713, validation loss: 1.2686767733615378.
epoch: 1344, train loss: 1.250772306678492, validation loss: 1.2754967938298765.
epoch: 1345, train loss: 1.2526917457580566, validation loss: 1.2965110540390015.
epoch: 1346, train loss: 1.2519930633929892, validation loss: 1.2746799562288367.
epoch: 1347, train loss: 1.2473852579746771, validation loss: 1.272271399912627.
epoch: 1348, train loss: 1.2494358108677994, validation loss: 1.2802629574485447.
epoch: 1349, train loss: 1.2522714148967637, validation loss: 1.2713714216066443.
epoch: 1350, train loss: 1.2562240810569274, validation loss: 1.2677702800087307.
epoch: 1351, train loss: 1.2486074287957007, validation loss: 1.2769698111907295.
epoch: 1352, train loss: 1.2485106374145647, validation loss: 1.267965327138486.
epoch: 1353, train loss: 1.245400778744199, validation loss: 1.2680736572846123.
epoch: 1354, train loss: 1.2491146063585894, validation loss: 1.2746341643126116.
epoch: 1355, train loss: 1.2557025611947437, validation loss: 1.299433329830999.
epoch: 1356, train loss: 1.2578763075924795, validation loss: 1.2871028547701628.
epoch: 1357, train loss: 1.2513333591846152, validation loss: 1.2741716322691545.
epoch: 1358, train loss: 1.2526719963878667, validation loss: 1.2970994140790857.
epoch: 1359, train loss: 1.2519811402767076, validation loss: 1.2745210657949033.
epoch: 1360, train loss: 1.2512108251589154, validation loss: 1.3093309246975442.
epoch: 1361, train loss: 1.2488298000545677, validation loss: 1.2643139828806338.
epoch: 1362, train loss: 1.2483054301060668, validation loss: 1.2807802687520566.
epoch: 1363, train loss: 1.2533797736561627, validation loss: 1.2790703307027402.
epoch: 1364, train loss: 1.2523731802581648, validation loss: 1.2629496221957.
epoch: 1365, train loss: 1.2573854004571197, validation loss: 1.3933119203733362.
epoch: 1366, train loss: 1.2599403825374917, validation loss: 1.2709572470706443.
epoch: 1367, train loss: 1.253835312817075, validation loss: 1.2857282317203025.
epoch: 1368, train loss: 1.2473343359221012, validation loss: 1.2615860856097678.
epoch: 1369, train loss: 1.2454605649370667, validation loss: 1.2785805049149885.
epoch: 1370, train loss: 1.252255070100137, validation loss: 1.2700285600579304.
epoch: 1371, train loss: 1.2539345397861725, validation loss: 1.2663986786552097.
epoch: 1372, train loss: 1.2584279392837385, validation loss: 1.2775375687557717.
epoch: 1373, train loss: 1.254521046209773, validation loss: 1.267908355464106.
epoch: 1374, train loss: 1.2511965058265475, validation loss: 1.2754210855649866.
epoch: 1375, train loss: 1.2488859618475678, validation loss: 1.2612362478090369.
epoch: 1376, train loss: 1.2487328829021629, validation loss: 1.2673921844233638.
epoch: 1377, train loss: 1.2496786576892258, validation loss: 1.2593923755314038.
epoch: 1378, train loss: 1.2497822921210473, validation loss: 1.2679436776949011.
epoch: 1379, train loss: 1.2498549824460932, validation loss: 1.2943793379742166.
epoch: 1380, train loss: 1.2495458355737388, validation loss: 1.2785551237023396.
epoch: 1381, train loss: 1.279608647757714, validation loss: 1.2925662838894387.
epoch: 1382, train loss: 1.2637099246366308, validation loss: 1.2723198455312978.
epoch: 1383, train loss: 1.2598598025260714, validation loss: 1.2832143876863562.
epoch: 1384, train loss: 1.2605240837149663, validation loss: 1.2757619982180388.
epoch: 1385, train loss: 1.2527168770448878, validation loss: 1.2657002469767695.
epoch: 1386, train loss: 1.252525500201304, validation loss: 1.2989186100337817.
epoch: 1387, train loss: 1.2546455925757731, validation loss: 1.2681202111036882.
epoch: 1388, train loss: 1.2497713445523464, validation loss: 1.28111834111421.
epoch: 1389, train loss: 1.2526951864225055, validation loss: 1.2602300436600395.
epoch: 1390, train loss: 1.249563401992168, validation loss: 1.2598273339478865.
epoch: 1391, train loss: 1.245296349219226, validation loss: 1.2764358520507812.
epoch: 1392, train loss: 1.2482282120153445, validation loss: 1.2719305598217507.
epoch: 1393, train loss: 1.2485852416502226, validation loss: 1.2793527064116106.
epoch: 1394, train loss: 1.2478517709522072, validation loss: 1.269839012104532.
epoch: 1395, train loss: 1.2479844312055395, validation loss: 1.2856088721233865.
epoch: 1396, train loss: 1.2474370604261347, validation loss: 1.2597923745279727.
epoch: 1397, train loss: 1.249243636743738, validation loss: 1.2552475514619246.
epoch: 1398, train loss: 1.2492633347117572, validation loss: 1.265793800354004.
epoch: 1399, train loss: 1.2522530074513287, validation loss: 1.2699097446773364.
epoch: 1400, train loss: 1.2550549725873754, validation loss: 1.2727707157964292.
epoch: 1401, train loss: 1.2549199718947803, validation loss: 1.2672279917675515.
epoch: 1402, train loss: 1.251617151662844, validation loss: 1.2769372929697451.
epoch: 1403, train loss: 1.2503122616251674, validation loss: 1.2851742868838103.
epoch: 1404, train loss: 1.2510854093306656, validation loss: 1.2647889178732168.
epoch: 1405, train loss: 1.2588293093060134, validation loss: 1.264559092728988.
epoch: 1406, train loss: 1.2493879948187312, validation loss: 1.2766937535742056.
epoch: 1407, train loss: 1.247409124986841, validation loss: 1.2644447658372961.
epoch: 1408, train loss: 1.2487747603600179, validation loss: 1.2623336626135784.
epoch: 1409, train loss: 1.2458371416144414, validation loss: 1.3113484175308892.
epoch: 1410, train loss: 1.2506924178622185, validation loss: 1.3006237278813901.
epoch: 1411, train loss: 1.2514773749430246, validation loss: 1.3064926499905793.
epoch: 1412, train loss: 1.2675045280281556, validation loss: 1.3502150877662327.
epoch: 1413, train loss: 1.2836062066051939, validation loss: 1.2827865610951963.
epoch: 1414, train loss: 1.260071155128129, validation loss: 1.2749377229939336.
epoch: 1415, train loss: 1.2590455648002274, validation loss: 1.2749906104543935.
epoch: 1416, train loss: 1.2535000995758476, validation loss: 1.3059173044951067.
epoch: 1417, train loss: 1.2507054685452663, validation loss: 1.263656937557718.
epoch: 1418, train loss: 1.2498343242417782, validation loss: 1.2736114730005679.
epoch: 1419, train loss: 1.248085147743925, validation loss: 1.2628561154655789.
epoch: 1420, train loss: 1.2481252994012395, validation loss: 1.2676515268242878.
epoch: 1421, train loss: 1.2486606158247782, validation loss: 1.2641883466554724.
epoch: 1422, train loss: 1.2521131366764733, validation loss: 1.2746381863303806.
epoch: 1423, train loss: 1.2537791663353597, validation loss: 1.2634925116663394.
epoch: 1424, train loss: 1.2491882984791327, validation loss: 1.275109923404196.
epoch: 1425, train loss: 1.254153256022602, validation loss: 1.2949759908344434.
epoch: 1426, train loss: 1.2537972675550968, validation loss: 1.2897766984027366.
epoch: 1427, train loss: 1.2534584233520227, validation loss: 1.271934493728306.
epoch: 1428, train loss: 1.2554849244038992, validation loss: 1.2622463236684385.
epoch: 1429, train loss: 1.2519634240264192, validation loss: 1.2816535182621167.
epoch: 1430, train loss: 1.2542375227726927, validation loss: 1.2682027868602588.
epoch: 1431, train loss: 1.2512961265143998, validation loss: 1.2717060006183127.
epoch: 1432, train loss: 1.2521926448979508, validation loss: 1.2747212907542353.
epoch: 1433, train loss: 1.2467042251464424, validation loss: 1.2617527920266856.
epoch: 1434, train loss: 1.249526731464841, validation loss: 1.2853774350622427.
epoch: 1435, train loss: 1.2537292909184727, validation loss: 1.2647117583648018.
epoch: 1436, train loss: 1.256748942060208, validation loss: 1.272141000498896.
epoch: 1437, train loss: 1.2538202137028405, validation loss: 1.2750896785570227.
epoch: 1438, train loss: 1.2506252494427041, validation loss: 1.2717931426089744.
epoch: 1439, train loss: 1.2532908993029812, validation loss: 1.280564168225164.
epoch: 1440, train loss: 1.251113179626815, validation loss: 1.2781003713607788.
epoch: 1441, train loss: 1.2467252191053617, validation loss: 1.2705219724903936.
epoch: 1442, train loss: 1.2495807879561678, validation loss: 1.284428207770638.
epoch: 1443, train loss: 1.2498174194895892, validation loss: 1.273377688034721.
epoch: 1444, train loss: 1.2505168575759327, validation loss: 1.2971390693084053.
epoch: 1445, train loss: 1.2486520644721635, validation loss: 1.281761029492254.
epoch: 1446, train loss: 1.2537079393316846, validation loss: 1.279298870459847.
epoch: 1447, train loss: 1.2528765070329018, validation loss: 1.2647796817447827.
epoch: 1448, train loss: 1.247937624607611, validation loss: 1.27261934073075.
epoch: 1449, train loss: 1.247844839314802, validation loss: 1.261790571005448.
epoch: 1450, train loss: 1.2509792518178258, validation loss: 1.293549506560616.
epoch: 1451, train loss: 1.2570442453436894, validation loss: 1.2948245639386384.
epoch: 1452, train loss: 1.2640438047024087, validation loss: 1.2771325681520544.
epoch: 1453, train loss: 1.25684043573677, validation loss: 1.2830103843108467.
epoch: 1454, train loss: 1.2521842280659108, validation loss: 1.2758728162102078.
epoch: 1455, train loss: 1.2526511216382368, validation loss: 1.2681392845900163.
epoch: 1456, train loss: 1.2468548914708129, validation loss: 1.2876382858856865.
epoch: 1457, train loss: 1.2492401851426571, validation loss: 1.2808630155480427.
epoch: 1458, train loss: 1.2497257191106814, validation loss: 1.2945811800334766.
epoch: 1459, train loss: 1.2527857242374245, validation loss: 1.2620264758234438.
epoch: 1460, train loss: 1.2513727299664, validation loss: 1.266879651857459.
epoch: 1461, train loss: 1.251341457760662, validation loss: 1.2650207954904307.
epoch: 1462, train loss: 1.274427489403191, validation loss: 1.2788353380949602.
epoch: 1463, train loss: 1.2597164046873741, validation loss: 1.2738075308177783.
epoch: 1464, train loss: 1.2616504004242224, validation loss: 1.2650165557861328.
epoch: 1465, train loss: 1.2532288196983687, validation loss: 1.2721525793490203.
epoch: 1466, train loss: 1.2472378387363678, validation loss: 1.2650885685630466.
epoch: 1467, train loss: 1.2507913714155146, validation loss: 1.2754097088523533.
epoch: 1468, train loss: 1.2481109067934368, validation loss: 1.2604492643605107.
epoch: 1469, train loss: 1.2471486187856131, validation loss: 1.2733481915100762.
epoch: 1470, train loss: 1.2486856628995422, validation loss: 1.2660711122595745.
epoch: 1471, train loss: 1.2464643005931049, validation loss: 1.2730109587959622.
epoch: 1472, train loss: 1.250464472201986, validation loss: 1.267432311306829.
epoch: 1473, train loss: 1.2465922559073213, validation loss: 1.2627024080442346.
epoch: 1474, train loss: 1.245680126575155, validation loss: 1.2852585056553716.
epoch: 1475, train loss: 1.2470395871258657, validation loss: 1.2628551358761995.
epoch: 1476, train loss: 1.2478060984830244, validation loss: 1.2637965679168701.
epoch: 1477, train loss: 1.2451376335336528, validation loss: 1.2743665653726328.
epoch: 1478, train loss: 1.2467841741141923, validation loss: 1.2663075094637664.
epoch: 1479, train loss: 1.24806832611014, validation loss: 1.2605144303777944.
epoch: 1480, train loss: 1.252227281211713, validation loss: 1.2604421066201252.
epoch: 1481, train loss: 1.2484056501213563, validation loss: 1.2747463091560032.
epoch: 1482, train loss: 1.2487155745882508, validation loss: 1.2607309766437695.
epoch: 1483, train loss: 1.245850746784735, validation loss: 1.2669714533764382.
epoch: 1484, train loss: 1.249737780028527, validation loss: 1.2615893560907114.
epoch: 1485, train loss: 1.257408286453387, validation loss: 1.2748415055482283.
epoch: 1486, train loss: 1.2507555583201417, validation loss: 1.2683785428171572.
epoch: 1487, train loss: 1.2509038404587212, validation loss: 1.2630758337352588.
epoch: 1488, train loss: 1.2464208624778537, validation loss: 1.2587338737819507.
epoch: 1489, train loss: 1.2495055318972386, validation loss: 1.2508404410403708.
epoch: 1490, train loss: 1.2497948517493151, validation loss: 1.2929683871891187.
epoch: 1491, train loss: 1.2502623118391825, validation loss: 1.2855091976082844.
epoch: 1492, train loss: 1.2535583808881428, validation loss: 1.270721637684366.
epoch: 1493, train loss: 1.2500224747789015, validation loss: 1.2629023375718489.
epoch: 1494, train loss: 1.2475571358969453, validation loss: 1.265399404194044.
epoch: 1495, train loss: 1.2483162387795406, validation loss: 1.2780379419741423.
epoch: 1496, train loss: 1.2462509575240108, validation loss: 1.2707659731740537.
epoch: 1497, train loss: 1.2467040600032981, validation loss: 1.2667861243952876.
epoch: 1498, train loss: 1.2470378066421648, validation loss: 1.2562895080317622.
epoch: 1499, train loss: 1.2542143830465615, validation loss: 1.277709027995234.
epoch: 1500, train loss: 1.2539730957888682, validation loss: 1.2774495249209197.
epoch: 1501, train loss: 1.248401192350125, validation loss: 1.2803079356317935.
epoch: 1502, train loss: 1.250315213422163, validation loss: 1.2709368830141814.
epoch: 1503, train loss: 1.2555848524111126, validation loss: 1.2758368875669397.
epoch: 1504, train loss: 1.2550093198041303, validation loss: 1.2617516102998152.
epoch: 1505, train loss: 1.2469075130760123, validation loss: 1.2831434115119602.
epoch: 1506, train loss: 1.2511140447144116, validation loss: 1.2602545904076619.
epoch: 1507, train loss: 1.2537115877921428, validation loss: 1.2935186313546223.
epoch: 1508, train loss: 1.2706321423206854, validation loss: 1.2824914973715078.
epoch: 1509, train loss: 1.251247056033633, validation loss: 1.2651807380759197.
epoch: 1510, train loss: 1.250351763646537, validation loss: 1.270436141801917.
epoch: 1511, train loss: 1.2500142755858394, validation loss: 1.270092627276545.
epoch: 1512, train loss: 1.2505491829793387, validation loss: 1.3060469990191252.
epoch: 1513, train loss: 1.255600421800526, validation loss: 1.2781376942344334.
epoch: 1514, train loss: 1.2481330108205113, validation loss: 1.2729599527690723.
epoch: 1515, train loss: 1.2456182044580442, validation loss: 1.2611704339151797.
epoch: 1516, train loss: 1.2484809728937412, validation loss: 1.2844495358674421.
epoch: 1517, train loss: 1.253743365270282, validation loss: 1.2875140335248865.
epoch: 1518, train loss: 1.2480758614496354, validation loss: 1.2733444234599238.
epoch: 1519, train loss: 1.2495372262569742, validation loss: 1.2744289325631184.
epoch: 1520, train loss: 1.2444975244889565, validation loss: 1.2700976392497187.
epoch: 1521, train loss: 1.2525321934201301, validation loss: 1.2675876824752144.
epoch: 1522, train loss: 1.2458954316760422, validation loss: 1.2776550883832185.
epoch: 1523, train loss: 1.2459361378206026, validation loss: 1.256808244663736.
epoch: 1524, train loss: 1.2476930213630746, validation loss: 1.2629273352415666.
epoch: 1525, train loss: 1.2461409218814394, validation loss: 1.267638061357581.
epoch: 1526, train loss: 1.2471429372052534, validation loss: 1.2668727584507153.
epoch: 1527, train loss: 1.246608346974084, validation loss: 1.2638296407202017.
epoch: 1528, train loss: 1.2459269018348205, validation loss: 1.2692938524743784.
epoch: 1529, train loss: 1.2470432640215672, validation loss: 1.2755876313085142.
epoch: 1530, train loss: 1.2496199935948082, validation loss: 1.2728706546451733.
epoch: 1531, train loss: 1.2490739286492725, validation loss: 1.2651382477387139.
epoch: 1532, train loss: 1.2443293092447683, validation loss: 1.269148878429247.
epoch: 1533, train loss: 1.2473113274355547, validation loss: 1.2671249586602915.
epoch: 1534, train loss: 1.2474867794491828, validation loss: 1.27136622822803.
epoch: 1535, train loss: 1.2478941832113704, validation loss: 1.3085500001907349.
epoch: 1536, train loss: 1.2463382679388064, validation loss: 1.2652345843937085.
epoch: 1537, train loss: 1.2584306723480925, validation loss: 1.2740258704061094.
epoch: 1538, train loss: 1.257688732322203, validation loss: 1.2697599452474844.
epoch: 1539, train loss: 1.2502935927942258, validation loss: 1.2833623834278272.
epoch: 1540, train loss: 1.2479224248763618, validation loss: 1.257754289585611.
epoch: 1541, train loss: 1.24765183291304, validation loss: 1.2697724725889123.
epoch: 1542, train loss: 1.2480458578932176, validation loss: 1.2752314339513364.
epoch: 1543, train loss: 1.246503403427404, validation loss: 1.2612074250760286.
epoch: 1544, train loss: 1.2465634674107262, validation loss: 1.264578041823014.
epoch: 1545, train loss: 1.24631687260549, validation loss: 1.2648015022277832.
epoch: 1546, train loss: 1.2468077775535233, validation loss: 1.2647702382958455.
epoch: 1547, train loss: 1.2468323062319275, validation loss: 1.2659475440564363.
epoch: 1548, train loss: 1.2475220249333512, validation loss: 1.2787702135417773.
epoch: 1549, train loss: 1.2466944663896473, validation loss: 1.2644507781318997.
epoch: 1550, train loss: 1.2476773994778274, validation loss: 1.2726489046345586.
epoch: 1551, train loss: 1.2516095802324627, validation loss: 1.2673020725664885.
epoch: 1552, train loss: 1.2610823911264402, validation loss: 1.3014665116434512.
epoch: 1553, train loss: 1.2512890614500833, validation loss: 1.2976611438004866.
epoch: 1554, train loss: 1.252121846610253, validation loss: 1.2654339956200642.
epoch: 1555, train loss: 1.250765668142826, validation loss: 1.260456199231355.
epoch: 1556, train loss: 1.245815137110719, validation loss: 1.2712611789288728.
epoch: 1557, train loss: 1.2487539818527502, validation loss: 1.268274037734322.
epoch: 1558, train loss: 1.2458817827592201, validation loss: 1.263007412786069.
epoch: 1559, train loss: 1.2567150888093022, validation loss: 1.28118722335152.
epoch: 1560, train loss: 1.2506885692613934, validation loss: 1.2651217035625293.
epoch: 1561, train loss: 1.249130420728561, validation loss: 1.2649708364320837.
epoch: 1562, train loss: 1.2464608402427184, validation loss: 1.265568453332652.
epoch: 1563, train loss: 1.245437461301821, validation loss: 1.2579194462817649.
epoch: 1564, train loss: 1.2515675595047278, validation loss: 1.2675618555234827.
epoch: 1565, train loss: 1.2557899459786372, validation loss: 1.2650344371795654.
epoch: 1566, train loss: 1.2494650958874904, validation loss: 1.2602810600529546.
epoch: 1567, train loss: 1.2467650251651028, validation loss: 1.2655755385108616.
epoch: 1568, train loss: 1.247505017376821, validation loss: 1.2681752235993096.
epoch: 1569, train loss: 1.2475400835002235, validation loss: 1.2650885478309963.
epoch: 1570, train loss: 1.2516837809063972, validation loss: 1.283911160800768.
epoch: 1571, train loss: 1.2498387120185641, validation loss: 1.277136610901874.
epoch: 1572, train loss: 1.247333335220267, validation loss: 1.2677138940147732.
epoch: 1573, train loss: 1.2544829954794787, validation loss: 1.2706097157105156.
epoch: 1574, train loss: 1.2467095348813118, validation loss: 1.2707003458686497.
epoch: 1575, train loss: 1.2486738316509702, validation loss: 1.266004795613496.
epoch: 1576, train loss: 1.2481959489507413, validation loss: 1.2617021643597146.
epoch: 1577, train loss: 1.2478673381542942, validation loss: 1.2595997323160586.
epoch: 1578, train loss: 1.2428758953689436, validation loss: 1.2659033640571262.
epoch: 1579, train loss: 1.249428740335167, validation loss: 1.264049566310385.
epoch: 1580, train loss: 1.2474518762815983, validation loss: 1.284738514734351.
epoch: 1581, train loss: 1.2476407956639561, validation loss: 1.2527180391809214.
epoch: 1582, train loss: 1.244812889930305, validation loss: 1.2748196798822153.
epoch: 1583, train loss: 1.2476801150435701, validation loss: 1.2710241390311199.
epoch: 1584, train loss: 1.247486467755169, validation loss: 1.2689839446026345.
epoch: 1585, train loss: 1.2467157228277364, validation loss: 1.2603557835454526.
epoch: 1586, train loss: 1.2466824907775318, validation loss: 1.2792801286863245.
epoch: 1587, train loss: 1.2508519592635128, validation loss: 1.2645121709160183.
epoch: 1588, train loss: 1.2464257194361557, validation loss: 1.2757212493730627.
epoch: 1589, train loss: 1.2511288233853262, validation loss: 1.2753548259320466.
epoch: 1590, train loss: 1.2462019296961093, validation loss: 1.2742726854656055.
epoch: 1591, train loss: 1.2454626888310143, validation loss: 1.270381880843121.
epoch: 1592, train loss: 1.2510810062425946, validation loss: 1.2870024857313738.
epoch: 1593, train loss: 1.251240066432078, validation loss: 1.2589137346848198.
epoch: 1594, train loss: 1.250625015398778, validation loss: 1.2647855385490085.
epoch: 1595, train loss: 1.2493509032310697, validation loss: 1.2755358115486477.
epoch: 1596, train loss: 1.2474403107931855, validation loss: 1.2905385908873186.
epoch: 1597, train loss: 1.2435429194651613, validation loss: 1.2827731370925903.
epoch: 1598, train loss: 1.246571733317244, validation loss: 1.2698316677756931.
epoch: 1599, train loss: 1.248256787247614, validation loss: 1.2972401069558186.
epoch: 1600, train loss: 1.255280117376135, validation loss: 1.265917912773464.
epoch: 1601, train loss: 1.2472438670079642, validation loss: 1.2665016443833061.
epoch: 1602, train loss: 1.2517890580203554, validation loss: 1.281094131262406.
epoch: 1603, train loss: 1.2512554116205339, validation loss: 1.284904340039129.
epoch: 1604, train loss: 1.2510782895831887, validation loss: 1.264011414154716.
epoch: 1605, train loss: 1.250735658024429, validation loss: 1.2552012516104656.
epoch: 1606, train loss: 1.2510916618032193, validation loss: 1.2833393086557803.
epoch: 1607, train loss: 1.2531905841389928, validation loss: 1.276388178700986.
epoch: 1608, train loss: 1.2470434663492604, validation loss: 1.2922025193338809.
epoch: 1609, train loss: 1.24695568019097, validation loss: 1.259483031604601.
epoch: 1610, train loss: 1.2457831988640882, validation loss: 1.2802867422933164.
epoch: 1611, train loss: 1.251811389529377, validation loss: 1.2755281147749529.
epoch: 1612, train loss: 1.246813368359837, validation loss: 1.2670481775117957.
epoch: 1613, train loss: 1.2493041360050166, validation loss: 1.2542902956838193.
epoch: 1614, train loss: 1.2480523531590033, validation loss: 1.2583238456560217.
epoch: 1615, train loss: 1.2451306548687295, validation loss: 1.2760481523430867.
epoch: 1616, train loss: 1.2531102491081307, validation loss: 1.259563430495884.
epoch: 1617, train loss: 1.2459784002479064, validation loss: 1.262070946071459.
epoch: 1618, train loss: 1.2481913686892308, validation loss: 1.2680656443471494.
epoch: 1619, train loss: 1.2467732385757866, validation loss: 1.2668250229047693.
epoch: 1620, train loss: 1.2505004843440624, validation loss: 1.2637812883957573.
epoch: 1621, train loss: 1.2485406180040552, validation loss: 1.2733857061551965.
epoch: 1622, train loss: 1.2499415130790221, validation loss: 1.283981416536414.
epoch: 1623, train loss: 1.249045428879764, validation loss: 1.2703668190085369.
epoch: 1624, train loss: 1.2465788421280888, validation loss: 1.2612363929333894.
epoch: 1625, train loss: 1.252265399749126, validation loss: 1.2669386552727742.
epoch: 1626, train loss: 1.2476640053845327, validation loss: 1.264377728752468.
epoch: 1627, train loss: 1.249171590586321, validation loss: 1.3470255654791128.
epoch: 1628, train loss: 1.2694437711610707, validation loss: 1.2721875335859216.
epoch: 1629, train loss: 1.2558884937828834, validation loss: 1.2722273339395938.
epoch: 1630, train loss: 1.255613029549975, validation loss: 1.3057182664456575.
epoch: 1631, train loss: 1.258546713295333, validation loss: 1.2643424946328867.
epoch: 1632, train loss: 1.247381303288521, validation loss: 1.255214530488719.
epoch: 1633, train loss: 1.24629692200127, validation loss: 1.2697194400040999.
epoch: 1634, train loss: 1.2449956651127667, validation loss: 1.2886525081551594.
epoch: 1635, train loss: 1.2451026833385503, validation loss: 1.2626018316849419.
epoch: 1636, train loss: 1.2505508475347396, validation loss: 1.2605402365974758.
epoch: 1637, train loss: 1.2476526542541084, validation loss: 1.2545929369719133.
epoch: 1638, train loss: 1.2491478362214674, validation loss: 1.2716130951176519.
epoch: 1639, train loss: 1.2478227298194116, validation loss: 1.2585954717967822.
epoch: 1640, train loss: 1.2558450884775285, validation loss: 1.2635647110317065.
epoch: 1641, train loss: 1.249023183770136, validation loss: 1.265309857285541.
epoch: 1642, train loss: 1.2484753219359512, validation loss: 1.2550736717555835.
epoch: 1643, train loss: 1.2496777083895623, validation loss: 1.2903887085292651.
epoch: 1644, train loss: 1.2451857022189219, validation loss: 1.2646437468736067.
epoch: 1645, train loss: 1.2443891665257445, validation loss: 1.2685604302779487.
epoch: 1646, train loss: 1.2494135121686742, validation loss: 1.2691575962564219.
epoch: 1647, train loss: 1.2475278268166639, validation loss: 1.2704798501470815.
epoch: 1648, train loss: 1.25972788596372, validation loss: 1.3358363897904106.
epoch: 1649, train loss: 1.2505877389820343, validation loss: 1.2748929469481758.
epoch: 1650, train loss: 1.2490651224731306, validation loss: 1.2663216642711475.
epoch: 1651, train loss: 1.2474868450689753, validation loss: 1.2563033933224885.
epoch: 1652, train loss: 1.2504834221043717, validation loss: 1.277425081833549.
epoch: 1653, train loss: 1.2499352562318153, validation loss: 1.254472810289134.
epoch: 1654, train loss: 1.2433665936146308, validation loss: 1.2638675389082537.
epoch: 1655, train loss: 1.2464258408327715, validation loss: 1.2716496198073677.
epoch: 1656, train loss: 1.2491769232881178, validation loss: 1.2608328487562097.
epoch: 1657, train loss: 1.2586437343457424, validation loss: 1.2794649186341658.
epoch: 1658, train loss: 1.2514268291105919, validation loss: 1.2633234106976052.
epoch: 1659, train loss: 1.2462231489496494, validation loss: 1.263964875884678.
epoch: 1660, train loss: 1.2460737600239045, validation loss: 1.3300253515658171.
epoch: 1661, train loss: 1.2477329433511157, validation loss: 1.2700391230375871.
epoch: 1662, train loss: 1.2445190215329511, validation loss: 1.2651167123214058.
epoch: 1663, train loss: 1.2500884871964062, validation loss: 1.2645469489304915.
epoch: 1664, train loss: 1.251846723600265, validation loss: 1.265360977338708.
epoch: 1665, train loss: 1.2506478510865378, validation loss: 1.2685161258863367.
epoch: 1666, train loss: 1.2494235738701778, validation loss: 1.272736844809159.
epoch: 1667, train loss: 1.2486781319346996, validation loss: 1.2627741927685945.
epoch: 1668, train loss: 1.2470849653996459, validation loss: 1.2674730757008428.
epoch: 1669, train loss: 1.245247440600614, validation loss: 1.271878304688827.
epoch: 1670, train loss: 1.264902480151675, validation loss: 1.283786996551182.
epoch: 1671, train loss: 1.2590610926304389, validation loss: 1.277660820795142.
epoch: 1672, train loss: 1.2509581124016997, validation loss: 1.2714373339777407.
epoch: 1673, train loss: 1.2519689142157178, validation loss: 1.268801186395728.
epoch: 1674, train loss: 1.2484193121621368, validation loss: 1.2536717342293782.
epoch: 1675, train loss: 1.2487094894461674, validation loss: 1.2651203145151553.
epoch: 1676, train loss: 1.252312892073885, validation loss: 1.3265747713006062.
epoch: 1677, train loss: 1.2671145922547087, validation loss: 1.3025894009548684.
epoch: 1678, train loss: 1.2584843230903695, validation loss: 1.2835086480430935.
epoch: 1679, train loss: 1.2514677375828454, validation loss: 1.2662862798442012.
epoch: 1680, train loss: 1.2573328510336919, validation loss: 1.2712981389916462.
epoch: 1681, train loss: 1.251168373527877, validation loss: 1.2724898587102476.
epoch: 1682, train loss: 1.2468508788205068, validation loss: 1.305596771447555.
epoch: 1683, train loss: 1.248381214404325, validation loss: 1.2737805014071257.
epoch: 1684, train loss: 1.2456992536509803, validation loss: 1.260552344114884.
epoch: 1685, train loss: 1.246125366709648, validation loss: 1.2659502081249072.
epoch: 1686, train loss: 1.2470683690604814, validation loss: 1.3074155320291934.
epoch: 1687, train loss: 1.2534315629836617, validation loss: 1.267790524855904.
epoch: 1688, train loss: 1.2463975160493763, validation loss: 1.2693350263263867.
epoch: 1689, train loss: 1.2453360470063095, validation loss: 1.2728028712065325.
epoch: 1690, train loss: 1.2445755617334209, validation loss: 1.2767562555230183.
epoch: 1691, train loss: 1.24881279687269, validation loss: 1.2603286815726238.
epoch: 1692, train loss: 1.2474999755894371, validation loss: 1.261124382848325.
epoch: 1693, train loss: 1.2443954846180907, validation loss: 1.260293063910111.
epoch: 1694, train loss: 1.2445456959785672, validation loss: 1.2640049613040427.
epoch: 1695, train loss: 1.2455939951292965, validation loss: 1.2604577541351318.
epoch: 1696, train loss: 1.242585237966765, validation loss: 1.260606102321459.
epoch: 1697, train loss: 1.2459632366075428, validation loss: 1.270371955374013.
epoch: 1698, train loss: 1.2507025408088615, validation loss: 1.2994934113129326.
epoch: 1699, train loss: 1.2472890888879058, validation loss: 1.2708992284277212.
epoch: 1700, train loss: 1.2472500833896323, validation loss: 1.284830243691154.
epoch: 1701, train loss: 1.247725009918213, validation loss: 1.258740326632624.
epoch: 1702, train loss: 1.2437915091120868, validation loss: 1.269551132036292.
epoch: 1703, train loss: 1.2514967546550506, validation loss: 1.2659922371739927.
epoch: 1704, train loss: 1.2457809131079858, validation loss: 1.2714887598286504.
epoch: 1705, train loss: 1.2482024540594958, validation loss: 1.2648296200710794.
epoch: 1706, train loss: 1.247158048349783, validation loss: 1.291367489358653.
epoch: 1707, train loss: 1.2514158268587305, validation loss: 1.2606388745100603.
epoch: 1708, train loss: 1.2468188607364619, validation loss: 1.2563776451608408.
epoch: 1709, train loss: 1.250040683177633, validation loss: 1.2982202561005303.
epoch: 1710, train loss: 1.2439905580030668, validation loss: 1.2661849363990452.
epoch: 1711, train loss: 1.2452357493409323, validation loss: 1.282768778179003.
epoch: 1712, train loss: 1.2458743524113927, validation loss: 1.2808828405711963.
epoch: 1713, train loss: 1.248861853135835, validation loss: 1.2837898679401563.
epoch: 1714, train loss: 1.2514757038256443, validation loss: 1.268653543099113.
epoch: 1715, train loss: 1.2586362547830705, validation loss: 1.2695237501807835.
epoch: 1716, train loss: 1.2494716556794052, validation loss: 1.2789616895758587.
epoch: 1717, train loss: 1.246186829488212, validation loss: 1.2701988634855852.
epoch: 1718, train loss: 1.2493266260952032, validation loss: 1.2664101693941199.
epoch: 1719, train loss: 1.2453187179127965, validation loss: 1.2636945040329643.
epoch: 1720, train loss: 1.250692320526193, validation loss: 1.2851481800493987.
epoch: 1721, train loss: 1.2460134116881485, validation loss: 1.2635435798893804.
epoch: 1722, train loss: 1.2441987608550886, validation loss: 1.265943423561428.
epoch: 1723, train loss: 1.2462841556706559, validation loss: 1.2773167827854985.
epoch: 1724, train loss: 1.2485832883677352, validation loss: 1.2726431670396223.
epoch: 1725, train loss: 1.2478673162810299, validation loss: 1.2651203974433567.
epoch: 1726, train loss: 1.2484846651007275, validation loss: 1.2726941108703613.
epoch: 1727, train loss: 1.2528172720462905, validation loss: 1.275141902591871.
epoch: 1728, train loss: 1.2504884901396724, validation loss: 1.2691035063370415.
epoch: 1729, train loss: 1.2500846889040886, validation loss: 1.2783013945040496.
epoch: 1730, train loss: 1.2538641472475245, validation loss: 1.2712269762287969.
epoch: 1731, train loss: 1.252100881086577, validation loss: 1.2623517772425776.
epoch: 1732, train loss: 1.2533656227479286, validation loss: 1.2900304794311523.
epoch: 1733, train loss: 1.249064802029811, validation loss: 1.2610662449961123.
epoch: 1734, train loss: 1.2483570007009244, validation loss: 1.2579723596572876.
epoch: 1735, train loss: 1.2458231700669735, validation loss: 1.2616215218668398.
epoch: 1736, train loss: 1.2442468295403577, validation loss: 1.2625055624091106.
epoch: 1737, train loss: 1.2466550945141994, validation loss: 1.2652273074440334.
epoch: 1738, train loss: 1.250998374518998, validation loss: 1.2797131279240483.
epoch: 1739, train loss: 1.246227529070793, validation loss: 1.260821565337803.
epoch: 1740, train loss: 1.246577955167228, validation loss: 1.2731304427851802.
epoch: 1741, train loss: 1.2471796208565389, validation loss: 1.2635001669759336.
epoch: 1742, train loss: 1.2462990283966064, validation loss: 1.2642437997071638.
epoch: 1743, train loss: 1.2468602504205266, validation loss: 1.2613502378049104.
epoch: 1744, train loss: 1.245293722240203, validation loss: 1.265514093896617.
epoch: 1745, train loss: 1.244711493133405, validation loss: 1.2606957425241885.
epoch: 1746, train loss: 1.2443765686192643, validation loss: 1.278589621834133.
epoch: 1747, train loss: 1.244405339617248, validation loss: 1.253998357316722.
epoch: 1748, train loss: 1.2468854648257615, validation loss: 1.2606683554856672.
epoch: 1749, train loss: 1.248002766469203, validation loss: 1.2698661607244741.
epoch: 1750, train loss: 1.2631205407851334, validation loss: 1.30255126953125.
epoch: 1751, train loss: 1.2556138224558, validation loss: 1.2849801986113838.
epoch: 1752, train loss: 1.2496061970334533, validation loss: 1.2701841489128445.
epoch: 1753, train loss: 1.2493464049942997, validation loss: 1.2609216544939124.
epoch: 1754, train loss: 1.2497465741743736, validation loss: 1.2936790248622065.
epoch: 1755, train loss: 1.250251873917536, validation loss: 1.2739960525346838.
epoch: 1756, train loss: 1.2439641208823669, validation loss: 1.2605621140936147.
epoch: 1757, train loss: 1.244919735357302, validation loss: 1.270950047866158.
epoch: 1758, train loss: 1.2478050791889155, validation loss: 1.2648860475291377.
epoch: 1759, train loss: 1.2454734439149908, validation loss: 1.2639587132827095.
epoch: 1760, train loss: 1.2459418172136358, validation loss: 1.2761293856993965.
epoch: 1761, train loss: 1.2451970883465688, validation loss: 1.2571716619574504.
epoch: 1762, train loss: 1.2468316205050967, validation loss: 1.2845174177833225.
epoch: 1763, train loss: 1.2468826912958688, validation loss: 1.2717564416968303.
epoch: 1764, train loss: 1.2463546936665106, validation loss: 1.2781593540440435.
epoch: 1765, train loss: 1.2509369565806259, validation loss: 1.2727153612219768.
epoch: 1766, train loss: 1.2433156639064125, validation loss: 1.2605230860088183.
epoch: 1767, train loss: 1.2471005697862818, validation loss: 1.3011988142262334.
epoch: 1768, train loss: 1.2538631071738147, validation loss: 1.2641626078149546.
epoch: 1769, train loss: 1.2688662469933887, validation loss: 1.2880404669305552.
epoch: 1770, train loss: 1.2619310267474673, validation loss: 1.267420592515365.
epoch: 1771, train loss: 1.2582554664086858, validation loss: 1.3327216376429019.
epoch: 1772, train loss: 1.2591898397568169, validation loss: 1.2680087193198826.
epoch: 1773, train loss: 1.2480993522416561, validation loss: 1.2722431162129277.
epoch: 1774, train loss: 1.2497802207229334, validation loss: 1.2598303504612134.
epoch: 1775, train loss: 1.2480018620097308, validation loss: 1.2887794764145561.
epoch: 1776, train loss: 1.2547456529162346, validation loss: 1.2614371880241062.
epoch: 1777, train loss: 1.2478774151670824, validation loss: 1.255092765973962.
epoch: 1778, train loss: 1.2446876983030126, validation loss: 1.2605188463045203.
epoch: 1779, train loss: 1.2449598924829326, validation loss: 1.2610776579898337.
epoch: 1780, train loss: 1.2476276356145877, validation loss: 1.2652240836102029.
epoch: 1781, train loss: 1.2425610701972192, validation loss: 1.2668406756027886.
epoch: 1782, train loss: 1.2488772158229022, validation loss: 1.2745977070020593.
epoch: 1783, train loss: 1.247975009297012, validation loss: 1.278577260349108.
epoch: 1784, train loss: 1.2444633026735499, validation loss: 1.2588939148446787.
epoch: 1785, train loss: 1.2488099960012173, validation loss: 1.2871443447859392.
epoch: 1786, train loss: 1.246629712778494, validation loss: 1.283936241398687.
epoch: 1787, train loss: 1.2509494899609768, validation loss: 1.2797060375628264.
epoch: 1788, train loss: 1.2556515330568365, validation loss: 1.2839994430541992.
epoch: 1789, train loss: 1.248974117664022, validation loss: 1.2734034476072893.
epoch: 1790, train loss: 1.2466408331459815, validation loss: 1.2556840129520581.
epoch: 1791, train loss: 1.246562488582156, validation loss: 1.2588723949764087.
epoch: 1792, train loss: 1.2475523904922905, validation loss: 1.2635128860888274.
epoch: 1793, train loss: 1.2472218843775058, validation loss: 1.2583084572916445.
epoch: 1794, train loss: 1.2425988300131001, validation loss: 1.264947051587312.
epoch: 1795, train loss: 1.2520705286515963, validation loss: 1.3038944368777068.
epoch: 1796, train loss: 1.2556354091801774, validation loss: 1.2923938087795093.
epoch: 1797, train loss: 1.2481962464271334, validation loss: 1.2576898025429768.
epoch: 1798, train loss: 1.2437217683967101, validation loss: 1.2604898318000461.
epoch: 1799, train loss: 1.2476222657282419, validation loss: 1.287792164346446.
epoch: 1800, train loss: 1.2508060046292226, validation loss: 1.2981034465458081.
epoch: 1801, train loss: 1.250311826347211, validation loss: 1.2870300127112346.
epoch: 1802, train loss: 1.2491302566790798, validation loss: 1.2652894051178643.
epoch: 1803, train loss: 1.2516462299801887, validation loss: 1.2584157197371773.
epoch: 1804, train loss: 1.2462680558545873, validation loss: 1.2921903548033342.
epoch: 1805, train loss: 1.2483754682978359, validation loss: 1.2592826356058535.
epoch: 1806, train loss: 1.26166425932438, validation loss: 1.287610396094944.
epoch: 1807, train loss: 1.2543759881903271, validation loss: 1.2744649959647136.
epoch: 1808, train loss: 1.2511353274004176, validation loss: 1.2663173468216606.
epoch: 1809, train loss: 1.248053255431149, validation loss: 1.26295500734578.
epoch: 1810, train loss: 1.2504838770682658, validation loss: 1.255898346071658.
epoch: 1811, train loss: 1.2472200656155927, validation loss: 1.2642778261848118.
epoch: 1812, train loss: 1.2462343918074161, validation loss: 1.287257256715194.
epoch: 1813, train loss: 1.252130870425373, validation loss: 1.3156990175661833.
epoch: 1814, train loss: 1.2487935112156998, validation loss: 1.2693320668261985.
epoch: 1815, train loss: 1.2548125435452941, validation loss: 1.2979637280754421.
epoch: 1816, train loss: 1.2692773659294898, validation loss: 1.2749700546264648.
epoch: 1817, train loss: 1.2479912458209816, validation loss: 1.274593270343283.
epoch: 1818, train loss: 1.2552570826416716, validation loss: 1.2663586657980215.
epoch: 1819, train loss: 1.2503922324661816, validation loss: 1.2676607992338098.
epoch: 1820, train loss: 1.2510462747801334, validation loss: 1.2827754590822302.
epoch: 1821, train loss: 1.2545381073558002, validation loss: 1.2679647829221643.
epoch: 1822, train loss: 1.250048860497431, validation loss: 1.2795368536658909.
epoch: 1823, train loss: 1.249814573777925, validation loss: 1.264618122059366.
epoch: 1824, train loss: 1.2462616054289932, validation loss: 1.2844336913979573.
epoch: 1825, train loss: 1.24823216998249, validation loss: 1.3045735722002776.
epoch: 1826, train loss: 1.2493669549259572, validation loss: 1.2649374889290852.
epoch: 1827, train loss: 1.2565083066257863, validation loss: 1.2854862316795017.
epoch: 1828, train loss: 1.260627458948608, validation loss: 1.2827651604362156.
epoch: 1829, train loss: 1.2519210412961628, validation loss: 1.2708963000256082.
epoch: 1830, train loss: 1.2599340261669334, validation loss: 1.2849678060282832.
epoch: 1831, train loss: 1.2541029442340956, validation loss: 1.287873599840247.
epoch: 1832, train loss: 1.2502097547601123, validation loss: 1.2664931235106096.
epoch: 1833, train loss: 1.249898408531049, validation loss: 1.2746117633322012.
epoch: 1834, train loss: 1.2600558329066005, validation loss: 1.2635369300842285.
epoch: 1835, train loss: 1.2524832071514305, validation loss: 1.2817927080651987.
epoch: 1836, train loss: 1.2530900261817721, validation loss: 1.2816035747528076.
epoch: 1837, train loss: 1.2500755590036374, validation loss: 1.2722203835197117.
epoch: 1838, train loss: 1.245450179511254, validation loss: 1.263448891432389.
epoch: 1839, train loss: 1.2445896371788936, validation loss: 1.2682472519252612.
epoch: 1840, train loss: 1.2518335405839693, validation loss: 1.2638755000155906.
epoch: 1841, train loss: 1.2472046952728832, validation loss: 1.2615297721779866.
epoch: 1842, train loss: 1.2469154847871273, validation loss: 1.2716381342514702.
epoch: 1843, train loss: 1.248266824888527, validation loss: 1.2718478544898655.
epoch: 1844, train loss: 1.2485151017477754, validation loss: 1.2662905402805493.
epoch: 1845, train loss: 1.247325331792919, validation loss: 1.2563233375549316.
epoch: 1846, train loss: 1.2492613409637312, validation loss: 1.2762906136720076.
epoch: 1847, train loss: 1.24849525504156, validation loss: 1.2747942727545034.
epoch: 1848, train loss: 1.247645150630846, validation loss: 1.2589520941609922.
epoch: 1849, train loss: 1.2500043713718378, validation loss: 1.2671440580616826.
epoch: 1850, train loss: 1.2506702514963413, validation loss: 1.269885286040928.
epoch: 1851, train loss: 1.2444555759429932, validation loss: 1.2703529596328735.
epoch: 1852, train loss: 1.2473581526257576, validation loss: 1.2726915971092556.
epoch: 1853, train loss: 1.2529361641735113, validation loss: 1.2747697052748308.
epoch: 1854, train loss: 1.253801147872155, validation loss: 1.2788864425990893.
epoch: 1855, train loss: 1.2532422990973937, validation loss: 1.2764670797016309.
epoch: 1856, train loss: 1.2488440931390186, validation loss: 1.2697590226712434.
epoch: 1857, train loss: 1.2509244308559173, validation loss: 1.2950395138367363.
epoch: 1858, train loss: 1.2540584124556375, validation loss: 1.2700021163277004.
epoch: 1859, train loss: 1.252111940208925, validation loss: 1.2626691331034121.
epoch: 1860, train loss: 1.2428773750952624, validation loss: 1.279644919478375.
epoch: 1861, train loss: 1.2461423534865772, validation loss: 1.2579871882563052.
epoch: 1862, train loss: 1.2492424938656868, validation loss: 1.2756937586742898.
epoch: 1863, train loss: 1.248936092087982, validation loss: 1.2591363243434741.
epoch: 1864, train loss: 1.2459590992796312, validation loss: 1.261002981144449.
epoch: 1865, train loss: 1.243279439593674, validation loss: 1.2703536126924597.
epoch: 1866, train loss: 1.2482428671023167, validation loss: 1.3180344260257224.
epoch: 1867, train loss: 1.2541282417577342, validation loss: 1.258172807486161.
epoch: 1868, train loss: 1.249861584890873, validation loss: 1.2594137502753215.
epoch: 1869, train loss: 1.2447968699516507, validation loss: 1.2703824457914934.
epoch: 1870, train loss: 1.2479081864750714, validation loss: 1.260028248247893.
epoch: 1871, train loss: 1.2461124352358897, validation loss: 1.272609881732775.
epoch: 1872, train loss: 1.2517300527030175, validation loss: 1.2635320010392561.
epoch: 1873, train loss: 1.2497904081957056, validation loss: 1.2792774542518284.
epoch: 1874, train loss: 1.250350208457457, validation loss: 1.2725262382756108.
epoch: 1875, train loss: 1.24982707106739, validation loss: 1.2584444388099338.
epoch: 1876, train loss: 1.249156333984585, validation loss: 1.2643459879833718.
epoch: 1877, train loss: 1.2447458932159143, validation loss: 1.2623720791028894.
epoch: 1878, train loss: 1.2465726126224623, validation loss: 1.3124241984408835.
epoch: 1879, train loss: 1.249356439354223, validation loss: 1.2740999252899834.
epoch: 1880, train loss: 1.2478523276267794, validation loss: 1.2658106347788936.
epoch: 1881, train loss: 1.2513356449407176, validation loss: 1.269874904466712.
epoch: 1882, train loss: 1.2454208605880037, validation loss: 1.2619878623796545.
epoch: 1883, train loss: 1.2453701102405512, validation loss: 1.3295941404674365.
epoch: 1884, train loss: 1.2738011430162903, validation loss: 1.2897605533185212.
epoch: 1885, train loss: 1.2557568943828619, validation loss: 1.2740420258563498.
epoch: 1886, train loss: 1.251469966468461, validation loss: 1.2705590465794439.
epoch: 1887, train loss: 1.2514723386239568, validation loss: 1.2731639302295188.
epoch: 1888, train loss: 1.2511659073173453, validation loss: 1.3074237782022227.
epoch: 1889, train loss: 1.25375653188163, validation loss: 1.257544149523196.
epoch: 1890, train loss: 1.2498726582308428, validation loss: 1.267885016358417.
epoch: 1891, train loss: 1.2485248091023997, validation loss: 1.2656900053438933.
epoch: 1892, train loss: 1.2499911730442572, validation loss: 1.2677245554716692.
epoch: 1893, train loss: 1.2459211065134872, validation loss: 1.3018317429915718.
epoch: 1894, train loss: 1.2462648022065468, validation loss: 1.2725895798724631.
epoch: 1895, train loss: 1.2478580956065326, validation loss: 1.274125187293343.
epoch: 1896, train loss: 1.2500109038221727, validation loss: 1.2689913148465364.
epoch: 1897, train loss: 1.2498354343099332, validation loss: 1.2710803228875864.
epoch: 1898, train loss: 1.2441924777599649, validation loss: 1.2910688027091648.
epoch: 1899, train loss: 1.2490515523000594, validation loss: 1.2704650370971016.
epoch: 1900, train loss: 1.246897340914525, validation loss: 1.2558893068977024.
epoch: 1901, train loss: 1.2498203242590669, validation loss: 1.26490202675695.
epoch: 1902, train loss: 1.253381910674069, validation loss: 1.2650620522706404.
epoch: 1903, train loss: 1.2522678922075745, validation loss: 1.2715238073597783.
epoch: 1904, train loss: 1.2455081130386492, validation loss: 1.2639556915863701.
epoch: 1905, train loss: 1.2498275982130558, validation loss: 1.2697623397993005.
epoch: 1906, train loss: 1.2445529819628514, validation loss: 1.258818735247073.
epoch: 1907, train loss: 1.2450662720094032, validation loss: 1.276051604229471.
epoch: 1908, train loss: 1.247634510381506, validation loss: 1.264844687088676.
epoch: 1909, train loss: 1.2454083698605178, validation loss: 1.2593543166699617.
epoch: 1910, train loss: 1.2476289130132132, validation loss: 1.2675124665965205.
epoch: 1911, train loss: 1.247766031037777, validation loss: 1.2613982635995615.
epoch: 1912, train loss: 1.245171424445756, validation loss: 1.2558937694715417.
epoch: 1913, train loss: 1.2454281400103089, validation loss: 1.29185660507368.
epoch: 1914, train loss: 1.2550551836643744, validation loss: 1.264250610185706.
epoch: 1915, train loss: 1.2468433402000216, validation loss: 1.2847523896590523.
epoch: 1916, train loss: 1.2443481115026211, validation loss: 1.2744334936141968.
epoch: 1917, train loss: 1.2498438631722686, validation loss: 1.2611533403396606.
epoch: 1918, train loss: 1.2464194330600424, validation loss: 1.2792525395103123.
epoch: 1919, train loss: 1.250927881363335, validation loss: 1.270643747371176.
epoch: 1920, train loss: 1.251840639551845, validation loss: 1.2633252713991248.
epoch: 1921, train loss: 1.2517371801061368, validation loss: 1.270011761914129.
epoch: 1922, train loss: 1.2550233547840643, validation loss: 1.2760076315506645.
epoch: 1923, train loss: 1.2498240744302032, validation loss: 1.2691217194432798.
epoch: 1924, train loss: 1.2480888344825956, validation loss: 1.2680285702580991.
epoch: 1925, train loss: 1.249351725665801, validation loss: 1.2572598612826804.
epoch: 1926, train loss: 1.255179926889752, validation loss: 1.2794531272805256.
epoch: 1927, train loss: 1.248700727016554, validation loss: 1.2688307813976123.
epoch: 1928, train loss: 1.2485557849254083, validation loss: 1.2659825760385264.
epoch: 1929, train loss: 1.2469191288729327, validation loss: 1.2768846335618391.
epoch: 1930, train loss: 1.2459476540941712, validation loss: 1.263883932777073.
epoch: 1931, train loss: 1.2495871629190007, validation loss: 1.2684308964273203.
epoch: 1932, train loss: 1.2460370829345984, validation loss: 1.3253070582514224.
epoch: 1933, train loss: 1.256464863042219, validation loss: 1.3049510199090708.
epoch: 1934, train loss: 1.2522385503173967, validation loss: 1.2815362266872241.
epoch: 1935, train loss: 1.2463758844848072, validation loss: 1.2610588747522105.
epoch: 1936, train loss: 1.2450118830444616, validation loss: 1.257775685061579.
epoch: 1937, train loss: 1.2451785901270875, validation loss: 1.2680985461110654.
epoch: 1938, train loss: 1.2455780418640976, validation loss: 1.26965434136598.
epoch: 1939, train loss: 1.24454238546004, validation loss: 1.251406747361888.
epoch: 1940, train loss: 1.2594610977610317, validation loss: 1.268110840216927.
epoch: 1941, train loss: 1.2487299486037788, validation loss: 1.2607233576152637.
epoch: 1942, train loss: 1.2452800394198216, validation loss: 1.286951640377874.
epoch: 1943, train loss: 1.2441455355477988, validation loss: 1.2844330642534338.
epoch: 1944, train loss: 1.2518755317827976, validation loss: 1.2685662870821746.
epoch: 1945, train loss: 1.2501426060265357, validation loss: 1.265803057214488.
epoch: 1946, train loss: 1.247256869569831, validation loss: 1.2682293187017026.
epoch: 1947, train loss: 1.2460447691996164, validation loss: 1.2714858780736509.
epoch: 1948, train loss: 1.2406666924100402, validation loss: 1.2577401917913686.
epoch: 1949, train loss: 1.2415698449546044, validation loss: 1.2896324862604556.
epoch: 1950, train loss: 1.246491556867547, validation loss: 1.2673410695532095.
epoch: 1951, train loss: 1.2487205157586194, validation loss: 1.2771322934523872.
epoch: 1952, train loss: 1.2505835261913614, validation loss: 1.2591793226159138.
epoch: 1953, train loss: 1.2557213229870579, validation loss: 1.2797935268153315.
epoch: 1954, train loss: 1.2551439497448982, validation loss: 1.2672580325085183.
epoch: 1955, train loss: 1.2505525274014255, validation loss: 1.2864291097806848.
epoch: 1956, train loss: 1.2507030242079988, validation loss: 1.2795771412227466.
epoch: 1957, train loss: 1.246566072516485, validation loss: 1.2810092490652334.
epoch: 1958, train loss: 1.2470913972329656, validation loss: 1.2737427846245144.
epoch: 1959, train loss: 1.2477365229107917, validation loss: 1.2663741370906.
epoch: 1960, train loss: 1.2453526816236864, validation loss: 1.2699180685955545.
epoch: 1961, train loss: 1.253074150566661, validation loss: 1.2884734661682793.
epoch: 1962, train loss: 1.2480027905297935, validation loss: 1.2844563100648962.
epoch: 1963, train loss: 1.2507726489950757, validation loss: 1.2703314086665278.
epoch: 1964, train loss: 1.2465296032231883, validation loss: 1.2863357429919036.
epoch: 1965, train loss: 1.2514712340241179, validation loss: 1.261653615080792.
epoch: 1966, train loss: 1.246996231035355, validation loss: 1.2657273334005605.
epoch: 1967, train loss: 1.2529269183447602, validation loss: 1.2819089008414226.
epoch: 1968, train loss: 1.2579502960957518, validation loss: 1.2763006220693174.
epoch: 1969, train loss: 1.2561385292525684, validation loss: 1.261597602263741.
epoch: 1970, train loss: 1.245398015057275, validation loss: 1.2720947991246763.
epoch: 1971, train loss: 1.253307132545961, validation loss: 1.2738612579262776.
epoch: 1972, train loss: 1.2602314533443626, validation loss: 1.280312330826469.
epoch: 1973, train loss: 1.2535317305031173, validation loss: 1.3074400321297024.
epoch: 1974, train loss: 1.2537248561141687, validation loss: 1.2792861979940664.
epoch: 1975, train loss: 1.2519288741120504, validation loss: 1.268824375194052.
epoch: 1976, train loss: 1.2511056519429617, validation loss: 1.2797229704649553.
epoch: 1977, train loss: 1.2488164825176975, validation loss: 1.2676906482033108.
epoch: 1978, train loss: 1.2479790383522664, validation loss: 1.2775653030561365.
epoch: 1979, train loss: 1.2536897451505749, validation loss: 1.2612475778745569.
epoch: 1980, train loss: 1.2492665599245545, validation loss: 1.258490018222643.
epoch: 1981, train loss: 1.2525070271360765, validation loss: 1.2561713768088298.
epoch: 1982, train loss: 1.2464675061199644, validation loss: 1.2598507715308147.
epoch: 1983, train loss: 1.2449760032356332, validation loss: 1.27337878683339.
epoch: 1984, train loss: 1.2449885759878596, validation loss: 1.2647925822631172.
epoch: 1985, train loss: 1.2487577724894252, validation loss: 1.2799603731735893.
epoch: 1986, train loss: 1.2483897909111934, validation loss: 1.2743600606918335.
epoch: 1987, train loss: 1.24572229057277, validation loss: 1.2626404865928318.
epoch: 1988, train loss: 1.2442374513783585, validation loss: 1.2615754656169726.
epoch: 1989, train loss: 1.246747687322284, validation loss: 1.2564352906268577.
epoch: 1990, train loss: 1.244302717917556, validation loss: 1.2845958523128345.
epoch: 1991, train loss: 1.2439225288706088, validation loss: 1.2672761626865552.
epoch: 1992, train loss: 1.2462256140665178, validation loss: 1.261548410291257.
epoch: 1993, train loss: 1.2447489456299248, validation loss: 1.2615370232125986.
epoch: 1994, train loss: 1.2477634532735982, validation loss: 1.270219756209332.
epoch: 1995, train loss: 1.2451719800266652, validation loss: 1.279334254886793.
epoch: 1996, train loss: 1.2511920218073993, validation loss: 1.2782625530077063.
epoch: 1997, train loss: 1.2451831999175045, validation loss: 1.281099366105121.
epoch: 1998, train loss: 1.2440763843168907, validation loss: 1.277067764945652.
epoch: 1999, train loss: 1.2550792376929467, validation loss: 1.2943291767783787.
epoch: 2000, train loss: 1.2408523504887152, validation loss: 1.2549836272778718.
epoch: 2001, train loss: 1.2334704760017745, validation loss: 1.2421021616977195.
epoch: 2002, train loss: 1.2303313519976555, validation loss: 1.2439374560895173.
epoch: 2003, train loss: 1.2275865198275364, validation loss: 1.2444993102032205.
epoch: 2004, train loss: 1.2280468022057769, validation loss: 1.247784329497296.
epoch: 2005, train loss: 1.2285015189319575, validation loss: 1.2478189416553662.
epoch: 2006, train loss: 1.2261203079048646, validation loss: 1.2514738207278044.
epoch: 2007, train loss: 1.2310720507158053, validation loss: 1.3097336655077727.
epoch: 2008, train loss: 1.2460777704868842, validation loss: 1.2522523765978606.
epoch: 2009, train loss: 1.2286608295703152, validation loss: 1.2409011540205583.
epoch: 2010, train loss: 1.2274393510381016, validation loss: 1.2497602545696755.
epoch: 2011, train loss: 1.2252019250064814, validation loss: 1.2438181483227273.
epoch: 2012, train loss: 1.2269544142101882, validation loss: 1.237908943839695.
epoch: 2013, train loss: 1.2227686260818342, validation loss: 1.2445511195970618.
epoch: 2014, train loss: 1.2271298487252051, validation loss: 1.2438280478767727.
epoch: 2015, train loss: 1.2273511241335389, validation loss: 1.243215597194174.
epoch: 2016, train loss: 1.225470723362144, validation loss: 1.25007775037185.
epoch: 2017, train loss: 1.2251571099692529, validation loss: 1.242982434189838.
epoch: 2018, train loss: 1.226918888748239, validation loss: 1.255847412606944.
epoch: 2019, train loss: 1.2279952447348779, validation loss: 1.2556826861008354.
epoch: 2020, train loss: 1.2258190375949265, validation loss: 1.259831340416618.
epoch: 2021, train loss: 1.2264708171197034, validation loss: 1.2434836315072102.
epoch: 2022, train loss: 1.22928437399208, validation loss: 1.2426352915556536.
epoch: 2023, train loss: 1.2259780649745136, validation loss: 1.245538037756215.
epoch: 2024, train loss: 1.2262244793253207, validation loss: 1.2425771433374155.
epoch: 2025, train loss: 1.225795601486066, validation loss: 1.2476449945698613.
epoch: 2026, train loss: 1.2272960855326522, validation loss: 1.2452532571295034.
epoch: 2027, train loss: 1.2254348533962844, validation loss: 1.2433795306993567.
epoch: 2028, train loss: 1.229788106515867, validation loss: 1.264537381089252.
epoch: 2029, train loss: 1.2364518653362169, validation loss: 1.2573054769764775.
epoch: 2030, train loss: 1.2301133925761651, validation loss: 1.2574937654578167.
epoch: 2031, train loss: 1.2294326134777944, validation loss: 1.245088297387828.
epoch: 2032, train loss: 1.2278654181629145, validation loss: 1.2428417827772058.
epoch: 2033, train loss: 1.2259079196037503, validation loss: 1.2468062483746072.
epoch: 2034, train loss: 1.2258431003728043, validation loss: 1.2433965983598128.
epoch: 2035, train loss: 1.2304220232394858, validation loss: 1.2423356356828108.
epoch: 2036, train loss: 1.22541177054064, validation loss: 1.255861759185791.
epoch: 2037, train loss: 1.2274081936670005, validation loss: 1.242554669794829.
epoch: 2038, train loss: 1.2233658657161468, validation loss: 1.2431714482929395.
epoch: 2039, train loss: 1.221701546546516, validation loss: 1.2491910302120706.
epoch: 2040, train loss: 1.2250113662229765, validation loss: 1.2433915915696516.
epoch: 2041, train loss: 1.2239846614522671, validation loss: 1.246272579483364.
epoch: 2042, train loss: 1.224814498096431, validation loss: 1.277431431023971.
epoch: 2043, train loss: 1.2297229624669486, validation loss: 1.2400664868562117.
epoch: 2044, train loss: 1.2241469402925684, validation loss: 1.2485192340353262.
epoch: 2045, train loss: 1.2252874374389648, validation loss: 1.2432911240536233.
epoch: 2046, train loss: 1.22357267086659, validation loss: 1.2414738561796106.
epoch: 2047, train loss: 1.2202728942993584, validation loss: 1.252556044122447.
epoch: 2048, train loss: 1.223017369935272, validation loss: 1.2470471029696257.
epoch: 2049, train loss: 1.2202771234949794, validation loss: 1.2442645922951077.
epoch: 2050, train loss: 1.221756914340028, validation loss: 1.2485439414563386.
epoch: 2051, train loss: 1.2292316736431297, validation loss: 1.256918658380923.
epoch: 2052, train loss: 1.2273440973474345, validation loss: 1.2447330277899038.
epoch: 2053, train loss: 1.2259057486822846, validation loss: 1.2600076043087503.
epoch: 2054, train loss: 1.227812763747819, validation loss: 1.2413690556650576.
epoch: 2055, train loss: 1.2223259298079605, validation loss: 1.2598524663759314.
epoch: 2056, train loss: 1.2222403944085498, validation loss: 1.2514591631682024.
epoch: 2057, train loss: 1.2257098025138224, validation loss: 1.2477718695350315.
epoch: 2058, train loss: 1.2211538061089473, validation loss: 1.2568433958551157.
epoch: 2059, train loss: 1.2252336182725538, validation loss: 1.2521107663278994.
epoch: 2060, train loss: 1.2226967341309294, validation loss: 1.2444803196450938.
epoch: 2061, train loss: 1.2250465668669535, validation loss: 1.2512592595556509.
epoch: 2062, train loss: 1.2270081743187862, validation loss: 1.2434796043064282.
epoch: 2063, train loss: 1.2251104641398158, validation loss: 1.2431043593779854.
epoch: 2064, train loss: 1.2221359069194269, validation loss: 1.243317935777747.
epoch: 2065, train loss: 1.232985252634101, validation loss: 1.2463293645692908.
epoch: 2066, train loss: 1.2264704113706537, validation loss: 1.2525047893109529.
epoch: 2067, train loss: 1.223255480101349, validation loss: 1.243403849394425.
epoch: 2068, train loss: 1.2240743298049366, validation loss: 1.2440171708231387.
epoch: 2069, train loss: 1.2236366982853741, validation loss: 1.2435582150583682.
epoch: 2070, train loss: 1.2217072532811295, validation loss: 1.2470569195954695.
epoch: 2071, train loss: 1.222324193070788, validation loss: 1.2565747343975564.
epoch: 2072, train loss: 1.227304420339952, validation loss: 1.2504512434420378.
epoch: 2073, train loss: 1.2239224374841113, validation loss: 1.2422754609066506.
epoch: 2074, train loss: 1.2289862392145559, validation loss: 1.2418239220328953.
epoch: 2075, train loss: 1.225580581831276, validation loss: 1.2419412602549014.
epoch: 2076, train loss: 1.223032103765995, validation loss: 1.2427670748337456.
epoch: 2077, train loss: 1.2246571483962032, validation loss: 1.250980636347895.
epoch: 2078, train loss: 1.222424616507434, validation loss: 1.2488909389661706.
epoch: 2079, train loss: 1.2226343734548726, validation loss: 1.2423800644667253.
epoch: 2080, train loss: 1.22996158556107, validation loss: 1.2398414715476658.
epoch: 2081, train loss: 1.2218767623288915, validation loss: 1.2532703980155613.
epoch: 2082, train loss: 1.223666607786756, validation loss: 1.2407298554544863.
epoch: 2083, train loss: 1.2191871776493317, validation loss: 1.268611332644587.
epoch: 2084, train loss: 1.2246323572386295, validation loss: 1.2416865721992825.
epoch: 2085, train loss: 1.2225529316368453, validation loss: 1.2507124050803806.
epoch: 2086, train loss: 1.225964681817851, validation loss: 1.2499139930890955.
epoch: 2087, train loss: 1.2227324739508671, validation loss: 1.2565057744150576.
epoch: 2088, train loss: 1.224597798574955, validation loss: 1.248541816421177.
epoch: 2089, train loss: 1.231726287701808, validation loss: 1.247934657594432.
epoch: 2090, train loss: 1.2267446824170034, validation loss: 1.2561498880386353.
epoch: 2091, train loss: 1.223071231754548, validation loss: 1.2430419196253237.
epoch: 2092, train loss: 1.2237513819965748, validation loss: 1.2439415765845256.
epoch: 2093, train loss: 1.2254746857039425, validation loss: 1.2514388198437898.
epoch: 2094, train loss: 1.2236692260164734, validation loss: 1.2439180146092954.
epoch: 2095, train loss: 1.2212614674086963, validation loss: 1.2404547255972158.
epoch: 2096, train loss: 1.2207226873537815, validation loss: 1.2476565837860107.
epoch: 2097, train loss: 1.2237774953929657, validation loss: 1.259830962056699.
epoch: 2098, train loss: 1.2247818774039592, validation loss: 1.2404912502869316.
epoch: 2099, train loss: 1.2229773768591226, validation loss: 1.2594805385755456.
epoch: 2100, train loss: 1.2240109957686258, validation loss: 1.245906783186871.
epoch: 2101, train loss: 1.2229400632578298, validation loss: 1.2497618198394775.
epoch: 2102, train loss: 1.2225353444388154, validation loss: 1.2438820963320525.
epoch: 2103, train loss: 1.2233045976096337, validation loss: 1.2390934021576592.
epoch: 2104, train loss: 1.220739663194079, validation loss: 1.2609810155370962.
epoch: 2105, train loss: 1.222160879625093, validation loss: 1.2429161227267722.
epoch: 2106, train loss: 1.2371941892378922, validation loss: 1.250537255535955.
epoch: 2107, train loss: 1.2276531118865406, validation loss: 1.2518988744072292.
epoch: 2108, train loss: 1.2250135765163177, validation loss: 1.2403227298156074.
epoch: 2109, train loss: 1.2228546131641493, validation loss: 1.2547197808390078.
epoch: 2110, train loss: 1.2244402443597076, validation loss: 1.2506694016249285.
epoch: 2111, train loss: 1.2206087298349504, validation loss: 1.2923518678416377.
epoch: 2112, train loss: 1.2272048368366486, validation loss: 1.2616420051325923.
epoch: 2113, train loss: 1.2234539920036946, validation loss: 1.2388084608575571.
epoch: 2114, train loss: 1.2239011679220637, validation loss: 1.2478752188060596.
epoch: 2115, train loss: 1.221449850896083, validation loss: 1.26004667904066.
epoch: 2116, train loss: 1.2285120924678417, validation loss: 1.2547750524852588.
epoch: 2117, train loss: 1.226787340750388, validation loss: 1.2574000306751416.
epoch: 2118, train loss: 1.2230749786446948, validation loss: 1.2455541154612666.
epoch: 2119, train loss: 1.2212627841791976, validation loss: 1.2384168998054836.
epoch: 2120, train loss: 1.2230335714620189, validation loss: 1.2467102745304937.
epoch: 2121, train loss: 1.2285908307504216, validation loss: 1.2458094617594844.
epoch: 2122, train loss: 1.2242169478617677, validation loss: 1.2442330329314522.
epoch: 2123, train loss: 1.220588789073699, validation loss: 1.2544506788253784.
epoch: 2124, train loss: 1.224343561251229, validation loss: 1.2368894711784695.
epoch: 2125, train loss: 1.223662806213449, validation loss: 1.2530857531920723.
epoch: 2126, train loss: 1.2189604689221862, validation loss: 1.2423099694044695.
epoch: 2127, train loss: 1.2219181356080082, validation loss: 1.2415022435395613.
epoch: 2128, train loss: 1.2241003994547992, validation loss: 1.2509454592414524.
epoch: 2129, train loss: 1.221725281225432, validation loss: 1.2502935399179873.
epoch: 2130, train loss: 1.2195856450894558, validation loss: 1.2464986469434656.
epoch: 2131, train loss: 1.2220149587053772, validation loss: 1.2436304610708486.
epoch: 2132, train loss: 1.2219762594328014, validation loss: 1.2510528771773628.
epoch: 2133, train loss: 1.2232631062148909, validation loss: 1.2429533367571624.
epoch: 2134, train loss: 1.2229996755582477, validation loss: 1.2614331763723623.
epoch: 2135, train loss: 1.2249808475511883, validation loss: 1.2480484091717263.
epoch: 2136, train loss: 1.2234840174333765, validation loss: 1.2508758565653926.
epoch: 2137, train loss: 1.222337589351409, validation loss: 1.2507621412691863.
epoch: 2138, train loss: 1.2248016169311804, validation loss: 1.2483489098756209.
epoch: 2139, train loss: 1.2199832725962367, validation loss: 1.2468565909758857.
epoch: 2140, train loss: 1.2292819110625381, validation loss: 1.2541649963544763.
epoch: 2141, train loss: 1.2223860342568214, validation loss: 1.25310494588769.
epoch: 2142, train loss: 1.218783425628592, validation loss: 1.2653876750365547.
epoch: 2143, train loss: 1.220331966330152, validation loss: 1.2532743733862173.
epoch: 2144, train loss: 1.2323067953827185, validation loss: 1.2539434847624407.
epoch: 2145, train loss: 1.2257939161510643, validation loss: 1.2597736690355383.
epoch: 2146, train loss: 1.2243754743436062, validation loss: 1.2482310222542805.
epoch: 2147, train loss: 1.2250368627933188, validation loss: 1.2406686959059343.
epoch: 2148, train loss: 1.220927837791793, validation loss: 1.245746866516445.
epoch: 2149, train loss: 1.2267343494870246, validation loss: 1.249580398849819.
epoch: 2150, train loss: 1.2210352639539526, validation loss: 1.249821611072706.
epoch: 2151, train loss: 1.22230722379247, validation loss: 1.2403094820354297.
epoch: 2152, train loss: 1.218774661011652, validation loss: 1.2501372513563738.
epoch: 2153, train loss: 1.2208104538261344, validation loss: 1.2444250324498052.
epoch: 2154, train loss: 1.2193586563845293, validation loss: 1.236242237298385.
epoch: 2155, train loss: 1.2237870037008862, validation loss: 1.2500339176343835.
epoch: 2156, train loss: 1.222185292375197, validation loss: 1.2545320417570032.
epoch: 2157, train loss: 1.2273543799689057, validation loss: 1.2516134044398433.
epoch: 2158, train loss: 1.2195230755237265, validation loss: 1.2453141367953757.
epoch: 2159, train loss: 1.2213048322485127, validation loss: 1.244100772816202.
epoch: 2160, train loss: 1.2215822891357841, validation loss: 1.266033613163492.
epoch: 2161, train loss: 1.2321919629333216, validation loss: 1.2401030011799024.
epoch: 2162, train loss: 1.2228481124300477, validation loss: 1.2419362845628157.
epoch: 2163, train loss: 1.2265351617008173, validation loss: 1.24564426359923.
epoch: 2164, train loss: 1.217353808770486, validation loss: 1.2571153588916943.
epoch: 2165, train loss: 1.220390833845926, validation loss: 1.247166913488637.
epoch: 2166, train loss: 1.2193877467321694, validation loss: 1.2422108805697898.
epoch: 2167, train loss: 1.2181119404801535, validation loss: 1.2413396783497022.
epoch: 2168, train loss: 1.2195955700830583, validation loss: 1.2445133665333623.
epoch: 2169, train loss: 1.2268195666304422, validation loss: 1.2618066538935122.
epoch: 2170, train loss: 1.2249859035561939, validation loss: 1.2549324761266294.
epoch: 2171, train loss: 1.2269393971206946, validation loss: 1.2458445455717004.
epoch: 2172, train loss: 1.2213148906690265, validation loss: 1.2466617459836213.
epoch: 2173, train loss: 1.2215306726070718, validation loss: 1.252809280934541.
epoch: 2174, train loss: 1.2184587192097935, validation loss: 1.2537034749984741.
epoch: 2175, train loss: 1.2207478383265504, validation loss: 1.2731499671936035.
epoch: 2176, train loss: 1.2283597779930184, validation loss: 1.247389554977417.
epoch: 2177, train loss: 1.2211239600400312, validation loss: 1.2457449747168499.
epoch: 2178, train loss: 1.2191099015944595, validation loss: 1.2508970861849578.
epoch: 2179, train loss: 1.220336628616403, validation loss: 1.2657046266224072.
epoch: 2180, train loss: 1.2211181767489931, validation loss: 1.2502048689386118.
epoch: 2181, train loss: 1.2194225011615578, validation loss: 1.2448632717132568.
epoch: 2182, train loss: 1.218836816079026, validation loss: 1.2449229748352715.
epoch: 2183, train loss: 1.218877927972636, validation loss: 1.272036490233048.
epoch: 2184, train loss: 1.2192452631959128, validation loss: 1.24942918445753.
epoch: 2185, train loss: 1.2199725459475037, validation loss: 1.243045889812967.
epoch: 2186, train loss: 1.223926533252821, validation loss: 1.2528286291205364.
epoch: 2187, train loss: 1.225327799079615, validation loss: 1.2458973915680596.
epoch: 2188, train loss: 1.2185006349458607, validation loss: 1.2439807497936746.
epoch: 2189, train loss: 1.225620144004122, validation loss: 1.2440135478973389.
epoch: 2190, train loss: 1.223221662941329, validation loss: 1.2450190834377124.
epoch: 2191, train loss: 1.220802162765363, validation loss: 1.246785889501157.
epoch: 2192, train loss: 1.2204492168688992, validation loss: 1.242618996164073.
epoch: 2193, train loss: 1.218647520476525, validation loss: 1.241735427275948.
epoch: 2194, train loss: 1.2231353007325338, validation loss: 1.2426735370055488.
epoch: 2195, train loss: 1.2225719230984329, validation loss: 1.2453017493952876.
epoch: 2196, train loss: 1.222953648742186, validation loss: 1.250258487203847.
epoch: 2197, train loss: 1.2196636746782776, validation loss: 1.2400346994400024.
epoch: 2198, train loss: 1.2173563591930845, validation loss: 1.2656756846801094.
epoch: 2199, train loss: 1.2183910652038155, validation loss: 1.2482231544411702.
epoch: 2200, train loss: 1.218783868562191, validation loss: 1.2454267014627871.
epoch: 2201, train loss: 1.2191232388172675, validation loss: 1.2494882293369458.
epoch: 2202, train loss: 1.21971056111362, validation loss: 1.243589504905369.
epoch: 2203, train loss: 1.222038397001564, validation loss: 1.2549995028454324.
epoch: 2204, train loss: 1.2189978492369347, validation loss: 1.252289839412855.
epoch: 2205, train loss: 1.2187410275870507, validation loss: 1.252708771954412.
epoch: 2206, train loss: 1.2230634219055876, validation loss: 1.2439148374225781.
epoch: 2207, train loss: 1.22682710962558, validation loss: 1.2544838915700498.
epoch: 2208, train loss: 1.219788067931429, validation loss: 1.259548316831174.
epoch: 2209, train loss: 1.217662214139186, validation loss: 1.269085759701936.
epoch: 2210, train loss: 1.2194811685369649, validation loss: 1.2738100756769595.
epoch: 2211, train loss: 1.227264695211288, validation loss: 1.2493574204652205.
epoch: 2212, train loss: 1.222434147782282, validation loss: 1.2443461418151855.
epoch: 2213, train loss: 1.221837889163866, validation loss: 1.241151695666106.
epoch: 2214, train loss: 1.2187551216247978, validation loss: 1.2498458520225857.
epoch: 2215, train loss: 1.2209538822874018, validation loss: 1.251257994900579.
epoch: 2216, train loss: 1.2233213875271858, validation loss: 1.255560014558875.
epoch: 2217, train loss: 1.2211865492916982, validation loss: 1.2451263666152954.
epoch: 2218, train loss: 1.2209505083364085, validation loss: 1.2553544873776643.
epoch: 2219, train loss: 1.2220259040867516, validation loss: 1.237802619519441.
epoch: 2220, train loss: 1.2251304114630464, validation loss: 1.246880469114884.
epoch: 2221, train loss: 1.2208008022483336, validation loss: 1.2575460465058037.
epoch: 2222, train loss: 1.2256945306008016, validation loss: 1.2426883137744407.
epoch: 2223, train loss: 1.2281939075627457, validation loss: 1.2507885590843533.
epoch: 2224, train loss: 1.2204345716248959, validation loss: 1.2709437608718872.
epoch: 2225, train loss: 1.2208730321411694, validation loss: 1.2633873379748801.
epoch: 2226, train loss: 1.2209553587327309, validation loss: 1.2465533329092937.
epoch: 2227, train loss: 1.2190171480178833, validation loss: 1.2413999775181646.
epoch: 2228, train loss: 1.2209295712479757, validation loss: 1.2588073015213013.
epoch: 2229, train loss: 1.220834266155138, validation loss: 1.2528578561285268.
epoch: 2230, train loss: 1.2232523565992304, validation loss: 1.2467525938282842.
epoch: 2231, train loss: 1.2185070788094756, validation loss: 1.2460222347922947.
epoch: 2232, train loss: 1.2220237178540012, validation loss: 1.245334531949914.
epoch: 2233, train loss: 1.2199485148858586, validation loss: 1.2431012132893438.
epoch: 2234, train loss: 1.2156589676480773, validation loss: 1.247748649638632.
epoch: 2235, train loss: 1.2230888758230647, validation loss: 1.2498464014219202.
epoch: 2236, train loss: 1.2212574011688933, validation loss: 1.246270760245945.
epoch: 2237, train loss: 1.2202078486801287, validation loss: 1.2473968474761299.
epoch: 2238, train loss: 1.2190197564046317, validation loss: 1.240497578745303.
epoch: 2239, train loss: 1.2186365947810882, validation loss: 1.2567762810250986.
epoch: 2240, train loss: 1.2218304697526705, validation loss: 1.251669785250788.
epoch: 2241, train loss: 1.2178733272290012, validation loss: 1.2378913475119548.
epoch: 2242, train loss: 1.2209983440714145, validation loss: 1.2689653738685276.
epoch: 2243, train loss: 1.2278217099128512, validation loss: 1.2559297654939734.
epoch: 2244, train loss: 1.2290782884720268, validation loss: 1.2464499110760896.
epoch: 2245, train loss: 1.224956116545091, validation loss: 1.2496329494144605.
epoch: 2246, train loss: 1.2170146025648905, validation loss: 1.2432314831277598.
epoch: 2247, train loss: 1.2224940050632582, validation loss: 1.247989509416663.
epoch: 2248, train loss: 1.2223315709227816, validation loss: 1.2494312991266665.
epoch: 2249, train loss: 1.2208053157963883, validation loss: 1.2458111410555632.
epoch: 2250, train loss: 1.2171766550169079, validation loss: 1.2393624160600745.
epoch: 2251, train loss: 1.2144071618351369, validation loss: 1.2452964005262956.
epoch: 2252, train loss: 1.220729958026781, validation loss: 1.2495333526445471.
epoch: 2253, train loss: 1.2166014647265093, validation loss: 1.241628646850586.
epoch: 2254, train loss: 1.2139432911479144, validation loss: 1.2532964011897212.
epoch: 2255, train loss: 1.2365867293209112, validation loss: 1.2475221053413723.
epoch: 2256, train loss: 1.2226829703794706, validation loss: 1.244217857070591.
epoch: 2257, train loss: 1.2188695078596063, validation loss: 1.2577268662660017.
epoch: 2258, train loss: 1.2318521814608792, validation loss: 1.239278855531112.
epoch: 2259, train loss: 1.2288367092062573, validation loss: 1.242831193882486.
epoch: 2260, train loss: 1.220866703112191, validation loss: 1.2402340173721313.
epoch: 2261, train loss: 1.219082721876442, validation loss: 1.2465818446615469.
epoch: 2262, train loss: 1.2148597874772658, validation loss: 1.2447208425273066.
epoch: 2263, train loss: 1.2189126386554963, validation loss: 1.2566512356633726.
epoch: 2264, train loss: 1.2207147375159306, validation loss: 1.245201639507128.
epoch: 2265, train loss: 1.216385857774577, validation loss: 1.2458766232366147.
epoch: 2266, train loss: 1.2167498791983369, validation loss: 1.2471641146618386.
epoch: 2267, train loss: 1.2188628901035414, validation loss: 1.2445236185322637.
epoch: 2268, train loss: 1.218179125304616, validation loss: 1.251891571542491.
epoch: 2269, train loss: 1.2353753267078225, validation loss: 1.2561475142188694.
epoch: 2270, train loss: 1.2287625468105352, validation loss: 1.264081447020821.
epoch: 2271, train loss: 1.2216642373198763, validation loss: 1.2407445389291514.
epoch: 2272, train loss: 1.2204837908438586, validation loss: 1.2505466264227163.
epoch: 2273, train loss: 1.226794920930075, validation loss: 1.2442947885264521.
epoch: 2274, train loss: 1.217027012361299, validation loss: 1.2631816449372664.
epoch: 2275, train loss: 1.2212976042283785, validation loss: 1.248259036437325.
epoch: 2276, train loss: 1.219535871383247, validation loss: 1.2522719424703848.
epoch: 2277, train loss: 1.2210823013148178, validation loss: 1.24096707675768.
epoch: 2278, train loss: 1.2146869668173135, validation loss: 1.2586245433143948.
epoch: 2279, train loss: 1.2147449484658897, validation loss: 1.242505280867867.
epoch: 2280, train loss: 1.2137354142075285, validation loss: 1.246035705442014.
epoch: 2281, train loss: 1.2166212731545125, validation loss: 1.2648931430733723.
epoch: 2282, train loss: 1.2435016785192927, validation loss: 1.2529272359350454.
epoch: 2283, train loss: 1.227244511656805, validation loss: 1.2386058620784595.
epoch: 2284, train loss: 1.220664830382811, validation loss: 1.2459919556327488.
epoch: 2285, train loss: 1.2157307305467238, validation loss: 1.245336211245993.
epoch: 2286, train loss: 1.2159687619690502, validation loss: 1.2593221197957578.
epoch: 2287, train loss: 1.2188119888305664, validation loss: 1.2403069319932356.
epoch: 2288, train loss: 1.218173083909061, validation loss: 1.2464039636694866.
epoch: 2289, train loss: 1.2190448483195873, validation loss: 1.2484794544137043.
epoch: 2290, train loss: 1.2191078651935683, validation loss: 1.2390797604685244.
epoch: 2291, train loss: 1.2167922116200858, validation loss: 1.2538866374803626.
epoch: 2292, train loss: 1.2156393506111356, validation loss: 1.2433241398438164.
epoch: 2293, train loss: 1.2197638662583237, validation loss: 1.2485178916350654.
epoch: 2294, train loss: 1.2115026931150243, validation loss: 1.261135204978611.
epoch: 2295, train loss: 1.2149645713491177, validation loss: 1.2651631054670915.
epoch: 2296, train loss: 1.22184174760766, validation loss: 1.2642854607623557.
epoch: 2297, train loss: 1.2160166403569213, validation loss: 1.2391636319782422.
epoch: 2298, train loss: 1.2195404844546536, validation loss: 1.2871646673783013.
epoch: 2299, train loss: 1.2429730093807256, validation loss: 1.2562789295030676.
epoch: 2300, train loss: 1.2280594657320496, validation loss: 1.238739480143008.
epoch: 2301, train loss: 1.219474503753382, validation loss: 1.242048776668051.
epoch: 2302, train loss: 1.218394462121736, validation loss: 1.2372436834418254.
epoch: 2303, train loss: 1.2156451459324689, validation loss: 1.2557580211888189.
epoch: 2304, train loss: 1.2222542576833602, validation loss: 1.2335276551868604.
epoch: 2305, train loss: 1.2178843076075982, validation loss: 1.242977981982024.
epoch: 2306, train loss: 1.21370403263547, validation loss: 1.2432868998983633.
epoch: 2307, train loss: 1.215418346431277, validation loss: 1.2370353367017664.
epoch: 2308, train loss: 1.2251036648356586, validation loss: 1.252739253251449.
epoch: 2309, train loss: 1.221750037385783, validation loss: 1.2416142432586006.
epoch: 2310, train loss: 1.2237087302251692, validation loss: 1.239221391470536.
epoch: 2311, train loss: 1.2147408362922318, validation loss: 1.2339807489643926.
epoch: 2312, train loss: 1.2176477963771295, validation loss: 1.2444884777069092.
epoch: 2313, train loss: 1.2178158661641112, validation loss: 1.2504730742910635.
epoch: 2314, train loss: 1.217506422909028, validation loss: 1.2528528804364412.
epoch: 2315, train loss: 1.2211013201179854, validation loss: 1.2618093335110208.
epoch: 2316, train loss: 1.2175981790647594, validation loss: 1.2376309892405635.
epoch: 2317, train loss: 1.2189137880955268, validation loss: 1.247349713159644.
epoch: 2318, train loss: 1.2152832790252266, validation loss: 1.2550079926200535.
epoch: 2319, train loss: 1.2167680679111306, validation loss: 1.24037838500479.
epoch: 2320, train loss: 1.2167217720539198, validation loss: 1.24166086445684.
epoch: 2321, train loss: 1.213792138143417, validation loss: 1.2543575608212014.
epoch: 2322, train loss: 1.220770740727766, validation loss: 1.242269904717155.
epoch: 2323, train loss: 1.23116694896593, validation loss: 1.2520984929540884.
epoch: 2324, train loss: 1.2255015362293349, validation loss: 1.2371613616528718.
epoch: 2325, train loss: 1.217721150555742, validation loss: 1.2404783083044963.
epoch: 2326, train loss: 1.2150317157080415, validation loss: 1.2592053257900735.
epoch: 2327, train loss: 1.2165693066535739, validation loss: 1.2523193359375.
epoch: 2328, train loss: 1.2133521596226124, validation loss: 1.253765370534814.
epoch: 2329, train loss: 1.2237014300232634, validation loss: 1.250320465668388.
epoch: 2330, train loss: 1.218663130331477, validation loss: 1.2408590368602588.
epoch: 2331, train loss: 1.2159279606757907, validation loss: 1.2377346598583718.
epoch: 2332, train loss: 1.2134162231322823, validation loss: 1.239482661952143.
epoch: 2333, train loss: 1.2181089099394071, validation loss: 1.2476450515829998.
epoch: 2334, train loss: 1.2176954319717688, validation loss: 1.2332029705462249.
epoch: 2335, train loss: 1.2151428603251047, validation loss: 1.2468667548635732.
epoch: 2336, train loss: 1.2135576534708705, validation loss: 1.2503407001495361.
epoch: 2337, train loss: 1.2186387230496887, validation loss: 1.2589277080867602.
epoch: 2338, train loss: 1.2159472386771386, validation loss: 1.24178001155024.
epoch: 2339, train loss: 1.218641229725759, validation loss: 1.2495252412298452.
epoch: 2340, train loss: 1.2256242025882826, validation loss: 1.2441299376280412.
epoch: 2341, train loss: 1.2253617988813907, validation loss: 1.2505652178888735.
epoch: 2342, train loss: 1.2177987514285866, validation loss: 1.2633966933126035.
epoch: 2343, train loss: 1.220035723589976, validation loss: 1.250835833342179.
epoch: 2344, train loss: 1.2154131154401586, validation loss: 1.2489242916521819.
epoch: 2345, train loss: 1.2189258052668441, validation loss: 1.2409057513527249.
epoch: 2346, train loss: 1.2179548729450331, validation loss: 1.2468560882236646.
epoch: 2347, train loss: 1.2168058736608662, validation loss: 1.2466000577677852.
epoch: 2348, train loss: 1.224630239906661, validation loss: 1.2510328137356301.
epoch: 2349, train loss: 1.2147677447817742, validation loss: 1.2484565817791482.
epoch: 2350, train loss: 1.2183758370373228, validation loss: 1.2385269766268523.
epoch: 2351, train loss: 1.2169166912726306, validation loss: 1.2447232007980347.
epoch: 2352, train loss: 1.2181489172331783, validation loss: 1.2459723586621492.
epoch: 2353, train loss: 1.2169831400617548, validation loss: 1.2464406179345173.
epoch: 2354, train loss: 1.2179321006897392, validation loss: 1.2481131035348643.
epoch: 2355, train loss: 1.213826959286261, validation loss: 1.2462739840797756.
epoch: 2356, train loss: 1.2167973212145884, validation loss: 1.2477288971776548.
epoch: 2357, train loss: 1.218396221825836, validation loss: 1.2550390803295632.
epoch: 2358, train loss: 1.2246503195631395, validation loss: 1.26351769592451.
epoch: 2359, train loss: 1.215694727153953, validation loss: 1.2511950212976206.
epoch: 2360, train loss: 1.2154262722085376, validation loss: 1.249133612798608.
epoch: 2361, train loss: 1.2125223765679456, validation loss: 1.2538273334503174.
epoch: 2362, train loss: 1.2155838986055567, validation loss: 1.2674683228782986.
epoch: 2363, train loss: 1.2155417597621954, validation loss: 1.2659387122029844.
epoch: 2364, train loss: 1.2115101650220539, validation loss: 1.2494410017262334.
epoch: 2365, train loss: 1.2285678988202997, validation loss: 1.2979487128879712.
epoch: 2366, train loss: 1.239648245890206, validation loss: 1.2633303455684497.
epoch: 2367, train loss: 1.2300684769219214, validation loss: 1.2429863784624182.
epoch: 2368, train loss: 1.2206324142053586, validation loss: 1.2408232326092927.
epoch: 2369, train loss: 1.2162064302951918, validation loss: 1.2588012322135593.
epoch: 2370, train loss: 1.220125659890131, validation loss: 1.2446710648744002.
epoch: 2371, train loss: 1.2139989618861347, validation loss: 1.2426440352978914.
epoch: 2372, train loss: 1.2131928117997055, validation loss: 1.2417114247446475.
epoch: 2373, train loss: 1.2149286674796989, validation loss: 1.251958447953929.
epoch: 2374, train loss: 1.2117184269318886, validation loss: 1.246631171392358.
epoch: 2375, train loss: 1.2166161023148703, validation loss: 1.2520327464393948.
epoch: 2376, train loss: 1.2141088662891213, validation loss: 1.247492816137231.
epoch: 2377, train loss: 1.2136926027612949, validation loss: 1.2577590631402058.
epoch: 2378, train loss: 1.2134973937218343, validation loss: 1.2463870825974837.
epoch: 2379, train loss: 1.223253020452797, validation loss: 1.2539434899454531.
epoch: 2380, train loss: 1.2147163491730297, validation loss: 1.2475861310958862.
epoch: 2381, train loss: 1.2108569779527296, validation loss: 1.2400369333184285.
epoch: 2382, train loss: 1.2122522133206008, validation loss: 1.2991872870403787.
epoch: 2383, train loss: 1.217731744871227, validation loss: 1.2640414548956829.
epoch: 2384, train loss: 1.2165714655447444, validation loss: 1.2435735049455061.
epoch: 2385, train loss: 1.220743464767386, validation loss: 1.2568146145862082.
epoch: 2386, train loss: 1.2224541421330304, validation loss: 1.244818775550179.
epoch: 2387, train loss: 1.2264193701087882, validation loss: 1.250593470490497.
epoch: 2388, train loss: 1.2157945775110788, validation loss: 1.243654676105665.
epoch: 2389, train loss: 1.2098920454672717, validation loss: 1.2413062686505525.
epoch: 2390, train loss: 1.2159953128307237, validation loss: 1.2445801237355107.
epoch: 2391, train loss: 1.2185800567679448, validation loss: 1.255289191785066.
epoch: 2392, train loss: 1.217841207434278, validation loss: 1.2441255890804788.
epoch: 2393, train loss: 1.223108368182401, validation loss: 1.2493703779966936.
epoch: 2394, train loss: 1.214707226928221, validation loss: 1.248705858769624.
epoch: 2395, train loss: 1.2154125511099438, validation loss: 1.2434593594592551.
epoch: 2396, train loss: 1.2216082603559582, validation loss: 1.2430675444395647.
epoch: 2397, train loss: 1.2407060511615298, validation loss: 1.2625207590020222.
epoch: 2398, train loss: 1.2287754793779566, validation loss: 1.284159199051235.
epoch: 2399, train loss: 1.2214016061310375, validation loss: 1.2476870132529216.
epoch: 2400, train loss: 1.2174277655575254, validation loss: 1.2353402531665305.
epoch: 2401, train loss: 1.2143549733205672, validation loss: 1.2473761257917986.
epoch: 2402, train loss: 1.2145291621531915, validation loss: 1.2412013696587605.
epoch: 2403, train loss: 1.2184455296315184, validation loss: 1.2440113243849382.
epoch: 2404, train loss: 1.2123314776551832, validation loss: 1.2349018013995627.
epoch: 2405, train loss: 1.2121350535559, validation loss: 1.2504539852556975.
epoch: 2406, train loss: 1.215351495174093, validation loss: 1.2442109895789104.
epoch: 2407, train loss: 1.2145398144328265, validation loss: 1.2506787103155386.
epoch: 2408, train loss: 1.2153857990142403, validation loss: 1.2602867976478909.
epoch: 2409, train loss: 1.2213187600494524, validation loss: 1.2642882751381916.
epoch: 2410, train loss: 1.2188891620810973, validation loss: 1.238898754119873.
epoch: 2411, train loss: 1.2197658698493188, validation loss: 1.2445219133211218.
epoch: 2412, train loss: 1.2179910666352018, validation loss: 1.2494789517444114.
epoch: 2413, train loss: 1.2178947805264675, validation loss: 1.255177668903185.
epoch: 2414, train loss: 1.2196394172283487, validation loss: 1.2522096996722014.
epoch: 2415, train loss: 1.2144037988207756, validation loss: 1.2414447898450105.
epoch: 2416, train loss: 1.2157228725765823, validation loss: 1.2399822836336882.
epoch: 2417, train loss: 1.2165119210514455, validation loss: 1.2586192255434783.
epoch: 2418, train loss: 1.224387288093567, validation loss: 1.2564125061035156.
epoch: 2419, train loss: 1.2179445334530752, validation loss: 1.2432981574017068.
epoch: 2420, train loss: 1.2120634656433666, validation loss: 1.2547384966974673.
epoch: 2421, train loss: 1.2159807102395854, validation loss: 1.2639226706131645.
epoch: 2422, train loss: 1.2207109578158877, validation loss: 1.2441777353701384.
epoch: 2423, train loss: 1.2141037074797745, validation loss: 1.2490859290827876.
epoch: 2424, train loss: 1.214128144290469, validation loss: 1.245655101278554.
epoch: 2425, train loss: 1.2157200574874878, validation loss: 1.2421265270399011.
epoch: 2426, train loss: 1.215120824105149, validation loss: 1.2567574511403623.
epoch: 2427, train loss: 1.2173531963190902, validation loss: 1.248868201089942.
epoch: 2428, train loss: 1.2135076500953885, validation loss: 1.2438529678013013.
epoch: 2429, train loss: 1.2138190761618657, validation loss: 1.2728596407434214.
epoch: 2430, train loss: 1.2226690228925932, validation loss: 1.2443753377251003.
epoch: 2431, train loss: 1.215923029348391, validation loss: 1.2451999394789985.
epoch: 2432, train loss: 1.2107573430472558, validation loss: 1.2498830142228499.
epoch: 2433, train loss: 1.2132803245421944, validation loss: 1.249735723371091.
epoch: 2434, train loss: 1.223339524837809, validation loss: 1.257109486538431.
epoch: 2435, train loss: 1.218086499686635, validation loss: 1.246008504991946.
epoch: 2436, train loss: 1.2160545062581334, validation loss: 1.2478962877522344.
epoch: 2437, train loss: 1.2119788522020392, validation loss: 1.2670585228049236.
epoch: 2438, train loss: 1.2172830870392126, validation loss: 1.2421834054200545.
epoch: 2439, train loss: 1.2148836840183364, validation loss: 1.2502571137055107.
epoch: 2440, train loss: 1.2130657084491274, validation loss: 1.2765766434047534.
epoch: 2441, train loss: 1.2205294687813575, validation loss: 1.2567761825478596.
epoch: 2442, train loss: 1.2137889282419048, validation loss: 1.272825142611628.
epoch: 2443, train loss: 1.2209968479401474, validation loss: 1.2853576877842778.
epoch: 2444, train loss: 1.2347801934688463, validation loss: 1.2471444865931636.
epoch: 2445, train loss: 1.2173533516192654, validation loss: 1.2472942704739778.
epoch: 2446, train loss: 1.2167725836465118, validation loss: 1.2451078217962515.
epoch: 2447, train loss: 1.215603443460727, validation loss: 1.246432179990022.
epoch: 2448, train loss: 1.218288455534419, validation loss: 1.2487019093140312.
epoch: 2449, train loss: 1.2131146269107083, validation loss: 1.2410681506861811.
epoch: 2450, train loss: 1.2125355748955262, validation loss: 1.2523094985796057.
epoch: 2451, train loss: 1.2171499718219863, validation loss: 1.2546798820080964.
epoch: 2452, train loss: 1.2194980240743094, validation loss: 1.2469549956529036.
epoch: 2453, train loss: 1.214250383027103, validation loss: 1.2437656806862873.
epoch: 2454, train loss: 1.2118333610919638, validation loss: 1.2558570996574734.
epoch: 2455, train loss: 1.212725397643693, validation loss: 1.2596623742062112.
epoch: 2456, train loss: 1.252455197343039, validation loss: 1.2770038273023523.
epoch: 2457, train loss: 1.2385313937423426, validation loss: 1.2485760398533032.
epoch: 2458, train loss: 1.2227851163356676, validation loss: 1.2423607784768809.
epoch: 2459, train loss: 1.2181016097375013, validation loss: 1.2659687788590142.
epoch: 2460, train loss: 1.2173724513535107, validation loss: 1.241079314895298.
epoch: 2461, train loss: 1.2145757806410484, validation loss: 1.245352206022843.
epoch: 2462, train loss: 1.2151938939313276, validation loss: 1.2390007609906404.
epoch: 2463, train loss: 1.2113139454377901, validation loss: 1.2431686391001162.
epoch: 2464, train loss: 1.2129531300396001, validation loss: 1.2691376934880796.
epoch: 2465, train loss: 1.2264972739263411, validation loss: 1.2468048852422964.
epoch: 2466, train loss: 1.2162752293665475, validation loss: 1.240743460862533.
epoch: 2467, train loss: 1.210715593547996, validation loss: 1.48765956837198.
epoch: 2468, train loss: 1.236813509136165, validation loss: 1.254302283991938.
epoch: 2469, train loss: 1.2214789882712407, validation loss: 1.2430615995241248.
epoch: 2470, train loss: 1.2119344527568292, validation loss: 1.2447609123976335.
epoch: 2471, train loss: 1.2159027747057993, validation loss: 1.2440717116646145.
epoch: 2472, train loss: 1.2123690942011842, validation loss: 1.247968782549319.
epoch: 2473, train loss: 1.2224400295030087, validation loss: 1.2550363903460295.
epoch: 2474, train loss: 1.2165929505584436, validation loss: 1.2539779051490452.
epoch: 2475, train loss: 1.2111269235610962, validation loss: 1.2429629823435908.
epoch: 2476, train loss: 1.212285010092849, validation loss: 1.2400572507277778.
epoch: 2477, train loss: 1.2225525269814588, validation loss: 1.2486688157786494.
epoch: 2478, train loss: 1.21386710219427, validation loss: 1.2488479821578315.
epoch: 2479, train loss: 1.2187453016228633, validation loss: 1.2512475200321362.
epoch: 2480, train loss: 1.2110936936982182, validation loss: 1.2547612190246582.
epoch: 2481, train loss: 1.2138161134282384, validation loss: 1.2504060942193735.
epoch: 2482, train loss: 1.2206676312542837, validation loss: 1.2558220780414084.
epoch: 2483, train loss: 1.217805885393685, validation loss: 1.2493274989335432.
epoch: 2484, train loss: 1.213656726233456, validation loss: 1.2754959230837615.
epoch: 2485, train loss: 1.2149016386872038, validation loss: 1.243319464766461.
epoch: 2486, train loss: 1.2259287637308103, validation loss: 1.241432407627935.
epoch: 2487, train loss: 1.2140849314698385, validation loss: 1.2436714535174163.
epoch: 2488, train loss: 1.2102122536493003, validation loss: 1.2739482547925867.
epoch: 2489, train loss: 1.2145110576524647, validation loss: 1.2428369677585105.
epoch: 2490, train loss: 1.2163344151383146, validation loss: 1.2392619018969329.
epoch: 2491, train loss: 1.2128298840391527, validation loss: 1.2515327256658804.
epoch: 2492, train loss: 1.210996785295119, validation loss: 1.2448863827663919.
epoch: 2493, train loss: 1.2166326111609782, validation loss: 1.2467853504678477.
epoch: 2494, train loss: 1.2130762983899597, validation loss: 1.240042173344156.
epoch: 2495, train loss: 1.213147726627665, validation loss: 1.246572707010352.
epoch: 2496, train loss: 1.2188396585097008, validation loss: 1.2478442451228267.
epoch: 2497, train loss: 1.2136264022337186, validation loss: 1.2455011917197185.
epoch: 2498, train loss: 1.211372585471617, validation loss: 1.2394161431685737.
epoch: 2499, train loss: 1.223349309842521, validation loss: 1.2522634578787761.
epoch: 2500, train loss: 1.216619325340341, validation loss: 1.2657034397125244.
epoch: 2501, train loss: 1.2227842884326199, validation loss: 1.255682162616564.
epoch: 2502, train loss: 1.2110931337426563, validation loss: 1.237729523492896.
epoch: 2503, train loss: 1.209876869796613, validation loss: 1.2500465175379878.
epoch: 2504, train loss: 1.2152561233677994, validation loss: 1.2565436363220215.
epoch: 2505, train loss: 1.2131406965605709, validation loss: 1.2458918561106143.
epoch: 2506, train loss: 1.2143192794344841, validation loss: 1.2451159954071045.
epoch: 2507, train loss: 1.2140968578671096, validation loss: 1.2561550451361614.
epoch: 2508, train loss: 1.2136686154461782, validation loss: 1.2534056798271511.
epoch: 2509, train loss: 1.218402930355947, validation loss: 1.240011427713477.
epoch: 2510, train loss: 1.2103032453344502, validation loss: 1.2573467285736748.
epoch: 2511, train loss: 1.211475895085466, validation loss: 1.2510782635730247.
epoch: 2512, train loss: 1.2129120137713372, validation loss: 1.246914469677469.
epoch: 2513, train loss: 1.213832774293532, validation loss: 1.3057732685752537.
epoch: 2514, train loss: 1.2115604385323482, validation loss: 1.2502446278281834.
epoch: 2515, train loss: 1.2168747580379522, validation loss: 1.257032757220061.
epoch: 2516, train loss: 1.2132708184216001, validation loss: 1.2500643574673196.
epoch: 2517, train loss: 1.210433613269701, validation loss: 1.2747820304787678.
epoch: 2518, train loss: 1.2104361975958589, validation loss: 1.2496241071949834.
epoch: 2519, train loss: 1.2168289280812674, validation loss: 1.2575132639511772.
epoch: 2520, train loss: 1.2142153497135968, validation loss: 1.3056372248608132.
epoch: 2521, train loss: 1.2243348425681437, validation loss: 1.2626743938611902.
epoch: 2522, train loss: 1.2190647267420358, validation loss: 1.249906679858332.
epoch: 2523, train loss: 1.2169374566559399, validation loss: 1.2448365429173345.
epoch: 2524, train loss: 1.2127169414397774, validation loss: 1.2630880397299062.
epoch: 2525, train loss: 1.2165353932511915, validation loss: 1.2720320224761963.
epoch: 2526, train loss: 1.214471332523801, validation loss: 1.2453563990800276.
epoch: 2527, train loss: 1.2134485594723203, validation loss: 1.2411644303280374.
epoch: 2528, train loss: 1.2194465256612235, validation loss: 1.2468551086342854.
epoch: 2529, train loss: 1.2182545071348139, validation loss: 1.2476897809816443.
epoch: 2530, train loss: 1.2162009915080638, validation loss: 1.2662858963012695.
epoch: 2531, train loss: 1.2133586362961235, validation loss: 1.2483847607737002.
epoch: 2532, train loss: 1.2117568691936107, validation loss: 1.2492805149244226.
epoch: 2533, train loss: 1.2104237145240153, validation loss: 1.245313234951185.
epoch: 2534, train loss: 1.2091236814446407, validation loss: 1.2679504467093425.
epoch: 2535, train loss: 1.215008792527225, validation loss: 1.3196256886357847.
epoch: 2536, train loss: 1.253152334361995, validation loss: 1.2525559767432835.
epoch: 2537, train loss: 1.2256949363498513, validation loss: 1.2408470537351526.
epoch: 2538, train loss: 1.2177586621100749, validation loss: 1.2526313584783804.
epoch: 2539, train loss: 1.2169830219461284, validation loss: 1.239135944324991.
epoch: 2540, train loss: 1.2317158607167935, validation loss: 1.2603527722151384.
epoch: 2541, train loss: 1.2204202511988649, validation loss: 1.247278726619223.
epoch: 2542, train loss: 1.2106422929588807, validation loss: 1.2462070299231487.
epoch: 2543, train loss: 1.209843419013767, validation loss: 1.2401679857917454.
epoch: 2544, train loss: 1.219817671207113, validation loss: 1.2439637080482815.
epoch: 2545, train loss: 1.2159166795398118, validation loss: 1.3564623386963555.
epoch: 2546, train loss: 1.2607791565973825, validation loss: 1.263975387034209.
epoch: 2547, train loss: 1.2346017338813993, validation loss: 1.2542188841363657.
epoch: 2548, train loss: 1.2254984203828585, validation loss: 1.2489048398059348.
epoch: 2549, train loss: 1.219638028276076, validation loss: 1.2727233378783516.
epoch: 2550, train loss: 1.2180375473214946, validation loss: 1.248510568038277.
epoch: 2551, train loss: 1.2156907068480045, validation loss: 1.2425659013831096.
epoch: 2552, train loss: 1.2116228495169123, validation loss: 1.238733022109322.
epoch: 2553, train loss: 1.2137271143974515, validation loss: 1.252214509507884.
epoch: 2554, train loss: 1.2133727117415962, validation loss: 1.2413563883822898.
epoch: 2555, train loss: 1.2148895624580733, validation loss: 1.2458632562471472.
epoch: 2556, train loss: 1.2116560750051375, validation loss: 1.258741223293802.
epoch: 2557, train loss: 1.211172918660925, validation loss: 1.2491431391757468.
epoch: 2558, train loss: 1.2176870151397285, validation loss: 1.2572482150533926.
epoch: 2559, train loss: 1.2198902007636674, validation loss: 1.2327614504358042.
epoch: 2560, train loss: 1.2106100605168473, validation loss: 1.264386052670686.
epoch: 2561, train loss: 1.2143497576407336, validation loss: 1.2504954700884612.
epoch: 2562, train loss: 1.2167296639276206, validation loss: 1.239912960840308.
epoch: 2563, train loss: 1.212795663317409, validation loss: 1.2740482973015828.
epoch: 2564, train loss: 1.2093990100633114, validation loss: 1.2484464489895364.
epoch: 2565, train loss: 1.2126079928984337, validation loss: 1.2385872084161509.
epoch: 2566, train loss: 1.2150266750143208, validation loss: 1.247689153837121.
epoch: 2567, train loss: 1.2112254888639538, validation loss: 1.2501767614613408.
epoch: 2568, train loss: 1.2075920072170572, validation loss: 1.2400256447170093.
epoch: 2569, train loss: 1.2132143154056794, validation loss: 1.240399199983348.
epoch: 2570, train loss: 1.2123004416806982, validation loss: 1.2795988684115203.
epoch: 2571, train loss: 1.2116143167565723, validation loss: 1.251082394434058.
epoch: 2572, train loss: 1.2103897311271878, validation loss: 1.2503662731336511.
epoch: 2573, train loss: 1.2132284105370899, validation loss: 1.2409563582876455.
epoch: 2574, train loss: 1.2114013936541497, validation loss: 1.2544046433075615.
epoch: 2575, train loss: 1.2110953626282719, validation loss: 1.2531755903492803.
epoch: 2576, train loss: 1.214693599884663, validation loss: 1.2478627640268076.
epoch: 2577, train loss: 1.211470455204675, validation loss: 1.257716178894043.
epoch: 2578, train loss: 1.2238256559459442, validation loss: 1.2416469169699627.
epoch: 2579, train loss: 1.2122617467827754, validation loss: 1.241941187692725.
epoch: 2580, train loss: 1.2119499893363463, validation loss: 1.2386770352073337.
epoch: 2581, train loss: 1.2173944689811917, validation loss: 1.284402619237485.
epoch: 2582, train loss: 1.222059257533572, validation loss: 1.2568682432174683.
epoch: 2583, train loss: 1.2131099197842659, validation loss: 1.2501602483832317.
epoch: 2584, train loss: 1.2111042595784598, validation loss: 1.2420882453089175.
epoch: 2585, train loss: 1.2080615233937535, validation loss: 1.2474102870277737.
epoch: 2586, train loss: 1.2093096085644643, validation loss: 1.3197899175726848.
epoch: 2587, train loss: 1.2185446997301295, validation loss: 1.2508399797522503.
epoch: 2588, train loss: 1.2136794864584546, validation loss: 1.281580810961516.
epoch: 2589, train loss: 1.239212250490801, validation loss: 1.272357551947884.
epoch: 2590, train loss: 1.2220144162484265, validation loss: 1.2698538199714993.
epoch: 2591, train loss: 1.2194944598259183, validation loss: 1.2485368407290915.
epoch: 2592, train loss: 1.2170568770224894, validation loss: 1.2437918497168499.
epoch: 2593, train loss: 1.215894933140606, validation loss: 1.249661290127298.
epoch: 2594, train loss: 1.215014654562014, validation loss: 1.2528490709221882.
epoch: 2595, train loss: 1.2143441952696634, validation loss: 1.2497242740962817.
epoch: 2596, train loss: 1.2172983359853062, validation loss: 1.240745741388072.
epoch: 2597, train loss: 1.2131284344086952, validation loss: 1.2591614308564558.
epoch: 2598, train loss: 1.2174397553872625, validation loss: 1.2598867105401081.
epoch: 2599, train loss: 1.2146923192050478, validation loss: 1.2455229707386182.
epoch: 2600, train loss: 1.2240984461723117, validation loss: 1.2557969041492627.
epoch: 2601, train loss: 1.217860570741356, validation loss: 1.2730655514675637.
epoch: 2602, train loss: 1.226443241495605, validation loss: 1.2420482272687166.
epoch: 2603, train loss: 1.215896175542009, validation loss: 1.2596687700437463.
epoch: 2604, train loss: 1.2233258015518889, validation loss: 1.2445222605829653.
epoch: 2605, train loss: 1.220550299784459, validation loss: 1.2843100402666174.
epoch: 2606, train loss: 1.2244556759475569, validation loss: 1.2455713126970374.
epoch: 2607, train loss: 1.2134042715807574, validation loss: 1.2468327491179756.
epoch: 2608, train loss: 1.2156058123352331, validation loss: 1.2492497226466304.
epoch: 2609, train loss: 1.2122823995187741, validation loss: 1.242337123207424.
epoch: 2610, train loss: 1.2165491373167125, validation loss: 1.2453888913859492.
epoch: 2611, train loss: 1.2114617212103047, validation loss: 1.243518336959507.
epoch: 2612, train loss: 1.2066018340784475, validation loss: 1.258196877396625.
epoch: 2613, train loss: 1.226931402442652, validation loss: 1.246733696564384.
epoch: 2614, train loss: 1.2126560342421226, validation loss: 1.2579094327014426.
epoch: 2615, train loss: 1.2098298018131781, validation loss: 1.2865260372991147.
epoch: 2616, train loss: 1.2141652730626797, validation loss: 1.2494450081949648.
epoch: 2617, train loss: 1.2181994805642224, validation loss: 1.300478712372158.
epoch: 2618, train loss: 1.220137706590355, validation loss: 1.252681887668112.
epoch: 2619, train loss: 1.212234357081422, validation loss: 1.2560608801634416.
epoch: 2620, train loss: 1.220154305116846, validation loss: 1.2382937151452769.
epoch: 2621, train loss: 1.2132354241992356, validation loss: 1.26287303281867.
epoch: 2622, train loss: 1.2104126947735427, validation loss: 1.2428830343744028.
epoch: 2623, train loss: 1.2128932990065409, validation loss: 1.2478173038233882.
epoch: 2624, train loss: 1.2066611423404938, validation loss: 1.2377831987712695.
epoch: 2625, train loss: 1.2103887566732705, validation loss: 1.252674761025802.
epoch: 2626, train loss: 1.212780406715673, validation loss: 1.2724484671717105.
epoch: 2627, train loss: 1.2156984652947942, validation loss: 1.264136122620624.
epoch: 2628, train loss: 1.219759406299766, validation loss: 1.231675764788752.
epoch: 2629, train loss: 1.2091976765098922, validation loss: 1.244321558786475.
epoch: 2630, train loss: 1.2186172445979686, validation loss: 1.246782836706742.
epoch: 2631, train loss: 1.211073060648157, validation loss: 1.257731178532476.
epoch: 2632, train loss: 1.211764408907759, validation loss: 1.263941650805266.
epoch: 2633, train loss: 1.2294709802767552, validation loss: 1.24559820216635.
epoch: 2634, train loss: 1.2155897759516305, validation loss: 1.2391876759736433.
epoch: 2635, train loss: 1.2128907660825536, validation loss: 1.2480486216752424.
epoch: 2636, train loss: 1.2212302520734455, validation loss: 1.2587253114451533.
epoch: 2637, train loss: 1.2149630281903328, validation loss: 1.2382578383321348.
epoch: 2638, train loss: 1.2118889858963293, validation loss: 1.2575476169586182.
epoch: 2639, train loss: 1.216529665736977, validation loss: 1.254627243332241.
epoch: 2640, train loss: 1.2124923128600513, validation loss: 1.2359947018001392.
epoch: 2641, train loss: 1.210358766240811, validation loss: 1.238630984140479.
epoch: 2642, train loss: 1.2147372195480066, validation loss: 1.243991214296092.
epoch: 2643, train loss: 1.2138922225444688, validation loss: 1.2373633436534717.
epoch: 2644, train loss: 1.2080026482223372, validation loss: 1.2371740237526272.
epoch: 2645, train loss: 1.212275225088137, validation loss: 1.2355877834817637.
epoch: 2646, train loss: 1.2086852482699473, validation loss: 1.241860006166541.
epoch: 2647, train loss: 1.2194722890853882, validation loss: 1.241738682207854.
epoch: 2648, train loss: 1.2120552128608073, validation loss: 1.2527482250462407.
epoch: 2649, train loss: 1.211462595047207, validation loss: 1.247333728748819.
epoch: 2650, train loss: 1.2124773045198634, validation loss: 1.23753415501636.
epoch: 2651, train loss: 1.2063847955213773, validation loss: 1.2428920217182324.
epoch: 2652, train loss: 1.2093331212297491, validation loss: 1.2449357665103415.
epoch: 2653, train loss: 1.2081869764065525, validation loss: 1.2392691943956458.
epoch: 2654, train loss: 1.2143180217217961, validation loss: 1.2460738057675569.
epoch: 2655, train loss: 1.212294181552502, validation loss: 1.291823553002399.
epoch: 2656, train loss: 1.2212741440589274, validation loss: 1.2526928860208262.
epoch: 2657, train loss: 1.221690418523386, validation loss: 1.2383391235185706.
epoch: 2658, train loss: 1.2135801588723418, validation loss: 1.2455453872680664.
epoch: 2659, train loss: 1.209749773008014, validation loss: 1.2378290684326836.
epoch: 2660, train loss: 1.2166072753591275, validation loss: 1.2532932084539663.
epoch: 2661, train loss: 1.2143811107775486, validation loss: 1.244644082110861.
epoch: 2662, train loss: 1.2101464709010692, validation loss: 1.2460284544074016.
epoch: 2663, train loss: 1.2163169482432374, validation loss: 1.243473716404127.
epoch: 2664, train loss: 1.2058709323953052, validation loss: 1.2349148625912874.
epoch: 2665, train loss: 1.2063751997204002, validation loss: 1.2491252629653267.
epoch: 2666, train loss: 1.211239604774965, validation loss: 1.2581916581029478.
epoch: 2667, train loss: 1.216328934791985, validation loss: 1.2543554202370022.
epoch: 2668, train loss: 1.2214839283479464, validation loss: 1.2460170776947685.
epoch: 2669, train loss: 1.2120697082729515, validation loss: 1.2552261093388433.
epoch: 2670, train loss: 1.2154850248896747, validation loss: 1.2382503747940063.
epoch: 2671, train loss: 1.2198500797289227, validation loss: 1.2373599902443264.
epoch: 2672, train loss: 1.2126777237708415, validation loss: 1.2506653536920962.
epoch: 2673, train loss: 1.2216745779054974, validation loss: 1.241014874499777.
epoch: 2674, train loss: 1.2111369382350816, validation loss: 1.235117186670718.
epoch: 2675, train loss: 1.2177729584755155, validation loss: 1.2421252831168796.
epoch: 2676, train loss: 1.2086870560952283, validation loss: 1.2572828842246013.
epoch: 2677, train loss: 1.2091760941601675, validation loss: 1.2703263655952786.
epoch: 2678, train loss: 1.2060955194158292, validation loss: 1.2618935833806577.
epoch: 2679, train loss: 1.2052978364699478, validation loss: 1.2548477857009224.
epoch: 2680, train loss: 1.2074741518825567, validation loss: 1.2659305023110432.
epoch: 2681, train loss: 1.2229530034808938, validation loss: 1.2423444623532502.
epoch: 2682, train loss: 1.2104261719852412, validation loss: 1.2551584451094917.
epoch: 2683, train loss: 1.218166401626867, validation loss: 1.2382145912750908.
epoch: 2684, train loss: 1.204044153930944, validation loss: 1.2610892420229705.
epoch: 2685, train loss: 1.2244006220353854, validation loss: 1.244640070459117.
epoch: 2686, train loss: 1.212031243044302, validation loss: 1.2400818441225134.
epoch: 2687, train loss: 1.209289498285416, validation loss: 1.244374104168104.
epoch: 2688, train loss: 1.2057801703794286, validation loss: 1.2544459933819978.
epoch: 2689, train loss: 1.2078314614952157, validation loss: 1.2481945960418037.
epoch: 2690, train loss: 1.209852669217171, validation loss: 1.2384201184563015.
epoch: 2691, train loss: 1.2171630071937491, validation loss: 1.2415372340575508.
epoch: 2692, train loss: 1.2078063969218402, validation loss: 1.2488679367562998.
epoch: 2693, train loss: 1.2108270389224411, validation loss: 1.2386331869208294.
epoch: 2694, train loss: 1.2125825236696717, validation loss: 1.2522233880084495.
epoch: 2695, train loss: 1.21468336429071, validation loss: 1.2558335065841675.
epoch: 2696, train loss: 1.2171430467465603, validation loss: 1.249612797861514.
epoch: 2697, train loss: 1.2056338229310621, validation loss: 1.2588553946951162.
epoch: 2698, train loss: 1.2146101304150503, validation loss: 1.2421247596326082.
epoch: 2699, train loss: 1.2054355144500732, validation loss: 1.2484158588492351.
epoch: 2700, train loss: 1.2032645601745044, validation loss: 1.253588899322178.
epoch: 2701, train loss: 1.2103070195661771, validation loss: 1.251054463179215.
epoch: 2702, train loss: 1.2098113867121005, validation loss: 1.2484219748040903.
epoch: 2703, train loss: 1.2064615958327547, validation loss: 1.270705565162327.
epoch: 2704, train loss: 1.2112911458409161, validation loss: 1.2607034341148708.
epoch: 2705, train loss: 1.2147857847563717, validation loss: 1.2505703749863997.
epoch: 2706, train loss: 1.2108926226239685, validation loss: 1.300827549851459.
epoch: 2707, train loss: 1.2385300561922405, validation loss: 1.241642977880395.
epoch: 2708, train loss: 1.2153525538400773, validation loss: 1.2629839648371157.
epoch: 2709, train loss: 1.2107486867029733, validation loss: 1.276791759159254.
epoch: 2710, train loss: 1.2141480861453835, validation loss: 1.2470583708389946.
epoch: 2711, train loss: 1.2073392354020285, validation loss: 1.2678907384043154.
epoch: 2712, train loss: 1.2220141111163918, validation loss: 1.2507922804873923.
epoch: 2713, train loss: 1.2355822051337007, validation loss: 1.2563927640085635.
epoch: 2714, train loss: 1.2188046164468889, validation loss: 1.2478702379309612.
epoch: 2715, train loss: 1.2193188732917155, validation loss: 1.24820746027905.
epoch: 2716, train loss: 1.2154190934032476, validation loss: 1.2450708513674529.
epoch: 2717, train loss: 1.2095115162910672, validation loss: 1.2473329150158425.
epoch: 2718, train loss: 1.206206530605981, validation loss: 1.2445482482080874.
epoch: 2719, train loss: 1.209492553264723, validation loss: 1.249314572500146.
epoch: 2720, train loss: 1.2071012050733654, validation loss: 1.2559680679570073.
epoch: 2721, train loss: 1.2063324101474306, validation loss: 1.2414516832517541.
epoch: 2722, train loss: 1.2089683670516407, validation loss: 1.2528055543484895.
epoch: 2723, train loss: 1.2152426024095728, validation loss: 1.2889689725378286.
epoch: 2724, train loss: 1.2092489879065698, validation loss: 1.2943139024402783.
epoch: 2725, train loss: 1.2140134069897712, validation loss: 1.266260509905608.
epoch: 2726, train loss: 1.2207537583254893, validation loss: 1.2418499874032063.
epoch: 2727, train loss: 1.211040757118015, validation loss: 1.278388982233794.
epoch: 2728, train loss: 1.2194021207476975, validation loss: 1.2499985332074373.
epoch: 2729, train loss: 1.2108737175617743, validation loss: 1.2745416890019956.
epoch: 2730, train loss: 1.208930064778809, validation loss: 1.2647465622943381.
epoch: 2731, train loss: 1.2167380927899563, validation loss: 1.2430003414983335.
epoch: 2732, train loss: 1.2150285287734566, validation loss: 1.2423370247301848.
epoch: 2733, train loss: 1.208367700970501, validation loss: 1.2544647714366084.
epoch: 2734, train loss: 1.2069507574816363, validation loss: 1.2384708342344866.
epoch: 2735, train loss: 1.21489602053931, validation loss: 1.2443917523259702.
epoch: 2736, train loss: 1.2101506836917422, validation loss: 1.2424297954725183.
epoch: 2737, train loss: 1.2111557568978826, validation loss: 1.2475886655890422.
epoch: 2738, train loss: 1.2305040173574324, validation loss: 1.279891910760299.
epoch: 2739, train loss: 1.2454718329490873, validation loss: 1.2536772904188738.
epoch: 2740, train loss: 1.2232131717401906, validation loss: 1.269557880318683.
epoch: 2741, train loss: 1.2248559118410862, validation loss: 1.2378587515457817.
epoch: 2742, train loss: 1.2213236410683448, validation loss: 1.249692704366601.
epoch: 2743, train loss: 1.2120852393841526, validation loss: 1.2433652204015981.
epoch: 2744, train loss: 1.2165588545143058, validation loss: 1.249076423437699.
epoch: 2745, train loss: 1.2098196329326805, validation loss: 1.2602778828662375.
epoch: 2746, train loss: 1.212039901575911, validation loss: 1.265191306238589.
epoch: 2747, train loss: 1.216423923816156, validation loss: 1.2408718648164168.
epoch: 2748, train loss: 1.2100663753824497, validation loss: 1.2705484265866487.
epoch: 2749, train loss: 1.2067899988331925, validation loss: 1.2463573113731716.
epoch: 2750, train loss: 1.2071869690483863, validation loss: 1.251684660496919.
epoch: 2751, train loss: 1.211204557243837, validation loss: 1.252565912578417.
epoch: 2752, train loss: 1.226340239201117, validation loss: 1.2578477963157322.
epoch: 2753, train loss: 1.210471240752334, validation loss: 1.2384236740029377.
epoch: 2754, train loss: 1.2086626553754194, validation loss: 1.2645075994989146.
epoch: 2755, train loss: 1.2128183098014342, validation loss: 1.2494427950485893.
epoch: 2756, train loss: 1.2091064015659718, validation loss: 1.244924026986827.
epoch: 2757, train loss: 1.2047652935763018, validation loss: 1.2575945698696633.
epoch: 2758, train loss: 1.2063978757333318, validation loss: 1.2389497912448386.
epoch: 2759, train loss: 1.2042627957982754, validation loss: 1.2708005386850107.
epoch: 2760, train loss: 1.20545704977228, validation loss: 1.266733319863029.
epoch: 2761, train loss: 1.2187484502792358, validation loss: 1.2478810082311216.
epoch: 2762, train loss: 1.206487388785826, validation loss: 1.2880442868108335.
epoch: 2763, train loss: 1.2061212773716778, validation loss: 1.2407414861347363.
epoch: 2764, train loss: 1.2112605462380506, validation loss: 1.2629596357760222.
epoch: 2765, train loss: 1.21109468674441, validation loss: 1.2494520052619602.
epoch: 2766, train loss: 1.2140612438184406, validation loss: 1.2509251884792163.
epoch: 2767, train loss: 1.2150364829859603, validation loss: 1.260224523751632.
epoch: 2768, train loss: 1.2223370479881217, validation loss: 1.245123080585314.
epoch: 2769, train loss: 1.2116410447916854, validation loss: 1.2452200858489326.
epoch: 2770, train loss: 1.2059842818373934, validation loss: 1.251633441966513.
epoch: 2771, train loss: 1.2056333110966813, validation loss: 1.250778835752736.
epoch: 2772, train loss: 1.2108359599332197, validation loss: 1.2438915449640024.
epoch: 2773, train loss: 1.2126216877491103, validation loss: 1.2850946447123652.
epoch: 2774, train loss: 1.2158921180515114, validation loss: 1.2596548951190452.
epoch: 2775, train loss: 1.2081689298699756, validation loss: 1.2488837501277095.
epoch: 2776, train loss: 1.2109965600004984, validation loss: 1.2512839514276255.
epoch: 2777, train loss: 1.2077550691202146, validation loss: 1.2481950417808865.
epoch: 2778, train loss: 1.2118093967437744, validation loss: 1.2726583843645842.
epoch: 2779, train loss: 1.2185704544049885, validation loss: 1.2450276457745095.
epoch: 2780, train loss: 1.2079989046131798, validation loss: 1.2516893874044004.
epoch: 2781, train loss: 1.2082917132508864, validation loss: 1.2505317459935728.
epoch: 2782, train loss: 1.2100709545502968, validation loss: 1.2437196969985962.
epoch: 2783, train loss: 1.2097448263693293, validation loss: 1.2474898566370425.
epoch: 2784, train loss: 1.2140056518239712, validation loss: 1.2361289884733118.
epoch: 2785, train loss: 1.2178221426972555, validation loss: 1.2441487312316895.
epoch: 2786, train loss: 1.2067170580592723, validation loss: 1.2612024131028547.
epoch: 2787, train loss: 1.2094172950184674, validation loss: 1.2457294775092083.
epoch: 2788, train loss: 1.2087554406682286, validation loss: 1.2423711393190466.
epoch: 2789, train loss: 1.2364927158443206, validation loss: 1.2567591874495796.
epoch: 2790, train loss: 1.2240170306022014, validation loss: 1.2478567154511162.
epoch: 2791, train loss: 1.2122098721495462, validation loss: 1.2433050093443498.
epoch: 2792, train loss: 1.2071432531426807, validation loss: 1.2514080742131108.
epoch: 2793, train loss: 1.2041681654956362, validation loss: 1.2431853543157163.
epoch: 2794, train loss: 1.2113791966657026, validation loss: 1.2448937530102937.
epoch: 2795, train loss: 1.2073015849524682, validation loss: 1.2782204773115076.
epoch: 2796, train loss: 1.204673445552861, validation loss: 1.248223118160082.
epoch: 2797, train loss: 1.2105451330132442, validation loss: 1.2686098969500998.
epoch: 2798, train loss: 1.215048946371866, validation loss: 1.252389026724774.
epoch: 2799, train loss: 1.2147745079950456, validation loss: 1.2408457061518794.
epoch: 2800, train loss: 1.2195599833759694, validation loss: 1.2503691186075625.
epoch: 2801, train loss: 1.212410235623701, validation loss: 1.2529726702234019.
epoch: 2802, train loss: 1.2140833314405668, validation loss: 1.2444675953491875.
epoch: 2803, train loss: 1.2077541602860897, validation loss: 1.2700507329857869.
epoch: 2804, train loss: 1.2111041644297609, validation loss: 1.2453292608261108.
epoch: 2805, train loss: 1.2110721704063065, validation loss: 1.2471759163815042.
epoch: 2806, train loss: 1.2034377340876727, validation loss: 1.2688467969065127.
epoch: 2807, train loss: 1.2166475243524675, validation loss: 1.2575266672217327.
epoch: 2808, train loss: 1.2069992537892194, validation loss: 1.2524645484012107.
epoch: 2809, train loss: 1.2053395487846585, validation loss: 1.2496398894683174.
epoch: 2810, train loss: 1.208925507484226, validation loss: 1.2919295559758726.
epoch: 2811, train loss: 1.2161980637716592, validation loss: 1.272383161213087.
epoch: 2812, train loss: 1.2069839993748097, validation loss: 1.2765217242033586.
epoch: 2813, train loss: 1.2079616435077212, validation loss: 1.2493693932243015.
epoch: 2814, train loss: 1.205772687535767, validation loss: 1.278737855994183.
epoch: 2815, train loss: 1.2150693978738347, validation loss: 1.2613733073939448.
epoch: 2816, train loss: 1.2027676236738853, validation loss: 1.2457721337028171.
epoch: 2817, train loss: 1.2005805455216574, validation loss: 1.247618369434191.
epoch: 2818, train loss: 1.2070564961214678, validation loss: 1.2761859893798828.
epoch: 2819, train loss: 1.2087322757878434, validation loss: 1.248158185378365.
epoch: 2820, train loss: 1.2138120504694248, validation loss: 1.2383250205413154.
epoch: 2821, train loss: 1.2045524743718838, validation loss: 1.2637853829757026.
epoch: 2822, train loss: 1.2021106798714454, validation loss: 1.253454037334608.
epoch: 2823, train loss: 1.215462137799744, validation loss: 1.2363064081772515.
epoch: 2824, train loss: 1.204155223085246, validation loss: 1.2660656856453938.
epoch: 2825, train loss: 1.2280481047586564, validation loss: 1.2514400326687356.
epoch: 2826, train loss: 1.2164084714487058, validation loss: 1.2495068622672039.
epoch: 2827, train loss: 1.2142738508521964, validation loss: 1.2586130266604216.
epoch: 2828, train loss: 1.216053320727217, validation loss: 1.245806968730429.
epoch: 2829, train loss: 1.211242955759031, validation loss: 1.2507911402246226.
epoch: 2830, train loss: 1.2084103057143885, validation loss: 1.252582047296607.
epoch: 2831, train loss: 1.203547542248297, validation loss: 1.266966083775396.
epoch: 2832, train loss: 1.2064423943878313, validation loss: 1.2679215410481328.
epoch: 2833, train loss: 1.2025763102627676, validation loss: 1.2522956029228542.
epoch: 2834, train loss: 1.2090761716212701, validation loss: 1.2533253379490064.
epoch: 2835, train loss: 1.268227520338986, validation loss: 1.2594404842542566.
epoch: 2836, train loss: 1.232768522490055, validation loss: 1.253172729326331.
epoch: 2837, train loss: 1.215659239970216, validation loss: 1.2882534939309824.
epoch: 2838, train loss: 1.2127109109808545, validation loss: 1.2518900425537773.
epoch: 2839, train loss: 1.2076076039480508, validation loss: 1.250942613767541.
epoch: 2840, train loss: 1.2118088510058342, validation loss: 1.267561648202979.
epoch: 2841, train loss: 1.2145290845031038, validation loss: 1.2480567071748816.
epoch: 2842, train loss: 1.2107152851349716, validation loss: 1.2482765239218008.
epoch: 2843, train loss: 1.2087742341767758, validation loss: 1.2728714580121248.
epoch: 2844, train loss: 1.208503505505553, validation loss: 1.240077635516291.
epoch: 2845, train loss: 1.2044238584850906, validation loss: 1.2459188129590906.
epoch: 2846, train loss: 1.2107659589259996, validation loss: 1.2565689812535825.
epoch: 2847, train loss: 1.2091189065110792, validation loss: 1.2694715676100359.
epoch: 2848, train loss: 1.215608286201407, validation loss: 1.248081948446191.
epoch: 2849, train loss: 1.2120423973153491, validation loss: 1.2718589513198189.
epoch: 2850, train loss: 1.2034369543058063, validation loss: 1.2682485476784084.
epoch: 2851, train loss: 1.207890822253096, validation loss: 1.2690132286237634.
epoch: 2852, train loss: 1.207719563344203, validation loss: 1.2504685702531233.
epoch: 2853, train loss: 1.2171463452347921, validation loss: 1.2506737760875537.
epoch: 2854, train loss: 1.2200822086509215, validation loss: 1.2486506856006125.
epoch: 2855, train loss: 1.2113018571783642, validation loss: 1.2386496015216992.
epoch: 2856, train loss: 1.2054246314075014, validation loss: 1.2387192145637844.
epoch: 2857, train loss: 1.209636187334673, validation loss: 1.250410644904427.
epoch: 2858, train loss: 1.2098916834647502, validation loss: 1.2380022536153379.
epoch: 2859, train loss: 1.2110633543871958, validation loss: 1.2547977592634119.
epoch: 2860, train loss: 1.2057343054255214, validation loss: 1.2429630652717922.
epoch: 2861, train loss: 1.2033706859711113, validation loss: 1.2677562962407651.
epoch: 2862, train loss: 1.2085421927478335, validation loss: 1.2510478755702144.
epoch: 2863, train loss: 1.2298340414642195, validation loss: 1.2406156166740085.
epoch: 2864, train loss: 1.2054640514041306, validation loss: 1.2672569077947866.
epoch: 2865, train loss: 1.20232058883807, validation loss: 1.254584939583488.
epoch: 2866, train loss: 1.2147088247701663, validation loss: 1.2473040041716204.
epoch: 2867, train loss: 1.2048325713621366, validation loss: 1.3192606438761172.
epoch: 2868, train loss: 1.2287643032336453, validation loss: 1.2525469893994539.
epoch: 2869, train loss: 1.2141579761417634, validation loss: 1.2475736244865085.
epoch: 2870, train loss: 1.2031785577809044, validation loss: 1.2547380509583845.
epoch: 2871, train loss: 1.207202725454208, validation loss: 1.243844695713209.
epoch: 2872, train loss: 1.2060297137006708, validation loss: 1.2618296820184458.
epoch: 2873, train loss: 1.2108408901669563, validation loss: 1.2488378234531567.
epoch: 2874, train loss: 1.2066299291925693, validation loss: 1.2424186364464138.
epoch: 2875, train loss: 1.210310518194776, validation loss: 1.2719267917715984.
epoch: 2876, train loss: 1.2020811968987142, validation loss: 1.2536587093187415.
epoch: 2877, train loss: 1.2060256507418572, validation loss: 1.2539592203886614.
epoch: 2878, train loss: 1.2055861381215787, validation loss: 1.2692004545875217.
epoch: 2879, train loss: 1.2031967355570663, validation loss: 1.248453959174778.
epoch: 2880, train loss: 1.205484918498118, validation loss: 1.2608078510864922.
epoch: 2881, train loss: 1.2020304148350287, validation loss: 1.2426405885945195.
epoch: 2882, train loss: 1.2196970445300461, validation loss: 1.2445197209067966.
epoch: 2883, train loss: 1.203159476638934, validation loss: 1.2600425740946894.
epoch: 2884, train loss: 1.2097747621186283, validation loss: 1.3085282885509988.
epoch: 2885, train loss: 1.205502167754217, validation loss: 1.2573982891829119.
epoch: 2886, train loss: 1.2187297825419574, validation loss: 1.2346802690754766.
epoch: 2887, train loss: 1.2056215104706791, validation loss: 1.2875748043474944.
epoch: 2888, train loss: 1.207218631691889, validation loss: 1.2527052319568137.
epoch: 2889, train loss: 1.2115083167312342, validation loss: 1.2747608786043914.
epoch: 2890, train loss: 1.204496990650072, validation loss: 1.2401053231695425.
epoch: 2891, train loss: 1.2048114899101607, validation loss: 1.2692647135776023.
epoch: 2892, train loss: 1.2073073321526204, validation loss: 1.259462620901025.
epoch: 2893, train loss: 1.2062315645567867, validation loss: 1.248187163601751.
epoch: 2894, train loss: 1.2037971993105128, validation loss: 1.2535425683726436.
epoch: 2895, train loss: 1.2050269481238969, validation loss: 1.2646908293599668.
epoch: 2896, train loss: 1.2087838999721983, validation loss: 1.2714943522992341.
epoch: 2897, train loss: 1.2250157638427315, validation loss: 1.276237280472465.
epoch: 2898, train loss: 1.2126158125903628, validation loss: 1.2364755506100862.
epoch: 2899, train loss: 1.2100347039896413, validation loss: 1.2683396598567134.
epoch: 2900, train loss: 1.212464796293766, validation loss: 1.254253853922305.
epoch: 2901, train loss: 1.2085097776640445, validation loss: 1.2822346428166265.
epoch: 2902, train loss: 1.2057504642994032, validation loss: 1.2458592134973276.
epoch: 2903, train loss: 1.212036720109642, validation loss: 1.2580844371215156.
epoch: 2904, train loss: 1.2083605899723298, validation loss: 1.2466465649397478.
epoch: 2905, train loss: 1.202409794571203, validation loss: 1.2617704971976902.
epoch: 2906, train loss: 1.2235395820862656, validation loss: 1.2748954140621682.
epoch: 2907, train loss: 1.2315642516547387, validation loss: 1.24521063203397.
epoch: 2908, train loss: 1.210600691104154, validation loss: 1.246146761852762.
epoch: 2909, train loss: 1.2093259336751536, validation loss: 1.240133575771166.
epoch: 2910, train loss: 1.2017942732627238, validation loss: 1.254530896311221.
epoch: 2911, train loss: 1.2051763239256832, validation loss: 1.2398614987083103.
epoch: 2912, train loss: 1.2094109189619713, validation loss: 1.2554577226224153.
epoch: 2913, train loss: 1.2079471918421054, validation loss: 1.2543204815491387.
epoch: 2914, train loss: 1.2010827611345765, validation loss: 1.2473682890767637.
epoch: 2915, train loss: 1.2105567116256153, validation loss: 1.2472338780112888.
epoch: 2916, train loss: 1.2082331803960538, validation loss: 1.2636050918827886.
epoch: 2917, train loss: 1.202592742552451, validation loss: 1.2541597926098367.
epoch: 2918, train loss: 1.1985346056999417, validation loss: 1.2630020587340645.
epoch: 2919, train loss: 1.2222838237744953, validation loss: 1.2550722464271213.
epoch: 2920, train loss: 1.2162283024656664, validation loss: 1.2467637943184895.
epoch: 2921, train loss: 1.205399535117893, validation loss: 1.2437072422193445.
epoch: 2922, train loss: 1.202988414589418, validation loss: 1.249008525972781.
epoch: 2923, train loss: 1.2008483683297393, validation loss: 1.2663180309793223.
epoch: 2924, train loss: 1.2055533347873513, validation loss: 1.2515035245729529.
epoch: 2925, train loss: 1.219440955634511, validation loss: 1.2781213003656138.
epoch: 2926, train loss: 1.2400851512173994, validation loss: 1.2591223250264707.
epoch: 2927, train loss: 1.2178712361449495, validation loss: 1.2485409871391628.
epoch: 2928, train loss: 1.2139148099706807, validation loss: 1.2423837236736133.
epoch: 2929, train loss: 1.210652644481134, validation loss: 1.2573516006055085.
epoch: 2930, train loss: 1.2136340939670527, validation loss: 1.2490196435347847.
epoch: 2931, train loss: 1.2050143130328677, validation loss: 1.2669749363608982.
epoch: 2932, train loss: 1.2047343636871477, validation loss: 1.2999988897987034.
epoch: 2933, train loss: 1.2071344239996114, validation loss: 1.2542596899944802.
epoch: 2934, train loss: 1.2063913465639866, validation loss: 1.2567317330318948.
epoch: 2935, train loss: 1.2079761673551086, validation loss: 1.2380279924558557.
epoch: 2936, train loss: 1.201622285974135, validation loss: 1.258997715037802.
epoch: 2937, train loss: 1.210379609274208, validation loss: 1.2414976617564326.
epoch: 2938, train loss: 1.20957186353316, validation loss: 1.2524619620779287.
epoch: 2939, train loss: 1.203678666998487, validation loss: 1.249180767847144.
epoch: 2940, train loss: 1.2084474268309566, validation loss: 1.2554938223050989.
epoch: 2941, train loss: 1.2263490049117203, validation loss: 1.2547241760336834.
epoch: 2942, train loss: 1.2119431134757646, validation loss: 1.2388261556625366.
epoch: 2943, train loss: 1.2020684513477011, validation loss: 1.2548092862834102.
epoch: 2944, train loss: 1.2100623364842267, validation loss: 1.2445694415465645.
epoch: 2945, train loss: 1.210213260913114, validation loss: 1.2544479110966558.
epoch: 2946, train loss: 1.2029888979885557, validation loss: 1.2522216827973076.
epoch: 2947, train loss: 1.2018182824511048, validation loss: 1.2515007257461548.
epoch: 2948, train loss: 1.2106412769457615, validation loss: 1.2493744000144626.
epoch: 2949, train loss: 1.2015223929641443, validation loss: 1.2777816834657088.
epoch: 2950, train loss: 1.2097107959449838, validation loss: 1.2789648615795632.
epoch: 2951, train loss: 1.2306540941973345, validation loss: 1.2446021463560022.
epoch: 2952, train loss: 1.2112778272103826, validation loss: 1.242536907610686.
epoch: 2953, train loss: 1.2121846807112389, validation loss: 1.2485912260801897.
epoch: 2954, train loss: 1.2044715837601128, validation loss: 1.3059184188428132.
epoch: 2955, train loss: 1.2059353732187814, validation loss: 1.2457737041556316.
epoch: 2956, train loss: 1.2056952310264657, validation loss: 1.2540717124938965.
epoch: 2957, train loss: 1.2041239836894044, validation loss: 1.2570022189098855.
epoch: 2958, train loss: 1.1997156875942825, validation loss: 1.2525162489517876.
epoch: 2959, train loss: 1.2265823696731428, validation loss: 1.2665497531061587.
epoch: 2960, train loss: 1.2156879267561327, validation loss: 1.2540785488875017.
epoch: 2961, train loss: 1.2111023478551741, validation loss: 1.3355963852094568.
epoch: 2962, train loss: 1.2079750354136896, validation loss: 1.2456536137539407.
epoch: 2963, train loss: 1.2045886844670006, validation loss: 1.2709425687789917.
epoch: 2964, train loss: 1.2089909041693452, validation loss: 1.2967237804246985.
epoch: 2965, train loss: 1.2244701079272349, validation loss: 1.2459247837895933.
epoch: 2966, train loss: 1.2125609774108326, validation loss: 1.2457937261332637.
epoch: 2967, train loss: 1.202785685521747, validation loss: 1.253166913986206.
epoch: 2968, train loss: 1.214019295272477, validation loss: 1.2561119276544321.
epoch: 2969, train loss: 1.2188199157014898, validation loss: 1.2512366149736487.
epoch: 2970, train loss: 1.21585640776048, validation loss: 1.250353165294813.
epoch: 2971, train loss: 1.2139163903140147, validation loss: 1.251912262128747.
epoch: 2972, train loss: 1.2160540906661148, validation loss: 1.3382643305737039.
epoch: 2973, train loss: 1.2610234864261172, validation loss: 1.2544500257657922.
epoch: 2974, train loss: 1.232790554335358, validation loss: 1.2616130528242693.
epoch: 2975, train loss: 1.2186464443119294, validation loss: 1.2679966066194617.
epoch: 2976, train loss: 1.214701464416784, validation loss: 1.2550653219223022.
epoch: 2977, train loss: 1.2147497146501454, validation loss: 1.2862736608671106.
epoch: 2978, train loss: 1.2224679835345766, validation loss: 1.2517738705096038.
epoch: 2979, train loss: 1.2160757309799894, validation loss: 1.2578814029693604.
epoch: 2980, train loss: 1.2088316175915779, validation loss: 1.248011614965356.
epoch: 2981, train loss: 1.208283760132046, validation loss: 1.2432124355564946.
epoch: 2982, train loss: 1.2110656193636973, validation loss: 1.2452803539193196.
epoch: 2983, train loss: 1.2028578935413186, validation loss: 1.247731239899345.
epoch: 2984, train loss: 1.2017569060719342, validation loss: 1.2632699168246726.
epoch: 2985, train loss: 1.2113247803591807, validation loss: 1.2569222450256348.
epoch: 2986, train loss: 1.2130981596238022, validation loss: 1.2459516680758933.
epoch: 2987, train loss: 1.208210233154647, validation loss: 1.3171494629072107.
epoch: 2988, train loss: 1.2146893641270629, validation loss: 1.2541037279626597.
epoch: 2989, train loss: 1.2130458868971659, validation loss: 1.2574334922044172.
epoch: 2990, train loss: 1.2163588694476206, validation loss: 1.260331444118334.
epoch: 2991, train loss: 1.2051926140391498, validation loss: 1.2671163030292676.
epoch: 2992, train loss: 1.2032377260540603, validation loss: 1.2899426377337913.
epoch: 2993, train loss: 1.2061512535865153, validation loss: 1.295261237932288.
epoch: 2994, train loss: 1.2043479593521957, validation loss: 1.2406350166901299.
epoch: 2995, train loss: 1.214562097820667, validation loss: 1.273334212925123.
epoch: 2996, train loss: 1.2136202886563923, validation loss: 1.24122605116471.
epoch: 2997, train loss: 1.2061489612684337, validation loss: 1.2433167799659397.
epoch: 2998, train loss: 1.2088656020820687, validation loss: 1.2402829139128975.
epoch: 2999, train loss: 1.209808661303389, validation loss: 1.270743701768958.
epoch: 3000, train loss: 1.2061706562654688, validation loss: 1.2459071045336516.
best validation loss 0.48860461038091907 at epoch 306.
