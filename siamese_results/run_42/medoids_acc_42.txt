how to merge clusters:  [[0, 9], [1, 5], 2, [3, 8], 4, 6, 7]
computing evaluation metrics for train
embedding path:  ../embeddings/run_42/train_embedding.npy
label path:  ../embeddings/run_42/train_label.npy
{} report:  train
              precision    recall  f1-score   support

           0       0.95      0.69      0.80      4597
           1       0.47      0.34      0.40      1699
           2       0.85      0.86      0.85       810
           3       0.61      0.55      0.58      1373
           4       0.87      0.90      0.88       737
           5       0.84      0.95      0.90       677
           6       0.69      0.90      0.78       634
           7       0.67      0.85      0.75       503
           8       0.23      0.54      0.32       500
           9       0.51      0.89      0.65       476
          10       0.48      0.87      0.62       466

    accuracy                           0.69     12472
   macro avg       0.65      0.76      0.68     12472
weighted avg       0.74      0.69      0.70     12472

top-3 train acc: 0.9001763951250802
----------------------------------------------------------
computing evaluation metrics for val
embedding path:  ../embeddings/run_42/val_embedding.npy
label path:  ../embeddings/run_42/val_label.npy
{} report:  val
              precision    recall  f1-score   support

           0       0.95      0.69      0.80       985
           1       0.49      0.33      0.39       364
           2       0.80      0.87      0.83       173
           3       0.60      0.57      0.58       294
           4       0.85      0.90      0.87       158
           5       0.84      0.95      0.89       145
           6       0.71      0.85      0.78       135
           7       0.61      0.75      0.67       107
           8       0.26      0.64      0.37       107
           9       0.53      0.92      0.68       102
          10       0.45      0.81      0.58        98

    accuracy                           0.69      2668
   macro avg       0.65      0.75      0.68      2668
weighted avg       0.74      0.69      0.70      2668

top-3 val acc: 0.9029235382308846
----------------------------------------------------------
computing evaluation metrics for test
embedding path:  ../embeddings/run_42/test_embedding.npy
label path:  ../embeddings/run_42/test_label.npy
{} report:  test
              precision    recall  f1-score   support

           0       0.96      0.68      0.79       986
           1       0.47      0.35      0.40       365
           2       0.86      0.81      0.83       175
           3       0.60      0.53      0.56       295
           4       0.85      0.91      0.88       159
           5       0.84      0.95      0.89       146
           6       0.71      0.88      0.79       137
           7       0.66      0.82      0.73       109
           8       0.20      0.51      0.29       108
           9       0.49      0.89      0.64       103
          10       0.43      0.84      0.57       101

    accuracy                           0.68      2684
   macro avg       0.64      0.74      0.67      2684
weighted avg       0.74      0.68      0.69      2684

top-3 test acc: 0.8915797317436661
----------------------------------------------------------
