how to merge clusters:  [[0, 9], [1, 5], 2, [3, 8], 4, 6, 7]
computing evaluation metrics for train
embedding path:  ../embeddings/run_37/train_embedding.npy
label path:  ../embeddings/run_37/train_label.npy
{} report:  train
              precision    recall  f1-score   support

           0       0.95      0.69      0.80      4597
           1       0.36      0.43      0.39      1699
           2       0.41      0.55      0.47       810
           3       0.50      0.57      0.53      1373
           4       0.49      0.51      0.50       737
           5       0.44      0.43      0.43       677
           6       0.31      0.51      0.38       631

    accuracy                           0.58     10524
   macro avg       0.49      0.53      0.50     10524
weighted avg       0.65      0.58      0.60     10524

top-3 train acc: 0.8658304827061953
----------------------------------------------------------
computing evaluation metrics for val
embedding path:  ../embeddings/run_37/val_embedding.npy
label path:  ../embeddings/run_37/val_label.npy
{} report:  val
              precision    recall  f1-score   support

           0       0.95      0.68      0.79       985
           1       0.31      0.37      0.34       364
           2       0.41      0.55      0.47       173
           3       0.50      0.55      0.52       294
           4       0.50      0.53      0.52       158
           5       0.38      0.30      0.34       145
           6       0.27      0.56      0.37       133

    accuracy                           0.56      2252
   macro avg       0.47      0.51      0.48      2252
weighted avg       0.64      0.56      0.58      2252

top-3 val acc: 0.8503552397868561
----------------------------------------------------------
computing evaluation metrics for test
embedding path:  ../embeddings/run_37/test_embedding.npy
label path:  ../embeddings/run_37/test_label.npy
{} report:  test
              precision    recall  f1-score   support

           0       0.95      0.68      0.79       986
           1       0.36      0.43      0.39       365
           2       0.40      0.53      0.45       175
           3       0.47      0.56      0.51       295
           4       0.49      0.53      0.51       159
           5       0.42      0.44      0.43       146
           6       0.29      0.48      0.36       134

    accuracy                           0.57      2260
   macro avg       0.48      0.52      0.49      2260
weighted avg       0.65      0.57      0.60      2260

top-3 test acc: 0.8707964601769912
----------------------------------------------------------
