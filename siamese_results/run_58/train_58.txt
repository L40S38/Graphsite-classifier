seed:  666
use pre-trained model: True. model path:../trained_models/trained_model_57.pt.
number of classes: 19
max number of 1000 pockets sampled from each merged class.
how to merge clusters:  [[0, 9, 12], [1, 5, 11], 2, [3, 8, 13], 4, 6, 7, [10, 16], 15, 17, 18]
whether to further subcluster data according to chemical reaction: False
number of epochs to train: 80
learning rate decay to half at epoch 40.
begin to select hard pairs at epoch 1
batch size: 128
number of hardest positive pairs for each mini-batch:  192
number of hardest negative pairs for each mini-batch:  256
number of workers to load data:  36
similar margin of contrastive loss: 0.0
dissimilar margin of contrastive loss: 2.0
device:  cuda
number of classes after merging:  11
number of pockets in training set:  14097
number of pockets in validation set:  3016
number of pockets in test set:  3031
first 5 pockets in train set of cluster 0 before merging (to verify reproducibility):
['6brxA00', '4c0lA00', '3rs8A02', '4nk4F00', '5fogD00']
first 5 pockets in val set of cluster 0 before merging (to verify reproducibility):
['4d86A00', '4u00A00', '1pujA00', '3nt5A00', '4j1nB01']
first 5 pockets in test set of cluster 0 before merging (to verify reproducibility):
['4k28A00', '6hwlB00', '3upqA01', '2p2bA00', '1h5rB02']
model architecture:
SelectiveSiameseNet(
  (embedding_net): ResidualEmbeddingNet(
    (conv1): GINMolecularConv(nn=Sequential(
      (0): Linear(in_features=8, out_features=48, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=48, out_features=48, bias=True)
    ))(edge_transformer=Sequential(
      (0): Linear(in_features=1, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=8, bias=True)
      (3): ELU(alpha=1.0)
    ))
    (rb_2): ResidualBlock(
      (bn1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=48, out_features=48, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=48, out_features=48, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=48, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (rb_3): ResidualBlock(
      (bn1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=48, out_features=48, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=48, out_features=48, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=48, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (rb_4): ResidualBlock(
      (bn1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=48, out_features=48, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=48, out_features=48, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=48, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (rb_5): ResidualBlock(
      (bn1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=48, out_features=48, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=48, out_features=48, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=48, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (rb_6): ResidualBlock(
      (bn1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=48, out_features=48, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=48, out_features=48, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=48, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (rb_7): ResidualBlock(
      (bn1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=48, out_features=48, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=48, out_features=48, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=48, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (rb_8): ResidualBlock(
      (bn1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): GINMolecularConv(nn=Sequential(
        (0): Linear(in_features=48, out_features=48, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=48, out_features=48, bias=True)
      ))(edge_transformer=Sequential(
        (0): Linear(in_features=1, out_features=8, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=8, out_features=48, bias=True)
        (3): ELU(alpha=1.0)
      ))
    )
    (bn_8): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (set2set): Set2Set(48, 96)
  )
)
optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.003
    weight_decay: 0.0005
)
loss function:
SelectiveContrastiveLoss(similar_margin=0.0, dissimilar_margin=2.0, num_pos_pair=192, num_neg_pair=256)
epoch: 1, train loss: 1.8636197376041055, train acc: 0.7854190154077415, validation acc: 0.6402519893899205.
epoch: 2, train loss: 1.5450197337178078, train acc: 0.8029562820994613, validation acc: 0.6654509283819628.
epoch: 3, train loss: 1.4590119664726378, train acc: 0.8231241387949393, validation acc: 0.6793766578249337.
epoch: 4, train loss: 1.3989444737139065, train acc: 0.8316422397594889, validation acc: 0.6926392572944297.
epoch: 5, train loss: 1.3495260101730466, train acc: 0.839659275961418, validation acc: 0.6942970822281167.
epoch: 6, train loss: 1.3334562494586797, train acc: 0.840536139296004, validation acc: 0.7005968169761273.
epoch: 7, train loss: 1.3110283492422827, train acc: 0.8360265564324189, validation acc: 0.6956233421750663.
epoch: 8, train loss: 1.299684849625412, train acc: 0.8437930602530377, validation acc: 0.6939655172413793.
epoch: 9, train loss: 1.28871984460804, train acc: 0.8556933483652762, validation acc: 0.6956233421750663.
epoch: 10, train loss: 1.2796056579266655, train acc: 0.8374044845296255, validation acc: 0.6807029177718833.
epoch: 11, train loss: 1.2703577317744885, train acc: 0.8232494049855944, validation acc: 0.6959549071618037.
epoch: 12, train loss: 1.2700687012308756, train acc: 0.84579731930352, validation acc: 0.6889920424403183.
epoch: 13, train loss: 1.2657077419932428, train acc: 0.844920455968934, validation acc: 0.6986074270557029.
epoch: 14, train loss: 1.2638027643193102, train acc: 0.8459225854941751, validation acc: 0.7012599469496021.
epoch: 15, train loss: 1.261840839841667, train acc: 0.8525616935988977, validation acc: 0.7042440318302388.
epoch: 16, train loss: 1.2528354456767055, train acc: 0.8331454340473506, validation acc: 0.6946286472148541.
epoch: 17, train loss: 1.252015882511656, train acc: 0.8444193912063134, validation acc: 0.6929708222811671.
epoch: 18, train loss: 1.2532721388110022, train acc: 0.8454215207315545, validation acc: 0.7015915119363395.
epoch: 19, train loss: 1.2516294534539678, train acc: 0.857321808843793, validation acc: 0.7098806366047745.
epoch: 20, train loss: 1.2499797619130217, train acc: 0.8495553050231742, validation acc: 0.696949602122016.
epoch: 21, train loss: 1.2439901224844394, train acc: 0.8177376925967681, validation acc: 0.6876657824933687.
epoch: 22, train loss: 1.243806124411231, train acc: 0.8442941250156583, validation acc: 0.6929708222811671.
epoch: 23, train loss: 1.2443841275361038, train acc: 0.8498058374044846, validation acc: 0.7075596816976127.
epoch: 24, train loss: 1.2436393761925468, train acc: 0.8432919954904171, validation acc: 0.7025862068965517.
epoch: 25, train loss: 1.2438511202316034, train acc: 0.8471752474007266, validation acc: 0.7095490716180372.
epoch: 26, train loss: 1.2462023994350324, train acc: 0.8434172616810722, validation acc: 0.7175066312997348.
epoch: 27, train loss: 1.2370666614567596, train acc: 0.842289865965176, validation acc: 0.6939655172413793.
epoch: 28, train loss: 1.241659575716643, train acc: 0.8380308154829011, validation acc: 0.6972811671087533.
epoch: 29, train loss: 1.240927749821995, train acc: 0.8345233621445571, validation acc: 0.6800397877984085.
epoch: 30, train loss: 1.2351961991990985, train acc: 0.8541901540774145, validation acc: 0.6883289124668435.
epoch: 31, train loss: 1.237455792627899, train acc: 0.8475510459726919, validation acc: 0.7198275862068966.
epoch: 32, train loss: 1.2402842876160491, train acc: 0.8306401102342478, validation acc: 0.7022546419098143.
epoch: 33, train loss: 1.2379387293982593, train acc: 0.8501816359764499, validation acc: 0.7019230769230769.
epoch: 34, train loss: 1.2402301778704878, train acc: 0.8411624702492797, validation acc: 0.7128647214854111.
epoch: 35, train loss: 1.2383673244696312, train acc: 0.844920455968934, validation acc: 0.7062334217506632.
epoch: 36, train loss: 1.2421419689370043, train acc: 0.8231241387949393, validation acc: 0.6909814323607427.
epoch: 37, train loss: 1.2379300271267362, train acc: 0.832519103094075, validation acc: 0.6763925729442971.
epoch: 38, train loss: 1.2362402314242407, train acc: 0.8376550169109357, validation acc: 0.7092175066312998.
epoch: 39, train loss: 1.2348513987792085, train acc: 0.8436677940623826, validation acc: 0.7138594164456233.
epoch: 40, train loss: 1.214011418509419, train acc: 0.8597018664662408, validation acc: 0.7208222811671088.
epoch: 41, train loss: 1.2091620564715004, train acc: 0.8622071902793436, validation acc: 0.718501326259947.
epoch: 42, train loss: 1.2059325607699067, train acc: 0.8714768883878241, validation acc: 0.7131962864721485.
epoch: 43, train loss: 1.2073327391303352, train acc: 0.8703494926719278, validation acc: 0.7178381962864722.
epoch: 44, train loss: 1.205221270952033, train acc: 0.874859075535513, validation acc: 0.708554376657825.
epoch: 45, train loss: 1.1984342517603386, train acc: 0.8712263560065139, validation acc: 0.7141909814323607.
epoch: 46, train loss: 1.2034986772771572, train acc: 0.8804960541149943, validation acc: 0.7320954907161804.
epoch: 47, train loss: 1.2011322267760114, train acc: 0.8629587874232745, validation acc: 0.7032493368700266.
epoch: 48, train loss: 1.2015658374704377, train acc: 0.8764875360140298, validation acc: 0.71684350132626.
epoch: 49, train loss: 1.1983329226443413, train acc: 0.8723537517224101, validation acc: 0.718501326259947.
epoch: 50, train loss: 1.196842574612235, train acc: 0.8700989602906175, validation acc: 0.7178381962864722.
epoch: 51, train loss: 1.198806384315507, train acc: 0.8515595640736565, validation acc: 0.7105437665782494.
epoch: 52, train loss: 1.1938149019744237, train acc: 0.8840035074533383, validation acc: 0.7337533156498673.
epoch: 53, train loss: 1.1957983962846757, train acc: 0.8772391331579606, validation acc: 0.7122015915119363.
epoch: 54, train loss: 1.1947619417632378, train acc: 0.8772391331579606, validation acc: 0.7264588859416445.
epoch: 55, train loss: 1.1941790725492147, train acc: 0.8759864712514093, validation acc: 0.728448275862069.
epoch: 56, train loss: 1.1989005846688088, train acc: 0.8640861831391707, validation acc: 0.7224801061007957.
epoch: 57, train loss: 1.1954084607446107, train acc: 0.8749843417261681, validation acc: 0.7108753315649867.
epoch: 58, train loss: 1.194881731437224, train acc: 0.8817487160215458, validation acc: 0.7257957559681698.
epoch: 59, train loss: 1.1928708160610826, train acc: 0.856444945509207, validation acc: 0.7055702917771883.
epoch: 60, train loss: 1.193564080361408, train acc: 0.8798697231617186, validation acc: 0.7211538461538461.
epoch: 61, train loss: 1.1900772812295892, train acc: 0.872228485531755, validation acc: 0.7211538461538461.
epoch: 62, train loss: 1.1829036389514085, train acc: 0.8850056369785795, validation acc: 0.7228116710875332.
epoch: 63, train loss: 1.1910095475001414, train acc: 0.8767380683953401, validation acc: 0.7231432360742706.
epoch: 64, train loss: 1.1905703380692803, train acc: 0.8778654641112363, validation acc: 0.721816976127321.
epoch: 65, train loss: 1.1879103565032965, train acc: 0.8729800826756858, validation acc: 0.7039124668435013.
epoch: 66, train loss: 1.1941539451937626, train acc: 0.8789928598271327, validation acc: 0.7347480106100795.
epoch: 67, train loss: 1.1871083201730703, train acc: 0.8786170612551673, validation acc: 0.7238063660477454.
epoch: 68, train loss: 1.1843577004862123, train acc: 0.8759864712514093, validation acc: 0.7005968169761273.
epoch: 69, train loss: 1.1847563471790739, train acc: 0.8851309031692346, validation acc: 0.7181697612732095.
epoch: 70, train loss: 1.1837051469172994, train acc: 0.8771138669673055, validation acc: 0.7271220159151194.
epoch: 71, train loss: 1.1905530437112333, train acc: 0.8762370036327195, validation acc: 0.7128647214854111.
epoch: 72, train loss: 1.1867632194005788, train acc: 0.8853814355505449, validation acc: 0.7204907161803713.
epoch: 73, train loss: 1.1828250401475695, train acc: 0.866090442189653, validation acc: 0.7175066312997348.
epoch: 74, train loss: 1.1810228503893894, train acc: 0.8825003131654766, validation acc: 0.7297745358090185.
epoch: 75, train loss: 1.185573287570281, train acc: 0.8847551045972692, validation acc: 0.7281167108753316.
epoch: 76, train loss: 1.1842439086085246, train acc: 0.8792433922084429, validation acc: 0.7214854111405835.
epoch: 77, train loss: 1.1823996116856816, train acc: 0.8882625579356132, validation acc: 0.71684350132626.
epoch: 78, train loss: 1.18297284391771, train acc: 0.8771138669673055, validation acc: 0.7141909814323607.
epoch: 79, train loss: 1.177976654545915, train acc: 0.8936490041337843, validation acc: 0.7257957559681698.
epoch: 80, train loss: 1.176014112389606, train acc: 0.8781159964925467, validation acc: 0.718501326259947.
best validation acc 0.7347480106100795 at epoch 66.
